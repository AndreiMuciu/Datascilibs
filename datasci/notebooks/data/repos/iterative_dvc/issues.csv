repo_full_name,issue_id,number,title,body,user_login,user_id,state,locked,comments_count,created_at,updated_at,closed_at,labels,reactions_total,reactions_plus1,reactions_minus1,reactions_laugh,reactions_hooray,reactions_confused,reactions_heart
iterative/dvc,3057444492,10744,exp run --run-all: checks on templated input data can't pass since folder is not copied in tmp/exps,"# Bug Report

## Description

Hi, first of all, thanks to all your team for the amazing tool you've provided to the community !

While working on multiple versions of one dataset, I've tried to get metrics for both versions and I've stumbled upon an issue specific to my setup : when I execute  `dvc repro` on each value of my templated `dataset_dirpath`, all my checks pass since it execution space is my workspace ; however, when I use `dvc exp run --queue`, since my workspace is copied in `tmp/exps` WITHOUT the gitignored files (including data tracked with `dvc`), the pipeline breaks.

### Reproduce

I've created a minimal repository to reproduce the issue :

```bash
git clone https://github.com/Gwenn-LR/dvc_exp_run_with_templated_input_dataset.git
cd dvc_exp_run_with_templated_input_dataset

dvc init

mkdir data/dataset_1 data/dataset_2
dvc get https://github.com/iterative/dataset-registry get-started/data.xml -o data/dataset_1/data.xml
cp data/dataset_1 data/dataset_2

dvc add data/dataset_1 data/dataset_2

dvc repro pipelines/default/dvc.yaml
# Works.

dvc exp run --queue -S ""pipelines/default/params.yaml:dataset_dirpath=dataset_1, dataset_2"" pipelines/default/dvc.yaml
dvc exp run --run-all
# Does not work !
```

### Expected

After what I've found on multiple discussions on this repository, I know that those gitignored files are not copied since it could interfere with the Git status of the associated experiment. However, I think that this behavior should not be ignored and integrated or clearly mentioned in the docs.

I know that the linked repository is not the simplest one, but its structure is meant to reproduce a more complex one which I am working on. So my structure might be improved and I also think that composition with `hydra` might be a solution, but I would like a quick solution focusing on the specific point of my issue.

It could ""only"" be an environment variable that might help me introduce a different behavior between an execution with `dvc repro` and another with `dvc exp run --queue` or even an answer like ""It is not possible as it is"". I'll be really glad to discuss all those improvements after a clear answer to this specific issue !

Thank you for your consideration.

### Environment information

**Output of `dvc doctor`:**

```console
$ dvc doctor
DVC version: 3.59.1 (pip)
-------------------------
Platform: Python 3.10.16 on Linux-6.11.0-25-generic-x86_64-with-glibc2.39
Subprojects:
        dvc_data = 3.16.10
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.11
Supports:
        http (aiohttp = 3.11.18, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.18, aiohttp-retry = 2.9.1)
Config:
        Global: /home/leroch/.config/dvc
        System: /etc/xdg/xdg-ubuntu/dvc
Cache types: hardlink, symlink
Cache directory: ext4 on /dev/mapper/ubuntu--vg-ubuntu--lv
Caches: local
Remotes: None
Workspace directory: ext4 on /dev/mapper/ubuntu--vg-ubuntu--lv
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/30f0eb604189e8e37e4eb38ec5c8d890
```

**Additional Information (if any):**

<!--
Please check https://github.com/iterative/dvc/wiki/Debugging-DVC on ways to gather more information regarding the issue.

If applicable, please also provide a `--verbose` output of the command, eg: `dvc add --verbose`.
If the issue is regarding the performance, please attach the profiling information and the benchmark comparisons.
-->
",Gwenn-LR,95341944,open,False,0,2025-05-12T15:58:36+00:00,2025-05-12T15:58:36+00:00,,,0,0,0,0,0,0,0
iterative/dvc,3053248985,10743,"add: can't set the cache type to ""copy"" if the filesystem supports reflinks","# Bug Report

## Description

When the underlying filesystem (for instance ZFS 2.3) supports reflinks, DVC will always use them, even if you set the cache type to ""copy"".

### Reproduce

1. Set the DVC cache type to ""copy""
2. Do a dvc add
3. Observe that the reflink() function in dvc_objects/fs/local.py is called

### Expected

DVC should use the copy strategy

### Environment information

<!--
This is required to ensure that we can reproduce the bug.
-->

**Output of `dvc doctor`:**

```console
$ dvc doctor
DVC version: 3.59.2 (pip)
-------------------------
Platform: Python 3.11.6 on Linux-6.8.0-59-generic-x86_64-with-glibc2.35
Subprojects:
        dvc_data = 3.16.10
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.11
Supports:
        http (aiohttp = 3.11.18, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.18, aiohttp-retry = 2.9.1),
        s3 (s3fs = 2025.3.0, boto3 = 1.37.3)
Config:
        Global: /home/mermerico/.config/dvc
        System: /etc/xdg/dvc
Cache types: reflink
Cache directory: zfs on tank
Caches: local
Remotes: s3
Workspace directory: zfs on tank
Repo: dvc, git
Repo.site_cache_dir: /home/mermerico/dvc_site_cache/repo/54ea0ca1cd8a6432245cbe79e3f79d2f
```

**Additional Information (if any):**

There's some bug in the reflink strategy where I get ""resource not available"" errors (using ZFS 2.3.2) I'd like to collect more information about that bug and submit a report but I'm using a cache that's shared with others on this machine. I need to enable reflinks on the FS level and then have all the other users use the ""copy"" strategy so they aren't blocked while I'm debugging.",mermerico,3631507,open,False,2,2025-05-09T21:39:07+00:00,2025-05-10T15:48:47+00:00,,,0,0,0,0,0,0,0
iterative/dvc,3053001378,10742,Add .toml support,"Right now DVC uses files such as params.yaml. Meanwhile .toml files are becoming an integral part of the python ecosystem through pyproject.toml being the standard project information file and even the tomllib library becoming part of the standard library.

It would be amazing to support the equivalent versions of the .yaml files but in .toml.",jrr96,92081722,open,False,2,2025-05-09T19:18:43+00:00,2025-05-10T13:29:58+00:00,,,0,0,0,0,0,0,0
iterative/dvc,3052314563,10741,`dvc exp show` remove workspace row,"I am using the `dvc` tool to track experiments in my repo. When I run `dvc exp show` I see a table with multiple rows, each corresponding to an experimental commit based off the HEAD commit. However, I also see a ""workspace"" row which includes information from HEAD itself. Since this does not correspond to an experiment, I'm wondering if there is a way to use `dvc exp show` but exclude this workspace row? The options in the `dvc` documentation seem to only exclude based on columns.",timgianitsos,14189758,open,False,0,2025-05-09T14:15:34+00:00,2025-05-09T14:15:34+00:00,,,0,0,0,0,0,0,0
iterative/dvc,3045214268,10740,drop inputs passed to codecov-action,"It can already search and find these coverage files, there's no need to specify them explicitly. On `v5`, they also deprecated the `file` option and renamed to `files`, which adds noisy warnings in CI.",skshetry,18718008,closed,False,1,2025-05-07T08:49:19+00:00,2025-05-07T08:58:05+00:00,2025-05-07T08:49:28+00:00,,0,0,0,0,0,0,0
iterative/dvc,3044906794,10739,tests: fix flaky test in test_get_used_objs,"Clear logs before assertions so that logs from other tests do not interfere with the test. Some destructors may also run in between due to GC, so hopefully this will fix that issue too, or reduce the chances of it happening.

See
https://github.com/iterative/dvc/actions/runs/14873217814/job/41775314725#step:6:97.

```console
>       assert first(caplog.messages) == expected_message
E       assert 'RC: discarding all clients' == ""Output 'path... 'stage.dvc'.""
E
E         + RC: discarding all clients
E         - Output 'path'(stage: 'stage.dvc') is missing version info. Cache for it will not be collected. Use `dvc repro` to get your pipeline up to date.
E         - You can also use `dvc commit stage.dvc` to associate existing 'path' with stage: 'stage.dvc'.
```

* [x] ‚ùó I have followed the [Contributing to DVC](https://dvc.org/doc/user-guide/contributing/core) checklist.

* [x] üìñ If this PR requires [documentation](https://dvc.org/doc) updates, I have created a separate PR (or issue, at least) in [dvc.org](https://github.com/iterative/dvc.org) and linked it here.

Thank you for the contribution - we'll try to review it as soon as possible. üôè
",skshetry,18718008,closed,False,0,2025-05-07T06:55:34+00:00,2025-05-07T07:01:49+00:00,2025-05-07T06:55:51+00:00,,0,0,0,0,0,0,0
iterative/dvc,3042316871,10738,"dvc push: webdav redirect error, missing trailing slash. Link after redirect is not allowed.","# Bug Report

<!--
## Issue name

-->

## Description

Hey there. I am facing an issue with DVC I can't figure out myself: whenever I try to push to our remote (webdav server) I hit this 301 moved permanently because a trailing forward slash is absent from the path the underlying library seems to query to. Then after the redirect I'm hitting a 405 method not allowed, but I'm pretty sure the server is configured for me to use webdav on those directories. 

I have also tried http as method instead of webdav. Not quite sure what the difference between the two methods is. With http DVC does try to upload the files, but the credentials I set do not get added to the requests, and so they are denied.

### Reproduce

reproduce:
1. dvc remote add nas ""webdav://your-url/BlobStoreData/test/""
2. set credentials to config.local using dvc remote modify --local
3. dvc push 


output:
```bash
2025-05-06 09:55:17,044 DEBUG: v3.59.1 (pip), CPython 3.12.9 on Linux-6.8.0-57-generic-x86_64-with-glibc2.36
2025-05-06 09:55:17,044 DEBUG: command: /home/apr/.conda/envs/dvc-env/bin/dvc push -vv
2025-05-06 09:55:17,044 TRACE: Namespace(quiet=0, verbose=2, cprofile=False, cprofile_dump=None, yappi=False, yappi_separate_threads=False, viztracer=False, viztracer_depth=None, viztracer_async=False, pdb=False, instrument=False, instrument_open=False, show_stack=False, cd='.', cmd='push', jobs=None, targets=[], remote=None, all_branches=False, all_tags=False, all_commits=False, with_deps=False, recursive=False, run_cache=False, glob=False, func=<class 'dvc.commands.data_sync.CmdDataPush'>, parser=DvcParser(prog='dvc', usage=None, description='Data Version Control', formatter_class=<class 'dvc.cli.formatter.RawTextHelpFormatter'>, conflict_handler='error', add_help=False))
2025-05-06 09:55:50,519 TRACE:     9.53 ms in collecting stages from /workspace/dvc-test/example-versioning
2025-05-06 09:55:50,559 DEBUG: Preparing to transfer data from '/workspace/dvc-test/example-versioning/.dvc/cache/files/md5' to 'http://192.168.87.77/BlobStoreData/test/files/md5'
2025-05-06 09:55:50,559 DEBUG: Preparing to collect status from 'files/md5'
2025-05-06 09:55:50,560 DEBUG: Collecting status from 'files/md5'
2025-05-06 09:55:50,560 DEBUG: Querying 1 oids via object_exists
2025-05-06 09:55:50,871 DEBUG: Estimated remote size: 256 files
2025-05-06 09:55:50,871 DEBUG: Querying 1801 oids via traverse
2025-05-06 09:55:51,365 DEBUG: Preparing to collect status from '/workspace/dvc-test/example-versioning/.dvc/cache/files/md5'
2025-05-06 09:55:51,366 DEBUG: Collecting status from '/workspace/dvc-test/example-versioning/.dvc/cache/files/md5'
2025-05-06 09:55:51,398 DEBUG: transfer dir: md5: b8f4d5a78e55e88906d5f4aeaf43802e.dir with 1800 files
2025-05-06 09:55:51,715 ERROR: unexpected error - received 301 (Moved Permanently): Redirect response '301 Moved Permanently' for url 'http://192.168.87.77/BlobStoreData/test/files'
Redirect location: 'http://192.168.87.77/BlobStoreData/test/files/'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/301
Traceback (most recent call last):
  File ""/home/apr/.conda/envs/dvc-env/lib/python3.12/site-packages/webdav4/client.py"", line 365, in _request
    http_resp.raise_for_status()
  File ""/home/apr/.conda/envs/dvc-env/lib/python3.12/site-packages/httpx/_models.py"", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '405 Method Not Allowed' for url 'http://192.168.87.77/BlobStoreData/test/files/'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/405

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/apr/.conda/envs/dvc-env/lib/python3.12/site-packages/webdav4/client.py"", line 453, in mkdir
    http_resp = self.with_retry(call)
                ^^^^^^^^^^^^^^^^^^^^^
  File ""/home/apr/.conda/envs/dvc-env/lib/python3.12/site-packages/webdav4/func_utils.py"", line 47, in wrapped_function
    return func()
           ^^^^^^
  File ""/home/apr/.conda/envs/dvc-env/lib/python3.12/site-packages/webdav4/func_utils.py"", line 70, in wrapped
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File ""/home/apr/.conda/envs/dvc-env/lib/python3.12/site-packages/webdav4/client.py"", line 376, in request
    http_resp = self._request(method, path, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/apr/.conda/envs/dvc-env/lib/python3.12/site-packages/webdav4/client.py"", line 367, in _request
    raise HTTPError(http_resp) from exc
webdav4.client.HTTPError: received 405 (Method Not Allowed)
```

### Expected
I expected dvc to synch my local cache to the remote. 

### Environment information
```
DVC version: 3.59.1 (pip)
-------------------------
Platform: Python 3.12.9 on Linux-6.8.0-57-generic-x86_64-with-glibc2.36
Subprojects:
        dvc_data = 3.16.10
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.11
Supports:
        http (aiohttp = 3.11.18, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.18, aiohttp-retry = 2.9.1),
        webdav (webdav4 = 0.10.0),
        webdavs (webdav4 = 0.10.0)
Config:
        Global: /home/apr/.config/dvc
        System: /etc/xdg/dvc
Cache types: hardlink, symlink
Cache directory: ext4 on /dev/nvme0n1p2
Caches: local
Remotes: webdav
Workspace directory: ext4 on /dev/nvme0n1p2
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/2a5bcb24ccfea51add80147566f5eab9
```
**Additional Information (if any):**

<!--
Please check https://github.com/iterative/dvc/wiki/Debugging-DVC on ways to gather more information regarding the issue.

If applicable, please also provide a `--verbose` output of the command, eg: `dvc add --verbose`.
If the issue is regarding the performance, please attach the profiling information and the benchmark comparisons.
-->
",JHeuverRiwo,131459607,open,False,0,2025-05-06T10:18:56+00:00,2025-05-06T21:36:18+00:00,,,0,0,0,0,0,0,0
iterative/dvc,3042056031,10737,Unable to get artifact from git submodule,"# Bug Report

<!--
Issue names must follow the pattern `command: description` where the command is the dvc command that you are trying to run. The description should describe the consequences of the bug.

Example: `repro: doesn't detect input changes`
-->

## Description

<!--
A clear and concise description of what the bug is.
-->
I am trying to have a global model registry, but instead of having a monorepo with multiple models, I want to have them in a git submodule.

When i use `dvc artifacts get . <GIT_SUBMODULE_PATH>:<ARTIFACT_NAME>` i get `DVC remote: directory '<GIT_SUBMODULE_PATH>' does not exist`

Everything works if I remove the `<GIT_SUBMODULE_PATH>` in the commands and do register and get directly in the submodule folder. But it creates a model registry only in the submodule.

### Reproduce

<!--
Step list of how to reproduce the bug
-->
1. Create a git repo with a submodule inside.
2. Init DVC in the repo root and in the submodule
3. Add the DVC pipeline with an artifact in the submodule
4. Register the artifact in the model registry from the repo root using:
 `gto register <GIT_SUBMODULE_PATH>:<ARTIFACT_NAME> --version v0.0.1`
5. Try to get the artifact from the repo root with DVC using:
 `dvc artifacts get . <GIT_SUBMODULE_PATH>:<ARTIFACT_NAME> --rev v0.0.1`


### Expected
The artifact is registered successfully in the repo, and the tag is created. When running the get command, the artifact is gathered from DVC.

<!--
A clear and concise description of what you expect to happen.
-->

### Environment information
Python 3.10
<!--
This is required to ensure that we can reproduce the bug.
-->

**Output of `dvc doctor`:**
```console
$ dvc doctor
DVC version: 3.59.1 (pip)
-------------------------
Platform: Python 3.10.12 on Linux-6.8.0-58-generic-x86_64-with-glibc2.35
Subprojects:
        dvc_data = 3.16.9
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.10
Supports:
        http (aiohttp = 3.11.4, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.4, aiohttp-retry = 2.9.1),
        ssh (sshfs = 2024.9.0)
Config:
        Global: /home/<USER>/.config/dvc
        System: /etc/xdg/dvc
Cache types: <https://error.dvc.org/no-dvc-cache>
Caches: local
Remotes: None
Workspace directory: btrfs on /dev/loop30
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/86493e7a4d5134bc7fb89474a308f91e
```

**Additional Information (if any):**
```
Traceback (most recent call last):
  File ""/home/<USER>/.local/lib/python3.10/site-packages/dvc/repo/artifacts.py"", line 368, in get
    return repo.artifacts.download(
  File ""/home/<USER>/.local/lib/python3.10/site-packages/dvc/repo/artifacts.py"", line 205, in download
    rev = self.get_rev(name, version=version, stage=stage)
  File ""/home/<USER>/.local/lib/python3.10/site-packages/dvc/repo/artifacts.py"", line 142, in get_rev
    raise ArtifactNotFoundError(name, version=version, stage=stage)
dvc.exceptions.ArtifactNotFoundError: Unable to find artifact '<GIT_SUBMODULE_PATH>:<ARTIFACT_NAME>@VERSION'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/<USER>/.local/lib/python3.10/site-packages/dvc/commands/artifacts.py"", line 20, in run
    count, out = Artifacts.get(
  File ""/home/<USER>/.local/lib/python3.10/site-packages/dvc/repo/artifacts.py"", line 381, in get
    raise DvcException(
dvc.exceptions.DvcException: Failed to download artifact '<GIT_SUBMODULE_PATH>:<ARTIFACT_NAME>' via DVC remote
```
<!--
Please check https://github.com/iterative/dvc/wiki/Debugging-DVC on ways to gather more information regarding the issue.

If applicable, please also provide a `--verbose` output of the command, eg: `dvc add --verbose`.
If the issue is regarding the performance, please attach the profiling information and the benchmark comparisons.
-->
",Ileal16,145340765,open,False,0,2025-05-06T08:56:46+00:00,2025-05-07T02:25:04+00:00,,,0,0,0,0,0,0,0
iterative/dvc,3041942842,10736,repo: try to support opening uninitialized/broken repositories,"This `_get_remote_config()` should use `uninitialized=True` so that it supports more broader kinds of broken/partially-initialized repositories, including some that have `.dvc` directory missing, or `.git` directory missing.

This partially reverts #10719. #10608 is also fixed, and no longer requires `core.no_scm` to be passed. This was already supported by `dvc.api.get_url()` as it uses `uninitialized=True`, but this was not respected in `_get_remote_config()` where it would fail before.

That said, this whole `open_repo`/`_get_remote_config` is terribly broken. For one, it is opening a local repository, and forcing it's remote config to a repository opened with `Repo(rev=...)`, where the config may be different.

",skshetry,18718008,closed,False,0,2025-05-06T08:15:52+00:00,2025-05-06T08:39:24+00:00,2025-05-06T08:39:23+00:00,,0,0,0,0,0,0,0
iterative/dvc,3040424267,10735,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.11.7 ‚Üí v0.11.8](https://github.com/astral-sh/ruff-pre-commit/compare/v0.11.7...v0.11.8)
<!--pre-commit.ci end-->",pre-commit-ci[bot],66853113,closed,False,0,2025-05-05T18:10:05+00:00,2025-05-06T01:20:13+00:00,2025-05-06T01:20:11+00:00,,0,0,0,0,0,0,0
iterative/dvc,3039951487,10734,`push`: Error when pushing to S3 `[Errno 22] Invalid Argument.: An error occurred (InvalidArgument) when calling the PutObject operation: Invalid Argument.`,"

## Description

Using DVC and a S3 server everything works fine except pushing.
`[Errno 22] Invalid Argument.: An error occurred (InvalidArgument) when calling the PutObject operation: Invalid Argument.`

Full log:
```
dvc push -v
2025-05-05 16:49:15,059 DEBUG: v3.50.0 (pip), CPython 3.10.16 on macOS-10.16-x86_64-i386-64bit
2025-05-05 16:49:15,059 DEBUG: command: /Users/pltrdy/anaconda3/envs/xx/bin/dvc push -v
Collecting                                                                                                                                                                   |0.00 [00:00,    ?entry/s]
2025-05-05 16:49:26,588 DEBUG: Preparing to transfer data from '/Users/pltrdy/xx/.dvc/cache/files/md5' to 's3://data-ia/files/md5'
2025-05-05 16:49:26,588 DEBUG: Preparing to collect status from 'data-ia/files/md5'
2025-05-05 16:49:26,791 DEBUG: Collecting status from 'data-ia/files/md5'
2025-05-05 16:49:34,254 DEBUG: Querying 21 oids via object_exists
2025-05-05 16:49:34,863 DEBUG: Querying 0 oids via object_exists                                                                                                                                       
2025-05-05 16:49:45,826 DEBUG: Estimated remote size: 458752 files                                                                                                                                     
2025-05-05 16:49:45,827 DEBUG: Large remote (255 oids < 458.752 traverse weight), using object_exists for remaining oids                                                                               
2025-05-05 16:49:45,827 DEBUG: Querying 255 oids via object_exists                                                                                                                                     
2025-05-05 16:49:47,488 DEBUG: Preparing to collect status from '/Users/pltrdy/yy/.dvc/cache/files/md5'                                                                                          
2025-05-05 16:49:47,656 DEBUG: Collecting status from '/Users/pltrdy/yy/.dvc/cache/files/md5'                                                                                                    
2025-05-05 16:50:03,701 ERROR: failed to transfer '147e909ee4a2b44dbdbbcd89fc633adc' - [Errno 22] Invalid Argument.: An error occurred (InvalidArgument) when calling the PutObject operation: Invalid Argument.                                                                                                                                                                                              
Traceback (most recent call last):                                                                                                                                                                     
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/s3fs/core.py"", line 114, in _error_wrapper
    return await func(*args, **kwargs)
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/aiobotocore/client.py"", line 412, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (InvalidArgument) when calling the PutObject operation: Invalid Argument.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/dvc_objects/fs/generic.py"", line 349, in transfer
    _try_links(
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/dvc_objects/fs/generic.py"", line 281, in _try_links
    return copy(
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/dvc_objects/fs/generic.py"", line 88, in copy
    return _put(
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/dvc_objects/fs/generic.py"", line 161, in _put
    _put_one(from_paths[0], to_paths[0])
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/dvc_objects/fs/generic.py"", line 151, in _put_one
    return to_fs.put_file(
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/dvc_objects/fs/base.py"", line 635, in put_file
    self.fs.put_file(os.fspath(from_file), to_info, callback=callback, **kwargs)
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/fsspec/asyn.py"", line 118, in wrapper
    return sync(self.loop, func, *args, **kwargs)
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/fsspec/asyn.py"", line 103, in sync
    raise return_result
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/fsspec/asyn.py"", line 56, in _runner
    result[0] = await coro
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/s3fs/core.py"", line 1266, in _put_file
    await self._call_s3(
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/s3fs/core.py"", line 371, in _call_s3
    return await _error_wrapper(
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/s3fs/core.py"", line 146, in _error_wrapper
    raise err
OSError: [Errno 22] Invalid Argument.

Pushing
2025-05-05 16:50:03,710 ERROR: failed to push data to the cloud - 1 files failed to upload                                                                                                             
Traceback (most recent call last):
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/dvc/commands/data_sync.py"", line 64, in run
    processed_files_count = self.repo.push(
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/dvc/repo/__init__.py"", line 58, in wrapper
    return f(repo, *args, **kwargs)
  File ""/Users/pltrdy/anaconda3/envs/zz/lib/python3.10/site-packages/dvc/repo/push.py"", line 167, in push
    raise UploadError(failed_count)
dvc.exceptions.UploadError: 1 files failed to upload

2025-05-05 16:50:03,713 DEBUG: Analytics is enabled.
2025-05-05 16:50:03,754 DEBUG: Trying to spawn ['daemon', 'analytics', '/var/folders/n7/7d_sgddx1mj99gc0k1ndbmnh0000gq/T/tmpen5beiwu', '-v']
2025-05-05 16:50:03,781 DEBUG: Spawned ['daemon', 'analytics', '/var/folders/n7/7d_sgddx1mj99gc0k1ndbmnh0000gq/T/tmpen5beiwu', '-v'] with pid 26407
```



### Expected

Push the files

### Environment information

<!--
This is required to ensure that we can reproduce the bug.
-->

**Output of `dvc doctor`:**

```console
$ dvc doctor
dvc doctor
DVC version: 3.50.0 (pip)
-------------------------
Platform: Python 3.10.16 on macOS-10.16-x86_64-i386-64bit
Subprojects:
        dvc_data = 3.15.2
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.11
Supports:
        http (aiohttp = 3.11.10, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.10, aiohttp-retry = 2.9.1),
        s3 (s3fs = 2025.3.2, boto3 = 1.37.3)
Config:
        Global: /Users/pltrdy/Library/Application Support/dvc
        System: /Library/Application Support/dvc
Cache types: reflink, hardlink, symlink
Cache directory: apfs on /dev/disk3s3s1
Caches: local
Remotes: s3
Workspace directory: apfs on /dev/disk3s3s1
Repo: dvc, git
Repo.site_cache_dir: /Library/Caches/dvc/repo/41a3d4fdaaa29cbe62d754804bb53f24
```

",pltrdy-spash,180158477,open,False,4,2025-05-05T14:55:51+00:00,2025-05-07T14:10:45+00:00,,,0,0,0,0,0,0,0
iterative/dvc,3037598648,10733,Option for DVC to use user login shell,"Hello, I rely on Bash features like `shopt -s globstar` in my `~/.bashrc` to use `**` for full recursive globs. However, when DVC runs a stage:

```yaml
stages:
  copy_parm:
    cmd: rsync -avhL data/interim/**/*.parm data/final/
```

it ends up executing under `/bin/sh` (or a non-interactive/non-login Bash, i think) with globstar disabled. As a result, `**` only matches one level of subdirectory (`*/*/*.parm`) instead of any depth.

Do you have more information on this? I'd like DVC to use my default login shell but if this goes against reproducibility, is there an option to pass in options to the shell that DVC invokes each time a `cmd` is performed?

Environment:
DVC version: 3.53.1 (conda)
---------------------------
Platform: Python 3.10.0 on Linux-4.18.0-305.el8.x86_64-x86_64-with-glibc2.28
Subprojects:
	dvc_data = 3.15.2
	dvc_objects = 5.1.0
	dvc_render = 1.0.2
	dvc_task = 0.4.0
	scmrepo = 3.3.7
Supports:
	http (aiohttp = 3.10.2, aiohttp-retry = 2.8.3),
	https (aiohttp = 3.10.2, aiohttp-retry = 2.8.3)
Config:
	Global: /nfs/home/.../.config/dvc
	System: /etc/xdg/dvc
Cache types: hardlink, symlink
Caches: local
Remotes: None
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/11780b188ea5eedf4869c1e629a797e5
",austinbenny,31543165,closed,False,2,2025-05-03T20:26:58+00:00,2025-05-05T02:58:49+00:00,2025-05-05T02:41:34+00:00,,0,0,0,0,0,0,0
iterative/dvc,3027362706,10732,tests: func test for #4344,"See https://github.com/iterative/dvc-data/pull/601 that fixed the issue. The test is based on reproduction steps from:
https://github.com/iterative/dvc/issues/4344#issuecomment-2822000925.

Related: #4344.

* [x] ‚ùó I have followed the [Contributing to DVC](https://dvc.org/doc/user-guide/contributing/core) checklist.

* [x] üìñ If this PR requires [documentation](https://dvc.org/doc) updates, I have created a separate PR (or issue, at least) in [dvc.org](https://github.com/iterative/dvc.org) and linked it here.

Thank you for the contribution - we'll try to review it as soon as possible. üôè
",skshetry,18718008,closed,False,1,2025-04-29T07:30:22+00:00,2025-04-29T07:40:56+00:00,2025-04-29T07:40:29+00:00,,0,0,0,0,0,0,0
iterative/dvc,3025721975,10731,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.11.4 ‚Üí v0.11.7](https://github.com/astral-sh/ruff-pre-commit/compare/v0.11.4...v0.11.7)
<!--pre-commit.ci end-->",pre-commit-ci[bot],66853113,closed,False,0,2025-04-28T18:02:08+00:00,2025-04-28T23:07:44+00:00,2025-04-28T23:07:43+00:00,,0,0,0,0,0,0,0
iterative/dvc,3024802784,10730,"Revert ""pre-commit: set autoupdate schedule to monthly""",Reverts iterative/dvc#10685,skshetry,18718008,closed,False,0,2025-04-28T12:38:02+00:00,2025-04-28T12:38:11+00:00,2025-04-28T12:38:09+00:00,,0,0,0,0,0,0,0
iterative/dvc,3018833494,10729,build(deps): bump astral-sh/setup-uv from 5 to 6,"Bumps [astral-sh/setup-uv](https://github.com/astral-sh/setup-uv) from 5 to 6.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/astral-sh/setup-uv/releases"">astral-sh/setup-uv's releases</a>.</em></p>
<blockquote>
<h2>v6.0.0 üåà activate-environment and working-directory</h2>
<h2>Changes</h2>
<p>This version contains some breaking changes which have been gathering up for a while. Lets dive into them:</p>
<ul>
<li><a href=""https://github.com/astral-sh/setup-uv/blob/HEAD/#activate-environment"">Activate environment</a></li>
<li><a href=""https://github.com/astral-sh/setup-uv/blob/HEAD/#working-directory"">Working Directory</a></li>
<li><a href=""https://github.com/astral-sh/setup-uv/blob/HEAD/#default-cache-dependency-glob"">Default <code>cache-dependency-glob</code></a></li>
<li><a href=""https://github.com/astral-sh/setup-uv/blob/HEAD/#use-default-cache-dir-on-self-hosted-runners"">Use default cache dir on self hosted runners</a></li>
</ul>
<h3>Activate environment</h3>
<p>In previous versions using the input <code>python-version</code> automatically activated a venv at the repository root.
This led to some unwanted side-effects, was sometimes unexpected and not flexible enough.</p>
<p>The venv activation is now explicitly controlled with the new input <code>activate-environment</code> (false by default):</p>
<pre lang=""yaml""><code>- name: Install the latest version of uv and activate the environment
  uses: astral-sh/setup-uv@v6
  with:
    activate-environment: true
- run: uv pip install pip
</code></pre>
<p>The venv gets created by the <a href=""https://docs.astral.sh/uv/pip/environments/""><code>uv venv</code></a> command so the python version is controlled by the <code>python-version</code> input or the files <code>pyproject.toml</code>, <code>uv.toml</code>, <code>.python-version</code> in the <code>working-directory</code>.</p>
<h3>Working Directory</h3>
<p>The new input <code>working-directory</code> controls where we look for <code>pyproject.toml</code>, <code>uv.toml</code> and <code>.python-version</code> files
which are used to determine the version of uv and python to install.</p>
<p>It can also be used to control where the venv gets created.</p>
<pre lang=""yaml""><code>- name: Install uv based on the config files in the working-directory
  uses: astral-sh/setup-uv@v6
  with:
    working-directory: my/subproject/dir
</code></pre>
<blockquote>
<p>[!CAUTION]</p>
<p>The inputs <code>pyproject-file</code> and <code>uv-file</code> have been removed.</p>
</blockquote>
<h3>Default <code>cache-dependency-glob</code></h3>
<p><a href=""https://github.com/ssbarnea""><code>@‚Äãssbarnea</code></a> found out that the default <code>cache-dependency-glob</code> was not suitable for a lot of users.</p>
<p>The old default</p>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/c7f87aa956e4c323abf06d5dec078e358f6b4d04""><code>c7f87aa</code></a> bump to v6 in README (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/382"">#382</a>)</li>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/aadfaf08d64f83cdd98eea14fdab8eb08f73656c""><code>aadfaf0</code></a> Change default cache-dependency-glob (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/352"">#352</a>)</li>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/a0f9da6273a171f2d94cce2036eaf5a07fefa23c""><code>a0f9da6</code></a> No default UV_CACHE_DIR on selfhosted runners (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/380"">#380</a>)</li>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/ec4c6916287cf1471f9f803d79ef6a0a04520e81""><code>ec4c691</code></a> new inputs activate-environment and working-directory (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/381"">#381</a>)</li>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/aa1290542ebcd3b6932d825ed2b40807f82b2fdd""><code>aa12905</code></a> chore: update known checksums for 0.6.16 (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/378"">#378</a>)</li>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/fcaddda076a8158a712b6d64986baf606c446694""><code>fcaddda</code></a> chore: update known checksums for 0.6.15 (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/377"">#377</a>)</li>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/fb3a0a97fac846cb3395265a3087ab94ad3ca2a0""><code>fb3a0a9</code></a> log info on venv activation (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/375"">#375</a>)</li>
<li>See full diff in <a href=""https://github.com/astral-sh/setup-uv/compare/v5...v6"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=astral-sh/setup-uv&package-manager=github_actions&previous-version=5&new-version=6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],49699333,closed,False,1,2025-04-25T02:26:37+00:00,2025-04-28T09:10:18+00:00,2025-04-28T09:10:16+00:00,,0,0,0,0,0,0,0
iterative/dvc,3012758524,10728,Bring the banner back,"* [x] ‚ùó I have followed the [Contributing to DVC](https://dvc.org/doc/user-guide/contributing/core) checklist.

* [ ] üìñ If this PR requires [documentation](https://dvc.org/doc) updates, I have created a separate PR (or issue, at least) in [dvc.org](https://github.com/iterative/dvc.org) and linked it here.

Thank you for the contribution - we'll try to review it as soon as possible. üôè
",PythonFZ,46721498,closed,False,1,2025-04-23T05:43:28+00:00,2025-04-24T00:34:38+00:00,2025-04-24T00:34:29+00:00,,1,0,0,0,0,0,0
iterative/dvc,3012389950,10727,DVC will max out swap even when plenty of memory available,"# Bug Report

<!--
## Issue name

Issue names must follow the pattern `command: description` where the command is the dvc command that you are trying to run. The description should describe the consequence of the bug.

Example: `repro: doesn't detect input changes`
-->

## Description

DVC will max out swap even when plenty of memory and CPU resources available.

This causes my system to heavily lag.

![Image](https://github.com/user-attachments/assets/0246a4e8-5e6f-4f14-87c3-db97b7776f30)

<!--
A clear and concise description of what the bug is.
-->

### Reproduce

<!--
Step list of how to reproduce the bug
-->

<!--
Example:

1. dvc init
2. Copy dataset.zip to the directory
3. dvc add dataset.zip
4. dvc run -d dataset.zip -o model ./train.sh
5. modify dataset.zip
6. dvc repro
-->

### Expected

<!--
A clear and concise description of what you expect to happen.
-->

### Environment information

<!--
This is required to ensure that we can reproduce the bug.
-->

Ubuntu 24.10

**Output of `dvc doctor`:**

```console
$ dvc doctor
```

**Additional Information (if any):**

<!--
Please check https://github.com/iterative/dvc/wiki/Debugging-DVC on ways to gather more information regarding the issue.

If applicable, please also provide a `--verbose` output of the command, eg: `dvc add --verbose`.
If the issue is regarding the performance, please attach the profiling information and the benchmark comparisons.
-->
",zndr27,31940813,closed,False,2,2025-04-23T00:11:54+00:00,2025-04-25T04:10:06+00:00,2025-04-25T04:09:55+00:00,,0,0,0,0,0,0,0
iterative/dvc,3009821194,10726,remove banner in README,"* [X] ‚ùó I have followed the [Contributing to DVC](https://dvc.org/doc/user-guide/contributing/core) checklist.

* [X] üìñ If this PR requires [documentation](https://dvc.org/doc) updates, I have created a separate PR (or issue, at least) in [dvc.org](https://github.com/iterative/dvc.org) and linked it here.

Thank you for the contribution - we'll try to review it as soon as possible. üôè
",shcheklein,3659196,closed,False,0,2025-04-22T04:27:13+00:00,2025-04-22T04:36:17+00:00,2025-04-22T04:36:16+00:00,,0,0,0,0,0,0,0
iterative/dvc,2997926637,10725,Wishlist: present DVC at upcoming distribits 2025?,"I wanted to inquire and thought this would be the best medium -- feel welcome to close upon (or even without) reading.

Distribits 2025 is coming and it would be great to hear about the DVC for [#distributed](https://fosstodon.org/tags/distributed) [#data_management](https://fosstodon.org/tags/data_management). We also hope you‚Äôll join us for a collaborative [#hackathon](https://fosstodon.org/tags/hackathon) to further network with other people who get excited about [#rdm](https://fosstodon.org/tags/rdm) and [#opendata](https://fosstodon.org/tags/opendata). üòé

‚è∞ there are still 3 weeks left to register and submit talk ideas for [#distribits2025](https://fosstodon.org/tags/distribits2025) (deadline 01 May): https://distribits.live/.

When? üóìÔ∏è 23-25 October, 2025
Where? üìç D√ºsseldorf, Germany (and online)
Cost? üí∞ Nothing ‚Äî it‚Äôs free!

Prior year distribits 2024 videos available from https://www.youtube.com/playlist?list=PLEQHbPfpVqU6esVrgqjfYybY394XD2qf2 and https://hub.datalad.org/distribits/recordings .

To rehearse memory about our related project DataLad -- here is our (now likely quite aged) comparison https://handbook.datalad.org/en/latest/beyond_basics/101-168-dvc.html .",yarikoptic,39889,closed,False,0,2025-04-15T23:53:03+00:00,2025-05-05T04:47:16+00:00,2025-05-05T04:47:16+00:00,,0,0,0,0,0,0,0
iterative/dvc,2995116902,10724,`git pull` hook when fast-forwarding,"Would it be possible to hook into `git pull` to automatically call `dvc pull` when doing a simple fast forward merge?

According to [here](https://github.com/brianstorti/git-hooks/blob/master/hooks/post-merge) and [here](https://stackoverflow.com/questions/73014362/skip-post-merge-hook-when-fast-forwarding), the `post-merge` hook is called during a fast-forward.

[Here](https://stackoverflow.com/questions/73014362/skip-post-merge-hook-when-fast-forwarding) is an example which checks whether the `post-merge` call is due to a fast-forward:

``` bash
if [[ `git reflog -1` = *Fast-forward ]]
    # then this is a fast-forward
fi
```

Pull hooks were discussed in #1551 but this is more narrow in scope.",Evidlo,5455841,open,False,0,2025-04-15T04:57:49+00:00,2025-05-07T02:53:27+00:00,,,0,0,0,0,0,0,0
iterative/dvc,2991597246,10722,check-ignore: .dvcignore doesn't handle directory ignores properly,"# Bug Report

<!--
## Issue name

Issue names must follow the pattern `command: description` where the command is the dvc command that you are trying to run. The description should describe the consequence of the bug.

Example: `repro: doesn't detect input changes`
-->

## Description

Ignore patterns with a trailing slash should only apply to directories. However, (at least when paired with `**`), they also match to files. This does not match git behavior.

This is important for repos with a large amount of junk or derived outputs, where we want to ignore everything except very specific input folders.

<!--
A clear and concise description of what the bug is.
-->

### Reproduce

```bash
mkdir -p /tmp/test
cd /tmp/test
git init
dvc init
mkdir -p 1/2/3
touch 1/2/shouldIgnore.txt
touch 1/2/3/shouldKeep.txt
cat <<EOF | tee .gitignore .dvcignore
# Ignore everything
1/**
# Except directories (leaves all files ignored)
!1/**/
# Don't ignore files in 3
!seq/**/3/**
EOF

dvc check-ignore -d 1/2/*
git check-ignore -v 1/2/*
dvc check-ignore -d 1/2/3/*
```

<!--
Step list of how to reproduce the bug
-->

<!--
Example:

1. dvc init
2. Copy dataset.zip to the directory
3. dvc add dataset.zip
4. dvc run -d dataset.zip -o model ./train.sh
5. modify dataset.zip
6. dvc repro
-->

### Expected

First check should ignore shouldIgnore.txt, but instead it is included under the rule `!1/**/`:
```
dvc check-ignore -d 1/2/*
.dvcignore:4:!1/**/	1/2/3
.dvcignore:4:!1/**/	1/2/shouldIgnore.txt
```

Git ignores it as expected.

```
git check-ignore -v 1/2/*
.gitignore:4:!1/**/	1/2/3
.gitignore:2:1/**	1/2/shouldIgnore.txt
```

2nd dvc check correctly includes shouldKeep.txt under the last rule.


<!--
A clear and concise description of what you expect to happen.
-->

### Environment information

<!--
This is required to ensure that we can reproduce the bug.
-->

**Output of `dvc doctor`:**

```console
DVC version: 3.56.0
-------------------
Platform: Python 3.12.8 on Linux-6.6.78-x86_64-with-glibc2.40
Subprojects:
	dvc_data = 3.16.7
	dvc_objects = 5.1.0
	dvc_render = 1.0.2
	dvc_task = 0.40.2
	scmrepo = 3.3.8
Supports:
	http (aiohttp = 3.10.10, aiohttp-retry = 2.8.3),
	https (aiohttp = 3.10.10, aiohttp-retry = 2.8.3)
Config:
	Global: /root/.config/dvc
	System: /root/.config/kdedefaults/dvc
Cache types: <https://error.dvc.org/no-dvc-cache>
Caches: local
Remotes: None
Workspace directory: ext4 on /dev/mapper/luks-59bb1234-ec63-4d49-a38a-f6adaef20fee
Repo: dvc, git
Repo.site_cache_dir: /var/cache/dvc/repo/35a50912b07ad0907dc968426d9e9409
```

**Additional Information (if any):**

<!--
Please check https://github.com/iterative/dvc/wiki/Debugging-DVC on ways to gather more information regarding the issue.

If applicable, please also provide a `--verbose` output of the command, eg: `dvc add --verbose`.
If the issue is regarding the performance, please attach the profiling information and the benchmark comparisons.
-->

",BlueDrink9,26474254,open,False,0,2025-04-14T00:41:59+00:00,2025-05-07T02:53:39+00:00,,,0,0,0,0,0,0,0
iterative/dvc,2985498359,10721,Traceback relating to fsspec,"# Bug Report


## Issue name

dvc --version: traceback with LocalFileSystem object


## Description

I am writing an EasyBuild easyconfig so DVC can be installed on HPC clusters.

As part of the easyconfig, once all the Python extensions including dvc have been installed, it runs ""sanity check commands"" to confirm basic functionality of the application. In this case the commands are:

`dvc --version && dvc doctor`

This causes an error:

`ERROR: unexpected error - 'LocalFileSystem' object has no attribute 'abspath'`

and a traceback (shown below).

We think this relates to the version of `fsspec`, which in the `pyproject.toml` is pinned to `2024.2.0`.

### Reproduce

dvc --version && dvc doctor


### Expected

The dvc version is shown and the `dvc doctor` output is shown.

### Environment information

The build host is running Rocky 8.10, the Python version is 3.11.3 from EasyBuild.
Here are the high-level dependencies in use:
```
    ('Python', '3.11.3'),
    ('git', '2.41.0', '-nodocs'),
    ('GitPython', '3.1.40'),
    ('networkx', '3.1'),
    ('PyYAML', '6.0'),
    ('ruamel.yaml', '0.17.32'),
    ('SciPy-bundle', '2023.07'),
    ('tqdm', '4.66.1'),
    ('pydantic', '2.5.3'),
```


**Output of `dvc doctor`:**

This is one of the failing commands, so I can't show the output.

**Additional Information (if any):**

It seems that there have been changes in `fsspec` which this version of `dvc` hasn't been modified to account for.

Here is the `2024.2.0` traceback:
```
ERROR: unexpected error - 'LocalFileSystem' object has no attribute 'abspath'

Having any troubles? Hit us up at https://dvc.org/support, we are always happy to help!
Traceback (most recent call last):
  File ""/apps/eb/el8/upstream/software/dvc/3.59.1-gfbf-2023a/bin/dvc"", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File ""/apps/eb/el8/upstream/software/dvc/3.59.1-gfbf-2023a/lib/python3.11/site-packages/dvc/cli/__init__.py"", line 243, in main
    if analytics.is_enabled():
       ^^^^^^^^^^^^^^^^^^^^^^
  File ""/apps/eb/el8/upstream/software/dvc/3.59.1-gfbf-2023a/lib/python3.11/site-packages/dvc/analytics.py"", line 53, in is_enabled
    Config.from_cwd(validate=False).get(""core"", {}).get(""analytics"", ""true"")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/apps/eb/el8/upstream/software/dvc/3.59.1-gfbf-2023a/lib/python3.11/site-packages/dvc/config.py"", line 126, in from_cwd
    dvc_dir = Repo.find_dvc_dir(fs=fs)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/apps/eb/el8/upstream/software/dvc/3.59.1-gfbf-2023a/lib/python3.11/site-packages/dvc/repo/__init__.py"", line 438, in find_dvc_dir
    root_dir = cls.find_root(root, fs=fs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/apps/eb/el8/upstream/software/dvc/3.59.1-gfbf-2023a/lib/python3.11/site-packages/dvc/repo/__init__.py"", line 410, in find_root
    root_dir = fs.abspath(root)
               ^^^^^^^^^^
AttributeError: 'LocalFileSystem' object has no attribute 'abspath'
```

I have tried changing to earlier versions of `fsspec` and they cause different tracebacks e.g.:
```
== FAILED: Installation ended unsuccessfully: Sanity check failed: sanity check command dvc --version && dvc doctor failed with exit code 1 (output: 3.59.1
Traceback (most recent call last):
  File ""/apps/eb/el8/upstream/software/dvc/3.59.1-gfbf-2023a/lib/python3.11/site-packages/dvc/cli/__init__.py"", line 211, in main
    ret = cmd.do_run()
          ^^^^^^^^^^^^
  File ""/apps/eb/el8/upstream/software/dvc/3.59.1-gfbf-2023a/lib/python3.11/site-packages/dvc/cli/command.py"", line 41, in do_run
    return self.run()
           ^^^^^^^^^^
  File ""/apps/eb/el8/upstream/software/dvc/3.59.1-gfbf-2023a/lib/python3.11/site-packages/dvc/commands/version.py"", line 12, in run
    from dvc.info import get_dvc_info
  File ""/apps/eb/el8/upstream/software/dvc/3.59.1-gfbf-2023a/lib/python3.11/site-packages/dvc/info.py"", line 11, in <module>
    from dvc.fs import Schemes, generic, get_fs_cls, get_fs_config, registry
  File ""/apps/eb/el8/upstream/software/dvc/3.59.1-gfbf-2023a/lib/python3.11/site-packages/dvc/fs/__init__.py"", line 30, in <module>
    from .callbacks import Callback  # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/apps/eb/el8/upstream/software/dvc/3.59.1-gfbf-2023a/lib/python3.11/site-packages/dvc/fs/callbacks.py"", line 5, in <module>
    from fsspec.callbacks import DEFAULT_CALLBACK, Callback  # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ImportError: cannot import name 'DEFAULT_CALLBACK' from 'fsspec.callbacks' (/apps/eb/el8/upstream/software/dvc/3.59.1-gfbf-2023a/lib/python3.11/site-packages/fsspec/callbacks.py)
```

That is with `fsspec` `2022.11.0`.

",verdurin,12435,closed,False,6,2025-04-10T12:25:26+00:00,2025-04-10T15:04:38+00:00,2025-04-10T14:22:26+00:00,,0,0,0,0,0,0,0
iterative/dvc,2984694706,10720,ci(build): use envvar override to omit local version for Test PyPI upload,"Uses `SETUPTOOLS_SCM_OVERRIDES_FOR_DVC` to omit the local version when uploading to Test PyPI. This is needed because (Test) PyPI does not support local version.

This requires bumping minimum version of `setuptools_scm` to `8.0.0`.

The envvar is documented here: https://setuptools-scm.readthedocs.io/en/latest/overrides/.

Also see:
https://github.com/pypa/setuptools-scm/issues/455#issuecomment-2791301186.",skshetry,18718008,closed,False,0,2025-04-10T07:11:58+00:00,2025-04-10T07:14:35+00:00,2025-04-10T07:14:33+00:00,,0,0,0,0,0,0,0
iterative/dvc,2984506590,10719,Forward args to _get_remote_config() and honour core/no_scm if present,"This is a proposed fix for #10608, the code here makes steps 9 and 10 described in the issue work.

**Summary:**

This change allows a user to access the dvc information in an environment that is disconnected from the original Git backend (e.g. in a deployed container, see #10608), by using something like:
```python
dvc.api.get_url(path,
                repo,
                config={""core"": {""no_scm"": True}}
                )
```


**Description:**

Mainly, a call to `dvc/repo/open_repo.py:open_repo(url, *args, **kwargs)` may contain a parameter `config` in `**kwargs`. With this `config` a user might indicate they do not want to access the repo with Git support, by using `config={""core"": {""no_scm"": True}}`. 

During the execution of `dvc/repo/open_repo.py:open_repo()`, there is a call to a function `dvc/repo/open_repo.py:_get_remote_config()` that returns the remote configuration(`{""core"": {""remote""}}`. This is then merged to the user provided `config` parameter before calling `Repo(url, *args, **kwargs)`.

`dvc/repo/open_repo.py:_get_remote_config()`, in turn, does a quick `Repo()` call to get the remote configuration. However, it does not use any of the parameters requested via `dvc/repo/open_repo.py:open_repo()` and thus relies entirely on the contents of `.dvc/config`. This means that even if the user requested no SCM support, it will try to look for a Git repo if `.dvc/config` says so, and fail if it does not find it.

This PR modifies `dvc/repo/open_repo.py:_get_remote_config()` to receive `*args, **kwargs` and honour the request to use or ignore Git support when accessing the dvc repo.


* [X] ‚ùó I have followed the [Contributing to DVC](https://dvc.org/doc/user-guide/contributing/core) checklist.

* [ ] üìñ If this PR requires [documentation](https://dvc.org/doc) updates, I have created a separate PR (or issue, at least) in [dvc.org](https://github.com/iterative/dvc.org) and linked it here.

Thank you for the contribution - we'll try to review it as soon as possible. üôè
",rgoya,5192495,closed,False,7,2025-04-10T05:29:44+00:00,2025-05-06T02:50:23+00:00,2025-04-30T06:35:09+00:00,,1,0,0,0,0,0,1
iterative/dvc,2984288126,10718,build(deps): bump rtCamp/action-slack-notify from 2.3.2 to 2.3.3,"Bumps [rtCamp/action-slack-notify](https://github.com/rtcamp/action-slack-notify) from 2.3.2 to 2.3.3.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/rtcamp/action-slack-notify/releases"">rtCamp/action-slack-notify's releases</a>.</em></p>
<blockquote>
<h2>v2.3.3</h2>
<h2>What's Changed</h2>
<p><strong>Changelog:</strong></p>
<h2>What's Changed</h2>
<ul>
<li>Pinning slackify-markdown-action to specific version by <a href=""https://github.com/Tello-Wharton""><code>@‚ÄãTello-Wharton</code></a> <a href=""https://github.com/adanalvarez""><code>@‚Äãadanalvarez</code></a> <a href=""https://redirect.github.com/rtcamp/action-slack-notify/issues/221"">#221</a> <a href=""https://redirect.github.com/rtcamp/action-slack-notify/issues/219"">#219</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/Tello-Wharton""><code>@‚ÄãTello-Wharton</code></a> <a href=""https://github.com/adanalvarez""><code>@‚Äãadanalvarez</code></a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/rtCamp/action-slack-notify/compare/v2.3.1...v2.3.3"">https://github.com/rtCamp/action-slack-notify/compare/v2.3.1...v2.3.3</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/rtCamp/action-slack-notify/commit/e31e87e03dd19038e411e38ae27cbad084a90661""><code>e31e87e</code></a> Update action image version to v2.3.3</li>
<li><a href=""https://github.com/rtCamp/action-slack-notify/commit/b2acbf4106a88ffa712abb98141eb3b7cf29cbab""><code>b2acbf4</code></a> Merge pull request <a href=""https://redirect.github.com/rtcamp/action-slack-notify/issues/221"">#221</a> from Tello-Wharton/master</li>
<li><a href=""https://github.com/rtCamp/action-slack-notify/commit/0410d0a55c2bc96e61632ae828c839eacd0b1702""><code>0410d0a</code></a> Pinning slackify-markdown-action to specific version</li>
<li>See full diff in <a href=""https://github.com/rtcamp/action-slack-notify/compare/v2.3.2...v2.3.3"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rtCamp/action-slack-notify&package-manager=github_actions&previous-version=2.3.2&new-version=2.3.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],49699333,closed,False,1,2025-04-10T02:30:27+00:00,2025-04-10T07:17:23+00:00,2025-04-10T07:17:20+00:00,,0,0,0,0,0,0,0
iterative/dvc,2977640149,10717,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.9.9 ‚Üí v0.11.4](https://github.com/astral-sh/ruff-pre-commit/compare/v0.9.9...v0.11.4)
<!--pre-commit.ci end-->",pre-commit-ci[bot],66853113,closed,False,0,2025-04-07T18:19:42+00:00,2025-04-08T03:15:10+00:00,2025-04-08T03:15:10+00:00,,0,0,0,0,0,0,0
iterative/dvc,2972374395,10716,Debian `apt update` GPG error The following signatures were invalid: EXPKEYSIG EFFAF4443CE9AD84 Iterative <eng@iterative.ai>,"# Bug Report

I have installed DVC following [dvc.org | Docs | Install from repository | On Debian/Ubuntu](https://dvc.org/doc/install/linux#from-repo-on-debian-ubuntu). 

When I want to update DVC I run `sudo apt update` but it fails to update from the repository
```console
Get:9 https://s3-us-east-2.amazonaws.com/dvc-s3-repo/deb stable InRelease [2,679 B]
Err:9 https://s3-us-east-2.amazonaws.com/dvc-s3-repo/deb stable InRelease

  The following signatures were invalid: EXPKEYSIG EFFAF4443CE9AD84 Iterative <eng@iterative.ai>

W: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: https://s3-us-east-2.amazonaws.com/dvc-s3-repo/deb stable InRelease: The following signatures were invalid: EXPKEYSIG EFFAF4443CE9AD84 Iterative <eng@iterative.ai>
W: Failed to fetch https://dvc.org/deb/dists/stable/InRelease  The following signatures were invalid: EXPKEYSIG EFFAF4443CE9AD84 Iterative <eng@iterative.ai>
W: Some index files failed to download. They have been ignored, or old ones used instead.
```

So it seems to me that your GPG key have expired.

I have tried to update the key by running
```bash
wget -qO - https://dvc.org/deb/iterative.asc | sudo gpg --dearmor -o /etc/apt/keyrings/packages.iterative.gpg
```
and ensure that it the gpg file still have mode 644, but it doesnt work.

### Environment information

**Output of `dvc doctor`:**

```console
DVC version: 3.59.0 (deb)
-------------------------
Platform: Python 3.12.7 on Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36
Subprojects:

Supports:
        azure (adlfs = 2024.12.0, knack = 0.12.0, azure-identity = 1.19.0),
        gdrive (pydrive2 = 1.21.3),
        gs (gcsfs = 2024.12.0),
        hdfs (fsspec = 2024.12.0, pyarrow = 18.1.0),
        http (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
        oss (ossfs = 2023.12.0),
        s3 (s3fs = 2024.12.0, boto3 = 1.35.93),
        ssh (sshfs = 2024.9.0),
        webdav (webdav4 = 0.10.0),
        webdavs (webdav4 = 0.10.0),
        webhdfs (fsspec = 2024.12.0)
Config:
        Global: ~/.config/dvc
        System: /etc/xdg/dvc
Cache types: hardlink, symlink
Cache directory: ext4 on /dev/sdc
Caches: local
Remotes: s3
Workspace directory: ext4 on /dev/sdc
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/83f466a3274e4e21df73127bf8e7c5cb

You are using dvc version 3.59.0; however, version 3.59.1 is available.
To upgrade, run 'apt-get install --only-upgrade dvc'.
```

Just to make it clear, eventhough dvc doctor acknowlegdes that an upgrade is available then
```bash
sudo apt-get install --only-upgrade dvc
```
```console
dvc is already the newest version (3.59.0)
```",DKAndreasen,118984462,closed,False,3,2025-04-04T13:22:27+00:00,2025-04-08T12:53:03+00:00,2025-04-08T12:53:02+00:00,,0,0,0,0,0,0,0
iterative/dvc,2972110319,10715,ci: install packages inside virtualenv using uv,"* [ ] ‚ùó I have followed the [Contributing to DVC](https://dvc.org/doc/user-guide/contributing/core) checklist.

* [ ] üìñ If this PR requires [documentation](https://dvc.org/doc) updates, I have created a separate PR (or issue, at least) in [dvc.org](https://github.com/iterative/dvc.org) and linked it here.

Thank you for the contribution - we'll try to review it as soon as possible. üôè
",skshetry,18718008,closed,False,1,2025-04-04T11:34:56+00:00,2025-04-04T11:43:23+00:00,2025-04-04T11:42:52+00:00,,0,0,0,0,0,0,0
iterative/dvc,2968791528,10714,Add ability to group stages,"Feature request: 

While the solution to this problem will be a bit complicated, this is a very common problem in my pipeline, and has been a little thorn in my side sice I started working with DVC so i finally decided to write this feature request :)

Problem:
In my pipeline I constantly need to submit jobs to the cloud. After the job is done I collect job's results and save them locally. This job can take well over than two days to complete, so submission of the job and collection of its results cannot be placed in the same stage.

Current solution:
I have job submission in one stage, and collection of its results in two different stages.
First stage outputs a file containing metadata needed to collect results from the job.
Second stage tries to collect the results, if the job is still running it fails, and asks user to come back later.
While this works, it's very inconvenient to deal with if the submitted jobs fails.
Then, according to dvc, submission of the job completed fine, but collection of results can never be complete.
You then end up with a situation where the first stage needs to be force rerun.

Possible solution:
1. Add ability to group stages, perhaps, but simply specifying a string, or by specifying them inside a `group:` in `dvc.yaml`
2. Add something like a `--rerun-failed-groups` flag to `dvc repro`. When any stage inside a group fails, the whole group will be rerun with the next `dvc repro --rerun-failed-groups`.
3. Unfortunately, some special exit code should be added to handle case, where a stage timed out, which technically failed the stage, but does not need to invalidate the whole group, like in my case, waiting for the submitted job to complete.

While this seems to be rather complicated, I can see this being very useful for everyone who needs to submit a job that runs on some external service.

I did not look into dvc's code heavily to consider how capable am I of trying to add something like this myself, so I don't want to make any promises.
Thanks for your feedback, and obviously I'm very happy for any alternative solutions!",janpawlowskiof,17483828,open,False,1,2025-04-03T08:49:19+00:00,2025-05-07T03:28:06+00:00,,,0,0,0,0,0,0,0
iterative/dvc,2962031353,10713,Support async in DVCFileSystem for use with Zarr,"Zarr supports a fsspec backed store for datasets, but requires the fsspec implementation to support async. Could the DVCFileSystem be enhanced to supported async (i.e. inherit from fsspec.asyn.AsyncFileSystem)?

Here's what the enhancement would allow:

```python
fs = dvc.api.DVCFileSystem(asynchronous=True)  # this arg is what's proposed here
store = zarr.storage.FsspecStore(fs, read_only=True, path=""path/to/local.zarr"")
dataset = xarray.open_dataset(store, engine=""zarr"")
```

And then you could read a Zarr from any DVC remote!",itcarroll,3383837,open,False,0,2025-04-01T02:33:12+00:00,2025-04-01T02:33:12+00:00,,,1,1,0,0,0,0,0
iterative/dvc,2960509623,10712,Better support for transferring a large number of files already in the cloud  into DVC,"Right now if you have a large number of (potentially small) files it is very time consuming to start tracking them with DVC. It is a particular problem if there are too many to store locally at once. One way to fix this would be to support glob patterns when using `dvc add --to-remote`. 

Right now if you use dvc add --to-remote --glob you get the following error:

```
ERROR: --glob option can't be used with --to-remote
```

Were this to work then the files could be transferred between google cloud buckets without needing to be copied locally, which would make the process much faster. ",thk123,638608,open,False,0,2025-03-31T13:29:40+00:00,2025-03-31T13:29:40+00:00,,,1,1,0,0,0,0,0
iterative/dvc,2950158089,10711,"remote: show default when run ""dvc remote list""","Fixes #10708

* [x] ‚ùó I have followed the [Contributing to DVC](https://dvc.org/doc/user-guide/contributing/core) checklist.

* [ ] üìñ If this PR requires [documentation](https://dvc.org/doc) updates, I have created a separate PR (or issue, at least) in [dvc.org](https://github.com/iterative/dvc.org) and linked it here.

Hello, I'm new to DVC and this is my first contribution to this repo. Please feel free to make suggestions or edits of course. 

I'd also be more than happy to make a documentation PR but I first wanted to check you're happy with the formatting choice I have gone for to show the default remote, as that would affect the documentation. 

I have configured it so that the default remote is shown in a similar way to how `git branch` does it:
 
![Screenshot from 2025-03-26 17-13-24](https://github.com/user-attachments/assets/c908e408-f724-41b0-a8cd-e47042d23812)

Thanks! ",RMCrean,49672044,closed,False,8,2025-03-26T16:15:37+00:00,2025-04-11T02:48:39+00:00,2025-04-07T03:17:09+00:00,,4,1,0,0,0,0,2
iterative/dvc,2947726356,10710,Support Wildcards (*) for deps in DVC,"Currently, DVC requires explicit file (or folder) paths when defining dependencies in `dvc.yaml`. It would be helpful to support wildcards (*) to simplify dependency management. Users could use patterns like `src/common/*.py` to track all python files (and skip untracked eg. README.md files) or `data/raw/foo_*.csv` to include files with common prefix.",T04STER,30447715,closed,False,2,2025-03-25T20:46:57+00:00,2025-05-07T02:34:38+00:00,2025-05-07T02:34:07+00:00,,1,1,0,0,0,0,0
iterative/dvc,2945121190,10709,pyproject: update license to PEP 639 format,"Requires bumping `setuptools` to 77.0.0 or later.

See:
- [PEP 639](https://peps.python.org/pep-0639)
- [Writing pyproject.toml - license](https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license)

",skshetry,18718008,closed,False,0,2025-03-25T03:34:02+00:00,2025-03-25T04:03:51+00:00,2025-03-25T04:03:50+00:00,,0,0,0,0,0,0,0
iterative/dvc,2944662744,10708,Show default in `dvc remote list`,`dvc remote list` does not show which is the default. It would be very helpful to add this as another column.,NedJWestern,25029241,closed,False,0,2025-03-24T22:58:57+00:00,2025-04-07T03:17:10+00:00,2025-04-07T03:17:10+00:00,good first issue;p3-nice-to-have,0,0,0,0,0,0,0
iterative/dvc,2944598678,10707,`dvc exp show -A` does not show all experiments,"# Bug Report

## exp show: doesn't show all experiments.

## Description

I have a slightly non-conventional git workflow that involves frequent rebasing and re-writing of history. I have found during this workflow that experiments can be lost from the `dvc exp show -A` view though they can still be interacted with, for example, by running commands like `dvc exp apply <exp-name>`.

For example, my repository has the experiment `./.git/refs/exps/a0/79b1b80f5d926dc321d3abebc13ffc23011e16/vatic-eild`, but it does not appear in `dvc exp show -A` even though I can apply it with `dvc exp apply vatic-eild`.
### Reproduce

I'm not exactly sure how to reproduce the issue. I'm not familiar enough with dvc internals to determine why it would be excluded even though I do have a ref in `.git/refs/exps` for this experiment.

### Expected

I should see *all* experiments when I run `dvc exp show -A`.

### Environment information

<!--
This is required to ensure that we can reproduce the bug.
-->

**Output of `dvc doctor`:**

```console
$ dvc doctor
DVC version: 3.59.1 (pip)
-------------------------
Platform: Python 3.12.9 on macOS-15.3.2-arm64-arm-64bit
Subprojects:
        dvc_data = 3.16.9
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.10
Supports:
        http (aiohttp = 3.11.14, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.14, aiohttp-retry = 2.9.1),
        s3 (s3fs = 2025.3.0, boto3 = 1.37.1)
Config:
        Global: /Users/kevinblissett/Library/Application Support/dvc
        System: /Library/Application Support/dvc
Cache types: reflink, hardlink, symlink
Cache directory: apfs on /dev/disk3s1s1
Caches: local
Remotes: s3
Workspace directory: apfs on /dev/disk3s1s1
Repo: dvc, git
Repo.site_cache_dir: /Library/Caches/dvc/repo/6f599a00529264e4aa3d71daa522caf0
```
",kblissett,17621204,open,False,0,2025-03-24T22:15:22+00:00,2025-03-24T23:15:24+00:00,,feature request;A: experiments,0,0,0,0,0,0,0
iterative/dvc,2943395297,10706,live.log_sklearn_plot Confusion Matrix throws 'Maximum call stack sized exceeded' when called with 1.4M values,"# Bug Report: Live.log_sklearn_plot with 1.4M values

<!--
## Issue name

Issue names must follow the pattern `command: description` where the command is the dvc command that you are trying to run. The description should describe the consequence of the bug.

Example: `repro: doesn't detect input changes`
-->
## Description

I'm training a model where I wanted to log and plot a confusion matrix in the dvc extension.
 
If I'm creating a confusion matrix by myself, I can display and save it in dvc. But if I want to log it in live.log_sklearn_plot and plotting it in the extension, the CPU Performance is reached maximum rapidly when I click on Plot and my IDE throws that Error Message:

    Maximum call stack size exceeded.

DVC can't handle vectors with 1.4M values. 
Alternative way how it could done at the moment is to create a function that is creating the confusion matrix and save it as a tsv-file. 
Afterwards plot it with a custom-made plot in dvc. 

<!--
A clear and concise description of what the bug is.
-->

### Reproduce
Create 2 vectors with over +1 million values. Then log it with live.log_sklearn_plot. After you ran it, open a terminal and look at the CPU Performance. While the terminal is open, start the extension and try to plot it.
For me, it crashes because of overflow.

<!--
Step list of how to reproduce the bug
-->

<!--
Example:

1. dvc init
2. Copy dataset.zip to the directory
3. dvc add dataset.zip
4. dvc run -d dataset.zip -o model ./train.sh
5. modify dataset.zip
6. dvc repro
-->

### Expected
A plot of a confusion matrix in 'Extension: dvc --> plot'
<!--
A clear and concise description of what you expect to happen.
-->

### Environment information
Python 3.10.4
<!--
This is required to ensure that we can reproduce the bug.
-->

**Output of `dvc doctor`:**

```console
$ dvc doctor
```
DVC version: 3.58.0 (pip)
-------------------------
Platform: Python 3.10.4 on Linux-6.8.0-51-generic-x86_64-with-glibc2.39
Subprojects:
        dvc_data = 3.16.7
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.9
Supports:
        http (aiohttp = 3.11.9, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.9, aiohttp-retry = 2.9.1),
        ssh (sshfs = 2024.9.0)
Config:
        Global: /home/dominicbechtold/.config/dvc
        System: /etc/xdg/dvc
Cache types: hardlink, symlink
Cache directory: ext4 on /dev/sda1
Caches: local
Remotes: None
Workspace directory: ext4 on /dev/sda1
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/b2a06e49ddecd45b3f218825ee38d78f
**Additional Information (if any):**

<!--
Please check https://github.com/iterative/dvc/wiki/Debugging-DVC on ways to gather more information regarding the issue.

If applicable, please also provide a `--verbose` output of the command, eg: `dvc add --verbose`.
If the issue is regarding the performance, please attach the profiling information and the benchmark comparisons.
-->
",Krinxy,147256540,open,False,0,2025-03-24T14:09:39+00:00,2025-03-24T23:48:32+00:00,,p3-nice-to-have;performance;A: plots,0,0,0,0,0,0,0
iterative/dvc,2940496153,10705,Replace tqdm progress bars with rich,"Purely a stylistic choice, but I think rich.progress bars have a nicer look and feel (colors etc.). I see `rich` is actually already a dependency - would replacing the tqdm bars with rich ones be considered?",jack-mcivor,10228081,closed,False,1,2025-03-22T16:54:26+00:00,2025-04-29T03:04:22+00:00,2025-04-29T03:04:22+00:00,,0,0,0,0,0,0,0
iterative/dvc,2936335636,10704,repro: overwrites dependencies,"# Bug Report

<!--
## Issue name

Issue names must follow the pattern `command: description` where the command is the dvc command that you are trying to run. The description should describe the consequence of the bug.

Example: `repro: doesn't detect input changes`
-->

## Description
We have a file (let's call it example.csv) that needs to be tracked in its own .dvc file (example.csv.dvc). That file is also a dependency to a pipeline. The .dvc file should be the source of truth specifying the version of the file we want to run the pipeline with. Running dvc repro sometimes instead overwrites the .dvc file of the dependency, turning the dependency into a silent randomly changing output (!!). Confusingly, this happens even if you delete the dvc.lock file. You get a message saying `Verifying data sources in stage: 'path/to/example.csv.dvc'`. It becomes very difficult to actually run the stage without overwriting the dependency.

**Output of `dvc doctor`:**

```console
$ dvc doctor
DVC version: 3.58.0 (pip)
-------------------------
Platform: Python 3.11.6 on Linux-6.8.0-55-generic-x86_64-with-glibc2.35
Subprojects:
        dvc_data = 3.16.7
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.9
Supports:
        http (aiohttp = 3.11.9, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.9, aiohttp-retry = 2.9.1),
        s3 (s3fs = 2024.9.0, boto3 = 1.35.36)
Config:
        Global: /home/mermerico/.config/dvc
        System: /etc/xdg/dvc
Cache types: symlink
Cache directory: zfs on tank
Caches: local
Remotes: s3
Workspace directory: zfs on tank
Repo: dvc, git
Repo.site_cache_dir: /home/mermerico/dvc_site_cache/repo/54ea0ca1cd8a6432245cbe79e3f79d2f
```

**Additional Information (if any):**

<!--
Please check https://github.com/iterative/dvc/wiki/Debugging-DVC on ways to gather more information regarding the issue.

If applicable, please also provide a `--verbose` output of the command, eg: `dvc add --verbose`.
If the issue is regarding the performance, please attach the profiling information and the benchmark comparisons.
-->
",mermerico,3631507,closed,False,0,2025-03-20T18:34:53+00:00,2025-03-20T18:39:39+00:00,2025-03-20T18:39:39+00:00,,0,0,0,0,0,0,0
iterative/dvc,2917937987,10703,`dvc pull` takes ~20 minutes with no console output for 15 minutes unless run with `-v -v`,"# Bug Report: `dvc pull` Takes ~20 Minutes as it collects stages from remote repository for files that were imported. 

## Description
When running `dvc pull`, the command takes around **20 minutes** to complete. 

With `-v -v`, DVC displays repeated trace messages about ‚Äústage collection‚Äù in blocks of 30 lines, each block taking ~30 seconds, repeated almost 30 times in a row.

The stage collection occurs once for each of the 30 files that were imported from the same remote repository.

We have a repository that stores about **31GB** of data in a Google Cloud Storage remote. Approximately **15GB** comes from ~60 main data files, and another **16GB** is apparently from 33 ‚Äútemp‚Äù files that do not seem to be actively used.


For example:

```
2025-03-11 21:09:47,135 TRACE: Context during resolution of stage create-chassis-projects:                                                                                                                                                  
{'paths': {'raw': {'jaguars': 'raw/chevrolet/jaguar-chassis-1.9M.csv'}}}                                                                                                                                                                      
2025-03-11 21:09:47,141 TRACE: Context during resolution of stage unpack-dataset1:                                                                                                                                                          
{'paths': {'raw': {'jaguars': 'raw/chevrolet/jaguar-chassis-1.9M.csv'}}}                                                                                                                                                                      
2025-03-11 21:09:47,146 TRACE: Context during resolution of stage create-muffler-projects:                                                                                                                                                   
{'paths': {'raw': {'jaguars': 'raw/chevrolet/jaguar-chassis-1.9M.csv'}}}                                                                                                                                                                      
2025-03-11 21:09:47,159 TRACE: Context during resolution of stage update-chassis-curation:                                                                                                                                                  
{'paths': {'raw': {'jaguars': 'raw/chevrolet/jaguar-chassis-1.9M.csv'}}}                                                                                                                                                                      
2025-03-11 21:09:47,171 TRACE: Context during resolution of stage update-muffler-curation:                                                                                                                                                   
{'paths': {'raw': {'jaguars': 'raw/chevrolet/jaguar-chassis-1.9M.csv'}}}                                                                                                                                                                      
2025-03-11 21:09:47,190 TRACE: Context during resolution of stage create-chassis-tag-projects:                                                                                                                                              
{'paths': {'raw': {'jaguars': 'raw/chevrolet/jaguar-chassis-1.9M.csv'}}}                                                                                                                                                                      
2025-03-11 21:09:47,200 TRACE:   113.24 ms in collecting stages from /                                                                                                                                                                      
2025-03-11 21:09:47,202 TRACE:     6.73 mks in collecting stages from /annotation                                                                                                                                                           
2025-03-11 21:09:47,204 TRACE:     9.45 mks in collecting stages from /annotation/chassis                                                                                                                                                   
2025-03-11 21:09:47,206 TRACE:     9.99 mks in collecting stages from /annotation/muffler                                                                                                                                                    
2025-03-11 21:09:47,207 TRACE:    10.32 mks in collecting stages from /curation                                                                                                                                                             
2025-03-11 21:09:47,207 TRACE:     4.05 mks in collecting stages from /curation/chassis                                                                                                                                                     
2025-03-11 21:09:47,208 TRACE:     6.49 mks in collecting stages from /curation/muffler                                                                                                                                                      
2025-03-11 21:09:47,209 TRACE:     8.16 mks in collecting stages from /inception                                                                                                                                                            
2025-03-11 21:09:47,209 TRACE:     6.80 mks in collecting stages from /inception/export                                                                                                                                                     
2025-03-11 21:09:47,210 TRACE:    11.79 mks in collecting stages from /inception/export/layer                                                                                                                                               
2025-03-11 21:09:47,210 TRACE:     6.00 mks in collecting stages from /inception/export/schema                                                                                                                                              
2025-03-11 21:09:47,211 TRACE:    12.09 mks in collecting stages from /inception/export/tagset                                                                                                                                              
2025-03-11 21:09:47,216 TRACE:    31.29 mks in collecting stages from /inception/guidelines                                                                                                                                                 
2025-03-11 21:09:47,216 TRACE:    11.20 mks in collecting stages from /project                                                                                                                                                              
2025-03-11 21:09:47,217 TRACE:     7.86 mks in collecting stages from /raw                                                                                                                                                                  
2025-03-11 21:09:47,218 TRACE:    21.03 mks in collecting stages from /raw/chassis                                                                                                                                                          
2025-03-11 21:10:17,196 TRACE:    29.98 s in collecting stages from /raw/muffler                                                                                                                                                             
2025-03-11 21:10:17,197 TRACE:     9.75 mks in collecting stages from /scripts                

```

These repeated logs consume the majority of the command‚Äôs execution time.

## Expected Behavior

1. `dvc pull` should complete in a few minutes to download the ~15GB of actively used data from Google Cloud Storage.


## Observed Behavior

1. The command runs for ~20 minutes in total.
2. `-v -v` reveals repeated 30-line trace blocks that each take ~30 seconds, repeated ~29 times.


## Additional Context

- About **half of the total remote size** is from `.tmp` files on GCS, which appear unused.
- Even ignoring those `.tmp` files, the repeated ‚Äústage collection‚Äù logs and the slow resolution process are unexpected.
- Please find attached the dvc-output.txt, dvc_yaml.txt and params_yaml.txt

We can provide further logs or details if necessary. Thank you for investigating!

[dvc-output.txt](https://github.com/user-attachments/files/19233753/dvc-output.txt)

[dvc_yaml.txt](https://github.com/user-attachments/files/19233830/dvc_yaml.txt)

[params_yaml.txt](https://github.com/user-attachments/files/19233837/params_yaml.txt)",vishvadesai9,49039936,open,False,0,2025-03-13T17:31:04+00:00,2025-04-25T18:56:49+00:00,,triage,1,1,0,0,0,0,0
iterative/dvc,2900582042,10702,dvc exp show: duplicate metric file tracked with different path separators on Linux & Windows,"## Description

Hi,

I'm encountering an issue when using DVC across Linux and Windows. In my DVC pipeline, I track a metric file located at `exp/scores.json`. This works correctly on Linux. However, when I switch to Windows, DVC creates a duplicate entry using the Windows path separator: `exp\scores.json`.

This results in DVC treating them as separate files, leading to inconsistencies in metrics tracking.

![Image](https://github.com/user-attachments/assets/f3785a2e-66bf-44cd-8239-14a9fc627ab4)

### Reproduce

1. On Linux, track a metric file in `dvc.yaml`:
```yaml
metrics:
  - exp/scores.json
``` 
2. Commit and push the changes.
3. Switch to Windows and run dvc repro.
4. Observe that dvc metrics show now lists both `exp/scores.json` and `exp\scores.json` as separate entries.

### Expected

DVC should handle file paths consistently across operating systems, ensuring that `exp/scores.json` and `exp\scores.json` are treated as the same file.

### Environment information


**Output of `dvc doctor`:**

```console
$ dvc doctor
DVC version: 3.59.0 (pip)
-------------------------
Platform: Python 3.13.1 on Windows-11-10.0.22631-SP0
Subprojects:
        dvc_data = 3.16.9
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.10
Supports:
        http (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.11, aiohttp-retry = 2.9.1)
Config:
        Global: C:\Users\dupinb\AppData\Local\iterative\dvc
        System: C:\ProgramData\iterative\dvc
Cache types: hardlink
Cache directory: NTFS on C:\
Caches: local
Remotes: None
Workspace directory: NTFS on C:\
Repo: dvc, git
Repo.site_cache_dir: C:\ProgramData\iterative\dvc\Cache\repo\5645f6a70fc599c92923e5445c0606d4
```",chisuikafuku,35301725,open,False,3,2025-03-06T14:32:19+00:00,2025-03-14T04:15:55+00:00,,A: experiments;P: windows,0,0,0,0,0,0,0
iterative/dvc,2897215090,10701,Allow dvc.yaml templating from non default params files,"Hi! First of all, thanks for your amazing work, I love it and I'm trying to push our team to use it on daily basis.

I'm trying to have multiple pipelines to handle different behaviors in a RAG library : a synthetic dataset generation and a RAG execution.

I have divided a folder `pipelines` into  2 subfolders `rag` and `synth_dataset_generation`, which have their own `dvc.yaml` and `params.yaml`, but they have some parameters in common, in `global_params.yaml`, which I'm trying to use to template their respective `dvc.yaml`. However, no matter how I try to structure its reference, I always get a  `dvc.parsing.ResolveError: failed to parse 'stages.data_extraction.cmd' in 'pipelines/rag/dvc.yaml': Could not find 'input_data'`.

I've tried to debug it with `dvc repro -vvvv` and it seems that the context stays empty from any key/value of `global_params.yaml` : 
```
Context during resolution of stage data_extraction:
{}
```

I've stumbled upon this issue while dividing my main pipeline in 2 others, but I've explored this behaviour in a test repo and it seems impossible to template my `dvc.yaml` with values from a param file other than the default one. ([here is the link to it](https://github.com/Gwenn-LR/templating_dvc_with_parameters))

So I was wondering if it was an expected behaviour or if you could add this feature  ?

Thank you for your consideration. ",Gwenn-LR,95341944,closed,False,7,2025-03-05T12:36:31+00:00,2025-03-05T15:03:54+00:00,2025-03-05T15:03:53+00:00,awaiting response,0,0,0,0,0,0,0
iterative/dvc,2896531670,10700,Broken Huggingface Datasets integration,"# Bug Report

<!--
## Issue name

Issue names must follow the pattern `command: description` where the command is the dvc command that you are trying to run. The description should describe the consequence of the bug.

Example: `repro: doesn't detect input changes`
-->

## Description

The DVC integration seems to be broken. 
Followed this guide: https://dvc.org/doc/user-guide/integrations/huggingface

### Reproduce

~~~python
from datasets import load_dataset

dataset = load_dataset(
    ""csv"",
    data_files=""dvc://workshop/satellite-data/jan_train.csv"",
    storage_options={""url"": ""https://github.com/iterative/dataset-registry.git""},
)

print(dataset)
~~~

~~~
Traceback (most recent call last):
  File ""C:\tmp\test\load.py"", line 3, in <module>
    dataset = load_dataset(
              ^^^^^^^^^^^^^
  File ""C:\tmp\test\.venv\Lib\site-packages\datasets\load.py"", line 2151, in load_dataset
    builder_instance.download_and_prepare(
  File ""C:\tmp\test\.venv\Lib\site-packages\datasets\builder.py"", line 808, in download_and_prepare
    fs, output_dir = url_to_fs(output_dir, **(storage_options or {}))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: url_to_fs() got multiple values for argument 'url'
~~~


### Expected

Integration would work and the indicated file is downloaded and opened.

### Environment information

#### Python version
~~~
python --version
Python 3.11.10
~~~

#### Venv (pip install datasets dvc):
~~~
Package                Version
---------------------- -----------
aiohappyeyeballs       2.4.6
aiohttp                3.11.13
aiohttp-retry          2.9.1
aiosignal              1.3.2
amqp                   5.3.1
annotated-types        0.7.0
antlr4-python3-runtime 4.9.3
appdirs                1.4.4
asyncssh               2.20.0
atpublic               5.1
attrs                  25.1.0
billiard               4.2.1
celery                 5.4.0
certifi                2025.1.31
cffi                   1.17.1
charset-normalizer     3.4.1
click                  8.1.8
click-didyoumean       0.3.1
click-plugins          1.1.1
click-repl             0.3.0
colorama               0.4.6
configobj              5.0.9
cryptography           44.0.1
datasets               3.3.2
dictdiffer             0.9.0
dill                   0.3.8
diskcache              5.6.3
distro                 1.9.0
dpath                  2.2.0
dulwich                0.22.7
dvc                    3.59.1
dvc-data               3.16.9
dvc-http               2.32.0
dvc-objects            5.1.0
dvc-render             1.0.2
dvc-studio-client      0.21.0
dvc-task               0.40.2
entrypoints            0.4
filelock               3.17.0
flatten-dict           0.4.2
flufl-lock             8.1.0
frozenlist             1.5.0
fsspec                 2024.12.0
funcy                  2.0
gitdb                  4.0.12
gitpython              3.1.44
grandalf               0.8
gto                    1.7.2
huggingface-hub        0.29.1
hydra-core             1.3.2
idna                   3.10
iterative-telemetry    0.0.10
kombu                  5.4.2
markdown-it-py         3.0.0
mdurl                  0.1.2
multidict              6.1.0
multiprocess           0.70.16
networkx               3.4.2
numpy                  2.2.3
omegaconf              2.3.0
orjson                 3.10.15
packaging              24.2
pandas                 2.2.3
pathspec               0.12.1
platformdirs           4.3.6
prompt-toolkit         3.0.50
propcache              0.3.0
psutil                 7.0.0
pyarrow                19.0.1
pycparser              2.22
pydantic               2.10.6
pydantic-core          2.27.2
pydot                  3.0.4
pygit2                 1.17.0
pygments               2.19.1
pygtrie                2.5.0
pyparsing              3.2.1
python-dateutil        2.9.0.post0
pytz                   2025.1
pywin32                308
pyyaml                 6.0.2
requests               2.32.3
rich                   13.9.4
ruamel-yaml            0.18.10
ruamel-yaml-clib       0.2.12
scmrepo                3.3.10
semver                 3.0.4
setuptools             75.8.0
shellingham            1.5.4
shortuuid              1.0.13
shtab                  1.7.1
six                    1.17.0
smmap                  5.0.2
sqltrie                0.11.2
tabulate               0.9.0
tomlkit                0.13.2
tqdm                   4.67.1
typer                  0.15.1
typing-extensions      4.12.2
tzdata                 2025.1
urllib3                2.3.0
vine                   5.1.0
voluptuous             0.15.2
wcwidth                0.2.13
xxhash                 3.5.0
yarl                   1.18.3
zc-lockfile            3.0.post1
~~~

**Additional Information (if any):**

- Raised the issue already in [huggingface/datasets](https://github.com/huggingface/datasets): https://github.com/huggingface/datasets/issues/7421

> Unfortunately `url` is a reserved argument in `fsspec.url_to_fs`, so ideally file system implementations like DVC should use another argument name to avoid this kind of errors

",maxstrobel,34747372,open,False,2,2025-03-05T07:52:22+00:00,2025-05-07T02:26:03+00:00,,bug,2,2,0,0,0,0,0
iterative/dvc,2891969304,10699,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.9.4 ‚Üí v0.9.9](https://github.com/astral-sh/ruff-pre-commit/compare/v0.9.4...v0.9.9)
<!--pre-commit.ci end-->",pre-commit-ci[bot],66853113,closed,False,0,2025-03-03T18:20:34+00:00,2025-03-07T02:21:16+00:00,2025-03-07T02:21:15+00:00,,0,0,0,0,0,0,0
iterative/dvc,2890586708,10698,invalid dvc.org/deb signing key,"# invalid dvc.org/deb signing key

## Description

`apt update` reports the following error:

```
W: Failed to fetch https://dvc.org/deb/dists/stable/InRelease  The following signatures were invalid: EXPKEYSIG EFFAF4443CE9AD84 Iterative <eng@iterative.ai>
```

I'm on debian stable bookworm and have never had issues updating/upgrading dvc via apt.

My `/etc/apt/sources.list.d/dvc.list` contains:

`deb [trusted=yes] https://dvc.org/deb/ stable main`

",sebitz,101337787,closed,False,2,2025-03-03T09:00:05+00:00,2025-03-04T16:01:34+00:00,2025-03-04T16:01:33+00:00,,0,0,0,0,0,0,0
iterative/dvc,2888255871,10697,`dvc run exp --queue` gives unclear error without committed pipeline files,"# Bug Report


## `dvc exp run --queue`: fails with ""No such file or directory"" on a cache path similar to .dvc/tmp/exps

## Description

1. It appears that `dvc exp run --queue` only works on DVC pipelines that have been previously committed to git
2. The error from this is not clear

When running a queued experiment with `dvc exp run --queue`, the job is queued and can be started with `dvc queue start`. However, it will fail with an error similar to `ERROR: unexpected error - [Errno 2] No such file or directory: '[path to repo]/.dvc/tmp/exps/tmpabc123/...`.

The same experiment can be successfully run with `dvc repro` and `dvc exp run`. It appears to work once the pipeline is committed with git, which suggests this is either the cause or related to the issue but there is no mention of this in the error message.

Also, once the pipeline is committed and a new uncommitted change made, it calls into question which version of the pipeline is being run - the committed version, or the ""dirty"" version in the current directory.

#### Other minor issues

These can be separate issues if required.

 - print statements are not shown in `--follow` unless explicitly flushed, though this may just be unavoidable celery behaviour
 - when running `dvc queue logs [task]` on task that requires some slow dvc checkout startup, it gives a ""no logs available"" message, but using `--follow` it gives `ERROR: unexpected error - : [Errno 2] No such file or directory: '/[path to repo]/.dvc/tmp/exps/run/[uuid]/[uuid].json`. The same command later succeeds, presumably once the job has actually started.
 - the UTC timestamps shown by `dvc queue status` move to `MM DD, YYYY` format on the next day, which hides helpful time info, especially if you don't work in UTC (i.e. this can happen during the day)

### Reproduce

1. Create a new repo: `mkdir /tmp/example; cd /tmp/example; git init; dvc init;`
2. Create a pipeline: `mkdir pipeline` and copy the following as files:
main.py
```import time
  
start_time = time.time()

while time.time() - start_time < 10:
    print(""Running at"", time.time())
    time.sleep(5)
```
dvc.yaml
```
stages:
  main:
    cmd: python3 main.py
```
3. Run `dvc repro`: pipeline runs successfully
4. Run `dvc exp run`: experiment cannot be run without an existing git commit (not really a problem in most repos, plus has a good error message)
5. Run `git commit -m ""Setup repo""` to commit init files but not the pipeline files to create a least one commit in the repo
6. Run `dvc exp run`: experiment runs successfully
7. Run `dvc exp run --queue`: command runs successfully
8. Run `dvc queue start`: command runs successfully
9. Run `dvc queue logs [task name]`: shows ""ERROR: unexpected error - [Errno 2] No such file or directory""
10. Run `dvc queue status`: task shown as ""Failed""
11. Commit pipeline files
12. Re-run steps 7 and 8
13. Run `dvc queue logs [task name]`: no error, task running as expected
14. Run `dvc queue status`: task eventually shown as success
15. Bonus: Run `dvc queue logs [task name] --follow`: note that print statements are not shown until end of task, unless `sys.stdout.flush()` is called


### Expected

Either `dvc exp run --queue` should work without first committing the pipeline, or a clear error message should be shown indicating it needs to be committed first.

If a committed pipeline is required it should be clear whether the committed version or the current ""dirty"" version of the pipeline is being run.

### Environment information

```
DVC version: 3.51.2 (pip)
-------------------------
Platform: Python 3.10.12 on Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.35
Subprojects:
        dvc_data = 3.15.1
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.4.0
        scmrepo = 3.3.6
Supports:
        http (aiohttp = 3.9.5, aiohttp-retry = 2.8.3),
        https (aiohttp = 3.9.5, aiohttp-retry = 2.8.3),
        s3 (s3fs = 2024.6.1, boto3 = 1.34.131)
Config:
        Global: ~/.config/dvc
        System: /etc/xdg/dvc
Cache types: <https://error.dvc.org/no-dvc-cache>
Caches: local
Remotes: None
Workspace directory: ext4 on /dev/sdc
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/c8f65ca41ec45168d44ff0121e3c0037
```

",pwithams,59623218,open,False,2,2025-02-28T23:54:04+00:00,2025-03-24T12:33:48+00:00,,,2,0,0,0,0,0,0
iterative/dvc,2885079344,10695,"push: ""Checksum Type mismatch occurred"" when pushing to Wasabi (S3 compatible)","# Bug Report

## Description

Pushing individual files to our established bucket at Wasabi (S3-compatible cloud store), we get:

```
(S3 ACCESS and SECRET KEY defined in environment variables)
$ dvc push <push some_large_file>
Collecting                                                                          |0.00 [00:00,    ?entry/s]
ERROR: failed to transfer '4041c2812ed00efb5a0d57de2b8a9c4d' - [Errno 22] Checksum Type mismatch occurred, expected checksum Type: null, actual checksum Type: crc32: An error occurred (InvalidRequest) when calling the UploadPart operation: Checksum Type mismatch occurred, expected checksum Type: null, actual checksum Type: crc32
Pushing
ERROR: failed to push data to the cloud - 1 files failed to upload 
```

This is a bucket we have used consistently over the last ~2-3 years.  We are able to pull from the bucket (i.e. it is not an acccess key issue)

### Reproduce

1. Set up S3 bucket at Wasabi.
2. git init my_repo
3. dvc init
4. dvc remote add -d wasabi s3://bucket-name/
5. dvc remote modify wasabi endpointurl   https://s3.us-west-1.wasabisys.com
6. dvc add big_file.txt
7. AWS_ACCESS_KEY_ID=""user"" AWS_SECRET_ACCESS_KEY=""secret"" dvc push -r wasabi big_file.txt

### Expected

File should be pushed to S3 remote and available for pulling by other users.

### Environment information

Tested on both Ubuntu 24.04 and 20.04.   DVC from snap:

```
$ snap info dvc
name:      dvc
summary:   Data Version Control
publisher: Casper (casper-dcl)
store-url: https://snapcraft.io/dvc
contact:   support@dvc.org
license:   Apache-2.0
description: |
  Git for Data & Models https://dvc.org
commands:
  - dvc
snap-id:      ceYKZQ2pf75cN9OVM33Bk36vVEwz3HaP
tracking:     v2/stable
refresh-date: yesterday at 13:58 PST
channels:
  latest/stable:    3.59.1  2025-02-16 (1488) 404MB classic
...                            
  v2/stable:        3.59.1  2025-02-16 (1488) 404MB classic
```

```
$ dvc doctor
DVC version: 3.59.1 (snap)
--------------------------
Platform: Python 3.12.9 on Linux-6.8.0-54-generic-x86_64-with-glibc2.31
Subprojects:
        dvc_data = 3.16.9
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.10
Supports:
        azure (adlfs = 2024.12.0, knack = 0.12.0, azure-identity = 1.20.0),
        gdrive (pydrive2 = 1.21.3),
        gs (gcsfs = 2025.2.0),
        hdfs (fsspec = 2025.2.0, pyarrow = 19.0.0),
        http (aiohttp = 3.11.12, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.12, aiohttp-retry = 2.9.1),
        oss (ossfs = 2023.12.0),
        s3 (s3fs = 2025.2.0, boto3 = 1.36.3),
        ssh (sshfs = 2025.2.0),
        webdav (webdav4 = 0.10.0),
        webdavs (webdav4 = 0.10.0),
        webhdfs (fsspec = 2025.2.0)
Config:
        Global: /home/aaron/.config/dvc
        System: /etc/dvc
Cache types: hardlink, symlink
Cache directory: zfs on zvol1/home/aaron
Caches: local
Remotes: s3, s3
Workspace directory: zfs on zvol1/home/aaron
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/f92fa966085d661846d8ea2e53107206
```



**Additional Information (if any):**

Here's the output from `dvc push -r wasabi --verbose <filename>`:   [output.txt](https://github.com/user-attachments/files/19013277/output.txt)


<!--
Please check https://github.com/iterative/dvc/wiki/Debugging-DVC on ways to gather more information regarding the issue.

If applicable, please also provide a `--verbose` output of the command, eg: `dvc add --verbose`.
If the issue is regarding the performance, please attach the profiling information and the benchmark comparisons.
-->
",amarburg,122743,closed,False,2,2025-02-27T16:53:50+00:00,2025-02-27T17:27:52+00:00,2025-02-27T17:27:50+00:00,bug;upstream;fs: s3,0,0,0,0,0,0,0
iterative/dvc,2869006927,10693,Support Win Btrfs reflinks on Windows,"When using Windows you can install additional drivers such as https://github.com/maharmstone/btrfs 
This allows Btrfs to make reflinks, but understandably DVC doesn't look for reflink on Windows;

I looked at the driver code and the DLL allows reflinking. 

https://github.com/maharmstone/btrfs?tab=readme-ov-file#commands

Could this be supported? I think it looks like a ctypes dll call is all that is needed.
[dvc objects fs.system.py#L85](https://github.com/iterative/dvc-objects/blob/035f53e1f6d987cf60597bd18e3f07d99bf8a453/src/dvc_objects/fs/system.py#L85)
Probably best to put it behind a feature flag.

DVC Doctor reports the following - importantly is determines the volume format as Btrfs:

```
PS E:\dvc-testing> dvc doctor
DVC version: 3.59.1 (pip)
-------------------------
Platform: Python 3.12.9 on Windows-11-10.0.22631-SP0
Subprojects:
        dvc_data = 3.16.9
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.10
Supports:
        http (aiohttp = 3.11.12, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.12, aiohttp-retry = 2.9.1)
Config:
        Global: C:\Users\joesct\AppData\Local\iterative\dvc
        System: C:\ProgramData\iterative\dvc
Cache types: hardlink, symlink
Cache directory: Btrfs on E:\
Caches: local
Remotes: None
Workspace directory: Btrfs on E:\
Repo: dvc (no_scm)
Repo.site_cache_dir: C:\ProgramData\iterative\dvc\Cache\repo\1b84a929dd5801ebca5205d220f7345f
```",thisiswhereitype,17139430,closed,False,2,2025-02-21T13:16:35+00:00,2025-02-21T18:09:01+00:00,2025-02-21T18:08:59+00:00,help wanted;p3-nice-to-have;P: windows,0,0,0,0,0,0,0
iterative/dvc,2867098693,10692,dvc add no longer working,"# Bug Report


## Issue name

dvc add <filename> causes an unexpected error:


## Description

I've had DVC running on a Linux server for the past 3 months. Yesterday I set up a new conda environment with DVC 3.59.1 and now when I add data with ""dvc add xxx"" I get the following error:  

""Adding... ERROR: unexpected error - no such column: ""size"" - should this be a string literal in single-quotes?"". 

Let me add that I have tried to reset DVC (""dvc init"") and I have also deleted the .dvc directory and started from scratch, but the error persists. Maybe I made a mistake deleting the .dvc directory. Is there something else I need to do for a complete dvc reset?

### Reproduce

1. conda install dvc==3.57.0
2. git init
3. dvc init
4. dvc add data/testfile.txt

### Expected

Dvc adds file and does not show an error.

### Environment information

Ubuntu 20.04
DVC 3.57.0

**Output of `dvc doctor`:**

```console
$ dvc doctor
```
DVC version: 3.57.0 (conda)
---------------------------
Platform: Python 3.9.21 on Linux-6.8.0-52-generic-x86_64-with-glibc2.35
Subprojects:
        dvc_data = 3.16.9
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.10
Supports:
        http (aiohttp = 3.11.12, aiohttp-retry = 2.8.3),
        https (aiohttp = 3.11.12, aiohttp-retry = 2.8.3)
Config:
        Global: /home/uli/.config/dvc
        System: /etc/xdg/dvc
Cache types: <https://error.dvc.org/no-dvc-cache>
Caches: local
Remotes: None
Workspace directory: ext4 on /dev/nvme0n1
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/1efc5571a372d9b6285ce7e59990bbae

<!--
Please check https://github.com/iterative/dvc/wiki/Debugging-DVC on ways to gather more information regarding the issue.

If applicable, please also provide a `--verbose` output of the command, eg: `dvc add --verbose`.
If the issue is regarding the performance, please attach the profiling information and the benchmark comparisons.
-->
",wappler99,16543721,closed,False,20,2025-02-20T19:37:03+00:00,2025-04-16T12:10:08+00:00,2025-03-19T13:22:19+00:00,bug;upstream,8,7,0,0,0,1,0
iterative/dvc,2865102336,10691,speed up checksum checks for large files,"Hey DVC devs!

First off, a huge thank you for creating this brilliant project. It has been a game-changer for our data science projects.

In our work with lot of large input files (2 - 50+ GB), we've noticed that the checksum checks for these files are incredibly slow. Is there any plan or interest in speeding up the checksum checks? Are there any options to utilize integrated file system checksums or faster implementations of checksum calculations?

Thanks a ton!

Tom",tschwarzl,62601256,closed,False,9,2025-02-20T05:13:41+00:00,2025-03-14T04:04:50+00:00,2025-03-14T04:04:50+00:00,,0,0,0,0,0,0,0
iterative/dvc,2861579411,10690,"dvc add: ""Invalid private key"" when using agent and specifying key with public key","# Bug Report

<!--
## Issue name

Issue names must follow the pattern `command: description` where the command is the dvc command that you are trying to run. The description should describe the consequence of the bug.

Example: `repro: doesn't detect input changes`
-->

## Description

I use an ssh agent with dozens of keys at a time. To avoid ""Too many authentication failures"" I must specify which private key my agent should use by adding an `Identity File <path to corresponding public key>` line to each of my hosts. Somewhere in the SSH stack that DVC uses (based on traceback info I'm guessing sshfs), this key loaded as a private key, which it of course fails the format checks on.

I took a look in the dvc_ssh client.py as well, and I'm not sure this case is handled properly there either.

Traceback I grabbed by setting logging output file: [dvc_ssh_debug.log](https://github.com/user-attachments/files/18854024/dvc_ssh_debug.log)

### Reproduce

1. Generate an ssh keypair with `ssh-keygen`
2. Install the public key to an `authorized_keys` file on a remote server with `ssh-copy-id`
3. Install the private key to a local ssh-agent with `ssh-add`
4. Edit your `~/.ssh/config` to include:
```
Host <remote server>
    Hostname <remote hostname>
    IdentityFile <path to key>.pub
```
5. In a new repo: `dvc init`
6. `dvc remote add remotessh ssh://<remote server>/<path>`
7. `dvc add -r remotessh --to-remote mydata`

Throws: ERROR: unexpected error - Invalid private key

### Expected

dvc specifies to the agent which key to use using the provided public key

### Environment information

<!--
This is required to ensure that we can reproduce the bug.
-->

**Output of `dvc doctor`:**

```console
DVC version: 3.59.1 (pip)
-------------------------
Platform: Python 3.13.1 on Linux-6.8.0-52-generic-x86_64-with-glibc2.35
Subprojects:
        dvc_data = 3.16.9
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.10
Supports:
        http (aiohttp = 3.11.12, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.12, aiohttp-retry = 2.9.1),
        ssh (sshfs = 2025.2.0)
Config:
        Global: /home/myuser/.config/dvc
        System: /etc/xdg/dvc
Cache types: hardlink, symlink
Cache directory: ext4 on /dev/mapper/vgubuntu-root
Caches: local
Remotes: ssh, ssh
Workspace directory: ext4 on /dev/mapper/vgubuntu-root
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/6cf41b69515915320785cfda6839dd61
```

**Additional Information (if any):**

<!--
Please check https://github.com/iterative/dvc/wiki/Debugging-DVC on ways to gather more information regarding the issue.

If applicable, please also provide a `--verbose` output of the command, eg: `dvc add --verbose`.
If the issue is regarding the performance, please attach the profiling information and the benchmark comparisons.
-->
",weberbr,54183565,closed,False,2,2025-02-18T20:33:58+00:00,2025-05-05T03:58:28+00:00,2025-05-05T03:58:27+00:00,triage;fs: ssh,0,0,0,0,0,0,0
iterative/dvc,2850639061,10689,Support for refreshing access tokens for authentification of WebDAV remote,"This was already discussed at:

https://discuss.dvc.org/t/updating-refreshed-oidc-token-in-config-local/2296?u=matthias

When using a WebDAV remote the token for authentication can be stored in the `config.local` file with 

` dvc remote modify --local hifis token <token>`

I use oidc-agent for authentication, which creates a new refreshed access token every 5 minutes, so the token in the `config.local` file has to be updated every 5 minutes. It would be nice if it would be possible to define the command , for oidc-agent this would be `oidc-token <config_name>`, that returns the current access token, so DVC can always use this current access token and it does not have to be updated in the `config.local` file all the time. For example rclone is doing it like this.",Matt1h,83637690,open,False,0,2025-02-13T10:35:26+00:00,2025-03-14T04:12:02+00:00,,help wanted;fs: webdav,0,0,0,0,0,0,0
iterative/dvc,2850268946,10688,Command: dvc get: Uninformative exception is thrown,"# Bug Report

## Description
When executing dvc get <url> <data> I get the following uninformative exception:
`
08:42:42 ERROR: failed to get '<data>' - SCM error: Failed to clone repo '<url>' to '/tmp/tmpn5ad473gdvc-clone': can't concat tuple to bytes
`

<!--
A clear and concise description of what the bug is.
-->

### Reproduce

<!--
Step list of how to reproduce the bug
-->
`
dvc get <url> <data> -o <output>
`
<!--
Example:
-->

### Expected
Data is downloaded or if there is a network / authentification issue, a more informative exception should be raised.

<!--
A clear and concise description of what you expect to happen.
-->

### Environment information
If there is an authentification problem, network problem I would expect an Exception that would better show what the problem is.

<!--
This is required to ensure that we can reproduce the bug.
-->

**Output of `dvc doctor`:**

```console
$ dvc doctor
08:59:19 Platform: Python 3.8.10 on Linux-5.15.0-97-generic-x86_64-with-glibc2.29
08:59:19 Subprojects:
08:59:19 	dvc_data = 3.8.0
08:59:19 	dvc_objects = 3.0.6
08:59:19 	dvc_render = 1.0.1
08:59:19 	dvc_task = 0.40.2
08:59:19 	scmrepo = 2.0.4
08:59:19 Supports:
08:59:19 	http (aiohttp = 3.8.4, aiohttp-retry = 2.9.1),
08:59:19 	https (aiohttp = 3.8.4, aiohttp-retry = 2.9.1),
08:59:19 	ssh (sshfs = 2025.2.0)
08:59:19 Config:
08:59:19 	Global: /home/buildfarm/.config/dvc
08:59:19 	System: /etc/xdg/dvc
```

**Additional Information (if any):**

<!--
Please check https://github.com/iterative/dvc/wiki/Debugging-DVC on ways to gather more information regarding the issue.

If applicable, please also provide a `--verbose` output of the command, eg: `dvc add --verbose`.
If the issue is regarding the performance, please attach the profiling information and the benchmark comparisons.
-->
",jeferal,62122095,closed,False,1,2025-02-13T08:03:11+00:00,2025-02-13T09:09:25+00:00,2025-02-13T09:07:14+00:00,,0,0,0,0,0,0,0
iterative/dvc,2840464777,10687,ls/ls-url: do not show size for entry with size<=0 for a directory,,skshetry,18718008,closed,False,0,2025-02-09T06:13:07+00:00,2025-02-09T13:27:24+00:00,2025-02-09T06:31:53+00:00,,0,0,0,0,0,0,0
iterative/dvc,2836217717,10686,doctor/version: reports incorrect cache types,"## Description

I am running on Linux with ZFS with reflinks (""block cloning"") enabled.

I have set option `cache.type` to `reflink`. When I run `strace -e trace=ioctl dvc checkout -R --relink`, the strace output shows that reflinks are created as I can see `ioctl(11, BTRFS_IOC_CLONE or FICLONE, 10) = 0` in the the output.

I've checked and the checked out files do not share inodes with files in the cache (so they are not hard links), and they are not symbolic links either.

But when I run `dvc version`, it incorrectly reports that the cache types are hardlinks and symlinks.

### Reproduce

git clone https://github.com/iterative/dataset-registry
cd dataset-registry
dvc config cache.type reflink
dvc fetch tutorials/versioning/data.zip.dvc
strace -e trace=ioctl dvc checkout --relink -v tutorials/versioning/data.zip.dvc

dvc version reports cache type is `hardlink, symlink` but links are reflinks:

```console
ls -li .dvc/cache/files/md5/fa/9c0eb4173d86695b4e800219651360
1641654 -r--r--r-- 1 james users 41122310 Feb  6 11:48 .dvc/cache/files/md5/fa/9c0eb4173d86695b4e800219651360

ls -li tutorials/versioning/data.zip 
1642760 -rw-r--r-- 1 james users 41122310 Feb  6 11:49 tutorials/versioning/data.zip
```

### Expected

Cache types should report reflinks.

### Environment information

**Output of `dvc doctor`:**

```console
DVC version: 3.59.0
-------------------
Platform: Python 3.12.8 on Linux-6.6.74-x86_64-with-glibc2.40
Subprojects:
	dvc_data = 3.16.8
	dvc_objects = 5.1.0
	dvc_render = 1.0.2
	dvc_task = 0.40.2
	scmrepo = 3.3.9
Supports:
	http (aiohttp = 3.11.11, aiohttp-retry = 2.8.3),
	https (aiohttp = 3.11.11, aiohttp-retry = 2.8.3)
Config:
	Global: /home/james/.config/dvc
	System: /etc/xdg/dvc
Cache types: hardlink, symlink
Cache directory: zfs on rpool/enc/home/james
Caches: local
Remotes: https, https
Workspace directory: zfs on rpool/enc/home/james
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/e33a1b717bf68539c232b23815d8e852
```

**Additional Information (if any):**

<!--
Please check https://github.com/iterative/dvc/wiki/Debugging-DVC on ways to gather more information regarding the issue.

If applicable, please also provide a `--verbose` output of the command, eg: `dvc add --verbose`.
If the issue is regarding the performance, please attach the profiling information and the benchmark comparisons.
-->
",james-atkins,9221409,closed,False,6,2025-02-06T17:55:59+00:00,2025-02-07T15:12:18+00:00,2025-02-07T03:11:34+00:00,,0,0,0,0,0,0,0
iterative/dvc,2834462106,10685,pre-commit: set autoupdate schedule to monthly,,skshetry,18718008,closed,False,0,2025-02-06T03:47:54+00:00,2025-02-06T03:48:06+00:00,2025-02-06T03:48:05+00:00,,0,0,0,0,0,0,0
iterative/dvc,2834395884,10684,build(deps): bump mypy from 1.14.1 to 1.15.0,"Bumps [mypy](https://github.com/python/mypy) from 1.14.1 to 1.15.0.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/python/mypy/blob/master/CHANGELOG.md"">mypy's changelog</a>.</em></p>
<blockquote>
<h1>Mypy Release Notes</h1>
<h2>Next Release</h2>
<p>...</p>
<h2>Mypy 1.15</h2>
<p>We‚Äôve just uploaded mypy 1.15 to the Python Package Index (<a href=""https://pypi.org/project/mypy/"">PyPI</a>).
Mypy is a static type checker for Python. This release includes new features, performance
improvements and bug fixes. You can install it as follows:</p>
<pre><code>python3 -m pip install -U mypy
</code></pre>
<p>You can read the full documentation for this release on <a href=""http://mypy.readthedocs.io"">Read the Docs</a>.</p>
<h3>Performance Improvements</h3>
<p>Mypy is up to 40% faster in some use cases. This improvement comes largely from tuning the performance
of the garbage collector. Additionally, the release includes several micro-optimizations that may
be impactful for large projects.</p>
<p>Contributed by Jukka Lehtosalo</p>
<ul>
<li>PR <a href=""https://redirect.github.com/python/mypy/pull/18306"">18306</a></li>
<li>PR <a href=""https://redirect.github.com/python/mypy/pull/18302"">18302</a></li>
<li>PR <a href=""https://redirect.github.com/python/mypy/pull/18298"">18298</a></li>
<li>PR <a href=""https://redirect.github.com/python/mypy/pull/18299"">18299</a></li>
</ul>
<h3>Mypyc Accelerated Mypy Wheels for ARM Linux</h3>
<p>For best performance, mypy can be compiled to C extension modules using mypyc. This makes
mypy 3-5x faster than when interpreted with pure Python. We now build and upload mypyc
accelerated mypy wheels for <code>manylinux_aarch64</code> to PyPI, making it easy for Linux users on
ARM platforms to realise this speedup -- just <code>pip install</code> the latest mypy.</p>
<p>Contributed by Christian Bundy and Marc Mueller
(PR <a href=""https://redirect.github.com/mypyc/mypy_mypyc-wheels/pull/76"">mypy_mypyc-wheels#76</a>,
PR <a href=""https://redirect.github.com/mypyc/mypy_mypyc-wheels/pull/89"">mypy_mypyc-wheels#89</a>).</p>
<h3><code>--strict-bytes</code></h3>
<p>By default, mypy treats <code>bytearray</code> and <code>memoryview</code> values as assignable to the <code>bytes</code>
type, for historical reasons. Use the <code>--strict-bytes</code> flag to disable this
behavior. <a href=""https://peps.python.org/pep-0688"">PEP 688</a> specified the removal of this
special case. The flag will be enabled by default in <strong>mypy 2.0</strong>.</p>
<p>Contributed by Ali Hamdan (PR <a href=""https://redirect.github.com/python/mypy/pull/18263"">18263</a>) and
Shantanu Jain (PR <a href=""https://redirect.github.com/python/mypy/pull/13952"">13952</a>).</p>
<h3>Improvements to Reachability Analysis and Partial Type Handling in Loops</h3>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/python/mypy/commit/9397454fb5aead107461b089e7cf190bf538d20a""><code>9397454</code></a> remove +dev from version ahead of final release</li>
<li><a href=""https://github.com/python/mypy/commit/686b591a69db216f714ad50698db785f4ac63eb0""><code>686b591</code></a> remove &quot;unreleased&quot; from 1.15 changelog entry</li>
<li><a href=""https://github.com/python/mypy/commit/cb4b243a5d9e03173e3e7275e5b92b98afaefb60""><code>cb4b243</code></a> Various small updates to 1.15 changelog (<a href=""https://redirect.github.com/python/mypy/issues/18599"">#18599</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/1a265024f901399c701a772e8c1f9e6e110f45e6""><code>1a26502</code></a> Prepare changelog for 1.15 release (<a href=""https://redirect.github.com/python/mypy/issues/18583"">#18583</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/d4515e4ad3eee6318744c64cf2eab0ea0b5b7562""><code>d4515e4</code></a> Fix a few PR links in the changelog (<a href=""https://redirect.github.com/python/mypy/issues/18586"">#18586</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/f83b6435b0c07a327f6b567dfb5e79ffa36708a2""><code>f83b643</code></a> Add object self-type to tuple test fixture (<a href=""https://redirect.github.com/python/mypy/issues/18592"">#18592</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/ebc2cb8befbadfc10b962af018b3fa3842d3fd87""><code>ebc2cb8</code></a> Prevent crash on generic NamedTuple with unresolved typevar bound (<a href=""https://redirect.github.com/python/mypy/issues/18585"">#18585</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/63c251e249e52256629dbe8b8334937a092f792d""><code>63c251e</code></a> empty commit to trigger wheel rebuild</li>
<li><a href=""https://github.com/python/mypy/commit/c30573e7b95eef9d057ff42ebfd326438dac3c42""><code>c30573e</code></a> Fix literal context for ternary expressions (for real) (<a href=""https://redirect.github.com/python/mypy/issues/18545"">#18545</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/23d862dd6fbb905a69bcb31e88746dc7a1eb4a43""><code>23d862d</code></a> Fix isinstance with explicit (non generic) type alias (<a href=""https://redirect.github.com/python/mypy/issues/18512"">#18512</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/python/mypy/compare/v1.14.1...v1.15.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mypy&package-manager=pip&previous-version=1.14.1&new-version=1.15.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],49699333,closed,False,0,2025-02-06T02:44:51+00:00,2025-02-06T03:45:39+00:00,2025-02-06T03:45:37+00:00,,0,0,0,0,0,0,0
iterative/dvc,2830307096,10683,dvc exp push fails if git connection is over a proxyjump,"## Description

Hey,

I have to use an ssh proxyjump to connect to my git repository. Sadly this results in all the dvc commands that rely on the remote failing.

### Reproduce

If I run a normal git command everything is fine and I get prompted for the 2fa for the ssh server.
```
(demultiple) [fuchsfa@cerberus04:demultiple]$ git push
(fuchsfa@ssh2.itwm.fhg.de) Password: 
(fuchsfa@ssh2.itwm.fhg.de) Verification code: 
Enter passphrase for key 'path': 
Everything up-to-date
```

Sadly dvc does not prompt me for my credentials but instead just fails.
```
(demultiple) [fuchsfa@cerberus04:demultiple]$ dvc exp push origin -v
2025-02-04 14:31:46,636 DEBUG: v3.56.0 (pip), CPython 3.12.7 on Linux-5.15.0-131-generic-x86_64-with-glibc2.36
2025-02-04 14:31:46,637 DEBUG: command: /home/fuchsfa/demultiple/.venv/bin/dvc exp push origin -v
2025-02-04 14:31:49,347 DEBUG: git push experiment [] -> 'origin'     
2025-02-04 14:31:50,899 ERROR: Authentication failed for: 'GIT_SERVER'                                                                                                                                                                                                                                                                                                                                                                                                 
See https://dvc.org/doc/user-guide/troubleshooting#git-auth
Traceback (most recent call last):
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/scmrepo/git/backend/dulwich/asyncssh_vendor.py"", line 297, in _run_command
    conn = await asyncssh.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/asyncssh/connection.py"", line 8865, in connect
    return await asyncio.wait_for(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/fuchsfa/.local/share/uv/python/cpython-3.12.7-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py"", line 520, in wait_for
    return await fut
           ^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/asyncssh/connection.py"", line 401, in _connect
    new_tunnel = await _open_tunnel(tunnel, options.passphrase, config)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/asyncssh/connection.py"", line 375, in _open_tunnel
    conn = await connect(host, port, username=username,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/asyncssh/connection.py"", line 8865, in connect
    return await asyncio.wait_for(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/fuchsfa/.local/share/uv/python/cpython-3.12.7-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py"", line 520, in wait_for
    return await fut
           ^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/asyncssh/connection.py"", line 450, in _connect
    await options.waiter
asyncssh.misc.PermissionDenied: Permission denied for user fuchsfa on host SSH_SERVER

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/dvc/repo/experiments/push.py"", line 153, in _push
    results: Mapping[str, SyncStatus] = repo.scm.push_refspecs(
                                        ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/scmrepo/git/__init__.py"", line 307, in _backend_func
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/scmrepo/git/backend/dulwich/__init__.py"", line 666, in push_refspecs
    result = client.send_pack(
             ^^^^^^^^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/dulwich/client.py"", line 1239, in send_pack
    proto, unused_can_read, stderr = self._connect(b""receive-pack"", path)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/dulwich/client.py"", line 2191, in _connect
    con = self.ssh_vendor.run_command(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/fsspec/asyn.py"", line 118, in wrapper
    return sync(self.loop, func, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/fsspec/asyn.py"", line 103, in sync
    raise return_result
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/fsspec/asyn.py"", line 56, in _runner
    result[0] = await coro
                ^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/scmrepo/git/backend/dulwich/asyncssh_vendor.py"", line 312, in _run_command
    raise AuthError(f""{username}@{host}:{port or 22}"") from exc
scmrepo.exceptions.AuthError: Authentication failed for: 'GIT_SERVER'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/dvc/cli/__init__.py"", line 211, in main
    ret = cmd.do_run()
          ^^^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/dvc/cli/command.py"", line 27, in do_run
    return self.run()
           ^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/dvc/commands/experiments/push.py"", line 55, in run
    result = self.repo.experiments.push(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/dvc/repo/experiments/__init__.py"", line 364, in push
    return push(self.repo, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/dvc/repo/__init__.py"", line 58, in wrapper
    return f(repo, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/dvc/repo/scm_context.py"", line 143, in run
    return method(repo, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/dvc/repo/experiments/push.py"", line 111, in push
    push_result = _push(repo, git_remote, exp_ref_set, force)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/fuchsfa/demultiple/.venv/lib/python3.12/site-packages/dvc/repo/experiments/push.py"", line 160, in _push
    raise GitAuthError(str(exc))  # noqa: B904
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
dvc.scm.GitAuthError: Authentication failed for: 'GIT_SERVER'
See https://dvc.org/doc/user-guide/troubleshooting#git-auth

2025-02-04 14:31:50,964 DEBUG: Analytics is enabled.
2025-02-04 14:31:51,696 DEBUG: Trying to spawn ['daemon', 'analytics', '/tmp/tmp4zxtqbcl', '-v']
2025-02-04 14:31:51,715 DEBUG: Spawned ['daemon', 'analytics', '/tmp/tmp4zxtqbcl', '-v'] with pid 1400

```
Is there a way for dvc to prompt me? Alternatively is there a way to figure out which git commands this would run and then run them myself?",f-fuchs,48164677,closed,False,10,2025-02-04T13:41:06+00:00,2025-02-06T13:41:36+00:00,2025-02-06T13:41:36+00:00,git,0,0,0,0,0,0,0
iterative/dvc,2828466011,10682,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.9.3 ‚Üí v0.9.4](https://github.com/astral-sh/ruff-pre-commit/compare/v0.9.3...v0.9.4)
- [github.com/codespell-project/codespell: v2.4.0 ‚Üí v2.4.1](https://github.com/codespell-project/codespell/compare/v2.4.0...v2.4.1)
<!--pre-commit.ci end-->",pre-commit-ci[bot],66853113,closed,False,0,2025-02-03T20:31:18+00:00,2025-02-04T05:15:37+00:00,2025-02-04T05:15:36+00:00,,0,0,0,0,0,0,0
iterative/dvc,2827117902,10681,auto push on a repository basis,"I run a lot of my ML workloads in short lived containers in a dedicated ML cluster. The typical workflow is like this:
1. Prepare experiment locally, run a single, smaller epoch for testing
2. `git push && dvc push` to repository
3. Start container, `git pull && dvc pull` in the container
4. Run either `dvc repro` or `dvc exp run`.
5. `git push && dvc push` in the container
More often than desirable, I forget step 5 here or I just run the `git push` part of it. As a result, I end up being left with a corrupted cache and I can't access the experiment's results using `dvc metrics` and similar.

I am aware that there are git-hooks that I can set up using `dvc install`. However, given that the containers are typically rather short lived, I tend to not install those either and there also is no guarantee that collaborators will remember to install the hooks. I would therefore appreciate a repository level setting in `.dvc/config`. I know that there is such a setting for experiments (`exp.auto_push`) but it doesn't seem to apply for cases where I run `dvc repro`.

Also, in a perfect world, this feature would be configurable on a per-host basis so that I can specify patterns on which autostage/auto_push are active like `ml-container-.*`).",igordertigor,471296,open,False,2,2025-02-03T10:34:09+00:00,2025-02-16T20:13:31+00:00,,triage;feature;A: data-sync,0,0,0,0,0,0,0
iterative/dvc,2820077256,10680,DVC Pull is not working with EFS and it is taking around 2 hours for 2.3GB files,"dvc pull is taking around 2 hours to pull 2.3 GB file amazon s3 when using EFS based PVC in the pods.

dvc doctor
DVC version: 3.59.0 (deb)
-------------------------
Platform: Python 3.12.7 on Linux-5.10.225-213.878.amzn2.x86_64-x86_64-with-glibc2.36
Subprojects:
	
Supports:
	azure (adlfs = 2024.12.0, knack = 0.12.0, azure-identity = 1.19.0),
	gdrive (pydrive2 = 1.21.3),
	gs (gcsfs = 2024.12.0),
	hdfs (fsspec = 2024.12.0, pyarrow = 18.1.0),
	http (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
	https (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
	oss (ossfs = 2023.12.0),
	s3 (s3fs = 2024.12.0, boto3 = 1.35.93),
	ssh (sshfs = 2024.9.0),
	webdav (webdav4 = 0.10.0),
	webdavs (webdav4 = 0.10.0),
	webhdfs (fsspec = 2024.12.0)
Config:
	Global: /root/.config/dvc
	System: /etc/xdg/dvc

I have attached the output of dvc pull --cprofile-dump pull_dump.prof to this issue. Since GitHub does not allow .prof files, I renamed it to pull_dump.txt. After downloading the file, please rename it back to pull_dump.prof.

When we run dvc pull -v, we observed that it gets stuck after downloading some files from S3 when using EFS PVC in the pods. However, the same files are downloaded from S3 in 1 to 2 minutes when using local or EBS-based storage in the pods.

[pull_dump.txt](https://github.com/user-attachments/files/18598731/pull_dump.txt)
",shmubara,45116945,open,False,2,2025-01-30T07:12:52+00:00,2025-02-03T03:43:26+00:00,,,2,2,0,0,0,0,0
iterative/dvc,2817783323,10679,studio login/logout break after moving config to local config,"Hey,

after I moved following from the .config/dvc/config file to the local config.local file in my repository the commands studio login and logout seem to be broken.
```
[studio]
    url = https://studio.dvc.ai
    token = SECRET
```
dvc login tellsthat I have to logout first, but logout tells me that I am not logged in.
```
(foundation-models) [fuchsfa@cerberus04:foundation-models]$ dvc studio login --verbose
2025-01-29 11:07:57,833 DEBUG: v3.58.0 (pip), CPython 3.12.7 on Linux-5.15.0-119-generic-x86_64-with-glibc2.36
2025-01-29 11:07:57,833 DEBUG: command: /home/fuchsfa/foundation-models/.venv/bin/dvc studio login --verbose
2025-01-29 11:07:59,458 ERROR: Token already exists. To login with a different token, logout using 'dvc studio logout'.
Traceback (most recent call last):
  File ""/home/fuchsfa/.local/share/uv/python/cpython-3.12.7-linux-x86_64-gnu/lib/python3.12/site-packages/dvc/cli/__init__.py"", line 211, in main
    ret = cmd.do_run()
          ^^^^^^^^^^^^
  File ""/home/fuchsfa/.local/share/uv/python/cpython-3.12.7-linux-x86_64-gnu/lib/python3.12/site-packages/dvc/cli/command.py"", line 41, in do_run
    return self.run()
           ^^^^^^^^^^
  File ""/home/fuchsfa/.local/share/uv/python/cpython-3.12.7-linux-x86_64-gnu/lib/python3.12/site-packages/dvc/commands/studio.py"", line 32, in run
    raise DvcException(
dvc.exceptions.DvcException: Token already exists. To login with a different token, logout using 'dvc studio logout'.

2025-01-29 11:07:59,501 DEBUG: Analytics is enabled.
2025-01-29 11:07:59,948 DEBUG: Trying to spawn ['daemon', 'analytics', '/tmp/tmpsri7ayds', '-v']
2025-01-29 11:07:59,964 DEBUG: Spawned ['daemon', 'analytics', '/tmp/tmpsri7ayds', '-v'] with pid 2396
(foundation-models) [fuchsfa@cerberus04:foundation-models]$ dvc studio logout --verbose
2025-01-29 11:08:11,955 DEBUG: v3.58.0 (pip), CPython 3.12.7 on Linux-5.15.0-119-generic-x86_64-with-glibc2.36
2025-01-29 11:08:11,955 DEBUG: command: /home/fuchsfa/foundation-models/.venv/bin/dvc studio logout --verbose
Not logged in to Studio. Log in with 'dvc studio login'.
2025-01-29 11:08:13,433 DEBUG: Writing '/home/fuchsfa/.config/dvc/config'.
2025-01-29 11:08:13,455 DEBUG: Analytics is enabled.
2025-01-29 11:08:13,741 DEBUG: Trying to spawn ['daemon', 'analytics', '/tmp/tmpzktwhuai', '-v']
2025-01-29 11:08:13,753 DEBUG: Spawned ['daemon', 'analytics', '/tmp/tmpzktwhuai', '-v'] with pid 2475
```
The logging to studio works though, I just have to manually change the token now üëç ",f-fuchs,48164677,open,False,6,2025-01-29T10:19:15+00:00,2025-03-04T07:40:03+00:00,,triage,0,0,0,0,0,0,0
iterative/dvc,2815678769,10678,import: fix broken progressbar when importing folder,"Add child progress bar to dvc fs to report directory import progress correctly.

Fixes #10677

* [x] ‚ùó I have followed the [Contributing to DVC](https://dvc.org/doc/user-guide/contributing/core) checklist.

* [x] üìñ If this PR requires [documentation](https://dvc.org/doc) updates, I have created a separate PR (or issue, at least) in [dvc.org](https://github.com/iterative/dvc.org) and linked it here.

Thank you for the contribution - we'll try to review it as soon as possible. üôè
",petrchmelar,13875092,closed,False,2,2025-01-28T13:29:31+00:00,2025-01-31T14:01:28+00:00,2025-01-31T13:56:28+00:00,,1,0,0,0,0,0,1
iterative/dvc,2815549619,10677,dvc import: breaks progress bar when importing folders,"# Bug Report

## dvc import: breaks progress bar when importing folders

## Description

It seems that progress bar is not working correctly when importing folder.

![Image](https://github.com/user-attachments/assets/738e5c48-d24e-424f-baa6-fe9e2b24272d)

### Reproduce

```console
# prepare repo
mkdir reproducer && cd reproducer
git init && dvc init 

# generate dummy data
mkdir data
dd if=/dev/zero of=./data/file0 bs=4k iflag=fullblock,count_bytes count=1G
dd if=/dev/zero of=./data/file1 bs=4k iflag=fullblock,count_bytes count=1G

# commit data
dvc add data
git add .
git commit -m ""Initial commit"" 

# try to import
dvc import . -o imported-data data
```
### Expected

Progress bar working.

### Environment information

**Output of `dvc doctor`:**

```console
‚ï∞‚îÄ‚ùØ dvc doctor
DVC version: 3.59.0 (pip)
-------------------------
Platform: Python 3.10.12 on Linux-5.15.0-117-generic-x86_64-with-glibc2.35
Subprojects:
        dvc_data = 3.16.8
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.9
Supports:
        http (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
        s3 (s3fs = 2024.9.0, boto3 = 1.36.3)
Config:
        Global: /home/pchmelar/.config/dvc
        System: /etc/xdg/dvc
Cache types: hardlink, symlink
Cache directory: nfs4 on 10.11.72.32:/mlops_data/workplace
Caches: local
Remotes: None
Workspace directory: nfs4 on 10.11.72.32:/mlops_data/workplace
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/f179e68f4c2a6cf27b5dc4aa96041e39
```

**Additional Information (if any):**

It can be probably fixed by adding child progress bars on line https://github.com/iterative/dvc/blob/main/dvc/fs/dvc.py#L581 
I will prepare bugfix pull request",petrchmelar,13875092,closed,False,0,2025-01-28T12:40:05+00:00,2025-01-31T13:56:29+00:00,2025-01-31T13:56:29+00:00,,1,1,0,0,0,0,0
iterative/dvc,2813949336,10676,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.9.2 ‚Üí v0.9.3](https://github.com/astral-sh/ruff-pre-commit/compare/v0.9.2...v0.9.3)
- [github.com/codespell-project/codespell: v2.3.0 ‚Üí v2.4.0](https://github.com/codespell-project/codespell/compare/v2.3.0...v2.4.0)
<!--pre-commit.ci end-->",pre-commit-ci[bot],66853113,closed,False,0,2025-01-27T20:07:50+00:00,2025-01-31T14:19:58+00:00,2025-01-31T14:19:56+00:00,,0,0,0,0,0,0,0
iterative/dvc,2811935001,10675,DVC get/import fails when running behind a proxy,"# Bug Report

## Issue name

get/import : Connection lost

## Description

I am running dvc from behind a proxy, and when trying to import a dvc dataset from GitHub, the git clone step fails.
Configuring Git to use a proxy does not change the error message.

A standard git clone of the target repository succeeds without issue. 

### Reproduce

From behind a proxy run the following:

```
dvc get <GIT_URL>
```

For example:

```console
dvc get https://github.com/iterative/dataset-registry get-started/data.xml -o data/data.xml
```

### Expected

dvc get/import works behind a proxy.

### Environment information

**Output of `dvc doctor`:**

```console
$ dvc doctor

## DVC version: 3.59.0 (pip)

Platform: Python 3.11.9 on Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.28
Subprojects:
dvc_data = 3.16.8
dvc_objects = 5.1.0
dvc_render = 1.0.2
dvc_task = 0.40.2
scmrepo = 3.3.9
Supports:
http (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
https (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
ssh (sshfs = 2024.9.0)
Config:
Global: /home/hoel/.config/dvc
System: /etc/xdg/dvc

```

**Additional Information (if any):**

<details>
<summary>Verbose output of dvc get</summary>

```console
2025-01-27 10:07:10,739 DEBUG: v3.59.0 (pip), CPython 3.11.9 on Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.28
2025-01-27 10:07:10,739 DEBUG: command: /home/hoel/Downloads/temp/.venv/bin/dvc get -v https://github.com/iterative/dataset-registry get-started/data.xml -o data/data.xml
2025-01-27 10:07:10,847 DEBUG: Creating external repo https://github.com/iterative/dataset-registry@None
2025-01-27 10:07:10,847 DEBUG: erepo: git clone 'https://github.com/iterative/dataset-registry' to a temporary dir
2025-01-27 10:07:10,983 ERROR: failed to get 'get-started/data.xml' - SCM error: Failed to clone repo 'https://github.com/iterative/dataset-registry' to '/tmp/tmpv69jxvo7dvc-clone': Connection lost
Traceback (most recent call last):
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/scmrepo/git/backend/dulwich/__init__.py"", line 261, in clone
    repo = clone_from()
           ^^^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/dulwich/porcelain.py"", line 559, in clone
    return client.clone(
           ^^^^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/dulwich/client.py"", line 874, in clone
    result = self.fetch(
             ^^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/dulwich/client.py"", line 981, in fetch
    result = self.fetch_pack(
             ^^^^^^^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/dulwich/client.py"", line 1351, in fetch_pack
    proto, can_read, stderr = self._connect(b""upload-pack"", path, protocol_version)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/dulwich/client.py"", line 2186, in _connect
    con = self.ssh_vendor.run_command(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/fsspec/asyn.py"", line 118, in wrapper
    return sync(self.loop, func, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/fsspec/asyn.py"", line 103, in sync
    raise return_result
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/fsspec/asyn.py"", line 56, in _runner
    result[0] = await coro
                ^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/scmrepo/git/backend/dulwich/asyncssh_vendor.py"", line 297, in _run_command
    conn = await asyncssh.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/asyncssh/connection.py"", line 8865, in connect
    return await asyncio.wait_for(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/hoel/.pyenv/versions/3.11.9/lib/python3.11/asyncio/tasks.py"", line 452, in wait_for
    return await fut
           ^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/asyncssh/connection.py"", line 450, in _connect
    await options.waiter
asyncssh.misc.ConnectionLost: Connection lost

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/dvc/scm.py"", line 150, in clone
    git = Git.clone(url, to_path, progress=pbar.update_git, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/scmrepo/git/__init__.py"", line 154, in clone
    backend.clone(url, to_path, bare=bare, mirror=mirror, **kwargs)
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/scmrepo/git/backend/dulwich/__init__.py"", line 269, in clone
    raise CloneError(url, os.fsdecode(to_path)) from exc
scmrepo.exceptions.CloneError: Failed to clone repo 'https://github.com/iterative/dataset-registry' to '/tmp/tmpv69jxvo7dvc-clone'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/dvc/commands/get.py"", line 37, in _get_file_from_repo
    Repo.get(
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/dvc/repo/get.py"", line 45, in get
    with Repo.open(
         ^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/dvc/repo/__init__.py"", line 302, in open
    return open_repo(url, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/dvc/repo/open_repo.py"", line 60, in open_repo
    return _external_repo(url, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/hoel/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py"", line 81, in inner
    return func(*args, **kwds)
           ^^^^^^^^^^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/dvc/repo/open_repo.py"", line 23, in _external_repo
    path = _cached_clone(url, rev)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/dvc/repo/open_repo.py"", line 134, in _cached_clone
    clone_path, shallow = _clone_default_branch(url, rev)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/funcy/decorators.py"", line 47, in wrapper
    return deco(call, *dargs, **dkwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/funcy/flow.py"", line 246, in wrap_with
    return call()
           ^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/funcy/decorators.py"", line 68, in __call__
    return self._func(*self._args, **self._kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/dvc/repo/open_repo.py"", line 198, in _clone_default_branch
    git = clone(url, clone_path)
          ^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/hoel/Downloads/temp/.venv/lib/python3.11/site-packages/dvc/scm.py"", line 155, in clone
    raise CloneError(""SCM error"") from exc
dvc.scm.CloneError: SCM error

2025-01-27 10:07:10,991 DEBUG: Analytics is enabled.
2025-01-27 10:07:11,010 DEBUG: Trying to spawn ['daemon', 'analytics', '/tmp/tmpurbiykps', '-v']
2025-01-27 10:07:11,014 DEBUG: Spawned ['daemon', 'analytics', '/tmp/tmpurbiykps', '-v'] with pid 3763879
```

</details>

The error might be related to #10563, but reading through that issue did not help me solve the issue. ",hoel-bagard,34478245,closed,False,1,2025-01-27T01:53:58+00:00,2025-01-28T01:50:31+00:00,2025-01-28T01:50:16+00:00,,0,0,0,0,0,0,0
iterative/dvc,2800187495,10674,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.9.1 ‚Üí v0.9.2](https://github.com/astral-sh/ruff-pre-commit/compare/v0.9.1...v0.9.2)
<!--pre-commit.ci end-->",pre-commit-ci[bot],66853113,closed,False,0,2025-01-20T19:57:51+00:00,2025-01-21T09:49:16+00:00,2025-01-21T09:49:14+00:00,,0,0,0,0,0,0,0
iterative/dvc,2792655245,10673,exp-workers failing without logs,"# Bug Report


## DVC EXP workers dying

Running multiple workers results in failed experiments and no logs

## Description

Launching ```dvc queue start``` with parameter ```-j``` greater than 1 fails some experiments that shouldn't fail and these experiments will have no logs. Furthermore, sometimes the exp-worker dies with the failed experiments.

### Reproduce

Example:

params.yaml
```yaml
value: 1
```

dvc.yaml
```yaml
stages:
  experiment_candles:
    cmd: sleep 5 ; echo DONE
    params:
      - params.yaml:
```

1. ```git init```
2. ```dvc init```
3. Copy dvc.yaml
4. Copy params.yaml
5. ```git add *.yaml```
6. ```git commit -m ""initial commit""```
7. Queue experiments
```console
dvc exp run \
    --queue \
    --set-param ""value=0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99""
```
8. Start 20 jobs
```console
dvc queue start -j 20
```
9. Check for failed jobs
```console
dvc queue status | grep Failed
```
10. Check logs of failed jobs
```console
dvc queue logs ...
```

**_Note: that it doesn't always fail, so maybe you have to iterate starting at step 7._**

#### Output sample

<img width=""454"" alt=""Image"" src=""https://github.com/user-attachments/assets/033af87a-fbaa-4fd6-bf89-fe62f60e319a"" />

### Environment information

**Output of `dvc doctor`:**

```console
$ dvc doctor
DVC version: 3.59.0 (brew)
--------------------------
Platform: Python 3.13.1 on macOS-15.2-arm64-arm-64bit-Mach-O
Subprojects:
        dvc_data = 3.16.7
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.9
Supports:
        azure (adlfs = 2024.12.0, knack = 0.12.0, azure-identity = 1.19.0),
        gdrive (pydrive2 = 1.21.3),
        gs (gcsfs = 2024.12.0),
        hdfs (fsspec = 2024.12.0, pyarrow = 18.1.0),
        http (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
        oss (ossfs = 2023.12.0),
        s3 (s3fs = 2024.12.0, boto3 = 1.35.93),
        ssh (sshfs = 2024.9.0),
        webdav (webdav4 = 0.10.0),
        webdavs (webdav4 = 0.10.0),
        webhdfs (fsspec = 2024.12.0)
Config:
        Global: /Users/pichurri/Library/Application Support/dvc
        System: /Users/pichurri/homebrew/share/dvc
Cache types: <https://error.dvc.org/no-dvc-cache>
Caches: local
Remotes: None
Workspace directory: apfs on /dev/disk3s3s1
Repo: dvc, git
Repo.site_cache_dir: /Users/pichurri/homebrew/var/cache/dvc/repo/7b5c17002f7a7963a4dc1afee2b961e2

```
",nv-pipo,7769945,open,False,1,2025-01-16T12:47:54+00:00,2025-05-07T15:16:09+00:00,,bug;help wanted;triage;A: experiments,0,0,0,0,0,0,0
iterative/dvc,2791233478,10672,lock file persists after task is complete,"# Bug Report

`pull: permission denied`

## Description


`dvc pull file_to_pull`

After the pull has completed, the lock file (`.dvc/tmp/lock`) is still there. It seems like it is deleted when the next task begins.

This is a problem in our multi-user environment, which shares a single copy of the repo. When a different user wants to `dvc pull`, they are unable to remove the lock file, so the pull command is blocked:

```
ERROR: unexpected error - [Errno 13] Permission denied: '/path/to/repo/.dvc/tmp/lock'
Having any troubles? Hit us up at https://dvc.org/support, we are always happy to help!
```

### Reproduce

1. Call `dvc pull` with one user
2. Change to a different user (e.g. `su user2`)
3. Call `dvc pull` again
4. Verify that a lock file still exists, and is owned by the first user: 
```
$ ls -l .dvc/tmp/lock
-rw-rw-r-- 1 user1 user1 9 Jan 16 12:13 .dvc/tmp/lock
```

### Expected

The lock file should be removed when the task is complete.

### Environment information

<!--
This is required to ensure that we can reproduce the bug.
-->

**Output of `dvc doctor`:**

$ dvc doctor
DVC version: 3.59.0 (snap)
--------------------------
Platform: Python 3.12.8 on Linux-5.15.0-130-generic-x86_64-with-glibc2.31
Subprojects:
	dvc_data = 3.16.8
	dvc_objects = 5.1.0
	dvc_render = 1.0.2
	dvc_task = 0.40.2
	scmrepo = 3.3.9
Supports:
	azure (adlfs = 2024.12.0, knack = 0.12.0, azure-identity = 1.19.0),
	gdrive (pydrive2 = 1.21.3),
	gs (gcsfs = 2024.12.0),
	hdfs (fsspec = 2024.12.0, pyarrow = 18.1.0),
	http (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
	https (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
	oss (ossfs = 2023.12.0),
	s3 (s3fs = 2024.12.0, boto3 = 1.35.93),
	ssh (sshfs = 2024.9.0),
	webdav (webdav4 = 0.10.0),
	webdavs (webdav4 = 0.10.0),
	webhdfs (fsspec = 2024.12.0)
Config:
	Global: /home/user1/.config/dvc
	System: /etc/dvc
Cache types: hardlink, symlink
Cache directory: ext4 on /dev/sda1
Caches: local
Remotes: gs
Workspace directory: ext4 on /dev/sda1
Repo: dvc (subdir), git
Repo.site_cache_dir: /var/tmp/dvc/repo/61bc2c9403cc66ebc304ff80f4128dba


**Additional Information (if any):**

N/A
",chris-rapson-formus,160089226,closed,False,4,2025-01-15T23:34:35+00:00,2025-02-06T04:50:06+00:00,2025-02-06T04:50:06+00:00,awaiting response;triage,0,0,0,0,0,0,0
iterative/dvc,2785246197,10671,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.9.0 ‚Üí v0.9.1](https://github.com/astral-sh/ruff-pre-commit/compare/v0.9.0...v0.9.1)
<!--pre-commit.ci end-->",pre-commit-ci[bot],66853113,closed,False,0,2025-01-13T20:04:13+00:00,2025-01-13T21:37:33+00:00,2025-01-13T21:37:31+00:00,,0,0,0,0,0,0,0
iterative/dvc,2783839625,10670,"dvc push to remote ssh:  ERROR: unexpected error - Permission denied for user , although ssh or sftp upload works","# Bug Report

## Description

When I do ""dvc push"" to a remote ssh, I get **ERROR: unexpected error - Permission denied for user**

I have checked my permissions with ssh and sftp, and encountered no problem .
With sftp I was able to upload a file.

 
### Reproduce

dvc push

### Expected

file pushed to remote ssh

### environment
**.dvc/config**
```
[core]
    remote = jeh-ssh-storage-dvc
['remote ""jeh-ssh-storage-dvc""']
    url = ssh://llsscdsc001a.cloud.socseccoredc.be
    user = rsz-6900
    ask_passphrase = true
```

**console output**
```
2025-01-13 13:18:41,968 ERROR: unexpected error - Permission denied for user rsz-6900 on host 10.10.129.66: Permission denied for user rsz-6900 on host 10.10.129.66
Traceback (most recent call last):
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/sshfs/utils.py"", line 27, in wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/sshfs/spec.py"", line 97, in _connect
    client = await self._stack.enter_async_context(_raw_client)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/anaconda3/lib/python3.11/contextlib.py"", line 638, in enter_async_context
    result = await _enter(cm)
             ^^^^^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/asyncssh/misc.py"", line 362, in __aenter__
    self._coro_result = await self._coro
                        ^^^^^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/asyncssh/connection.py"", line 8865, in connect
    return await asyncio.wait_for(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/anaconda3/lib/python3.11/asyncio/tasks.py"", line 442, in wait_for
    return await fut
           ^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/asyncssh/connection.py"", line 450, in _connect
    await options.waiter
asyncssh.misc.PermissionDenied: Permission denied for user rsz-6900 on host 10.10.129.66

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/dvc/cli/__init__.py"", line 211, in main
    ret = cmd.do_run()
          ^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/dvc/cli/command.py"", line 27, in do_run
    return self.run()
           ^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/dvc/commands/data_sync.py"", line 64, in run
    processed_files_count = self.repo.push(
                            ^^^^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/dvc/repo/__init__.py"", line 58, in wrapper
    return f(repo, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/dvc/repo/push.py"", line 147, in push
    push_transferred, push_failed = ipush(
                                    ^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/dvc_data/index/push.py"", line 78, in push
    result = transfer(
             ^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/dvc_data/hashfile/transfer.py"", line 203, in transfer
    status = compare_status(
             ^^^^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/dvc_data/hashfile/status.py"", line 179, in compare_status
    dest_exists, dest_missing = status(
                                ^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/dvc_data/hashfile/status.py"", line 151, in status
    exists.update(odb.oids_exist(hashes, jobs=jobs, progress=pbar.callback))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/dvc_objects/db.py"", line 418, in oids_exist
    return list(wrap_iter(remote_oids, callback))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/dvc_objects/db.py"", line 35, in wrap_iter
    for index, item in enumerate(iterable, start=1):
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/dvc_objects/db.py"", line 366, in list_oids_exists
    in_remote = self.fs.exists(paths, batch_size=jobs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/dvc_objects/fs/base.py"", line 454, in exists
    if self.fs.async_impl:
       ^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/funcy/objects.py"", line 47, in __get__
    return prop.__get__(instance, type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/funcy/objects.py"", line 25, in __get__
    res = instance.__dict__[self.fget.__name__] = self.fget(instance)
                                                  ^^^^^^^^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/dvc_ssh/__init__.py"", line 126, in fs
    return _SSHFileSystem(**self.fs_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/fsspec/spec.py"", line 81, in __call__
    obj = super().__call__(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/sshfs/spec.py"", line 67, in __init__
    self._client, self._pool = self.connect(
                               ^^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/fsspec/asyn.py"", line 118, in wrapper
    return sync(self.loop, func, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/fsspec/asyn.py"", line 103, in sync
    raise return_result
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/fsspec/asyn.py"", line 56, in _runner
    result[0] = await coro
                ^^^^^^^^^^
  File ""/opt/anaconda3/lib/python3.11/asyncio/tasks.py"", line 479, in wait_for
    return fut.result()
           ^^^^^^^^^^^^
  File ""/home/rsz-6900/venv/venv-dvc--fix-ssh/lib/python3.11/site-packages/sshfs/utils.py"", line 29, in wrapper
    raise PermissionError(exc.reason) from exc
PermissionError: Permission denied for user rsz-6900 on host 10.10.129.66

2025-01-13 13:18:41,986 DEBUG: Removing '/home/rsz-6900/pocs/.RfCsCza5PpTP13vQa_206Q.tmp'
2025-01-13 13:18:41,987 DEBUG: Removing '/home/rsz-6900/pocs/.RfCsCza5PpTP13vQa_206Q.tmp'
2025-01-13 13:18:41,987 DEBUG: Removing '/home/rsz-6900/pocs/.RfCsCza5PpTP13vQa_206Q.tmp'
2025-01-13 13:18:41,987 DEBUG: Removing '/home/rsz-6900/pocs/dvc/.dvc/cache/files/md5/.8MC4Zxq7D3ylTfBk74rlFQ.tmp'
2025-01-13 13:18:41,990 DEBUG: Version info for developers:
DVC version: 3.58.0 (pip)
-------------------------
Platform: Python 3.11.5 on Linux-5.14.0-362.18.1.el9_3.x86_64-x86_64-with-glibc2.34
Subprojects:
        dvc_data = 3.16.7
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.9
Supports:
        http (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
        ssh (sshfs = 2024.9.0)
Config:
        Global: /home/rsz-6900/.config/dvc
        System: /etc/xdg/dvc
Cache types: reflink, hardlink, symlink
Cache directory: xfs on /dev/sda2
Caches: local
Remotes: ssh
Workspace directory: xfs on /dev/sda2
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/5da16981034e7554d63906fd3c19cbc8
```

**Output of `dvc doctor`:**

```console
$ dvc doctor
DVC version: 3.58.0 (pip)
-------------------------
Platform: Python 3.11.5 on Linux-5.14.0-362.18.1.el9_3.x86_64-x86_64-with-glibc2.34
Subprojects:
        dvc_data = 3.16.7
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.9
Supports:
        http (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
        ssh (sshfs = 2024.9.0)
Config:
        Global: /home/rsz-6900/.config/dvc
        System: /etc/xdg/dvc
Cache types: reflink, hardlink, symlink
Cache directory: xfs on /dev/sda2
Caches: local
Remotes: ssh
Workspace directory: xfs on /dev/sda2
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/5da16981034e7554d63906fd3c19cbc8
```

**Additional Information**
I have checked my permissions with ssh and sftp, and encountered no problem .
With sftp I was able to upload a file.

```console
$ ssh llsscdsc001a.cloud.socseccoredc.be
rsz-6900@10.10.129.66's password: 
Last login: Mon Jan 13 12:54:41 2025 from 10.10.129.66
rsz-6900@llsscdsc001a ~
```",jehout,32927304,closed,False,2,2025-01-13T12:33:28+00:00,2025-01-15T08:55:19+00:00,2025-01-15T08:55:18+00:00,awaiting response;triage,0,0,0,0,0,0,0
iterative/dvc,2783808680,10669,Prevent strings from wrapping in .yaml for a proper round-trip,"- [x] ‚ùó I have followed the [Contributing to DVC](https://dvc.org/doc/user-guide/contributing/core) checklist.

- [x] üìñ If this PR requires [documentation](https://dvc.org/doc) updates, I have created a separate PR (or issue, at least) in [dvc.org](https://github.com/iterative/dvc.org) and linked it here.
    - Does not change things for the user

Solve for #10668
This issue and solution was somewhat mentioned in https://github.com/iterative/dvc/issues/9397

Cheers!",janpawlowskiof,17483828,closed,False,5,2025-01-13T12:19:52+00:00,2025-05-02T12:05:03+00:00,2025-05-02T12:04:18+00:00,,0,0,0,0,0,0,0
iterative/dvc,2783709603,10668,Long strings dumped to dvc.lock contain extra space upon load,"# Bug Report

## repro: long strings dumped to dvc.lock contain extra space upon load

## Edit:
In PR, I replaced the `float(""inf"")` with `sys.maxsize` as suggested in https://github.com/iterative/dvc/issues/9397#issuecomment-1534045898

## Description

The actual bug seems to be originating from `ruamel.yaml`, but we should mitigate it here.

### How it manifests:
I have this stage in`dvc.yaml`
```yaml
  faulty_stage:
    cmd: >-
      echo imruneverytime > faulty.txt
    params:
      - fault_parameter_name
    outs:
      - faulty.txt
```
and this in `params.yaml`
```yaml
fault_parameter_name: |
  This is a prompt.
  This is a prompt.
  This is a prompt.
  This is a prompt.
  This is a prompt.
```

Despite not changing anything, dvc sees the step as changed, but then realizes the step was cached and loads it from cache.
```console
# Running for the first time, expected

bash-5.2$ dvc repro -s faulty_stage
Running stage 'faulty_stage':                                         
> echo imruneverytime > faulty.txt
Updating lock file 'dvc.lock'                                                                                                                                              
Use `dvc push` to send your updates to remote storage.

# Nothing changes here, yet it tries to run, but finally does not, because of the previous run being cached

bash-5.2$ dvc repro -s faulty_stage
Stage 'faulty_stage' is cached - skipping run, checking out outputs   
Updating lock file 'dvc.lock'                                                                                                                                              
Use `dvc push` to send your updates to remote storage.
bash-5.2$ 
```


### Why it occurs:
When long lines are dumped to `dvc.lock` the line gets wrapped.
The issue happens (only sometimes I think), when this wrap occurs after ""\n"" character.
When the yaml is then loaded it contains and additional space.

You can see this happen directly in the `ruamel.yaml`
<img width=""1521"" alt=""Image"" src=""https://github.com/user-attachments/assets/bd989b1e-f8bd-4507-bb33-c7d9bf1884de"" />

This can be worked around by adding this line, which makes it so that string is dumped in one line.
```
yaml.width = float(""inf"")
```
<img width=""1728"" alt=""Image"" src=""https://github.com/user-attachments/assets/f0da3a69-2f06-47ec-bbe6-428ec903f8eb"" />
You can see this fixes the bug.

### How it can be solved.
This can be probably solved be adding this line
```python
yaml.width = float(""inf"")
```
here
https://github.com/iterative/dvc/blob/7d14acb5a7fc4b6d4378ae83367f26cf07fe4213/dvc/utils/serialize/_yaml.py#L48

This solves my issue, and while I didn't do any real testing of this, I don't think this should cause any issues elsewhere.

**Output of `dvc doctor`:**

```console
DVC version: 3.58.0 (pip)
-------------------------
Platform: Python 3.11.9 on macOS-14.3-arm64-arm-64bit
Subprojects:
        dvc_data = 3.16.7
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.9
Supports:
        http (aiohttp = 3.11.11, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.11, aiohttp-retry = 2.9.1)
Config:
        Global: /Users/jpawlowski/Library/Application Support/dvc
        System: /Library/Application Support/dvc
Cache types: reflink, hardlink, symlink
Cache directory: apfs on /dev/disk3s1s1
Caches: local
Remotes: None
Workspace directory: apfs on /dev/disk3s1s1
Repo: dvc, git
Repo.site_cache_dir: /Library/Caches/dvc/repo/c7d0d0e3856141270a471060952e5a84
```

This will hopefully be a one line fix, and I can add a PR for it today.

Best regards!",janpawlowskiof,17483828,open,False,7,2025-01-13T11:33:06+00:00,2025-05-02T12:47:36+00:00,,bug;upstream,1,1,0,0,0,0,0
iterative/dvc,2779692172,10667,3.13 support for Windows,"* [x] ‚ùó I have followed the [Contributing to DVC](https://dvc.org/doc/user-guide/contributing/core) checklist.

* [x] üìñ If this PR requires [documentation](https://dvc.org/doc) updates, I have created a separate PR (or issue, at least) in [dvc.org](https://github.com/iterative/dvc.org) and linked it here.

Thank you for the contribution - we'll try to review it as soon as possible. üôè
",skshetry,18718008,closed,False,0,2025-01-10T09:25:14+00:00,2025-01-10T12:54:41+00:00,2025-01-10T12:54:38+00:00,,0,0,0,0,0,0,0
iterative/dvc,2778251453,10666,fix implicit concatenated strings,"* [x] ‚ùó I have followed the [Contributing to DVC](https://dvc.org/doc/user-guide/contributing/core) checklist.

* [x] üìñ If this PR requires [documentation](https://dvc.org/doc) updates, I have created a separate PR (or issue, at least) in [dvc.org](https://github.com/iterative/dvc.org) and linked it here.

Thank you for the contribution - we'll try to review it as soon as possible. üôè
",skshetry,18718008,closed,False,0,2025-01-09T16:20:21+00:00,2025-01-09T16:20:35+00:00,2025-01-09T16:20:33+00:00,,0,0,0,0,0,0,0
iterative/dvc,2778131107,10665,tests: try to make tests pass on Python 3.13 on unix platforms,"* [x] ‚ùó I have followed the [Contributing to DVC](https://dvc.org/doc/user-guide/contributing/core) checklist.

* [x] üìñ If this PR requires [documentation](https://dvc.org/doc) updates, I have created a separate PR (or issue, at least) in [dvc.org](https://github.com/iterative/dvc.org) and linked it here.

Thank you for the contribution - we'll try to review it as soon as possible. üôè
",skshetry,18718008,closed,False,0,2025-01-09T15:27:58+00:00,2025-01-09T16:51:38+00:00,2025-01-09T16:51:36+00:00,,0,0,0,0,0,0,0
iterative/dvc,2778023109,10664,ls-url: add support for `--tree`/`--level`,"Similar to `ls` command.

* [x] ‚ùó I have followed the [Contributing to DVC](https://dvc.org/doc/user-guide/contributing/core) checklist.

* [x] üìñ If this PR requires [documentation](https://dvc.org/doc) updates, I have created a separate PR (or issue, at least) in [dvc.org](https://github.com/iterative/dvc.org) and linked it here.

Thank you for the contribution - we'll try to review it as soon as possible. üôè
",skshetry,18718008,closed,False,0,2025-01-09T14:42:16+00:00,2025-01-09T15:27:36+00:00,2025-01-09T15:27:34+00:00,,0,0,0,0,0,0,0
iterative/dvc,2771397880,10663,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.8.4 ‚Üí v0.8.6](https://github.com/astral-sh/ruff-pre-commit/compare/v0.8.4...v0.8.6)
<!--pre-commit.ci end-->",pre-commit-ci[bot],66853113,closed,False,0,2025-01-06T20:31:49+00:00,2025-01-09T16:04:51+00:00,2025-01-09T16:04:49+00:00,,0,0,0,0,0,0,0
iterative/dvc,2763892290,10662,build(deps): bump mypy from 1.14.0 to 1.14.1,"Bumps [mypy](https://github.com/python/mypy) from 1.14.0 to 1.14.1.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/python/mypy/commit/251d12fe9f89f8d4818fd6ff1c48224e77119004""><code>251d12f</code></a> Remove +dev from version for release 1.14.1</li>
<li><a href=""https://github.com/python/mypy/commit/667e5f752aaa4d1c62341d27af54e9ffff82620c""><code>667e5f7</code></a> Revert &quot;Remove redundant inheritances from Iterator in builtins&quot; (<a href=""https://redirect.github.com/python/mypy/issues/18324"">#18324</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/67f673a79d3114b3aa06d9642b9feefc2f20631a""><code>67f673a</code></a> Fix enum truthiness for StrEnum (<a href=""https://redirect.github.com/python/mypy/issues/18379"">#18379</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/3755abbb875c80698c928711b5aa8f59e71ce973""><code>3755abb</code></a> Fix getargs argument passing (<a href=""https://redirect.github.com/python/mypy/issues/18350"">#18350</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/b9fa8eeaebfda2b6ac01a2651659d3206fab9854""><code>b9fa8ee</code></a> Update version to 1.14.1+dev for point release</li>
<li>See full diff in <a href=""https://github.com/python/mypy/compare/v1.14.0...v1.14.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mypy&package-manager=pip&previous-version=1.14.0&new-version=1.14.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],49699333,closed,False,0,2024-12-31T02:49:49+00:00,2025-01-09T15:29:43+00:00,2025-01-09T15:29:41+00:00,,0,0,0,0,0,0,0
iterative/dvc,2756659695,10661,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.8.3 ‚Üí v0.8.4](https://github.com/astral-sh/ruff-pre-commit/compare/v0.8.3...v0.8.4)
<!--pre-commit.ci end-->",pre-commit-ci[bot],66853113,closed,False,0,2024-12-23T20:11:48+00:00,2024-12-26T09:00:03+00:00,2024-12-26T09:00:00+00:00,,0,0,0,0,0,0,0
iterative/dvc,2755084651,10660,build(deps): bump astral-sh/setup-uv from 4 to 5,"Bumps [astral-sh/setup-uv](https://github.com/astral-sh/setup-uv) from 4 to 5.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/astral-sh/setup-uv/releases"">astral-sh/setup-uv's releases</a>.</em></p>
<blockquote>
<h2>v5.0.0 üéÑ Merry Christmas - Help fastly and users by default</h2>
<h2>Changes</h2>
<p>This christmans üéÑ release is a bit early bit still full of presents üéÅ
Since we are changing some of the defaults this can lead to breaking changes, thus the major version increase.</p>
<p>Here are the highlights:</p>
<h3><a href=""https://redirect.github.com/astral-sh/setup-uv/pull/193"">Default to enable-cache: true on GitHub hosted runners</a></h3>
<p>Did you know that that Fastly, the company hosting PyPI, theoretically has to pay $12.5 million per month and so far have served more than 2.41 <strong>exabytes</strong> of data?
<img src=""https://github.com/user-attachments/assets/f2f6cb3f-68f6-4e37-abb1-d3bf1f278533"" alt=""image"" /></p>
<p>This is why <a href=""https://redirect.github.com/astral-sh/setup-uv/issues/54"">they asked us</a> to turn on caching by default. After weighting the pros and cons we decided to automatically upload the cache to the GitHub Actions cache when running on GitHub hosted runners. You can still disable that with <code>enable-cache: false</code>.</p>
<p>I remember when I first got into actions and didn't understand all the magic. I was baffled that some actions did something behind the scenes to make everything faster. I hope with this change we help a lot of users who are don't want to or are afraid to understand what <code>enable-cache</code> does.</p>
<h3><a href=""https://redirect.github.com/astral-sh/setup-uv/pull/185"">Add **/requirements*.txt to default cache-dependency-glob</a></h3>
<p>If caching is enabled we automatically searched for a <code>uv.lock</code> file and when this changed we knew we had to refresh the cache. A lot of projects don't use this but rather the good old <code>requirements.txt</code>. We now automatically search for both <code>uv.lock</code>and <code>requirements*.txt</code> (this means also <code>requirements-test.txt</code>, <code>requirements-dev.txt</code>, ...) files.
You can change this with <code>cache-dependency-glob</code></p>
<h3><a href=""https://redirect.github.com/astral-sh/setup-uv/pull/194"">Auto activate venv when python-version is set</a></h3>
<p>Some workflows install packages on the fly. This automatically works when using a python version that is already present on the runner. But if uv installs the version, e.g. because it is a free-threaded version or an old one, it is a <a href=""https://astral.sh/blog/python-build-standalone"">standalone-build</a> and installing packages &quot;into the system&quot; is not possible.</p>
<p>We now automatically create a new virtual environment with <code>uv venv</code> and activate it for the rest of the workflow if <code>python-version</code> is used. This means you can now do</p>
<pre lang=""yaml""><code>- name: Install uv
  uses: astral-sh/setup-uv@auto-environment
  with:
    python-version: 3.13t
- run: uv pip install -i https://pypi.anaconda.org/scientific-python-nightly-wheels/simple cython
</code></pre>
<h2>üö® Breaking changes</h2>
<ul>
<li>Default to enable-cache: true on GitHub hosted runners <a href=""https://github.com/eifinger""><code>@‚Äãeifinger</code></a> (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/193"">#193</a>)</li>
<li>Add **/requirements*.txt to default cache-dependency-glob <a href=""https://github.com/eifinger""><code>@‚Äãeifinger</code></a> (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/185"">#185</a>)</li>
</ul>
<h2>üêõ Bug fixes</h2>
<ul>
<li>Always use api.github.com <a href=""https://github.com/eifinger""><code>@‚Äãeifinger</code></a> (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/191"">#191</a>)</li>
</ul>
<h2>üöÄ Enhancements</h2>
<ul>
<li>Auto activate venv when python-version is set <a href=""https://github.com/eifinger""><code>@‚Äãeifinger</code></a> (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/194"">#194</a>)</li>
<li>Add python version to cache key <a href=""https://github.com/eifinger""><code>@‚Äãeifinger</code></a> (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/187"">#187</a>)</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/180f8b44399608a850e1db031fa65c77746566d3""><code>180f8b4</code></a> Fix wrong cacheDependencyPathHash (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/201"">#201</a>)</li>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/e3fb95a68959a9be3d650989dc1d43a9a324447a""><code>e3fb95a</code></a> Warn instead of fail for no-dependency-glob (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/200"">#200</a>)</li>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/2af22b5b2dcfc0729ee842c635f300f1fc5a9e9a""><code>2af22b5</code></a> chore: update known checksums for 0.5.11 (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/198"">#198</a>)</li>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/dd578776bbb50c3f5b3de9e6379065aa0077c56f""><code>dd57877</code></a> Auto activate venv when python-version is set (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/194"">#194</a>)</li>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/85aa0bf0c11c139baabd61df94702a838ff76d62""><code>85aa0bf</code></a> chore: update known checksums for 0.5.10 (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/196"">#196</a>)</li>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/1f2cbfa7bb518f97c35c3cd1ac38271d6e45b512""><code>1f2cbfa</code></a> Bump <code>@‚Äãtypes/node</code> from 22.10.1 to 22.10.2 (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/189"">#189</a>)</li>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/25b3ce6330ae41c3f95bd2addaf55f4db2d4820a""><code>25b3ce6</code></a> chore: update known checksums for 0.5.9 (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/195"">#195</a>)</li>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/856099c958e7f2d5560824c4068f415104f5e436""><code>856099c</code></a> Add python version to cache key (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/187"">#187</a>)</li>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/e3017a763c9554c4df1f8374df36156df9c2bb8b""><code>e3017a7</code></a> Default to enable-cache: true on GitHub hosted runners (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/193"">#193</a>)</li>
<li><a href=""https://github.com/astral-sh/setup-uv/commit/3460fe1a9ab32cdfff176fd684479d2f6dff237c""><code>3460fe1</code></a> Always use api.github.com (<a href=""https://redirect.github.com/astral-sh/setup-uv/issues/191"">#191</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/astral-sh/setup-uv/compare/v4...v5"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=astral-sh/setup-uv&package-manager=github_actions&previous-version=4&new-version=5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],49699333,closed,False,0,2024-12-23T02:41:20+00:00,2024-12-23T02:55:58+00:00,2024-12-23T02:55:56+00:00,,0,0,0,0,0,0,0
iterative/dvc,2755051205,10659,build(deps): bump mypy from 1.13.0 to 1.14.0,"Bumps [mypy](https://github.com/python/mypy) from 1.13.0 to 1.14.0.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/python/mypy/blob/master/CHANGELOG.md"">mypy's changelog</a>.</em></p>
<blockquote>
<h1>Mypy Release Notes</h1>
<h2>Next release</h2>
<p>...</p>
<h2>Mypy 1.14</h2>
<p>We‚Äôve just uploaded mypy 1.14 to the Python Package Index (<a href=""https://pypi.org/project/mypy/"">PyPI</a>).
Mypy is a static type checker for Python. This release includes new features and bug fixes.
You can install it as follows:</p>
<pre><code>python3 -m pip install -U mypy
</code></pre>
<p>You can read the full documentation for this release on <a href=""http://mypy.readthedocs.io"">Read the Docs</a>.</p>
<h3>Change to Enum Membership Semantics</h3>
<p>As per the updated <a href=""https://typing.readthedocs.io/en/latest/spec/enums.html#defining-members"">typing specification for enums</a>,
enum members must be left unannotated.</p>
<pre lang=""python""><code>class Pet(Enum):
    CAT = 1  # Member attribute
    DOG = 2  # Member attribute
<pre><code># New error: Enum members must be left unannotated
WOLF: int = 3

species: str  # Considered a non-member attribute
</code></pre>
<p></code></pre></p>
<p>In particular, the specification change can result in issues in type stubs (<code>.pyi</code> files), since
historically it was common to leave the value absent:</p>
<pre lang=""python""><code># In a type stub (.pyi file)
<p>class Pet(Enum):
# Change in semantics: previously considered members,
# now non-member attributes
CAT: int
DOG: int</p>
<pre><code># Mypy will now issue a warning if it detects this
# situation in type stubs:
# &amp;gt; Detected enum &amp;quot;Pet&amp;quot; in a type stub with zero
# &amp;gt; members. There is a chance this is due to a recent
# &amp;gt; change in the semantics of enum membership. If so,
# &amp;gt; use `member = value` to mark an enum member,
</code></pre>
<p>&lt;/tr&gt;&lt;/table&gt;
</code></pre></p>
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/python/mypy/commit/6f37859612cd8670724c2ee2df21aa691276a9dc""><code>6f37859</code></a> Remove +dev from version for release 1.14</li>
<li><a href=""https://github.com/python/mypy/commit/5a6a7548a9ae25c79690108b1dc1aaec559a18de""><code>5a6a754</code></a> Minor updates to 1.14 changelog (<a href=""https://redirect.github.com/python/mypy/issues/18310"">#18310</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/9772d486ada2c198811c34f47be7d0bad44cdbf5""><code>9772d48</code></a> Update changelog for release 1.14 (<a href=""https://redirect.github.com/python/mypy/issues/18301"">#18301</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/92473c8bef8a2969e2a649c6c84b3165ba342b0c""><code>92473c8</code></a> Warn about --follow-untyped-imports (<a href=""https://redirect.github.com/python/mypy/issues/18249"">#18249</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/e6ce8be8a61a4a8c17523a828e800a76331ee4b5""><code>e6ce8be</code></a> PEP 702 (<a href=""https://github.com/deprecated""><code>@‚Äãdeprecated</code></a>): descriptors (<a href=""https://redirect.github.com/python/mypy/issues/18090"">#18090</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/5082a221f33e6f2ceb32830f733890a1b21061db""><code>5082a22</code></a> [mypyc] Document optimized bytes ops and additional str ops (<a href=""https://redirect.github.com/python/mypy/issues/18242"">#18242</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/ee19ea7d26ccdda3e0e79ef36aeb98cddb527903""><code>ee19ea7</code></a> [mypyc] Add primitives and specialization for ord() (<a href=""https://redirect.github.com/python/mypy/issues/18240"">#18240</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/cc45bec732d6ccf4f846c5fd40617fed9cc04e8d""><code>cc45bec</code></a> [mypyc] Make exception type check in assertRaises test helper precise (<a href=""https://redirect.github.com/python/mypy/issues/18241"">#18241</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/f51090d053874aed0f3bfdb354e42f641296eaac""><code>f51090d</code></a> Make &quot;deprecated&quot; Note a standard Error, disabled by default (<a href=""https://redirect.github.com/python/mypy/issues/18192"">#18192</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/242873a2e8a1d98762b30fcf7b28a699a230279d""><code>242873a</code></a> Implement flag to allow typechecking of untyped modules (<a href=""https://redirect.github.com/python/mypy/issues/17712"">#17712</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/python/mypy/compare/v1.13.0...v1.14.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mypy&package-manager=pip&previous-version=1.13.0&new-version=1.14.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],49699333,closed,False,0,2024-12-23T02:06:03+00:00,2024-12-23T02:16:09+00:00,2024-12-23T02:16:07+00:00,,0,0,0,0,0,0,0
iterative/dvc,2754722056,10658,dvc pull cannot be stopped by Ctrl+C (at least on Windows),"# Bug Report

pull: cannot be stopped by Ctrl+C
<!--
## Issue name

Issue names must follow the pattern `command: description` where the command is the dvc command that you are trying to run. The description should describe the consequence of the bug.

Example: `repro: doesn't detect input changes`
-->

## Description
When DVC downloads huge files from S3, an attempt to cancel the process using Ctrl+C is just ignored.
<!--
A clear and concise description of what the bug is.
-->

### Reproduce
1. Prepare and push several huge DVC files to S3, commit repo changes
2. Get clean repo copy
3. dvc pull
4. Try to press Ctrl+C
-->

<!--
Example:

1. dvc init
2. Copy dataset.zip to the directory
3. dvc add dataset.zip
4. dvc run -d dataset.zip -o model ./train.sh
5. modify dataset.zip
6. dvc repro
-->

### Expected
The downloading process should stop neary immediately (probably, within 1-2 seconds).
<!--
A clear and concise description of what you expect to happen.
-->

### Environment information

<!--
This is required to ensure that we can reproduce the bug.
-->

**Output of `dvc doctor`:**

```console
$ dvc doctor
DVC version: 3.58.0 (pip)
-------------------------
Platform: Python 3.9.18 on Windows-10-10.0.19041-SP0
Subprojects:
        dvc_data = 3.16.5
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.4.0
        scmrepo = 3.3.9
Supports:
        http (aiohttp = 3.10.5, aiohttp-retry = 2.8.3),
        https (aiohttp = 3.10.5, aiohttp-retry = 2.8.3),
        s3 (s3fs = 2024.5.0, boto3 = 1.35.16)
Config:
        Global: C:\Users\User11\AppData\Local\iterative\dvc
        System: C:\ProgramData\iterative\dvc
Cache types: hardlink
Cache directory: NTFS on D:\
Caches: local
Remotes: s3
Workspace directory: NTFS on D:\
Repo: dvc, git
Repo.site_cache_dir: C:\ProgramData\iterative\dvc\Cache\repo\7d446d749c90842fa5ee817a678499c6

```

**Additional Information (if any):**
Similar old issue, but for ""run"" command and on Linux: https://github.com/iterative/dvc/issues/2272
<!--
Please check https://github.com/iterative/dvc/wiki/Debugging-DVC on ways to gather more information regarding the issue.

If applicable, please also provide a `--verbose` output of the command, eg: `dvc add --verbose`.
If the issue is regarding the performance, please attach the profiling information and the benchmark comparisons.
-->
",a18,5310923,open,False,0,2024-12-22T15:56:45+00:00,2024-12-22T20:35:05+00:00,,help wanted;triage;P: windows;A: data-sync,0,0,0,0,0,0,0
iterative/dvc,2752207846,10657,Import ignore cache,"# Bug Report

## DVC 3.56 Import ignore cache

## Description

I have local DVC repo with json annotations added each one and large data storage with thousand image files added as full folder.
I use symlinks  for cache.
But import in external storage doesn't create symlinks for images data storage. DVC download first, than link files. 


### Reproduce
##### Local data repo
Config
```
cache.type=symlink
core.autostage=true
```
Local storage dirs:
```
annotations/
     master_annotation.json
     train_annotation.json
     test_annotations.json
data_storage/
     image_0
     image_1
     ...
     image_N
```
In local storage comands
```
dvc add ./annotations/*
dvc add ./data_storage
```
##### Project repo
Config
```
cache.type=symlink
cache.dir=path/to/local/data/repo/.dvc/cache
core.autostage=true
```
commands:
```
dvc import path/to/local/data/repo data_storage
```
This command start downloading copies files from cache
```
dvc import path/to/local/data/repo data_storage --no-download
```
Check data_storage.dvc file and create it in project repo, but
```
dvc checkout data_storage.dvc
```
or 
```
dvc checkout data_storage.dvc --relink
```
start downloading files again

### Expected

I think DVC must create symlink for files without downloading originals

### Environment information

<!--
This is required to ensure that we can reproduce the bug.
-->

**Output of `dvc doctor` in local data repo:**

```DVC version: 3.56.0 (deb)
-------------------------
Platform: Python 3.12.7 on Linux-5.15.0-86-generic-x86_64-with-glibc2.31
Subprojects:

Supports:
        azure (adlfs = 2024.7.0, knack = 0.12.0, azure-identity = 1.19.0),
        gdrive (pydrive2 = 1.21.1),
        gs (gcsfs = 2024.10.0),
        hdfs (fsspec = 2024.10.0, pyarrow = 18.0.0),
        http (aiohttp = 3.10.10, aiohttp-retry = 2.9.0),
        https (aiohttp = 3.10.10, aiohttp-retry = 2.9.0),
        oss (ossfs = 2023.12.0),
        s3 (s3fs = 2024.10.0, boto3 = 1.35.36),
        ssh (sshfs = 2024.9.0),
        webdav (webdav4 = 0.10.0),
        webdavs (webdav4 = 0.10.0),
        webhdfs (fsspec = 2024.10.0)
Config:
        Global: /home/user/.config/dvc
        System: /etc/xdg/dvc
Cache types: hardlink, symlink
Cache directory: nfs on ip-addr:/storage/
Caches: local
Remotes: None
Workspace directory: nfs on [ip-addr:/storage/](ip-addr:/storage/)
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/76de345055c7e5635fd954ee44e5d4e2
```
**Output of `dvc doctor` in project repo:**
```
DVC version: 3.56.0 (deb)
-------------------------
Platform: Python 3.12.7 on Linux-5.15.0-86-generic-x86_64-with-glibc2.31
Subprojects:

Supports:
        azure (adlfs = 2024.7.0, knack = 0.12.0, azure-identity = 1.19.0),
        gdrive (pydrive2 = 1.21.1),
        gs (gcsfs = 2024.10.0),
        hdfs (fsspec = 2024.10.0, pyarrow = 18.0.0),
        http (aiohttp = 3.10.10, aiohttp-retry = 2.9.0),
        https (aiohttp = 3.10.10, aiohttp-retry = 2.9.0),
        oss (ossfs = 2023.12.0),
        s3 (s3fs = 2024.10.0, boto3 = 1.35.36),
        ssh (sshfs = 2024.9.0),
        webdav (webdav4 = 0.10.0),
        webdavs (webdav4 = 0.10.0),
        webhdfs (fsspec = 2024.10.0)
Config:
        Global: /home/user/.config/dvc
        System: /etc/xdg/dvc
Cache types: symlink
Cache directory: nfs on ip-addr:/storage/
Caches: local
Remotes: None
Workspace directory: ext4 on /dev/sda2
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/f967073321531b0cc07fba234dd73d7b
```
",konstantin-frolov,44438924,open,False,2,2024-12-20T08:26:33+00:00,2025-05-07T02:26:03+00:00,,bug;p1-important;A: data-sync,0,0,0,0,0,0,0
iterative/dvc,2749846091,10656,"pull: ssh remote fails, error in asyncssh 2.19.0, missing arguments","# Bug Report

## Description

When I try to do a `dvc pull` for a ssh remote, I do get the following error:

```
TypeError: SSHClientConfig.__init__() missing 2 required positional arguments: 'host' and 'port'
```

This happens when using `asyncssh==2.19.0`, with `asyncssh==2.18.0` it does work. 
So my guess is that something changed in asyncssh api. 

### Reproduce

1. init dvc on one machine, add any testdata
2 on another machine add the first machine as an ssh remote
3. dvc pull


### Expected

The data should be pulled.

### Environment information

verbose output
```
2024-12-19 11:29:08,486 DEBUG: v3.58.0 (pip), CPython 3.11.4 on Linux-5.14.21-150500.55.49_13.0.56-cray_shasta_c-x86_64-with-glibc2.31
2024-12-19 11:29:08,486 DEBUG: command: /users/sbeyer/mambaforge/envs/snakemake/bin/dvc pull -v
Collecting                                                                                                           |0.00 [00:00,    ?entry/s]
2024-12-19 11:29:10,178 ERROR: failed to connect to ssh (/gpfs/scratch/ehpc01/ifs-inputs_dvc-remote/files/md5) - SSHClientConfig.__init__() missing 2 required positional arguments: 'host' and 'port'
Traceback (most recent call last):
  File ""/pfs/lustrep2/users/sbeyer/mambaforge/envs/snakemake/lib/python3.11/site-packages/dvc_data/index/fetch.py"", line 118, in fetch
    data.fs.exists(data.path)
  File ""/pfs/lustrep2/users/sbeyer/mambaforge/envs/snakemake/lib/python3.11/site-packages/dvc_objects/fs/base.py"", line 451, in exists
    return self.fs.exists(path)
           ^^^^^^^
  File ""/pfs/lustrep2/users/sbeyer/mambaforge/envs/snakemake/lib/python3.11/site-packages/funcy/objects.py"", line 47, in __get__
    return prop.__get__(instance, type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/pfs/lustrep2/users/sbeyer/mambaforge/envs/snakemake/lib/python3.11/site-packages/funcy/objects.py"", line 25, in __get__
    res = instance.__dict__[self.fget.__name__] = self.fget(instance)
                                                  ^^^^^^^^^^^^^^^^^^^
  File ""/pfs/lustrep2/users/sbeyer/mambaforge/envs/snakemake/lib/python3.11/site-packages/dvc_ssh/__init__.py"", line 126, in fs
    return _SSHFileSystem(**self.fs_args)
                            ^^^^^^^^^^^^
  File ""/pfs/lustrep2/users/sbeyer/mambaforge/envs/snakemake/lib/python3.11/site-packages/funcy/objects.py"", line 25, in __get__
    res = instance.__dict__[self.fget.__name__] = self.fget(instance)
                                                  ^^^^^^^^^^^^^^^^^^^
  File ""/pfs/lustrep2/users/sbeyer/mambaforge/envs/snakemake/lib/python3.11/site-packages/dvc_objects/fs/base.py"", line 90, in fs_args
    ret.update(self._prepare_credentials(**self._config))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/pfs/lustrep2/users/sbeyer/mambaforge/envs/snakemake/lib/python3.11/site-packages/dvc_ssh/__init__.py"", line 55, in _prepare_credentials
    user_ssh_config = parse_config(host=config[""host""])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/pfs/lustrep2/users/sbeyer/mambaforge/envs/snakemake/lib/python3.11/site-packages/sshfs/config.py"", line 23, in parse_config
    return SSHClientConfig.load(
           ^^^^^^^^^^^^^^^^^^^^^
  File ""/pfs/lustrep2/users/sbeyer/mambaforge/envs/snakemake/lib/python3.11/site-packages/asyncssh/config.py"", line 433, in load
    config = cls(last_config, reload, canonical, final, *args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: SSHClientConfig.__init__() missing 2 required positional arguments: 'host' and 'port'

Fetching
2024-12-19 11:29:10,312 ERROR: failed to pull data from the cloud - 96 files failed to download
Traceback (most recent call last):
  File ""/pfs/lustrep2/users/sbeyer/mambaforge/envs/snakemake/lib/python3.11/site-packages/dvc/commands/data_sync.py"", line 35, in run
    stats = self.repo.pull(
            ^^^^^^^^^^^^^^^
  File ""/pfs/lustrep2/users/sbeyer/mambaforge/envs/snakemake/lib/python3.11/site-packages/dvc/repo/__init__.py"", line 58, in wrapper
    return f(repo, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/pfs/lustrep2/users/sbeyer/mambaforge/envs/snakemake/lib/python3.11/site-packages/dvc/repo/pull.py"", line 30, in pull
    processed_files_count = self.fetch(
                            ^^^^^^^^^^^
  File ""/pfs/lustrep2/users/sbeyer/mambaforge/envs/snakemake/lib/python3.11/site-packages/dvc/repo/__init__.py"", line 58, in wrapper
    return f(repo, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/pfs/lustrep2/users/sbeyer/mambaforge/envs/snakemake/lib/python3.11/site-packages/dvc/repo/fetch.py"", line 200, in fetch
    raise DownloadError(failed_count)
dvc.exceptions.DownloadError: 96 files failed to download

2024-12-19 11:29:10,385 DEBUG: Analytics is enabled.
2024-12-19 11:29:10,644 DEBUG: Trying to spawn ['daemon', 'analytics', '/tmp/tmplwq32hb2', '-v']
2024-12-19 11:29:10,658 DEBUG: Spawned ['daemon', 'analytics', '/tmp/tmplwq32hb2', '-v'] with pid 67719
```

**Output of `dvc doctor`:**

DVC version: 3.58.0 (pip)
-------------------------
Platform: Python 3.11.4 on Linux-5.14.21-150500.55.49_13.0.56-cray_shasta_c-x86_64-with-glibc2.31
Subprojects:
        dvc_data = 3.16.7
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.9
Supports:
        http (aiohttp = 3.11.10, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.10, aiohttp-retry = 2.9.1),
        s3 (s3fs = 2024.10.0, boto3 = 1.35.36),
        ssh (sshfs = 2024.9.0)
Config:
        Global: /users/sbeyer/.config/dvc
        System: /etc/xdg/dvc
Cache types: hardlink, symlink
Cache directory: lustre on:/lustrep3
Caches: local
Remotes: s3, ssh
Workspace directory: lustre on :/lustrep3
Repo: dvc, git
Repo.site_cache_dir: /var/tmp/dvc/repo/818a09880835c36dded81b0960402c9f


**Additional Information (if any):**

",sebastianbeyer,7209020,closed,False,8,2024-12-19T10:18:41+00:00,2025-02-11T03:35:07+00:00,2025-02-11T03:34:08+00:00,bug;p1-important;dependencies;fs: ssh,6,6,0,0,0,0,0
iterative/dvc,2748174793,10655,Aborting dvc exp run using CTRL-c can lead to apparent loss of recent script edits,"Had a somewhat scary thing happen last night where I was editing and testing a dvc pipeline stage manually (`python stages/my_stage.py`) and then accidentally ran `dvc exp run` which I did not want to do, so I quickly pressed `CTRL-c` (possibly more than once).

Once it exited I realised my code was back to the state it was in at the previous git commit and I thought I had lost all my changes.  Fortunately, I found them all in the stash

For other users having this problem here are the recovery steps:

```bash
git stash show
git stash pop
```

I tried googling this and couldn't find any other reports of this problem or the recovery steps.

My immediate problem is solved but my questions are
 - How can this be avoided?
 - Is there a better/safer way to abort a dvc run?
 - Is the recovery step well known and if not can we make it easier to find, (e.g. in the documentation)?

Bill.
",billtubbs,7958850,open,False,0,2024-12-18T15:50:05+00:00,2024-12-18T23:42:45+00:00,,p2-medium;ui;A: experiments,1,1,0,0,0,0,0
iterative/dvc,2744664682,10654,dvc experiment queue error: output does not exist,"# Bug Report

<!--
## Issue name

Issue names must follow the pattern `command: description` where the command is the dvc command that you are trying to run. The description should describe the consequence of the bug.

Example: `repro: doesn't detect input changes`
-->

## Description

<!--
A clear and concise description of what the bug is.
-->
When running experiments with queue we encountered this error :

`ERROR: failed to reproduce 'inference': output 'data/predictions.parquet' does not exist`



### Reproduce

<!--
Step list of how to reproduce the bug
-->
This error happens when the directory has this specific structure:

```
workdir/
       dvc.yaml
       params.yaml
       data/
             predictions.parquet
       scripts/
             inference.py
```
and in `inference.py` we declare the path to the `data` folder as this:

`LOCAL_FOLDER: Path = Path(__file__).parent.parent / ""data""
`

An example of the dvc.yaml used:
```
stages:
  generate:
    deps:
      - data/dataset.parquet
    cmd: >-
     python scripts/inference.py
    outs:
      - data/predictions.parquet
```

In this configuration `dvc exp run --queue` will throw an error that it does not find the output of the step.

The fix we found is to declare the local folder path using cwd() instead: `LOCAL_FOLDER: Path = Path.cwd() / ""data""`

### Environment information

DVC version: 3.56.0 (pip)
-------------------------
Platform: Python 3.10.12 on Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.35
Subprojects:
        dvc_data = 3.16.7
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.8
Supports:
        http (aiohttp = 3.11.4, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.4, aiohttp-retry = 2.9.1),
        s3 (s3fs = 2024.10.0, boto3 = 1.35.36)
Config:
        Global: /home/leopra96/.config/dvc
        System: /etc/xdg/dvc
Cache types: hardlink, symlink
Cache directory: ext4 on /dev/sdc
Caches: local
Remotes: s3
Workspace directory: ext4 on /dev/sdc
Repo: dvc (subdir), git
Repo.site_cache_dir: /var/tmp/dvc/repo/3a1e0f4a3b3ed376f7986e42bf618f01

",OS-leonardopratesi,148537381,open,False,2,2024-12-17T11:22:30+00:00,2025-05-09T10:32:14+00:00,,awaiting response;triage,1,1,0,0,0,0,0
iterative/dvc,2744219163,10653,Dvc commit operation is too slow,"# Bug Report


## Description

I use git and dvc to manage my training datasets, which consists of thousands of jsonl files.

After I modify several jsonl files,  I use `dvc status && dvc commit`. `dvc status` operation is completed quickly (I know dvc will only hash files once until it gets modified. Here only several jsonl files are modified so `dvc status` operation cost little). However, `dvc commit` operation cost a lot of time.

While `dvc commit` is executing, I see lots of ""Checking out xxx/xxx/xxx.jsonl"" shows in the terminal, and I believe those jsonl files are not modified. Why dvc need to check out files that are not modified?

### Expected

Assume two files `a.jsonl` and `b.jsonl`  are modified, I think `dvc commit` should equal to `dvc add a.jsonl b.jsonl`. However, it seems that `dvc commit` will check out all files tracked by dvc.

I expect `dvc commit` operation skip files which are not modified, so it can be completed quickly.

### Environment information

**Output of `dvc doctor`:**

```console
$ dvc doctor
DVC version: 3.55.2 (pip)
-------------------------
Platform: Python 3.9.19 on Linux-5.14.0-284.25.1.el9_2.x86_64-x86_64-with-glibc2.31
Subprojects:
        dvc_data = 3.16.5
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.4.0
        scmrepo = 3.3.7
Supports:
        http (aiohttp = 3.10.5, aiohttp-retry = 2.8.3),
        https (aiohttp = 3.10.5, aiohttp-retry = 2.8.3),
        s3 (s3fs = 2024.6.1, boto3 = 1.35.7)
Config:
        Global: /mnt/afs/jiangtan/.config/dvc
        System: /etc/xdg/dvc
Cache types: hardlink, symlink
Cache directory: fuse.quarkfs_client on quarkfs_client
Caches: local
Remotes: s3
Workspace directory: fuse.quarkfs_client on quarkfs_client
Repo: dvc, git
Repo.site_cache_dir: /path/to/repo/.dvc/site_cache_dir/repo/eddf3641719990517f0cfc808ea33376
```
",jiangtann,39088437,open,False,10,2024-12-17T08:15:02+00:00,2024-12-22T18:52:26+00:00,,performance;triage,0,0,0,0,0,0,0
iterative/dvc,2743294307,10651,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.8.2 ‚Üí v0.8.3](https://github.com/astral-sh/ruff-pre-commit/compare/v0.8.2...v0.8.3)
<!--pre-commit.ci end-->",pre-commit-ci[bot],66853113,closed,False,0,2024-12-16T20:05:07+00:00,2024-12-17T12:00:16+00:00,2024-12-17T12:00:15+00:00,,0,0,0,0,0,0,0
iterative/dvc,2743136758,10650,Weekly Processing?,"I'd like to be able to run a dvc pipeline that will maintain a weekly state..


EG:

Input is:
s3:week-1.df.gz
s3:week-2.df.gz


Intermediate Output:
dvc_data/intermediate/week-1-processed.df
dvc_data/intermediate/week-2-processed.df

Final Output:
dvc_data/final/combined-formatted.dataset


So that when a new s3:week-3.df.gz appears, dvc will just run on that file, and produce:

dvc_data/intermediate/week-3-processed.df 

and then updates the  weeks together to produce:

dvc_data/final/combined-formatted.dataset

Extra credit if you can suck in the original version of dvc_data/final/combined-formatted.dataset and merge it with dvc_data/intermediate/week-3-processed.df 

",davies-w,6550854,closed,True,0,2024-12-16T18:50:44+00:00,2024-12-16T23:35:21+00:00,2024-12-16T23:35:21+00:00,,0,0,0,0,0,0,0
iterative/dvc,2731034537,10648,Set core.checksum_jobs can not accelerate dvc operations,"# Bug Report


## Description

I use git and dvc to manage my training datasets, which consists of thousands of `jsonl` files. 

I use `dvc add file1.jsonl file2.jsonl ... file9999.jsonl`(just to illustrate, a shell script is actually used) to add .dvc file for every jsonl file.

After I change `core.site_cache_dir` and execute `dvc status`, I can only see two dvc process in `htop`, although I have already set core.checksum_jobs as 8. And it takes too long to finish `dvc status`.

### Reproduce

```sh
cd /path/to/repo/
dvc config core.checksum_jobs 8

# First set core.site_cache_dir, so last site_cache_dir is at /var/tmp/dvc/repo/xxx
dvc config core.site_cache_dir $(pwd)/.dvc/site_cache_dir
dvc status
```
Execute `htop` in terminal:
![Image](https://github.com/user-attachments/assets/f09b5846-5224-47ac-9abf-6b4198b7c62e)


### Expected

`core.checksum_jobs=8` means 8 process hash different jsonl files concurrently, am I correct? Just like this:
```python
with multiprocessing.Pool(8) as pool:
    hashes = list(pool.map(hash_function, all_files_to_hash))
```


I expect to see at least 8 process in `htop`, so the `hashes` and `links` can be quickly built if I change core.site_cache_dir. Now it takes too long to execute `dvc status`.

I think `core.checksum_jobs` also influence `dvc add` and `dvc checkout`, so if `core.checksum_jobs` works correctly, the process of `dvc add` many jsonl files can be also accelerated.

### Environment information

<!--
This is required to ensure that we can reproduce the bug.
-->

**Output of `dvc doctor`:**

```console
$ dvc doctor
DVC version: 3.55.2 (pip)
-------------------------
Platform: Python 3.9.19 on Linux-5.14.0-284.25.1.el9_2.x86_64-x86_64-with-glibc2.31
Subprojects:
        dvc_data = 3.16.5
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.4.0
        scmrepo = 3.3.7
Supports:
        http (aiohttp = 3.10.5, aiohttp-retry = 2.8.3),
        https (aiohttp = 3.10.5, aiohttp-retry = 2.8.3),
        s3 (s3fs = 2024.6.1, boto3 = 1.35.7)
Config:
        Global: /mnt/afs/jiangtan/.config/dvc
        System: /etc/xdg/dvc
Cache types: hardlink, symlink
Cache directory: fuse.quarkfs_client on quarkfs_client
Caches: local
Remotes: s3
Workspace directory: fuse.quarkfs_client on quarkfs_client
Repo: dvc, git
Repo.site_cache_dir: /path/to/repo/.dvc/site_cache_dir/repo/eddf3641719990517f0cfc808ea33376
```
",jiangtann,39088437,closed,False,6,2024-12-10T19:43:10+00:00,2024-12-12T11:28:32+00:00,2024-12-12T11:28:32+00:00,awaiting response,0,0,0,0,0,0,0
iterative/dvc,2728599089,10647,DVCFileSystem: inconsistent behavior of DVCFileSystem,"# Bug Report

## Description

`DVCFileSystem` exhibits some inconsistent behavior (I think, based on my understanding of the documentation), and I'm not sure what the intended behavior is. In particular, `DVCFileSystem`'s `get_file` raises an error with `rpath=lpath` and `rev=None` from a non-default branch. But if explicitly instantiated with `rev='name of branch'`, then the error is not raised.

### Reproduce

```console
$ cd /tmp
$ mkdir dvc-test-1
$ cd dvc-test-1
$ pdm init --python cpython@3.12
$ pdm add dvc==3.58.0 # not specific to this version though
$ git init
$ dvc init
$ git add .
$ git commit -m ""initial commit""
$ git checkout -b train_model
$ echo 1 > model.ckpt
$ dvc add model.ckpt
$ git add . 
$ git commit -m ""trained first model""
```

Now, from Python (e.g., `pdm run python`):

```python
from dvc.api import DVCFileSystem
fs = DVCFileSystem()
fs.get_file(""model.ckpt"", ""model.ckpt"") # raises shutil.SameFileError
fs2 = DVCFileSystem(rev=""train_model"")
fs2.get_file(""model.ckpt"", ""model.ckpt"") # no error raised
```

### Expected

I'm not sure what the intended behavior is supposed to be. The documentation for `rev` says ""In case of a local repository, if rev is unspecified, it will default to the working directory."" Is ""working directory"" here supposed to be `git`'s concept of ""working tree""? If so, this makes me think the behavior of `fs.get_file(""model.ckpt"", ""model.ckpt"")` and `fs2.get_file(""model.ckpt"", ""model.ckpt"")` in the example above should be identical; but one raises an error and one does not. Is this expected?

### Environment information

```console
$ dvc doctor
DVC version: 3.58.0 (pip)
-------------------------
Platform: Python 3.12.8 on macOS-14.7.1-x86_64-i386-64bit
Subprojects:
	dvc_data = 3.16.7
	dvc_objects = 5.1.0
	dvc_render = 1.0.2
	dvc_task = 0.40.2
	scmrepo = 3.3.9
Supports:
	http (aiohttp = 3.11.10, aiohttp-retry = 2.9.1),
	https (aiohttp = 3.11.10, aiohttp-retry = 2.9.1)
Config:
	Global: /Users/adam.liter/Library/Application Support/dvc
	System: /Library/Application Support/dvc
Cache types: reflink, hardlink, symlink
Cache directory: apfs on /dev/disk1s5s1
Caches: local
Remotes: None
Workspace directory: apfs on /dev/disk1s5s1
Repo: dvc, git
Repo.site_cache_dir: /Library/Caches/dvc/repo/e935e1cd05376dcbfdd7b97f975e242b
```",adamliter,4974404,open,False,0,2024-12-10T00:13:00+00:00,2025-05-07T02:43:21+00:00,,,0,0,0,0,0,0,0
iterative/dvc,2728149427,10646,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.8.1 ‚Üí v0.8.2](https://github.com/astral-sh/ruff-pre-commit/compare/v0.8.1...v0.8.2)
<!--pre-commit.ci end-->",pre-commit-ci[bot],66853113,closed,False,0,2024-12-09T20:04:32+00:00,2024-12-10T08:08:18+00:00,2024-12-10T08:08:15+00:00,,0,0,0,0,0,0,0
iterative/dvc,2723777450,10645,dvc exp show does not visualize experiments,"# Bug Report

<!--
## Issue name

Issue names must follow the pattern `command: description` where the command is the dvc command that you are trying to run. The description should describe the consequence of the bug.

Example: `repro: doesn't detect input changes`
-->


After running some experiments in branch A,  I then pushed the experiments in dvc, then I squashed and merge branch A into main, and then deleted branch A.
Now I can still see the experiments with `dvc exp list --all`.
I can apply the experiments with `dvc exp apply`.
But it I do `dvc exp show` I cannot see any experiment.

<!--
A clear and concise description of what the bug is.
-->

### Reproduce
- run some experiments in a branch
- push the experiments `dvc exp push origin --all`
- squash and merge the branch
- delete the branch
- run `dvc exp show --all-commit --all-branches` <!--
Step list of how to reproduce the bug
-->

<!--
Example:

1. dvc init
2. Copy dataset.zip to the directory
3. dvc add dataset.zip
4. dvc run -d dataset.zip -o model ./train.sh
5. modify dataset.zip
6. dvc repro
-->

### Expected
![Image](https://github.com/user-attachments/assets/79dd437f-9d62-458e-b695-86af0f7c665f)


<!--
A clear and concise description of what you expect to happen.
-->

### Environment information

<!--
This is required to ensure that we can reproduce the bug.
-->

DVC version: 3.56.0 (pip)
-------------------------
Platform: Python 3.10.12 on Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.35
Subprojects:
        dvc_data = 3.16.7
        dvc_objects = 5.1.0
        dvc_render = 1.0.2
        dvc_task = 0.40.2
        scmrepo = 3.3.8
Supports:
        http (aiohttp = 3.11.4, aiohttp-retry = 2.9.1),
        https (aiohttp = 3.11.4, aiohttp-retry = 2.9.1),
        s3 (s3fs = 2024.10.0, boto3 = 1.35.36)
Config:
        Global: /home/leopra96/.config/dvc
        System: /etc/xdg/dvc
Cache types: hardlink, symlink
Cache directory: ext4 on /dev/sdc
Caches: local
Remotes: s3
Workspace directory: ext4 on /dev/sdc
Repo: dvc (subdir), git
Repo.site_cache_dir: /var/tmp/dvc/repo/c956f7904aee9f04196cd0369a56f204
```console
$ dvc doctor
```

**Additional Information (if any):**

<!--
Please check https://github.com/iterative/dvc/wiki/Debugging-DVC on ways to gather more information regarding the issue.

If applicable, please also provide a `--verbose` output of the command, eg: `dvc add --verbose`.
If the issue is regarding the performance, please attach the profiling information and the benchmark comparisons.
-->
",OS-leonardopratesi,148537381,closed,False,3,2024-12-06T19:32:10+00:00,2024-12-07T20:23:03+00:00,2024-12-07T04:41:32+00:00,triage;A: experiments,0,0,0,0,0,0,0
iterative/dvc,2719326891,10644,DVC can not push large file to OSS anymore once the uploading has been interrupted,"# Bug Report


## Description

Currently dvc can not upload large file to oss, after applying fix described in https://github.com/iterative/dvc/issues/10643, `dvc` still suffer from a subtle bug: if the uploading process is interrupted, then it can not been upload again.

### Reproduce

```bash
dvc init
mkfile -n 200m test.blob
dvc add test.blob
dvc remote add foo oss://<oss_bucket>
dvc push -r foo #use ctrl+c to interrupt this function call
dvc push  -r foo 
```

the error message of last push will contain

```
ERROR: failed to transfer 'xxxx' - 'coroutine' object has no attribute 'parts'
```

### Expected

`dvc` should push file to remote, either by recovering from the local state or pruning local state and then launch another new uploading session.

### Environment information

same env to https://github.com/iterative/dvc/issues/10643

with patch applied.



**Additional Information (if any):**

A quick fix to this issue is deleting the uploading store

```
rm -rf ~/.py-oss-upload/
```

This directory is created by the `oss2` .

The root cause  is this line https://github.com/karajan1001/aiooss2/blob/875a06b99881df6fe900b1fed29e3a91dec12a7f/src/aiooss2/resumable.py#L339

aiooss2 pass an  `AioBucket` to the `oss2` and the later one does not invoke await properly.

```mermaid
flowchart LR
   dvc --> dvc-oss --> ossfs --> aiooss2 --> oss2
```",CNLHC,21005146,open,False,2,2024-12-05T05:02:54+00:00,2024-12-07T04:33:38+00:00,,fs: oss;A: data-sync,0,0,0,0,0,0,0
iterative/dvc,2719094509,10643,DVC can not push file larger than 100MiB due to an upstream bug,"# Bug Report

## Description

Since a bug in the `ossfs` dependency, `dvc` can not push file larger than `100MiB` to the `oss` remote.

### Reproduce

```bash
dvc init
mkfile -n 200m test.blob
dvc add test.blob
dvc remote add foo oss://<oss_bucket>
dvc push -r s9t
```

The output report the file is pushed to remote which is false.

```
...python3.12/site-packages/ossfs/async_oss.py:388: RuntimeWarning: coroutine 'resumable_upload' was never awaited                                                                  
  await self._call_oss(
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
Pushing
1 file pushed
```

### Expected

The file should be pushed to the oss, or if something unexpected happen, the CLI should report an error.

### Environment information


**Output of `dvc doctor`:**

```console
$ dvc doctor

DVC version: 3.58.0 (pip)
-------------------------
Platform: Python 3.12.7 on macOS-15.1.1-arm64-arm-64bit
Subprojects:
	dvc_data = 3.16.7
	dvc_objects = 5.1.0
	dvc_render = 1.0.2
	dvc_task = 0.40.2
	scmrepo = 3.3.9
Supports:
	http (aiohttp = 3.9.5, aiohttp-retry = 2.9.1),
	https (aiohttp = 3.9.5, aiohttp-retry = 2.9.1),
	oss (ossfs = 2023.12.0),
	s3 (s3fs = 2024.10.0, boto3 = 1.35.36)
Config:
	Global: /Users/liuhancheng/Library/Application Support/dvc
	System: /Library/Application Support/dvc
Cache types: reflink, hardlink, symlink
Cache directory: apfs on /dev/disk3s1s1
Caches: local
Remotes: oss
Workspace directory: apfs on /dev/disk3s1s1
Repo: dvc, git
Repo.site_cache_dir: /Library/Caches/dvc/repo/adbc8e36d46e0788fce6cf0882302974
```

**Additional Information (if any):**

The root cause of this issue is a bug in the `ossfs` package. According to the warning info, this line is used to upload large file
https://github.com/fsspec/ossfs/blob/224e98868f32018fabacdac1eb5daddb16ce419c/src/ossfs/async_oss.py#L388
and finally this line(L159) will invoke the underlying method to perform uploading.  
https://github.com/fsspec/ossfs/blob/224e98868f32018fabacdac1eb5daddb16ce419c/src/ossfs/async_oss.py#L159

when the `method_name` is , the `method(service, *args, **kwargs)` returns a future that is not awaited, which cause this problem. 

A small and quick fix is applying this patch:


```patch
diff --git a/src/ossfs/async_oss.py b/src/ossfs/async_oss.py
index 8a07b5e..f01b501 100644
--- a/src/ossfs/async_oss.py
+++ b/src/ossfs/async_oss.py
@@ -156,7 +156,10 @@ class AioOSSFileSystem(BaseOSSFileSystem, AsyncFileSystem):
             if not method:
                 method = getattr(aiooss2, method_name)
                 logger.debug(""CALL: %s - %s - %s"", method.__name__, args, kwargs)
-                out = method(service, *args, **kwargs)
+                if method_name ==""resumable_upload"":
+                    out = await method(service, *args, **kwargs)
+                else:
+                    out = method(service, *args, **kwargs)
             else:
                 logger.debug(""CALL: %s - %s - %s"", method.__name__, args, kwargs)
                 out = await method(*args, **kwargs)
```",CNLHC,21005146,closed,False,3,2024-12-05T01:13:07+00:00,2025-05-07T02:40:19+00:00,2025-05-07T02:40:18+00:00,bug;fs: oss;A: data-sync,0,0,0,0,0,0,0
iterative/dvc,2713252209,10642,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.8.0 ‚Üí v0.8.1](https://github.com/astral-sh/ruff-pre-commit/compare/v0.8.0...v0.8.1)
<!--pre-commit.ci end-->",pre-commit-ci[bot],66853113,closed,False,0,2024-12-02T20:18:08+00:00,2024-12-07T02:22:53+00:00,2024-12-07T02:22:51+00:00,,0,0,0,0,0,0,0
iterative/dvc,2708073782,10641,Fix #10638 : makes remove return correct list when used with both `--queue` and `-A` ,"# Description

This PR addresses issue [#10638](https://github.com/iterative/dvc/issues/10638), by providing a minimal code fix that makes the `--all-commits`(aka. `-A` flag) append to the existing `removed` list instead of replacing it with a new value. 

When `--queue` is used, it might already contain the names of experiments removed from the queue. In all other cases, the list should exist but be empty, so appending still makes the job correctly.

# Checklist 
* [X] ‚ùó I have followed the [Contributing to DVC](https://dvc.org/doc/user-guide/contributing/core) checklist.

* [N/A] üìñ If this PR requires [documentation](https://dvc.org/doc) updates, I have created a separate PR (or issue, at least) in [dvc.org](https://github.com/iterative/dvc.org) and linked it here.

Thank you for the contribution - we'll try to review it as soon as possible. üôè
",rmic,1642534,closed,False,3,2024-11-30T21:29:23+00:00,2024-12-01T16:21:54+00:00,2024-12-01T16:21:46+00:00,,0,0,0,0,0,0,0
iterative/dvc,2705054850,10640,set DVC_NO_ANALYTICS on lint,"Hopefully, this will fix windows lint failures. My guess is that dvc daemon is running in the background preventing `uv` to prune cache.

But this is just a guess. Setting this one does not hurt us. We'll know if this was really an issue. :)",skshetry,18718008,closed,False,0,2024-11-29T13:02:52+00:00,2024-11-29T13:03:03+00:00,2024-11-29T13:03:01+00:00,,0,0,0,0,0,0,0
