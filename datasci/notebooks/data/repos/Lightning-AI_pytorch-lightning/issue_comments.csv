repo_full_name,issue_id,comment_id,user_login,user_id,created_at,updated_at,body,reactions_total,reactions_plus1,reactions_minus1,reactions_laugh,reactions_hooray,reactions_confused,reactions_heart
Lightning-AI/pytorch-lightning,3048715208,2865271823,KAVYANSHTYAGI,142140238,2025-05-09T06:19:37+00:00,2025-05-09T06:19:37+00:00,"**_### Bug Discussion:_**
The following error occurs when attempting to convert layers where bias is explicitly disabled:
 
AttributeError: 'NoneType' object has no attribute 'data'

 This happens in `_convert_layers` when trying to access `child.bias.data.clone()` without verifying
 that `child.bias` is not None. In PyTorch, modules like `nn.Linear` can be constructed with `bias=False`,
 in which case the `.bias` attribute is set to None by design.

 Example:
     layer = nn.Linear(16, 32, bias=False)
     print(layer.bias)  # Output: None

 During layer replacement, the logic assumes bias is always present and attempts to clone its `.data`.
 This breaks if the original layer has `bias=False`, leading to the AttributeError on `NoneType`.
",0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3041682696,2862325031,mauvilsa,5780272,2025-05-08T09:10:02+00:00,2025-05-08T09:10:02+00:00,"After thinking a bit I think that implementing this is not trivial. The main difficulty comes from the argument links. Regardless on how the code is changed, it should work well when argument links are added to the parser. I am not sure if I am aware of all the details that need to be considered. And could be that some are only noticed while implementing. For now I would propose to do the following:

1. Behavior only changes when `LightningCLI` is working in subcommands mode, i.e. `run=True`.
2. Before instantiation and running, check whether `ckpt_path` is passed to the subcommand. Note that in principle `ckpt_path` could be defined as a command line argument, in a config file or as an environment variable. So a simple solution could be to parse, check if `ckpt_path` set, and if set, a second parse would be needed.
3. If `ckpt_path` is set, use `torch.load` to read the checkpoint, and check if hyperparameters are included (i.e. `save_hyperparameters` was used).
4. If hyperparameters are included, remove the keys that correspond to link targets (both applied on parse and on instantiate). Unfortunately, right now there is no official way (jsonargparse public API) to know which keys are link targets.
5. After removing link targets, parse again, but modifying the args such that right after the subcommand (e.g. `predict`) and before all other arguments, there is a new `--config` option with value the modified hyperparameters from the checkpoint.
6. Continue the normal flow which would instantiate classes and then run the trainer method.

I need to figure out what to do about point 4. Most likely new feature in jsonargparse is needed.
",0,0,0,0,0,0,0
