repo_full_name,issue_id,number,title,body,user_login,user_id,state,locked,comments_count,created_at,updated_at,closed_at,labels,reactions_total,reactions_plus1,reactions_minus1,reactions_laugh,reactions_hooray,reactions_confused,reactions_heart
Lightning-AI/pytorch-lightning,3057162143,20822,Erreur avec le le logger mlflow,"### Bug description


With the mlflow logger, I have the following error:
```Epoch 9: 100%|█| 23/23 [00:40<00:00,  0.57it/s, v_num=0a0d, phase_loss/train_step=0.0224, mae/train_step=0.153, loss/train_ste
Traceback (most recent call last):
  File ""/opt/venvs/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py"", line 48, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File ""/opt/venvs/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py"", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File ""/opt/venvs/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py"", line 1025, in _run
    call._call_teardown_hook(self)
  File ""/opt/venvs/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py"", line 148, in _call_teardown_hook
    logger.finalize(""success"")
  File ""/opt/venvs/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py"", line 41, in wrapped_fn
    return fn(*args, **kwargs)
  File ""/opt/venvs/lib/python3.10/site-packages/pytorch_lightning/loggers/mlflow.py"", line 289, in finalize
    self._scan_and_log_checkpoints(self._checkpoint_callback)
  File ""/opt/venvs/lib/python3.10/site-packages/pytorch_lightning/loggers/mlflow.py"", line 369, in _scan_and_log_checkpoints
    self.experiment.log_artifact(self._run_id, p, artifact_path)
  File ""/opt/venvs/lib/python3.10/site-packages/mlflow/tracking/client.py"", line 2379, in log_artifact
    self._tracking_client.log_artifact(run_id, local_path, artifact_path)
  File ""/opt/venvs/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py"", line 931, in log_artifact
    artifact_repo.log_artifact(local_path, artifact_path)
  File ""/opt/venvs/lib/python3.10/site-packages/mlflow/store/artifact/local_artifact_repo.py"", line 33, in log_artifact
    verify_artifact_path(artifact_path)
  File ""/opt/venvs/lib/python3.10/site-packages/mlflow/store/artifact/artifact_repo.py"", line 464, in verify_artifact_path
    raise MlflowException(
mlflow.exceptions.MlflowException: Invalid artifact path: 'ordering-model-epoch=09-val_loss=0.00'. Names may be treated as files in certain cases, and must not resolve to other names when treated as such. This name would resolve to 'ordering-model-epoch=09-val_loss=0.00'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.10/pdb.py"", line 1726, in main
    pdb._runscript(mainpyfile)
  File ""/usr/lib/python3.10/pdb.py"", line 1586, in _runscript
    self.run(statement)
  File ""/usr/lib/python3.10/bdb.py"", line 597, in run
    exec(cmd, globals, locals)
  File ""<string>"", line 1, in <module>
  File ""/workspace/perso/train.py"", line 66, in <module>
    train_model(config)
  File ""/workspace/vrsgen/training/train.py"", line 145, in train_model
    trainer.fit(model, train_loader, val_loader)
  File ""/opt/venvs/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py"", line 561, in fit
    call._call_and_handle_interrupt(
  File ""/opt/venvs/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py"", line 68, in _call_and_handle_interrupt
    _interrupt(trainer, exception)
  File ""/opt/venvs/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py"", line 82, in _interrupt
    logger.finalize(""failed"")
  File ""/opt/venvs/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py"", line 41, in wrapped_fn
    return fn(*args, **kwargs)
  File ""/opt/venvs/lib/python3.10/site-packages/pytorch_lightning/loggers/mlflow.py"", line 289, in finalize
    self._scan_and_log_checkpoints(self._checkpoint_callback)
  File ""/opt/venvs/lib/python3.10/site-packages/pytorch_lightning/loggers/mlflow.py"", line 369, in _scan_and_log_checkpoints
    self.experiment.log_artifact(self._run_id, p, artifact_path)
  File ""/opt/venvs/lib/python3.10/site-packages/mlflow/tracking/client.py"", line 2379, in log_artifact
    self._tracking_client.log_artifact(run_id, local_path, artifact_path)
  File ""/opt/venvs/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py"", line 931, in log_artifact
    artifact_repo.log_artifact(local_path, artifact_path)
  File ""/opt/venvs/lib/python3.10/site-packages/mlflow/store/artifact/local_artifact_repo.py"", line 33, in log_artifact
    verify_artifact_path(artifact_path)
  File ""/opt/venvs/lib/python3.10/site-packages/mlflow/store/artifact/artifact_repo.py"", line 464, in verify_artifact_path
    raise MlflowException(
mlflow.exceptions.MlflowException: Invalid artifact path: 'ordering-model-epoch=09-val_loss=0.00'. Names may be treated as files in certain cases, and must not resolve to other names when treated as such. This name would resolve to 'ordering-model-epoch=09-val_loss=0.00'
Uncaught exception. Entering post mortem debugging
Running 'cont' or 'step' will restart the program
```
The problem comes from the path_not_unique function (line 168 in mlflow.utils.validation) which works only with str and here receives a pathlib.Path object ->posixpath.normpath(name) will return a str even for a Path as input and then `norm != name` is always false

to correct this, in the mlflow logger in pytorch_ligntning.loggers.mlflow, line 369 should be:
self.experiment.log_artifact(self._run_id, p, str(artifact_path))

### What version are you seeing the problem on?

v2.5

### Reproduced in studio

_No response_

### How to reproduce the bug

```python

```

### Error messages and logs

```
# Error messages and logs here please
```


### Environment

<details>
  <summary>Current environment</summary>

```
#- PyTorch Lightning Version (e.g., 2.5.0):
#- PyTorch Version (e.g., 2.5):
#- Python version (e.g., 3.12):
#- OS (e.g., Linux):
#- CUDA/cuDNN version:
#- GPU models and configuration:
#- How you installed Lightning(`conda`, `pip`, source):
```

</details>


### More info

_No response_",brunorigal,29140541,open,False,0,2025-05-12T14:22:27+00:00,2025-05-12T14:22:39+00:00,,bug;needs triage;ver: 2.5.x,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3055397420,20821,build(deps): update setuptools requirement from <70.1.1 to <80.4.1 in /requirements,"[//]: # (dependabot-start)
⚠️  **Dependabot is rebasing this PR** ⚠️ 

Rebasing might not happen immediately, so don't worry if this takes some time.

Note: if you make any changes to this PR yourself, they will take precedence over the rebase.

---

[//]: # (dependabot-end)

Updates the requirements on [setuptools](https://github.com/pypa/setuptools) to permit the latest version.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/setuptools/blob/main/NEWS.rst"">setuptools's changelog</a>.</em></p>
<blockquote>
<h1>v80.4.0</h1>
<h2>Features</h2>
<ul>
<li>Simplified the error reporting in editable installs. (<a href=""https://redirect.github.com/pypa/setuptools/issues/4984"">#4984</a>)</li>
</ul>
<h1>v80.3.1</h1>
<h2>Bugfixes</h2>
<ul>
<li>Restored select attributes in easy_install for temporary pbr compatibility. (<a href=""https://redirect.github.com/pypa/setuptools/issues/4976"">#4976</a>)</li>
</ul>
<h1>v80.3.0</h1>
<h2>Features</h2>
<ul>
<li>Removed easy_install and package_index modules. (<a href=""https://redirect.github.com/pypa/setuptools/issues/917"">#917</a>)</li>
<li>Restored license declaration in package metadata. See <a href=""https://redirect.github.com/jaraco/skeleton/issues/171"">jaraco/skeleton#171</a>. (<a href=""https://redirect.github.com/pypa/setuptools/issues/4956"">#4956</a>)</li>
</ul>
<h1>v80.2.0</h1>
<h2>Features</h2>
<ul>
<li>Restored support for install_scripts --executable (and classic behavior for the executable for those invocations). Instead, build_editable provides the portable form of the executables for downstream installers to rewrite. (<a href=""https://redirect.github.com/pypa/setuptools/issues/4934"">#4934</a>)</li>
</ul>
<h1>v80.1.0</h1>
<h2>Features</h2>
<ul>
<li>Added a deadline of Oct 31 to the setup.py install deprecation.</li>
</ul>
<h2>Bugfixes</h2>
<ul>
<li>With <code>setup.py install --prefix=...</code>, fall back to distutils install rather than failing. Note that running <code>setup.py install</code> is deprecated. (<a href=""https://redirect.github.com/pypa/setuptools/issues/3143"">#3143</a>)</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pypa/setuptools/commit/a82f96dc43cbfb9968b100256cb50702becd614e""><code>a82f96d</code></a> Bump version: 80.3.1 → 80.4.0</li>
<li><a href=""https://github.com/pypa/setuptools/commit/aa4bdf8281e7d4e716abcff7ad2a916e0f05e27b""><code>aa4bdf8</code></a> Merge pull request <a href=""https://redirect.github.com/pypa/setuptools/issues/4985"">#4985</a> from pypa/feature/user-focused-editable-installs</li>
<li><a href=""https://github.com/pypa/setuptools/commit/af2f2baf5b4ee81ed45a003070d68badf3f10b11""><code>af2f2ba</code></a> Add news fragment.</li>
<li><a href=""https://github.com/pypa/setuptools/commit/bcc23a221e4d811bd37f5fe73d08f4013890cfb0""><code>bcc23a2</code></a> Implement the editable debugging tips as a reference to the docs.</li>
<li><a href=""https://github.com/pypa/setuptools/commit/aa911c6db2c10c5ac022afaa8d6da1e6c5688524""><code>aa911c6</code></a> By default, provide a much more concise error message.</li>
<li><a href=""https://github.com/pypa/setuptools/commit/f37845bce6bb06ec25c24cf30210a485e945d21e""><code>f37845b</code></a> Bump version: 80.3.0 → 80.3.1</li>
<li><a href=""https://github.com/pypa/setuptools/commit/a6f8db0c3932879f5e1876d97d32b3a7b567b9d5""><code>a6f8db0</code></a> Merge pull request <a href=""https://redirect.github.com/pypa/setuptools/issues/4980"">#4980</a> from pypa/debt/4976-pbr-compat</li>
<li><a href=""https://github.com/pypa/setuptools/commit/05cf544d23b8bbe5f914d198c2620abced8b7477""><code>05cf544</code></a> Add news fragment.</li>
<li><a href=""https://github.com/pypa/setuptools/commit/5b39e4e50510e62902260fd4a437143cbf42c7f8""><code>5b39e4e</code></a> Add the deprecation warning to attribute access.</li>
<li><a href=""https://github.com/pypa/setuptools/commit/30c00380093b1a7ff5693f98d06ab4fa4f8923cf""><code>30c0038</code></a> Render the attributes dynamically.</li>
<li>Additional commits viewable in <a href=""https://github.com/pypa/setuptools/compare/0.6...v80.4.0"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20821.org.readthedocs.build/en/20821/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,1,2025-05-12T01:34:40+00:00,2025-05-12T07:19:28+00:00,2025-05-12T07:19:27+00:00,docs;ci;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3055397348,20820,build(deps): bump click from 8.1.7 to 8.1.8 in /requirements,"[//]: # (dependabot-start)
⚠️  **Dependabot is rebasing this PR** ⚠️ 

Rebasing might not happen immediately, so don't worry if this takes some time.

Note: if you make any changes to this PR yourself, they will take precedence over the rebase.

---

[//]: # (dependabot-end)

Bumps [click](https://github.com/pallets/click) from 8.1.7 to 8.1.8.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pallets/click/releases"">click's releases</a>.</em></p>
<blockquote>
<h2>8.1.8</h2>
<p>This is the Click 8.1.8 fix release, which fixes bugs but does not otherwise change behavior and should not result in breaking changes compared to the latest feature release.</p>
<p>PyPI: <a href=""https://pypi.org/project/click/8.1.8/"">https://pypi.org/project/click/8.1.8/</a>
Changes: <a href=""https://click.palletsprojects.com/en/stable/changes/#version-8-1-8"">https://click.palletsprojects.com/en/stable/changes/#version-8-1-8</a>
Milestone <a href=""https://github.com/pallets/click/milestones/23?closed=1"">https://github.com/pallets/click/milestones/23?closed=1</a></p>
<ul>
<li>Fix an issue with type hints for <code>click.open_file()</code>. <a href=""https://redirect.github.com/pallets/click/issues/2717"">#2717</a></li>
<li>Fix issue where error message for invalid <code>click.Path</code> displays on
multiple lines. <a href=""https://redirect.github.com/pallets/click/issues/2697"">#2697</a></li>
<li>Fixed issue that prevented a default value of <code>&quot;&quot;</code> from being displayed in
the help for an option. <a href=""https://redirect.github.com/pallets/click/issues/2500"">#2500</a></li>
<li>The test runner handles stripping color consistently on Windows. <a href=""https://redirect.github.com/pallets/click/issues/2705"">#2705</a></li>
<li>Show correct value for flag default when using <code>default_map</code>. <a href=""https://redirect.github.com/pallets/click/issues/2632"">#2632</a></li>
<li>Fix <code>click.echo(color=...)</code> passing <code>color</code> to coloroma so it can be
forced on Windows. <a href=""https://redirect.github.com/pallets/click/issues/2606"">#2606</a>.</li>
<li>More robust bash version check, fixing problem on Windows with git-bash. <a href=""https://redirect.github.com/pallets/click/issues/2638"">#2638</a></li>
<li>Cache the help option generated by the <code>help_option_names</code> setting to
respect its eagerness. <a href=""https://redirect.github.com/pallets/click/issues/2811"">#2811</a></li>
<li>Replace uses of <code>os.system</code> with <code>subprocess.Popen</code>. <a href=""https://redirect.github.com/pallets/click/issues/1476"">#1476</a></li>
<li>Exceptions generated during a command will use the context's <code>color</code>
setting when being displayed. <a href=""https://redirect.github.com/pallets/click/issues/2193"">#2193</a></li>
<li>Error message when defining option with invalid name is more descriptive. <a href=""https://redirect.github.com/pallets/click/issues/2452"">#2452</a></li>
<li>Refactor code generating default <code>--help</code> option to deduplicate code. <a href=""https://redirect.github.com/pallets/click/issues/2563"">#2563</a></li>
<li>Test <code>CLIRunner</code> resets patched <code>_compat.should_strip_ansi</code>. <a href=""https://redirect.github.com/pallets/click/issues/2732"">#2732</a></li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/pallets/click/blob/main/CHANGES.rst"">click's changelog</a>.</em></p>
<blockquote>
<h2>Version 8.1.8</h2>
<p>Released 2024-12-19</p>
<ul>
<li>Fix an issue with type hints for <code>click.open_file()</code>. :issue:<code>2717</code></li>
<li>Fix issue where error message for invalid <code>click.Path</code> displays on
multiple lines. :issue:<code>2697</code></li>
<li>Fixed issue that prevented a default value of <code>&quot;&quot;</code> from being displayed in
the help for an option. :issue:<code>2500</code></li>
<li>The test runner handles stripping color consistently on Windows.
:issue:<code>2705</code></li>
<li>Show correct value for flag default when using <code>default_map</code>.
:issue:<code>2632</code></li>
<li>Fix <code>click.echo(color=...)</code> passing <code>color</code> to coloroma so it can be
forced on Windows. :issue:<code>2606</code>.</li>
<li>More robust bash version check, fixing problem on Windows with git-bash.
:issue:<code>2638</code></li>
<li>Cache the help option generated by the <code>help_option_names</code> setting to
respect its eagerness. :pr:<code>2811</code></li>
<li>Replace uses of <code>os.system</code> with <code>subprocess.Popen</code>. :issue:<code>1476</code></li>
<li>Exceptions generated during a command will use the context's <code>color</code>
setting when being displayed. :issue:<code>2193</code></li>
<li>Error message when defining option with invalid name is more descriptive.
:issue:<code>2452</code></li>
<li>Refactor code generating default <code>--help</code> option to deduplicate code.
:pr:<code>2563</code></li>
<li>Test <code>CLIRunner</code> resets patched <code>_compat.should_strip_ansi</code>.
:issue:<code>2732</code></li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pallets/click/commit/934813e4d421071a1b3db3973c02fe2721359a6e""><code>934813e</code></a> release version 8.1.8</li>
<li><a href=""https://github.com/pallets/click/commit/c23223b13c847ae472faa258907ffb5c27b504fa""><code>c23223b</code></a> Add links to third-party projects enhancing Click (<a href=""https://redirect.github.com/pallets/click/issues/2815"">#2815</a>)</li>
<li><a href=""https://github.com/pallets/click/commit/822d4fd0bcfcd0ab22c9eec550ee2dae2a3d260c""><code>822d4fd</code></a> Add links to third-party projects</li>
<li><a href=""https://github.com/pallets/click/commit/8e7bed0466fd49acf8bcf1399f54d7dc783fd6a1""><code>8e7bed0</code></a> Break up arguments section (<a href=""https://redirect.github.com/pallets/click/issues/2586"">#2586</a>)</li>
<li><a href=""https://github.com/pallets/click/commit/3241541fc89fe9c79908a6099fa2235dd20016e8""><code>3241541</code></a> Remove some typing hints.</li>
<li><a href=""https://github.com/pallets/click/commit/bed037717d5f39cf875d83df4025e62beebc77f4""><code>bed0377</code></a> remove test pypi</li>
<li><a href=""https://github.com/pallets/click/commit/653459007a15e4d75187acc5a1e1a08cbd787814""><code>6534590</code></a> update dev dependencies</li>
<li><a href=""https://github.com/pallets/click/commit/b1e392e69b2a32566550aa41c38875e9cafe2456""><code>b1e392e</code></a> fix typos</li>
<li><a href=""https://github.com/pallets/click/commit/fdc6b020465751d26f9e74a707f2c058b0dd251f""><code>fdc6b02</code></a> Fix missing reset in isolation function (<a href=""https://redirect.github.com/pallets/click/issues/2733"">#2733</a>)</li>
<li><a href=""https://github.com/pallets/click/commit/ffd43e9dc3b90bd698088fc7ebac9dbc6a4444b2""><code>ffd43e9</code></a> Fixed missing reset on _compat.should_strip_ansi.</li>
<li>Additional commits viewable in <a href=""https://github.com/pallets/click/compare/8.1.7...8.1.8"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=click&package-manager=pip&previous-version=8.1.7&new-version=8.1.8)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20820.org.readthedocs.build/en/20820/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,1,2025-05-12T01:34:35+00:00,2025-05-12T07:19:19+00:00,2025-05-12T07:19:18+00:00,ci;fabric;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3055397255,20819,"build(deps): update rich requirement from <13.6.0,>=12.3.0 to >=12.3.0,<14.1.0 in /requirements","Updates the requirements on [rich](https://github.com/Textualize/rich) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/Textualize/rich/releases"">rich's releases</a>.</em></p>
<blockquote>
<h2>The ENVy of all other releases</h2>
<p>Mostly updates to Traceback rendering, to add support for features introduced in Python3.11</p>
<p>We also have a new env var that I am proposing to become a standard. <code>TTY_COMPATIBLE=1</code> tells Rich to write ansi-escape sequences even if it detects it is not writing to a terminal. This is intended for use with GitHub Actions / CI, which can interpret escape sequences, but aren't a terminal.</p>
<p>There is also a change to how NO_COLOR and FORCE_COLOR are interpreted, which is the reason for the major version bump.</p>
<h2>[14.0.0] - 2025-03-30</h2>
<h3>Added</h3>
<ul>
<li>Added env var <code>TTY_COMPATIBLE</code> to override auto-detection of TTY support (See console.rst for details). <a href=""https://redirect.github.com/Textualize/rich/pull/3675"">Textualize/rich#3675</a></li>
</ul>
<h3>Changed</h3>
<ul>
<li>An empty <code>NO_COLOR</code> env var is now considered disabled. <a href=""https://redirect.github.com/Textualize/rich/pull/3675"">Textualize/rich#3675</a></li>
<li>An empty <code>FORCE_COLOR</code> env var is now considered disabled. <a href=""https://redirect.github.com/Textualize/rich/pull/3675"">Textualize/rich#3675</a></li>
<li>Rich tracebacks will now render notes on Python 3.11 onwards (added with <code>Exception.add_note</code>) <a href=""https://redirect.github.com/Textualize/rich/pull/3676"">Textualize/rich#3676</a></li>
<li>Indentation in exceptions won't be underlined <a href=""https://redirect.github.com/Textualize/rich/pull/3678"">Textualize/rich#3678</a></li>
<li>Rich tracebacks will now render Exception Groups <a href=""https://redirect.github.com/Textualize/rich/pull/3677"">Textualize/rich#3677</a></li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/Textualize/rich/blob/master/CHANGELOG.md"">rich's changelog</a>.</em></p>
<blockquote>
<h2>[14.0.0] - 2025-03-30</h2>
<h3>Added</h3>
<ul>
<li>Added env var <code>TTY_COMPATIBLE</code> to override auto-detection of TTY support (See console.rst for details). <a href=""https://redirect.github.com/Textualize/rich/pull/3675"">Textualize/rich#3675</a></li>
</ul>
<h3>Changed</h3>
<ul>
<li>An empty <code>NO_COLOR</code> env var is now considered disabled. <a href=""https://redirect.github.com/Textualize/rich/pull/3675"">Textualize/rich#3675</a></li>
<li>An empty <code>FORCE_COLOR</code> env var is now considered disabled. <a href=""https://redirect.github.com/Textualize/rich/pull/3675"">Textualize/rich#3675</a></li>
<li>Rich tracebacks will now render notes on Python 3.11 onwards (added with <code>Exception.add_note</code>) <a href=""https://redirect.github.com/Textualize/rich/pull/3676"">Textualize/rich#3676</a></li>
<li>Indentation in exceptions won't be underlined <a href=""https://redirect.github.com/Textualize/rich/pull/3678"">Textualize/rich#3678</a></li>
<li>Rich tracebacks will now render Exception Groups <a href=""https://redirect.github.com/Textualize/rich/pull/3677"">Textualize/rich#3677</a></li>
</ul>
<h2>[13.9.4] - 2024-11-01</h2>
<h3>Changed</h3>
<ul>
<li>Optimizations to cell_len which may speed up Rich / Textual output <a href=""https://redirect.github.com/Textualize/rich/pull/3546"">Textualize/rich#3546</a></li>
</ul>
<h2>[13.9.3] - 2024-10-22</h2>
<h3>Fixed</h3>
<ul>
<li>Fixed broken regex that may have resulted in poor performance. <a href=""https://redirect.github.com/Textualize/rich/pull/3535"">Textualize/rich#3535</a></li>
</ul>
<h2>[13.9.2] - 2024-10-04</h2>
<h3>Fixed</h3>
<ul>
<li>Fixed <code>Table</code> columns not highlighting when added by <code>add_row</code> <a href=""https://redirect.github.com/Textualize/rich/issues/3517"">Textualize/rich#3517</a></li>
<li>Fixed an issue with Segment.split_cells reported in Textual <a href=""https://redirect.github.com/Textualize/textual/issues/5090"">Textualize/textual#5090</a></li>
</ul>
<h2>[13.9.1] - 2024-10-01</h2>
<h3>Fixed</h3>
<ul>
<li>Fixed typing_extensions dependency</li>
</ul>
<h2>[13.9.0] - 2024-10-01</h2>
<h3>Changed</h3>
<ul>
<li>Dropped support for Python3.7 <a href=""https://redirect.github.com/Textualize/rich/pull/3509"">Textualize/rich#3509</a></li>
<li>Rich will display tracebacks with finely grained error locations on python 3.11+ <a href=""https://redirect.github.com/Textualize/rich/pull/3486"">Textualize/rich#3486</a></li>
</ul>
<h3>Fixed</h3>
<ul>
<li>Fixed issue with Segment._split_cells <a href=""https://redirect.github.com/Textualize/rich/pull/3506"">Textualize/rich#3506</a></li>
<li>Fix auto detection of terminal size on Windows <a href=""https://redirect.github.com/Textualize/rich/pull/2916"">Textualize/rich#2916</a></li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/Textualize/rich/commit/72e3bb33d44fd96881f7742b77137983907a942f""><code>72e3bb3</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3681"">#3681</a> from Textualize/bump14.0.0</li>
<li><a href=""https://github.com/Textualize/rich/commit/859d77bd6fbe67a72ddeacc300c85deed3b26598""><code>859d77b</code></a> bump to 13.0.0</li>
<li><a href=""https://github.com/Textualize/rich/commit/2bae2fe3d861ef83d778c289f6e1e17733225b76""><code>2bae2fe</code></a> Update feature_request.md</li>
<li><a href=""https://github.com/Textualize/rich/commit/07b738a23005076c75ecaeae1202e3a7772905b6""><code>07b738a</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3610"">#3610</a> from kotfu/master</li>
<li><a href=""https://github.com/Textualize/rich/commit/e6673492e52a2290d765438c33547df0a8b3e290""><code>e667349</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3624"">#3624</a> from itamaro/patch-1</li>
<li><a href=""https://github.com/Textualize/rich/commit/a48a5b309f9273ffba85fb9491b974634c8f7ab9""><code>a48a5b3</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3677"">#3677</a> from Textualize/exception-groups</li>
<li><a href=""https://github.com/Textualize/rich/commit/4de139ef0ec2581a6e1fe045949a86c183b734ac""><code>4de139e</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3679"">#3679</a> from bcapener/remove-leftover-code</li>
<li><a href=""https://github.com/Textualize/rich/commit/8f68c848bf458a1bf371c073d1e366da574eccde""><code>8f68c84</code></a> changelog</li>
<li><a href=""https://github.com/Textualize/rich/commit/ec5d2f1589c4c20e0f51f600f7a67f196948bcd4""><code>ec5d2f1</code></a> Merge branch 'master' into exception-groups</li>
<li><a href=""https://github.com/Textualize/rich/commit/13f9b4f874985cc2aeafc7954251597acdaa8544""><code>13f9b4f</code></a> style tweak</li>
<li>Additional commits viewable in <a href=""https://github.com/Textualize/rich/compare/v12.3.0...v14.0.0"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20819.org.readthedocs.build/en/20819/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,1,2025-05-12T01:34:29+00:00,2025-05-12T07:19:13+00:00,2025-05-12T07:19:11+00:00,ci;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3055397141,20818,build(deps): bump sphinxcontrib-video from 0.2.0 to 0.4.1 in /requirements,"[//]: # (dependabot-start)
⚠️  **Dependabot is rebasing this PR** ⚠️ 

Rebasing might not happen immediately, so don't worry if this takes some time.

Note: if you make any changes to this PR yourself, they will take precedence over the rebase.

---

[//]: # (dependabot-end)

Bumps [sphinxcontrib-video](https://github.com/sphinx-contrib/video) from 0.2.0 to 0.4.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/sphinx-contrib/video/releases"">sphinxcontrib-video's releases</a>.</em></p>
<blockquote>
<h2>v0.4.1</h2>
<h2>What's Changed</h2>
<ul>
<li>Add additional container class by <a href=""https://github.com/Piralein""><code>@​Piralein</code></a> in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/58"">sphinx-contrib/video#58</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/Piralein""><code>@​Piralein</code></a> made their first contribution in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/58"">sphinx-contrib/video#58</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/sphinx-contrib/video/compare/v0.4.0...v0.4.1"">https://github.com/sphinx-contrib/video/compare/v0.4.0...v0.4.1</a></p>
<h2>v0.4.0</h2>
<h2>What's Changed</h2>
<ul>
<li>Add controlslist attribute by <a href=""https://github.com/nkr0""><code>@​nkr0</code></a> in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/56"">sphinx-contrib/video#56</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/nkr0""><code>@​nkr0</code></a> made their first contribution in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/56"">sphinx-contrib/video#56</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/sphinx-contrib/video/compare/v0.3.2...v0.4.0"">https://github.com/sphinx-contrib/video/compare/v0.3.2...v0.4.0</a></p>
<h2>v0.3.2</h2>
<h2>What's Changed</h2>
<ul>
<li>Fix typos (NFC) by <a href=""https://github.com/sciencewhiz""><code>@​sciencewhiz</code></a> in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/54"">sphinx-contrib/video#54</a></li>
<li>Fix python testing, add testing up to 3.13 by <a href=""https://github.com/sciencewhiz""><code>@​sciencewhiz</code></a> in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/53"">sphinx-contrib/video#53</a></li>
<li>Add playsinline to supported options by <a href=""https://github.com/sciencewhiz""><code>@​sciencewhiz</code></a> in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/52"">sphinx-contrib/video#52</a></li>
<li>align and caption by <a href=""https://github.com/berlin2123""><code>@​berlin2123</code></a> in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/40"">sphinx-contrib/video#40</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/berlin2123""><code>@​berlin2123</code></a> made their first contribution in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/40"">sphinx-contrib/video#40</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/sphinx-contrib/video/compare/v0.3.1...v0.3.2"">https://github.com/sphinx-contrib/video/compare/v0.3.1...v0.3.2</a></p>
<h2>v0.3.1</h2>
<h2>What's Changed</h2>
<ul>
<li>refactor: stop overiding type of existing class members by <a href=""https://github.com/12rambau""><code>@​12rambau</code></a> in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/42"">sphinx-contrib/video#42</a></li>
<li>Fix references to favicon in contributing by <a href=""https://github.com/sciencewhiz""><code>@​sciencewhiz</code></a> in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/46"">sphinx-contrib/video#46</a></li>
<li>refactor: replace deprecated commit stages by <a href=""https://github.com/12rambau""><code>@​12rambau</code></a> in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/49"">sphinx-contrib/video#49</a></li>
<li>feat: add playsinline parameter by <a href=""https://github.com/12rambau""><code>@​12rambau</code></a> in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/48"">sphinx-contrib/video#48</a></li>
<li>Support for relative width by <a href=""https://github.com/AnonymouX47""><code>@​AnonymouX47</code></a> in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/26"">sphinx-contrib/video#26</a></li>
<li>build: use the sphinxcontrib namespace by <a href=""https://github.com/12rambau""><code>@​12rambau</code></a> in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/50"">sphinx-contrib/video#50</a></li>
<li>build: avoid building the unit tests twice per PR by <a href=""https://github.com/12rambau""><code>@​12rambau</code></a> in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/51"">sphinx-contrib/video#51</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/sciencewhiz""><code>@​sciencewhiz</code></a> made their first contribution in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/46"">sphinx-contrib/video#46</a></li>
<li><a href=""https://github.com/AnonymouX47""><code>@​AnonymouX47</code></a> made their first contribution in <a href=""https://redirect.github.com/sphinx-contrib/video/pull/26"">sphinx-contrib/video#26</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/sphinx-contrib/video/compare/v0.2.2...v0.3.1"">https://github.com/sphinx-contrib/video/compare/v0.2.2...v0.3.1</a></p>
<h2>v0.2.2</h2>
<p>refactor folder structure in hope to improve <a href=""https://redirect.github.com/sphinx-contrib/video/issues/35"">sphinx-contrib/video#35</a></p>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/sphinx-contrib/video/compare/v0.2.1...v0.2.2"">https://github.com/sphinx-contrib/video/compare/v0.2.1...v0.2.2</a></p>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/sphinx-contrib/video/commit/bc88acda4e82b9eae6ae8e82cac8890b489cacda""><code>bc88acd</code></a> bump: version 0.4.0 → 0.4.1</li>
<li><a href=""https://github.com/sphinx-contrib/video/commit/05799eccc1bfb6cee6042428e65cb32fda49a389""><code>05799ec</code></a> test: reorder the options in regression file</li>
<li><a href=""https://github.com/sphinx-contrib/video/commit/626e0bdee49c10583f8b83369eb6419a8e22ffcb""><code>626e0bd</code></a> test: use pathlib Path instead of internal sphinx ones</li>
<li><a href=""https://github.com/sphinx-contrib/video/commit/8317a504b4f7fff88a9ea8033dcb3076e74b1d63""><code>8317a50</code></a> Add additional container class (<a href=""https://redirect.github.com/sphinx-contrib/video/issues/58"">#58</a>)</li>
<li><a href=""https://github.com/sphinx-contrib/video/commit/8232c70713fed9372890ca962dd3282a8978e1ee""><code>8232c70</code></a> Add additional container class</li>
<li><a href=""https://github.com/sphinx-contrib/video/commit/a29edef2bb404701f58c5869c98ebc2f6ce54f2f""><code>a29edef</code></a> bump: version 0.3.2 → 0.4.0</li>
<li><a href=""https://github.com/sphinx-contrib/video/commit/15c82246c7d395645c2136fa6cf26cec75fd9f62""><code>15c8224</code></a> feat: Add controlslist attribute (<a href=""https://redirect.github.com/sphinx-contrib/video/issues/56"">#56</a>)</li>
<li><a href=""https://github.com/sphinx-contrib/video/commit/6a52ece93e037b32a24d8f0af9c8b8034917a5cb""><code>6a52ece</code></a> fix: mypy error</li>
<li><a href=""https://github.com/sphinx-contrib/video/commit/dc46c7b24aa561fd43043638dcb0590129f8e7cc""><code>dc46c7b</code></a> fix: typo</li>
<li><a href=""https://github.com/sphinx-contrib/video/commit/0ecbb81ed92230c93ed1c637f5fca457527d26ba""><code>0ecbb81</code></a> fix: typo and build only file that is relevant to a test</li>
<li>Additional commits viewable in <a href=""https://github.com/sphinx-contrib/video/compare/v0.2.0...v0.4.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinxcontrib-video&package-manager=pip&previous-version=0.2.0&new-version=0.4.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20818.org.readthedocs.build/en/20818/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,1,2025-05-12T01:34:23+00:00,2025-05-12T07:19:05+00:00,2025-05-12T07:19:04+00:00,docs;ci;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3055397070,20817,"build(deps): update tqdm requirement from <4.67.0,>=4.57.0 to >=4.57.0,<4.68.0 in /requirements","Updates the requirements on [tqdm](https://github.com/tqdm/tqdm) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/tqdm/tqdm/releases"">tqdm's releases</a>.</em></p>
<blockquote>
<h2>tqdm v4.67.1 stable</h2>
<ul>
<li>fix <code>gui</code> (<code>matplotlib</code> syntax) (<a href=""https://redirect.github.com/tqdm/tqdm/issues/1629"">#1629</a>)</li>
<li>misc test &amp; framework updates
<ul>
<li>bump <code>pytest-asyncio</code> (<a href=""https://redirect.github.com/tqdm/tqdm/issues/1630"">#1630</a>)</li>
<li>fix <code>codecov</code> rate limit</li>
<li>fix pybuild</li>
<li>sync dependencies</li>
</ul>
</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/tqdm/tqdm/commit/0ed5d7f18fa3153834cbac0aa57e8092b217cc16""><code>0ed5d7f</code></a> bump version, merge pull request <a href=""https://redirect.github.com/tqdm/tqdm/issues/1629"">#1629</a> from tqdm/fix-gui</li>
<li><a href=""https://github.com/tqdm/tqdm/commit/a2d5f1c9d1cbdbcf56f52dc4365ea4124e3e33f7""><code>a2d5f1c</code></a> tests: fix codecov rate limit</li>
<li><a href=""https://github.com/tqdm/tqdm/commit/cac7150d7c8a650c7e76004cd7f8643990932c7f""><code>cac7150</code></a> tests: bump pytest-asyncio</li>
<li><a href=""https://github.com/tqdm/tqdm/commit/6338f6216996918fdc9c9a73bf095acac54ce0bb""><code>6338f62</code></a> deps: fix pybuild</li>
<li><a href=""https://github.com/tqdm/tqdm/commit/342b15ed68ae7c5ec1082cadb1b563c7dfde610f""><code>342b15e</code></a> tests: sync deps</li>
<li><a href=""https://github.com/tqdm/tqdm/commit/c66458d9ac2ad096937406f79d105af891cee6e7""><code>c66458d</code></a> gui: fix matplotlib</li>
<li><a href=""https://github.com/tqdm/tqdm/commit/35a6ee9a4527bab5c0c7234531269e0c7fd0f2fd""><code>35a6ee9</code></a> bump version, merge pull request <a href=""https://redirect.github.com/tqdm/tqdm/issues/1536"">#1536</a> from guigoruiz1</li>
<li><a href=""https://github.com/tqdm/tqdm/commit/8aa9470e485a90679936d3781a4f953cf5afa8f4""><code>8aa9470</code></a> add discord requests dep</li>
<li><a href=""https://github.com/tqdm/tqdm/commit/1db24b4ff442c43752cf56a55b1782998c76801c""><code>1db24b4</code></a> better user-agent</li>
<li><a href=""https://github.com/tqdm/tqdm/commit/61365d8321ae4ca433d2c6cda770a73a8e0e62cb""><code>61365d8</code></a> handle rate limit</li>
<li>Additional commits viewable in <a href=""https://github.com/tqdm/tqdm/compare/v4.57.0...v4.67.1"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20817.org.readthedocs.build/en/20817/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,1,2025-05-12T01:34:19+00:00,2025-05-12T07:18:58+00:00,2025-05-12T07:18:56+00:00,ci;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3055396689,20816,build(deps): bump twine from 6.0.1 to 6.1.0 in /requirements,"Bumps [twine](https://github.com/pypa/twine) from 6.0.1 to 6.1.0.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/twine/blob/main/docs/changelog.rst"">twine's changelog</a>.</em></p>
<blockquote>
<h2>Twine 6.1.0 (2025-01-17)</h2>
<p>Features
^^^^^^^^</p>
<ul>
<li>Twine now has preliminary built-in support for
<code>Trusted Publishing &lt;https://docs.pypi.org/trusted-publishers/&gt;</code>_ as an
authentication mechanism. (<code>[#1194](https://github.com/pypa/twine/issues/1194) &lt;https://github.com/pypa/twine/pull/1194&gt;</code>_)</li>
</ul>
<p>Deprecations and Removals
^^^^^^^^^^^^^^^^^^^^^^^^^</p>
<ul>
<li>
<p>Remove support for <code>egg</code> and <code>wininst</code> distribution types. These are not
accepted by PyPI and not produced by any modern build-backends.
(<code>[#1195](https://github.com/pypa/twine/issues/1195) &lt;https://github.com/pypa/twine/issues/1195&gt;</code>_)</p>
</li>
<li>
<p>Twine no longer supports <code>.tar.bz2</code> source distributions.
(<code>[#1200](https://github.com/pypa/twine/issues/1200) &lt;https://github.com/pypa/twine/pull/1200&gt;</code>_)</p>
</li>
</ul>
<p>Misc
^^^^</p>
<ul>
<li>
<p><code>packaging</code> is used instead of <code>pkginfo</code> for parsing and validating
metadata. This aligns metadata validation to the one performed by PyPI.
<code>packaging</code> version 24.0 or later is required. Support for metadata
version 2.4 requires <code>packaging</code> 24.2 or later. <code>pkginfo</code> is not a
dependency anymore. (<code>[#1180](https://github.com/pypa/twine/issues/1180) &lt;https://github.com/pypa/twine/issues/1180&gt;</code>_)</p>
</li>
<li>
<p>Use <code>&quot;source&quot;</code> instead of <code>None</code> as <code>pyversion</code> for <code>sdist</code>
uploads. This is what PyPI (and most likely other package indexes)
expects. (<code>[#1191](https://github.com/pypa/twine/issues/1191) &lt;https://github.com/pypa/twine/issues/1191&gt;</code>_)</p>
</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pypa/twine/commit/aa3a910cdef8e0a3cb4e893f4c371b58015f52e0""><code>aa3a910</code></a> Update changelog for 6.1.0 (<a href=""https://redirect.github.com/pypa/twine/issues/1214"">#1214</a>)</li>
<li><a href=""https://github.com/pypa/twine/commit/440603423ac579946aec0c15b280c6ef44477400""><code>4406034</code></a> Merge pull request <a href=""https://redirect.github.com/pypa/twine/issues/1208"">#1208</a> from dnicolodi/rm-setuptools</li>
<li><a href=""https://github.com/pypa/twine/commit/2ca55db34c537bbcb00e157e407320c1e5f8f08b""><code>2ca55db</code></a> Simplify generation of test packages used in test_check</li>
<li><a href=""https://github.com/pypa/twine/commit/bffd2963bbc9c321670eea659d30178000a7bae7""><code>bffd296</code></a> Move build_archive() from test_sdist to common helpers module</li>
<li><a href=""https://github.com/pypa/twine/commit/fd0646e12e25752d136f9520d7af0d108bc1f29e""><code>fd0646e</code></a> Merge pull request <a href=""https://redirect.github.com/pypa/twine/issues/1206"">#1206</a> from dnicolodi/rm-binary-blobs-part1</li>
<li><a href=""https://github.com/pypa/twine/commit/ab4ec8cc0f926a935070731246905f3985ff735d""><code>ab4ec8c</code></a> Merge pull request <a href=""https://redirect.github.com/pypa/twine/issues/1211"">#1211</a> from pypa/dependabot/github_actions/actions/upload-a...</li>
<li><a href=""https://github.com/pypa/twine/commit/b562f7422403b0cadff694d2e81b98cf2e28894f""><code>b562f74</code></a> build(deps): bump actions/upload-artifact from 4.5.0 to 4.6.0</li>
<li><a href=""https://github.com/pypa/twine/commit/b2832de88421edd0d11bfe2ceb53470e12f18bb2""><code>b2832de</code></a> Remove tests/fixtures/twine-1.5.0.zip</li>
<li><a href=""https://github.com/pypa/twine/commit/970851d9b188dc916e6d95083b1797bd6c277ce5""><code>970851d</code></a> Remove tests/alt-fixtures/twine-1.5.0-py2.py3-none-any.whl</li>
<li><a href=""https://github.com/pypa/twine/commit/2386ca5300cd7bde59432834d362c07de61e9a53""><code>2386ca5</code></a> build(deps): bump actions/upload-artifact from 4.4.3 to 4.5.0 (<a href=""https://redirect.github.com/pypa/twine/issues/1205"">#1205</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/pypa/twine/compare/6.0.1...6.1.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=twine&package-manager=pip&previous-version=6.0.1&new-version=6.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20816.org.readthedocs.build/en/20816/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,1,2025-05-12T01:34:14+00:00,2025-05-12T07:18:50+00:00,2025-05-12T07:18:48+00:00,ci;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3055396650,20815,"build(deps): update nbsphinx requirement from <=0.9.2,>=0.8.5 to >=0.8.5,<=0.9.7 in /requirements","Updates the requirements on [nbsphinx](https://github.com/spatialaudio/nbsphinx) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/spatialaudio/nbsphinx/releases"">nbsphinx's releases</a>.</em></p>
<blockquote>
<h2>nbsphinx 0.9.7</h2>
<p><a href=""https://pypi.org/project/nbsphinx/0.9.7/"">https://pypi.org/project/nbsphinx/0.9.7/</a></p>
<ul>
<li>Disable Sphinx 8.2+ (for now)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/spatialaudio/nbsphinx/blob/master/NEWS.rst"">nbsphinx's changelog</a>.</em></p>
<blockquote>
<p>Version 0.9.7 -- 2025-03-03 -- PyPI__ -- diff__</p>
<ul>
<li>Disable Sphinx 8.2+ (for now)</li>
</ul>
<p>__ <a href=""https://pypi.org/project/nbsphinx/0.9.7/"">https://pypi.org/project/nbsphinx/0.9.7/</a>
__ <a href=""https://github.com/spatialaudio/nbsphinx/compare/0.9.6...0.9.7"">https://github.com/spatialaudio/nbsphinx/compare/0.9.6...0.9.7</a></p>
<p>Version 0.9.6 -- 2024-12-24 -- PyPI__ -- diff__</p>
<ul>
<li>Markdown: allow lists without leading blank line</li>
</ul>
<p>__ <a href=""https://pypi.org/project/nbsphinx/0.9.6/"">https://pypi.org/project/nbsphinx/0.9.6/</a>
__ <a href=""https://github.com/spatialaudio/nbsphinx/compare/0.9.5...0.9.6"">https://github.com/spatialaudio/nbsphinx/compare/0.9.5...0.9.6</a></p>
<p>Version 0.9.5 -- 2024-08-13 -- PyPI__ -- diff__</p>
<ul>
<li>Miscellaneous fixes</li>
</ul>
<p>__ <a href=""https://pypi.org/project/nbsphinx/0.9.5/"">https://pypi.org/project/nbsphinx/0.9.5/</a>
__ <a href=""https://github.com/spatialaudio/nbsphinx/compare/0.9.4...0.9.5"">https://github.com/spatialaudio/nbsphinx/compare/0.9.4...0.9.5</a></p>
<p>Version 0.9.4 -- 2024-05-06 -- PyPI__ -- diff__</p>
<ul>
<li>Require <code>docutils &gt;= 0.18.1</code></li>
<li>Minor fixes, documentation and CI updates</li>
</ul>
<p>__ <a href=""https://pypi.org/project/nbsphinx/0.9.4/"">https://pypi.org/project/nbsphinx/0.9.4/</a>
__ <a href=""https://github.com/spatialaudio/nbsphinx/compare/0.9.3...0.9.4"">https://github.com/spatialaudio/nbsphinx/compare/0.9.3...0.9.4</a></p>
<p>Version 0.9.3 -- 2023-08-27 -- PyPI__ -- diff__</p>
<ul>
<li>Fix gallery regression in Sphinx 7.2</li>
</ul>
<p>__ <a href=""https://pypi.org/project/nbsphinx/0.9.3/"">https://pypi.org/project/nbsphinx/0.9.3/</a>
__ <a href=""https://github.com/spatialaudio/nbsphinx/compare/0.9.2...0.9.3"">https://github.com/spatialaudio/nbsphinx/compare/0.9.2...0.9.3</a></p>
<p>Version 0.9.2 -- 2023-05-24 -- PyPI__ -- diff__</p>
<ul>
<li>Improve support for <code>sphinx_immaterial</code> theme</li>
<li>Improve support for links starting with <code>#</code></li>
<li>Add support for in-text citations</li>
<li>LaTeX: Add support for admonition titles</li>
</ul>
<p>__ <a href=""https://pypi.org/project/nbsphinx/0.9.2/"">https://pypi.org/project/nbsphinx/0.9.2/</a>
__ <a href=""https://github.com/spatialaudio/nbsphinx/compare/0.9.1...0.9.2"">https://github.com/spatialaudio/nbsphinx/compare/0.9.1...0.9.2</a></p>
<p>Version 0.9.1 -- 2023-03-14 -- PyPI__ -- diff__</p>
<ul>
<li>pandoc: disable &quot;smart&quot; option only for version 2.0+</li>
</ul>
<p>__ <a href=""https://pypi.org/project/nbsphinx/0.9.1/"">https://pypi.org/project/nbsphinx/0.9.1/</a>
__ <a href=""https://github.com/spatialaudio/nbsphinx/compare/0.9.0...0.9.1"">https://github.com/spatialaudio/nbsphinx/compare/0.9.0...0.9.1</a></p>
<p>Version 0.9.0 -- 2023-03-12 -- PyPI__ -- diff__</p>
<ul>
<li>
<p>Split <code>nbsphinx.py</code> (a Python <em>module</em>) into:</p>
<ul>
<li><code>nbsphinx/__init__.py</code> (a Python <em>package</em>)</li>
</ul>
</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/spatialaudio/nbsphinx/commit/b59d3a5ffc203d89b4f44bfcff21dbefdeb44816""><code>b59d3a5</code></a> Release 0.9.7</li>
<li><a href=""https://github.com/spatialaudio/nbsphinx/commit/cc1981aee8b65402dec94aacb614252b8ed65481""><code>cc1981a</code></a> linkcheck: ignore repology</li>
<li><a href=""https://github.com/spatialaudio/nbsphinx/commit/eb05c986aac939e6ad6f6db6f890ea93541bdfab""><code>eb05c98</code></a> CI: bump Python versions</li>
<li><a href=""https://github.com/spatialaudio/nbsphinx/commit/9165a342255ed4427dbba6adc8fe801b37ab0365""><code>9165a34</code></a> Ensure that old sphinx is tested with supported python version</li>
<li><a href=""https://github.com/spatialaudio/nbsphinx/commit/08ee77d4475b5227776c36f3e0192ffa111b351c""><code>08ee77d</code></a> Disable Sphinx 8.2+</li>
<li><a href=""https://github.com/spatialaudio/nbsphinx/commit/9965d2f9fd35d7860ef44e153b8fafcc11f23bf7""><code>9965d2f</code></a> Specify sphinx.configuration for RTD</li>
<li><a href=""https://github.com/spatialaudio/nbsphinx/commit/215bf0d9b2108c739a224736d8763dffc91f3479""><code>215bf0d</code></a> Release 0.9.6</li>
<li><a href=""https://github.com/spatialaudio/nbsphinx/commit/35686f55088bdc4d0c6bf96c582e48a19bbdda63""><code>35686f5</code></a> DOC: Remove broken link</li>
<li><a href=""https://github.com/spatialaudio/nbsphinx/commit/837bea68cf79101d2dd7f4d888fe170c92f1f479""><code>837bea6</code></a> CI: ignore deprecated import_object</li>
<li><a href=""https://github.com/spatialaudio/nbsphinx/commit/40d8cd4846f6c37a152b05ecf90d2244f2dd9d4c""><code>40d8cd4</code></a> Use force=True with copyfile (<a href=""https://redirect.github.com/spatialaudio/nbsphinx/issues/819"">#819</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/spatialaudio/nbsphinx/compare/0.8.5...0.9.7"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20815.org.readthedocs.build/en/20815/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,1,2025-05-12T01:34:12+00:00,2025-05-12T07:18:41+00:00,2025-05-12T07:18:39+00:00,docs;ci;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3055396613,20814,build(deps): bump sphinx-toolbox from 3.5.0 to 3.10.0 in /requirements,"Bumps [sphinx-toolbox](https://github.com/sphinx-toolbox/sphinx-toolbox) from 3.5.0 to 3.10.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/sphinx-toolbox/sphinx-toolbox/releases"">sphinx-toolbox's releases</a>.</em></p>
<blockquote>
<h2>Version 3.10.0</h2>
<p>Automatically copied from <a href=""https://pypi.org/project/sphinx-toolbox/3.10.0"">PyPI</a>.</p>
<hr />
<p>Powered by OctoCheese<br />
<a href=""https://octocheese.readthedocs.io"">📝 docs</a> | <a href=""https://github.com/domdfcoding/octocheese"">:octocat: repo</a> | <a href=""https://github.com/domdfcoding/octocheese/issues"">🙋 issues</a> | <a href=""https://github.com/marketplace/octocheese"">🏪 marketplace</a></p>
<!-- raw HTML omitted -->
<h2>Version 3.9.0</h2>
<p>Automatically copied from <a href=""https://pypi.org/project/sphinx-toolbox/3.9.0"">PyPI</a>.</p>
<hr />
<p>Powered by OctoCheese<br />
<a href=""https://octocheese.readthedocs.io"">📝 docs</a> | <a href=""https://github.com/domdfcoding/octocheese"">:octocat: repo</a> | <a href=""https://github.com/domdfcoding/octocheese/issues"">🙋 issues</a> | <a href=""https://github.com/marketplace/octocheese"">🏪 marketplace</a></p>
<!-- raw HTML omitted -->
<h2>Version 3.8.3</h2>
<p>Automatically copied from <a href=""https://pypi.org/project/sphinx-toolbox/3.8.3"">PyPI</a>.</p>
<hr />
<p>Powered by OctoCheese<br />
<a href=""https://octocheese.readthedocs.io"">📝 docs</a> | <a href=""https://github.com/domdfcoding/octocheese"">:octocat: repo</a> | <a href=""https://github.com/domdfcoding/octocheese/issues"">🙋 issues</a> | <a href=""https://github.com/marketplace/octocheese"">🏪 marketplace</a></p>
<!-- raw HTML omitted -->
<h2>Version 3.8.2</h2>
<p>Automatically copied from <a href=""https://pypi.org/project/sphinx-toolbox/3.8.2"">PyPI</a>.</p>
<hr />
<p>Powered by OctoCheese<br />
<a href=""https://octocheese.readthedocs.io"">📝 docs</a> | <a href=""https://github.com/domdfcoding/octocheese"">:octocat: repo</a> | <a href=""https://github.com/domdfcoding/octocheese/issues"">🙋 issues</a> | <a href=""https://github.com/marketplace/octocheese"">🏪 marketplace</a></p>
<!-- raw HTML omitted -->
<h2>Version 3.8.1</h2>
<p>Automatically copied from <a href=""https://pypi.org/project/sphinx-toolbox/3.8.1"">PyPI</a>.</p>
<hr />
<p>Powered by OctoCheese<br />
<a href=""https://octocheese.readthedocs.io"">📝 docs</a> | <a href=""https://github.com/domdfcoding/octocheese"">:octocat: repo</a> | <a href=""https://github.com/domdfcoding/octocheese/issues"">🙋 issues</a> | <a href=""https://github.com/marketplace/octocheese"">🏪 marketplace</a></p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/sphinx-toolbox/sphinx-toolbox/blob/master/doc-source/changelog.rst"">sphinx-toolbox's changelog</a>.</em></p>
<blockquote>
<h2>3.10.0</h2>
<p>Allow GitHub branch to be specified for :rst:dir:<code>installation</code> directive.</p>
<h2>3.9.0</h2>
<p>Improved support for Sphinx 8.1+</p>
<h2>3.8.2</h2>
<p>(BUG) Fix GitHub issue title parsing.</p>
<h2>3.8.0</h2>
<p>Improved support for Sphinx 7.3+</p>
<h2>3.7.0</h2>
<ul>
<li>Add :class:<code>sphinx_toolbox.more_autodoc.variables.PropertyDocumenter</code>.</li>
<li>Use sphinx's <code>HTML5Translator</code> over <code>HTMLTranslator</code>.</li>
</ul>
<h2>3.6.0</h2>
<ul>
<li>Documentation fixes in :mod:<code>~.collapse</code>.</li>
<li>Dunder methods added in Python 3.13 are hidden by :mod:<code>~.autoprotocol</code> (<code>__non_callable_proto_members__</code>, <code>__firstlineno__</code>, <code>__replace__</code>, <code>__static_attributes__</code>)</li>
<li>mod:<code>~.autoprotocol</code> doesn't document subclasses of protocols, unless :class:<code>~.Protocol</code> is one of their direct base classes.</li>
<li>Support for Sphinx 7.x</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/sphinx-toolbox/sphinx-toolbox/commit/e7f4d29d813147d7ef89c2d579eaa53c01fa7074""><code>e7f4d29</code></a> Bump version v3.9.0 -&gt; v3.10.0</li>
<li><a href=""https://github.com/sphinx-toolbox/sphinx-toolbox/commit/36afdac60c96b5e4177c660fd3d41a8403650756""><code>36afdac</code></a> Allow GitHub branch to be specified for installation directive. (<a href=""https://redirect.github.com/sphinx-toolbox/sphinx-toolbox/issues/185"">#185</a>)</li>
<li><a href=""https://github.com/sphinx-toolbox/sphinx-toolbox/commit/f3ae5048d6492bff8724e629857c5b27fcbed579""><code>f3ae504</code></a> Add changelog entries for past few versions.</li>
<li><a href=""https://github.com/sphinx-toolbox/sphinx-toolbox/commit/dac42618ba0ec10672ba0cfd4b07ce4724718d18""><code>dac4261</code></a> Updated files with 'repo_helper'. (<a href=""https://redirect.github.com/sphinx-toolbox/sphinx-toolbox/issues/183"">#183</a>)</li>
<li><a href=""https://github.com/sphinx-toolbox/sphinx-toolbox/commit/b2013dd86e756e64c68b11a934adbcf4462af700""><code>b2013dd</code></a> Update tests for installation directive.</li>
<li><a href=""https://github.com/sphinx-toolbox/sphinx-toolbox/commit/c15ca3ca55740d12895a4aa0e7b18740cf53c301""><code>c15ca3c</code></a> Fix installation tabs in HTML when not under &quot;Installation&quot; heading.</li>
<li><a href=""https://github.com/sphinx-toolbox/sphinx-toolbox/commit/0d872122690b04dafafbb6ddde0806aef0ee2878""><code>0d87212</code></a> Lint</li>
<li><a href=""https://github.com/sphinx-toolbox/sphinx-toolbox/commit/dfd16379d0804fce1308b2b3f7d60d4ed7adae6a""><code>dfd1637</code></a> Fix tests on newer Sphinx versions on newer Pythons.</li>
<li><a href=""https://github.com/sphinx-toolbox/sphinx-toolbox/commit/1cf39a23237e52c767864b04cd6cb4f63c51f679""><code>1cf39a2</code></a> Fix tests on Python 3.12</li>
<li><a href=""https://github.com/sphinx-toolbox/sphinx-toolbox/commit/30d84f96fba1736868cd98b4c274e266f0f5f829""><code>30d84f9</code></a> Don't test Python 3.12 with older Sphinx versions (require distutils)</li>
<li>Additional commits viewable in <a href=""https://github.com/sphinx-toolbox/sphinx-toolbox/compare/v3.5.0...v3.10.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-toolbox&package-manager=pip&previous-version=3.5.0&new-version=3.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20814.org.readthedocs.build/en/20814/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,1,2025-05-12T01:34:10+00:00,2025-05-12T07:18:32+00:00,2025-05-12T07:18:31+00:00,docs;ci;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3055396579,20813,"build(deps): update sphinx requirement from <6.0,>5.0 to >5.0,<8.0 in /requirements","Updates the requirements on [sphinx](https://github.com/sphinx-doc/sphinx) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/sphinx-doc/sphinx/releases"">sphinx's releases</a>.</em></p>
<blockquote>
<h2>Sphinx 7.4.7</h2>
<p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/sphinx-doc/sphinx/blob/v7.4.7/CHANGES.rst"">sphinx's changelog</a>.</em></p>
<blockquote>
<h1>Release 7.4.7 (released Jul 20, 2024)</h1>
<h2>Bugs fixed</h2>
<ul>
<li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12096"">#12096</a>: Warn when files are overwritten in the build directory.
Patch by Adam Turner and Bénédikt Tran.</li>
<li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12620"">#12620</a>: Ensure that old-style object description options are respected.
Patch by Adam Turner.</li>
<li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12601"">#12601</a>, <a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12625"">#12625</a>: Support callable objects in :py:class:<code>~typing.Annotated</code> type
metadata in the Python domain.
Patch by Adam Turner.</li>
<li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12601"">#12601</a>, <a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12622"">#12622</a>: Resolve :py:class:<code>~typing.Annotated</code> warnings with
<code>sphinx.ext.autodoc</code>,
especially when using :mod:<code>dataclasses</code> as type metadata.
Patch by Adam Turner.</li>
<li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12589"">#12589</a>, <a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12626"">#12626</a>: autosummary: Fix warnings with :rst:role:<code>!autolink</code>.
Patch by Adam Turner.</li>
</ul>
<h1>Release 7.4.6 (released Jul 18, 2024)</h1>
<h2>Bugs fixed</h2>
<ul>
<li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12589"">#12589</a>, <a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/9743"">#9743</a>, <a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12609"">#12609</a>: autosummary: Do not add the package prefix when
generating autosummary directives for modules within a package.
Patch by Adam Turner.</li>
<li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12613"">#12613</a>: Reduce log severity for ambiguity detection during inventory loading.
Patch by James Addison.</li>
</ul>
<h1>Release 7.4.5 (released Jul 16, 2024)</h1>
<h2>Bugs fixed</h2>
<ul>
<li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12593"">#12593</a>, <a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12600"">#12600</a>: Revert coercing the type of selected :confval:<code>html_sidebars</code>
values to a list.
Log an error message when string values are detected.
Patch by Adam Turner.</li>
<li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12594"">#12594</a>: LaTeX: since 7.4.0, :rst:dir:<code>seealso</code> and other &quot;light&quot; admonitions
now break PDF builds if they contain a :dudir:<code>figure</code> directive; and also
if they are contained in a table cell (rendered by <code>tabulary</code>).
Patch by Jean-François B.</li>
</ul>
<h1>Release 7.4.4 (released Jul 15, 2024)</h1>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/sphinx-doc/sphinx/commit/0d912c85fd3ec385432fe707f6a0678425d1e841""><code>0d912c8</code></a> Bump to 7.4.7 final</li>
<li><a href=""https://github.com/sphinx-doc/sphinx/commit/bbc97e035720d96f617921dbd25022e121495b98""><code>bbc97e0</code></a> autosummary: Filter invalid import prefixes in <code>autolink</code> (<a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12626"">#12626</a>)</li>
<li><a href=""https://github.com/sphinx-doc/sphinx/commit/6c486a575c858b8b82d2580b76c410121663505f""><code>6c486a5</code></a> Fix detecting file changes for the overwritten file warning (<a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12627"">#12627</a>)</li>
<li><a href=""https://github.com/sphinx-doc/sphinx/commit/2bd973e7191c5bc382c1a92b37ab1f20268f42d6""><code>2bd973e</code></a> autodoc: Fix warnings with dataclasses in <code>Annotated</code> metadata (<a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12622"">#12622</a>)</li>
<li><a href=""https://github.com/sphinx-doc/sphinx/commit/dd77f851494d24d19aecf0328c6913d121b8b51c""><code>dd77f85</code></a> Support callables in <code>Annotated</code> types (<a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12625"">#12625</a>)</li>
<li><a href=""https://github.com/sphinx-doc/sphinx/commit/1ed4ca7e038364b3b10e3d36abb84ee034d4d94c""><code>1ed4ca7</code></a> Mark <code>test_build_manpage</code> as XFAIL following changes in Docutils master</li>
<li><a href=""https://github.com/sphinx-doc/sphinx/commit/cd8ce07d31cfab61b6996cec1334681600dd3259""><code>cd8ce07</code></a> Update message catalogues following reverted commits</li>
<li><a href=""https://github.com/sphinx-doc/sphinx/commit/c6cd25f50dcc2a0bc369da80e75f105a4821d43b""><code>c6cd25f</code></a> Partially revert &quot;Update message catalogues (<a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/11626"">#11626</a>)&quot;</li>
<li><a href=""https://github.com/sphinx-doc/sphinx/commit/fa2ba7d5aeaff36aeb1a6c2f49846432fc932c7a""><code>fa2ba7d</code></a> Partially Revert &quot;[bot]: Update message catalogues (<a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12563"">#12563</a>)&quot;</li>
<li><a href=""https://github.com/sphinx-doc/sphinx/commit/e439c6f33f8d8e7bc06b4f6f25dadfda74869ee0""><code>e439c6f</code></a> Ensure that old-style object description options are respected (<a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/12620"">#12620</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v5.0.1...v7.4.7"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20813.org.readthedocs.build/en/20813/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,3,2025-05-12T01:34:07+00:00,2025-05-12T07:20:05+00:00,2025-05-12T07:19:41+00:00,docs;ci;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3054865516,20812,Reloading every_n_epochs (trainer flag reload_dataloaders_every_n_epochs) not working in 2.5.1.,"### Bug description

When using pytorch-lightning==2.5.1, the train_dataloader() method of a LightningDataModule is only called once at the very beginning of the training process (before Epoch 0), even when trainer.reload_dataloaders_every_n_epochs is explicitly set to 1 on the Trainer instance.

The expected behavior is that train_dataloader() should be called by the Trainer at the start of every epoch (Epoch 1, Epoch 2, etc.) when reload_dataloaders_every_n_epochs=1.

This prevents the intended dynamic reloading or switching of the training dataset each epoch.

Environment:

PyTorch Lightning Version: 2.5.1
PyTorch Version: 2.7.0
Python Version: 3.11
CUDA/GPU information: NVIDIA A100

### What version are you seeing the problem on?

v2.5

### Reproduced in studio

_No response_

### How to reproduce the bug

```python

```

### Error messages and logs

```
# Error messages and logs here please
```


### Environment

<details>
  <summary>Current environment</summary>

```
#- PyTorch Lightning Version (e.g., 2.5.0):
#- PyTorch Version (e.g., 2.5):
#- Python version (e.g., 3.12):
#- OS (e.g., Linux):
#- CUDA/cuDNN version:
#- GPU models and configuration:
#- How you installed Lightning(`conda`, `pip`, source):
```

</details>


### More info

_No response_",carlos10garrido,29857305,closed,False,0,2025-05-11T09:37:17+00:00,2025-05-11T11:58:19+00:00,2025-05-11T11:58:19+00:00,bug;needs triage;ver: 2.5.x,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3054781299,20811,WIP: to_onnx return ONNXProgram,"## What does this PR do?

<!--
Please include a summary of the change and which issue is fixed.
Please also include relevant motivation and context.
List any dependencies that are required for this change.

If we didn't discuss your PR in Github issues there's a high chance it will not be merged.

The following links the related issue to the PR (https://docs.github.com/en/free-pro-team@latest/github/managing-your-work-on-github/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword)
-->

Fixes #20810

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [ ] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [ ] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [ ] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [ ] Is this pull request ready for review? (if not, please submit in draft mode)
- [ ] Check that all items from **Before submitting** are resolved
- [ ] Make sure the title is self-explanatory and the description concisely explains the PR
- [ ] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20811.org.readthedocs.build/en/20811/

<!-- readthedocs-preview pytorch-lightning end -->",GdoongMathew,25893369,open,False,0,2025-05-11T07:01:31+00:00,2025-05-11T11:37:45+00:00,,pl;dependencies;package,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3054770601,20810,Allow to return `ONNXProgram` when calling `to_onnx(dynamo=True)`,"### Description & Motivation

Since torch 2.7.0, they started to unify the onnx export logic, thus when calling 
```python
torch.onnx.export(dynamo=True)
```
torch would start to return the `ONNXProgram` object. (https://github.com/pytorch/pytorch/pull/137296)

The `LightningModule` should also have the same behavior.

## Solution
```python
class LightningModule:
    @torch.no_grad()
    def to_onnx(
        self,
        file_path: Union[str, Path, BytesIO, None] = None,
        input_sample: Optional[Any] = None,
        **kwargs: Any,
    ) -> Union[""ONNXProgram"", None]:
        if kwargs.get(""dynamo"", False) and not _ONNXSCRIPT_AVAILABLE:
            raise ModuleNotFoundError(...)
        ...
        ret = torch.onnx.export(self, input_sample, file_path, **kwargs)
        self.train(mode)
        return ret
```

### Pitch

_No response_

### Alternatives

_No response_

### Additional context

_No response_

cc @lantiga @borda",GdoongMathew,25893369,open,False,0,2025-05-11T06:35:32+00:00,2025-05-11T06:35:53+00:00,,feature;needs triage,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3054324191,20809,Fix advanced profiler for python >=3.12,"## What does this PR do?

Fixes #19983

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [ ] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [ ] Is this pull request ready for review? (if not, please submit in draft mode)
- [ ] Check that all items from **Before submitting** are resolved
- [ ] Make sure the title is self-explanatory and the description concisely explains the PR
- [ ] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20809.org.readthedocs.build/en/20809/

<!-- readthedocs-preview pytorch-lightning end -->",relativityhd,37540371,open,False,0,2025-05-10T16:15:56+00:00,2025-05-12T08:14:28+00:00,,pl,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3053895383,20808,WIP: Torch-Tensorrt Integration with LightningModule,"## What does this PR do?

<!--
Please include a summary of the change and which issue is fixed.
Please also include relevant motivation and context.
List any dependencies that are required for this change.

If we didn't discuss your PR in Github issues there's a high chance it will not be merged.

The following links the related issue to the PR (https://docs.github.com/en/free-pro-team@latest/github/managing-your-work-on-github/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword)
-->

Fixes #11438 

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [ ] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [ ] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [ ] Is this pull request ready for review? (if not, please submit in draft mode)
- [ ] Check that all items from **Before submitting** are resolved
- [ ] Make sure the title is self-explanatory and the description concisely explains the PR
- [ ] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20808.org.readthedocs.build/en/20808/

<!-- readthedocs-preview pytorch-lightning end -->",GdoongMathew,25893369,open,False,0,2025-05-10T08:14:59+00:00,2025-05-11T11:37:08+00:00,,pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3053289982,20807,DeviceStatsMonitor lacks documentation,"### 📚 Documentation

I only know of two places where DeviceStatsMonitor() is mentioned in the docs: [here](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.DeviceStatsMonitor.html#lightning.pytorch.callbacks.DeviceStatsMonitor) and [here](https://lightning.ai/docs/pytorch/stable/tuning/profiler_basic.html). Neither place documents what any of the metrics it logs mean!

* e.g. ""active.all.current"" what does active mean? is this memory or compute? _what units is it in?_
* or ""active.large_pool.current"" what is the large vs small pool?
* Furthermore [here](https://lightning.ai/docs/pytorch/stable/tuning/profiler_basic.html) it says ""ensure that you’re using the full capacity of your accelerator (GPU/TPU/HPU). This can be measured with the DeviceStatsMonitor()"" this implies it can measure **GPU utilization** but it does not say which metric records that.

cc @lantiga @borda",profPlum,4739054,open,False,0,2025-05-09T22:14:36+00:00,2025-05-09T23:03:16+00:00,,docs;needs triage,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3052758445,20806,SIGTERMException is not raised consistently across all ranks in DDP,"### Bug description

SIGTERMException is not raised consistently across all ranks in DDP training because PyTorch Lightning doesn't handle SIGTERM-s well for distributed jobs. As a result checkpointing on SIGTERM can not be implemented reliably for DDP without workarounds in client code.

## Issue

The `SIGTERMException` is raised in `on_advance_end`. When certain ranks proceed beyond this point and begin the next training step, they become deadlocked while waiting for ranks that raised the exception. The complete SIGTERM handling logic is detailed in the section below. Steps #6 - #8 are not executed consistently.

This can lead to the following deadlock condition:

- All ranks complete gradient sharing and optimization at step N-1.
- Rank 0 receives SIGTERM, enters the handler, and forwards the SIGTERM to other ranks.
- Meanwhile, other ranks finish step N-1 and begin step N. They wait for rank 0 to join.
- Rank 0 completes step N-1 and raises `SIGTERMException` in on_advance_end.
    - Rank 0 never joins step N, and other ranks never reach `on_advance_end` on step N, preventing them from raising `SIGTERMException`.

Schematically:

![Image](https://github.com/user-attachments/assets/d8801431-373f-49a7-b069-76b9847d02a8)

## SIGTERM handling logic in PyTorch Lightning

1. Kubernetes API Server receives a request to abort a job.
2. Kubernetes API Server sends an abort request to kubelets on every node.
3. Kubelet sends a SIGTERM signal to the main process of the pytorch container.
    1. It waits for grace period and then
    2. It sends a KILL signal.
4. PL `_SignalConnector` receives the SIGTERM on the local rank 0 (main process) ([[github](https://github.com/Lightning-AI/pytorch-lightning/blob/2.5.0.post0/src/lightning/pytorch/trainer/connectors/signal_connector.py#L105-L113)](https://github.com/Lightning-AI/pytorch-lightning/blob/2.5.0.post0/src/lightning/pytorch/trainer/connectors/signal_connector.py#L105-L113))
    1. It prints `[rank: 0] Received SIGTERM: ...`
    2. It calls `strategy.auncher.kill`
5. The [[DDPStrategy](https://github.com/Lightning-AI/pytorch-lightning/blob/2.5.0.post0/src/lightning/pytorch/strategies/ddp.py)](https://github.com/Lightning-AI/pytorch-lightning/blob/2.5.0.post0/src/lightning/pytorch/strategies/ddp.py) uses [[_MultiProcessingLauncher](https://github.com/Lightning-AI/pytorch-lightning/blob/2.5.0.post0/src/lightning/pytorch/strategies/launchers/multiprocessing.py)](https://github.com/Lightning-AI/pytorch-lightning/blob/2.5.0.post0/src/lightning/pytorch/strategies/launchers/multiprocessing.py). The launcher passes the SIGTERM to ranks 1 - N-1 ([[github](https://github.com/Lightning-AI/pytorch-lightning/blob/2.5.0.post0/src/lightning/pytorch/strategies/launchers/multiprocessing.py#L260-L266C39)](https://github.com/Lightning-AI/pytorch-lightning/blob/2.5.0.post0/src/lightning/pytorch/strategies/launchers/multiprocessing.py#L260-L266C39))
    1. It prints `Process <parent> is terminating <child> with 15.`
6. All ranks set `self.received_sigterm = True` ([[github](https://github.com/Lightning-AI/pytorch-lightning/blob/2.5.0/src/lightning/pytorch/trainer/connectors/signal_connector.py#L113)](https://github.com/Lightning-AI/pytorch-lightning/blob/2.5.0/src/lightning/pytorch/trainer/connectors/signal_connector.py#L113))
    1. It prints `[rank: N] Received SIGTERM: ...`
7. PL `_*TrainingEpochLoop.on_*advance_end` raises `SIGTERMException` when the batch processing completes ([[github](https://github.com/Lightning-AI/pytorch-lightning/blob/2.5.0.post0/src/lightning/pytorch/loops/training_epoch_loop.py#L385-L386)](https://github.com/Lightning-AI/pytorch-lightning/blob/2.5.0.post0/src/lightning/pytorch/loops/training_epoch_loop.py#L385-L386))
8. The exception is passed to `on_exception` hook ([[github](https://github.com/Lightning-AI/pytorch-lightning/blob/2.5.0.post0/src/lightning/pytorch/trainer/call.py#L76)](https://github.com/Lightning-AI/pytorch-lightning/blob/2.5.0.post0/src/lightning/pytorch/trainer/call.py#L76))

### What version are you seeing the problem on?

v2.5.0.post0

### How to reproduce the bug

This issue can be consistently reproduced by introducing a 10-second sleep in the `on_train_batch_end` hook on rank 0. It will ensure that we certainly hit the deadlock condition described above.",olegc-wayve,153237680,open,False,0,2025-05-09T17:22:34+00:00,2025-05-09T17:25:04+00:00,,bug;needs triage;ver: 2.5.x,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3051250073,20805,Fix: `TransformerEnginePrecision` conversion for layers with `bias=False`,"**What does this PR do?**
This PR resolves a runtime AttributeError occurring in the TransformerEnginePrecision plugin during layer conversion.

When the convert_module() method replaces standard PyTorch layers (nn.Linear, nn.LayerNorm, etc.) with transformer engine counterparts, it attempts to clone both weight and bias tensors. However, some layers may be instantiated with bias=False, resulting in child.bias being None. The following line in the plugin causes a crash when this is the case:

`replacement.bias.data = child.bias.data.clone()`
This PR introduces a safe check to ensure both child.bias and replacement.bias are not None before attempting to access .data. This ensures compatibility with modules that omit bias, such as:

`nn.Linear(in_features=16, out_features=32, bias=False)`
Additionally, the PR includes a targeted unit test (test_convert_module_handles_linear_without_bias) that defines a model using such a bias-less layer and verifies that the conversion logic runs without error. This prevents regression and guards against similar issues in future updates.

The fix is surgical, backward-compatible, and maintains the expected behavior for all other layers with bias enabled.

Fixes #20803
cc @Lightning-AI/fabric-maintainers

**Summary of changes**
Guarded .bias.data.clone() with if child.bias is not None and replacement.bias is not None

Added test test_convert_module_handles_linear_without_bias in test_transformer_engine.py

-No breaking changes introduced.

Before submitting
Was this discussed/agreed via a GitHub issue? No

Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), Pull Request section? Yes

Did you make sure your PR does only one thing, instead of bundling different changes together? Yes

Did you write any new necessary tests? Yes, for the edge case bias=False

Did you verify new and existing tests pass locally with your changes? Yes

Not applicable to update the CHANGELOG for this bugfix



🙃 Did you have fun coding?

Absolutely. Excited to contribute more improvements soon!

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20805.org.readthedocs.build/en/20805/

<!-- readthedocs-preview pytorch-lightning end -->",KAVYANSHTYAGI,142140238,closed,False,1,2025-05-09T07:21:55+00:00,2025-05-12T10:22:31+00:00,2025-05-12T10:22:11+00:00,fabric,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3048722758,20804,Add support for converting `RMSNorm` when using `transformer-engine`,"### Description & Motivation

Recently, models (e.g., Qwen3/Llama) have replaced the `LayerNorm` layers with the `RMSNorm` layers because they perform identically but are slightly more efficient.

To support it, a new branch almost identical to the `LayerNorm` would have to be added to the conversion function.
",cyanic-selkie,32219669,open,False,0,2025-05-08T11:37:48+00:00,2025-05-08T11:38:30+00:00,,feature;needs triage,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3048715208,20803,LayerNorm with `bias=False` or `elementwise_affine=False` fails to convert when using `transformer-engine`,"### Bug description

During the conversion, a check must be made that `bias` and `weight` are not `None`.

Here is the error for `bias=False`:
```
File ""/usr/local/lib/python3.10/dist-packages/lightning/fabric/plugins/precision/transformer_engine.py"", line 174, in _convert_layers
    replacement.bias.data = child.bias.data.clone()
AttributeError: 'NoneType' object has no attribute 'data'
```

### What version are you seeing the problem on?

v2.5
",cyanic-selkie,32219669,closed,False,1,2025-05-08T11:34:23+00:00,2025-05-12T10:22:12+00:00,2025-05-12T10:22:12+00:00,bug;needs triage;ver: 2.5.x,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3045459905,20802,CLI: resolve jsonargparse deprecation warning,"## What does this PR do?

The latest [jsonargparse release](https://jsonargparse.readthedocs.io/en/stable/changelog.html#v4-39-0-2025-04-29) deprecates `set_config_read_mode` in favor of `set_parsing_settings`. This results in the following warning message during testing:
```
../../../../../opt/hostedtoolcache/Python/3.13.3/x64/lib/python3.13/site-packages/lightning/pytorch/cli.py:52
  /opt/hostedtoolcache/Python/3.13.3/x64/lib/python3.13/site-packages/lightning/pytorch/cli.py:52: 
      By default only one JsonargparseDeprecationWarning per type is shown. To see all warnings set environment
      variable JSONARGPARSE_DEPRECATION_WARNINGS=all and to disable the warnings set
      JSONARGPARSE_DEPRECATION_WARNINGS=off.

../../../../../opt/hostedtoolcache/Python/3.13.3/x64/lib/python3.13/site-packages/lightning/pytorch/cli.py:52
  /opt/hostedtoolcache/Python/3.13.3/x64/lib/python3.13/site-packages/lightning/pytorch/cli.py:52: 
      set_config_read_mode was deprecated in v4.39.0 and will be removed in v5.0.0. Optional config read modes
      should now be set using function set_parsing_settings.
```
This PR defaults to the new function when available and falls back to the old function for older versions. This makes the code more futureproof and compatible with jsonargparse v5 once it is released. Let me know if you would rather replace the try-except with a version check.

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [x] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [ ] Is this pull request ready for review? (if not, please submit in draft mode)
- [ ] Check that all items from **Before submitting** are resolved
- [ ] Make sure the title is self-explanatory and the description concisely explains the PR
- [ ] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20802.org.readthedocs.build/en/20802/

<!-- readthedocs-preview pytorch-lightning end -->",adamjstewart,12021217,open,False,0,2025-05-07T10:11:25+00:00,2025-05-07T10:11:50+00:00,,pl,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3041682696,20801,Inconcistency in loading from checkpoint in LightningCLI,"### Bug description

When using a checkpoint in LightningCLI, the model is first instantiated and then the checkpoint is loaded by supplying it to the `Trainer`'s method's `ckpt_path` argument.

The problem is that hyperparameters in the checkpoint are not used when instantiating the model, and thus when allocating tensors, which can cause checkpoint loading to fail if tensor sizes do not match. Furthermore, if there is complicated instantiation logic in the model, this may lead to other silent bugs or failures.

This was first raised as a discussion in #20715 

### What version are you seeing the problem on?

v2.5

### How to reproduce the bug

Here is a minimal example, where the `predict` method is used. We modify the `out_dim` in fit, so that the last layer has a different size, causing loading in predict to fail.

```python
# cli.py
from lightning.pytorch.cli import LightningCLI
from lightning.pytorch.demos.boring_classes import DemoModel, BoringDataModule

class DemoModelWithHyperparameters(DemoModel):
    def __init__(self, *args, **kwargs):
        self.save_hyperparameters()
        super().__init__(*args, **kwargs)

def cli_main():
    cli = LightningCLI(DemoModelWithHyperparameters, BoringDataModule)

if __name__ == ""__main__"":
    cli_main()
```

and then run

```console
$ python src/lightning_cli_load_checkpoint/cli.py fit --trainer.max_epochs 1 --model.out_dim 2
$ python src/lightning_cli_load_checkpoint/cli.py predict --ckpt_path <path_to_checkpoint>
```

### Error messages and logs

```
Restoring states from the checkpoint path at lightning_logs/version_23/checkpoints/epoch=0-step=64.ckpt
Traceback (most recent call last):
  File "".../lightning_cli_load_checkpoint/src/lightning_cli_load_checkpoint/cli.py"", line 20, in <module>
    cli_main()
  File "".../lightning_cli_load_checkpoint/src/lightning_cli_load_checkpoint/cli.py"", line 16, in cli_main
    cli = MyLightningCLI(DemoModelWithHyperparameters, datamodule_class=BoringDataModule)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "".../lightning_cli_load_checkpoint/.venv/lib/python3.12/site-packages/lightning/pytorch/cli.py"", line 398, in __init__
    self._run_subcommand(self.subcommand)
  File "".../lightning_cli_load_checkpoint/.venv/lib/python3.12/site-packages/lightning/pytorch/cli.py"", line 708, in _run_subcommand
    fn(**fn_kwargs)
  File "".../lightning_cli_load_checkpoint/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py"", line 887, in predict
    return call._call_and_handle_interrupt(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "".../lightning_cli_load_checkpoint/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py"", line 48, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "".../lightning_cli_load_checkpoint/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py"", line 928, in _predict_impl
    results = self._run(model, ckpt_path=ckpt_path)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "".../lightning_cli_load_checkpoint/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py"", line 981, in _run
    self._checkpoint_connector._restore_modules_and_callbacks(ckpt_path)
  File "".../lightning_cli_load_checkpoint/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py"", line 409, in _restore_modules_and_callbacks
    self.restore_model()
  File "".../lightning_cli_load_checkpoint/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py"", line 286, in restore_model
    self.trainer.strategy.load_model_state_dict(
  File "".../lightning_cli_load_checkpoint/.venv/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py"", line 372, in load_model_state_dict
    self.lightning_module.load_state_dict(checkpoint[""state_dict""], strict=strict)
  File "".../lightning_cli_load_checkpoint/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py"", line 2581, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for DemoModelWithHyperparameters:
	size mismatch for l1.weight: copying a param with shape torch.Size([2, 32]) from checkpoint, the shape in current model is torch.Size([10, 32]).
	size mismatch for l1.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([10]).
```


### Expected behavior

I'd expect the loading to respect the checkpoint's arguments. In other words, while the current implementation roughly follows this logic:

```python
model = Model(**cli_args)
Trainer().predict(model, data, ckpt_path=ckpt_path)
```
I'd expect it to be closer to
```python
model = Model.load_from_checkpoint(ckpt_path, **cli_args)
Trainer().predict(model, data, ckpt_path=ckpt_path)
```

### Environment

<details>
  <summary>Current environment</summary>

* CUDA:
	- GPU:               None
	- available:         False
	- version:           None
* Lightning:
	- lightning:         2.5.1
	- lightning-cli-load-checkpoint: 0.1.0
	- lightning-utilities: 0.14.3
	- pytorch-lightning: 2.5.1
	- torch:             2.6.0
	- torchmetrics:      1.7.1
* Packages:
	- aiohappyeyeballs:  2.6.1
	- aiohttp:           3.11.16
	- aiosignal:         1.3.2
	- antlr4-python3-runtime: 4.9.3
	- attrs:             25.3.0
	- autocommand:       2.2.2
	- backports.tarfile: 1.2.0
	- contourpy:         1.3.1
	- cycler:            0.12.1
	- docstring-parser:  0.16
	- filelock:          3.18.0
	- fonttools:         4.57.0
	- frozenlist:        1.5.0
	- fsspec:            2025.3.2
	- hydra-core:        1.3.2
	- idna:              3.10
	- importlib-metadata: 8.0.0
	- importlib-resources: 6.5.2
	- inflect:           7.3.1
	- jaraco.collections: 5.1.0
	- jaraco.context:    5.3.0
	- jaraco.functools:  4.0.1
	- jaraco.text:       3.12.1
	- jinja2:            3.1.6
	- jsonargparse:      4.38.0
	- kiwisolver:        1.4.8
	- lightning:         2.5.1
	- lightning-cli-load-checkpoint: 0.1.0
	- lightning-utilities: 0.14.3
	- markdown-it-py:    3.0.0
	- markupsafe:        3.0.2
	- matplotlib:        3.10.1
	- mdurl:             0.1.2
	- more-itertools:    10.3.0
	- mpmath:            1.3.0
	- multidict:         6.4.3
	- networkx:          3.4.2
	- numpy:             2.2.4
	- omegaconf:         2.3.0
	- packaging:         24.2
	- pillow:            11.2.1
	- platformdirs:      4.2.2
	- propcache:         0.3.1
	- protobuf:          6.30.2
	- pygments:          2.19.1
	- pyparsing:         3.2.3
	- python-dateutil:   2.9.0.post0
	- pytorch-lightning: 2.5.1
	- pyyaml:            6.0.2
	- rich:              13.9.4
	- setuptools:        78.1.0
	- six:               1.17.0
	- sympy:             1.13.1
	- tensorboardx:      2.6.2.2
	- tomli:             2.0.1
	- torch:             2.6.0
	- torchmetrics:      1.7.1
	- tqdm:              4.67.1
	- typeguard:         4.3.0
	- typeshed-client:   2.7.0
	- typing-extensions: 4.13.2
	- wheel:             0.45.1
	- yarl:              1.19.0
	- zipp:              3.19.2
* System:
	- OS:                Darwin
	- architecture:
		- 64bit
		-
	- processor:         arm
	- python:            3.12.7
	- release:           24.4.0
	- version:           Darwin Kernel Version 24.4.0: Fri Apr 11 18:33:47 PDT 2025; root:xnu-11417.101.15~117/RELEASE_ARM64_T6000

</details>
",Northo,7114880,open,False,1,2025-05-06T06:40:12+00:00,2025-05-08T09:10:03+00:00,,bug;needs triage;ver: 2.5.x,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3041509119,20800,"Remove LightningCLI python>=3.11.9 xfail, since issue was resolved long ago","## What does this PR do?

Issue https://github.com/omni-us/jsonargparse/issues/484 was fixed long ago, but tests show as xpass even though no failure is expected. This pull request removes the xfail.

<!--
Please include a summary of the change and which issue is fixed.
Please also include relevant motivation and context.
List any dependencies that are required for this change.

If we didn't discuss your PR in Github issues there's a high chance it will not be merged.

The following links the related issue to the PR (https://docs.github.com/en/free-pro-team@latest/github/managing-your-work-on-github/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword)
-->

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [x] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [ ] Is this pull request ready for review? (if not, please submit in draft mode)
- [ ] Check that all items from **Before submitting** are resolved
- [ ] Make sure the title is self-explanatory and the description concisely explains the PR
- [ ] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20800.org.readthedocs.build/en/20800/

<!-- readthedocs-preview pytorch-lightning end -->",mauvilsa,5780272,closed,False,0,2025-05-06T04:50:00+00:00,2025-05-06T11:36:22+00:00,2025-05-06T08:24:11+00:00,pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3041176432,20799,Save checkpoint version dirs as `version_003` so that they sort lexicographically,"### Description & Motivation

Lightning saves checkpoint version dirs as `version_3`, `version_21`, etc.  The problem with this is that when you do a listing, `version_21` is between `version_2` and `version_3`, making it easy to miss.

A simple solution, which is commonly used for these situations, is to name them `version_002, version_003,... version_021`, which solves the problem completely.

Note: If there's interest for this, this seems like a great `first issue`, and I'd be happy to write the patch.

### Pitch

_No response_

### Alternatives

_No response_

### Additional context

_No response_

cc @lantiga @borda",Taylor-C-Reese,165421805,open,False,0,2025-05-06T00:47:33+00:00,2025-05-06T00:47:54+00:00,,feature;needs triage,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3040856233,20798,"The ""You are using the plain ModelCheckpoint callback..."" log is annoying and unhelpful.","### 📚 Documentation

I do not like this message being displayed everytime I try to load a checkpoint, especially if it points to what seems to be a new, undocumented project, so effectively even if I wanted I do not see a way to actually follow the advice. 
I don't think logs should suggest not necessarily viable recommendations, especially for something that looks like a SaaS product. 

Also, the sentence ""Consider using LitModelCheckpoint which with seamless uploading to Model registry."" is grammatically incorrect.

cc @lantiga @borda",damiankucharski,17047332,open,False,1,2025-05-05T21:19:26+00:00,2025-05-08T19:53:17+00:00,,docs;needs triage,2,2,0,0,0,0,0
Lightning-AI/pytorch-lightning,3040795528,20797,LightningCLI fails to recognize custom Callback due to mixed import styles,"### Bug description

I implemented a custom PyTorch Lightning `Callback` and passed it to the Trainer via `LightningCLI.` However, I encountered an error where my callback was not recognized as an instance of `Callback` inside `_validate_callbacks_list()`.

After debugging, I found that the issue stems from `_check_mixed_imports()` in `lightning/pytorch/utilities/model_helpers.py`, which does not correctly detect mixed imports when using `lightning.pytorch` vs `pytorch_lightning`.

The Studio Template can be found here: https://lightning.ai/acme-ai/studios/lightningcli-fails-to-recognize-custom-callback-due-to-mixed-import-styles~01hpygektnhxpn0tgm1jk6z485

### What version are you seeing the problem on?

v2.5

### How to reproduce the bug

```python
import torch
from lightning.pytorch.demos.boring_classes import BoringModel as BoringLightningModule
from lightning.pytorch.demos.dummy_data import DummyDataModule as DummyDatamodule

from lightning.pytorch.cli import LightningCLI    # New import syntax
from pytorch_lightning.callbacks import Callback  # Old import syntax


class MyCallback(Callback):
    def __init__(self):
        super().__init__()
    # More code...


class MyCLI(LightningCLI):
    def add_arguments_to_parser(self, parser):
        super().add_arguments_to_parser(parser)
        parser.add_optimizer_args(torch.optim.SGD)

def cli_main():
    return MyCLI(
        BoringLightningModule,
        DummyDatamodule,
        trainer_defaults={""callbacks"": [MyCallback]}
    )

if __name__ == ""__main__"":
    torch.set_float32_matmul_precision(""medium"")
    cli = cli_main()
```

### Error messages and logs

```
  File ""/opt/conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/callback_connector.py"", line 228, in _validate_callbacks_list
    stateful_callbacks = [cb for cb in callbacks if is_overridden(""state_dict"", instance=cb)]
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/conda/lib/python3.11/site-packages/lightning/pytorch/utilities/model_helpers.py"", line 42, in is_overridden
    raise ValueError(""Expected a parent"")
ValueError: Expected a parent```


### Environment

<details>
  <summary>Current environment</summary>

```
#- PyTorch Lightning Version (e.g., 2.5.0):
#- PyTorch Version (e.g., 2.5):
#- Python version (e.g., 3.12):
#- OS (e.g., Linux):
#- CUDA/cuDNN version:
#- GPU models and configuration:
#- How you installed Lightning(`conda`, `pip`, source):
```

</details>


### More info

_No response_",NikStaBurd,101211699,closed,False,0,2025-05-05T20:50:56+00:00,2025-05-05T20:52:08+00:00,2025-05-05T20:52:08+00:00,bug;needs triage;ver: 2.5.x,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3038401056,20795,"build(deps): update onnx requirement from <1.17.0,>=1.12.0 to >=1.12.0,<1.18.0 in /requirements","[//]: # (dependabot-start)
⚠️  **Dependabot is rebasing this PR** ⚠️ 

Rebasing might not happen immediately, so don't worry if this takes some time.

Note: if you make any changes to this PR yourself, they will take precedence over the rebase.

---

[//]: # (dependabot-end)

Updates the requirements on [onnx](https://github.com/onnx/onnx) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/onnx/onnx/releases"">onnx's releases</a>.</em></p>
<blockquote>
<h2>v1.17.0</h2>
<p>ONNX v1.17.0 is now available with exciting new features! We would like to thank everyone who contributed to this release!
Please visit <a href=""https://onnx.ai/"">onnx.ai</a> to learn more about ONNX and associated projects.</p>
<h1>Key Updates</h1>
<h2>ai.onnx Opset 22</h2>
<ul>
<li>Update to support bfloat16:
<ul>
<li><a href=""https://onnx.ai/onnx/operators/onnx__Acos.html#acos-22"">Acos</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Acosh.html#acosh-22"">Acosh</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Asin.html#asin-22"">Asin</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Asinh.html#asinh-22"">Asinh</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Atan.html#atan-22"">Atan</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Atanh.html#atanh-22"">Atanh</a>, <a href=""https://onnx.ai/onnx/operators/onnx__AveragePool.html#averagepool-22"">AveragePool</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Bernoulli.html#bernoulli-22"">Bernoulli</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Conv.html#conv-22"">Conv</a>, <a href=""https://onnx.ai/onnx/operators/onnx__ConvTranspose.html#convtranspose-22"">ConvTranspose</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Cos.html#cos-22"">Cos</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Cosh.html#cosh-22"">Cosh</a>, <a href=""https://onnx.ai/onnx/operators/onnx__DeformConv.html#deformconv-22"">DeformConv</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Det.html#det-22"">Det</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Dropout.html#dropout-22"">Dropout</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Elu.html#elu-22"">Elu</a>, <a href=""https://onnx.ai/onnx/operators/onnx__EyeLike.html#eyelike-22"">EyeLike</a>, <a href=""https://onnx.ai/onnx/operators/onnx__GRU.html#gru-22"">GRU</a>, <a href=""https://onnx.ai/onnx/operators/onnx__GlobalAveragePool.html#globalaveragepool-22"">GlobalAveragePool</a>, <a href=""https://onnx.ai/onnx/operators/onnx__GlobalLpPool.html#globallppool-22"">GlobalLpPool</a>, <a href=""https://onnx.ai/onnx/operators/onnx__GlobalMaxPool.html#globalmaxpool-22"">GlobalMaxPool</a>, <a href=""https://onnx.ai/onnx/operators/onnx__GridSample.html#gridsample-22"">GridSample</a>, <a href=""https://onnx.ai/onnx/operators/onnx__HardSigmoid.html#hardsigmoid-22"">HardSigmoid</a>, <a href=""https://onnx.ai/onnx/operators/onnx__HardSwish.html#hardswish-22"">HardSwish</a>, <a href=""https://onnx.ai/onnx/operators/onnx__InstanceNormalization.html#instancenormalization-22"">InstanceNormalization</a>, <a href=""https://onnx.ai/onnx/operators/onnx__LSTM.html#lstm-22"">LSTM</a>, <a href=""https://onnx.ai/onnx/operators/onnx__LpNormalization.html#lpnormalization-22"">LpNormalization</a>, <a href=""https://onnx.ai/onnx/operators/onnx__LpPool.html#lppool-22"">LpPool</a>, <a href=""https://onnx.ai/onnx/operators/onnx__MaxPool.html#maxpool-22"">MaxPool</a>, <a href=""https://onnx.ai/onnx/operators/onnx__MaxRoiPool.html#maxroipool-22"">MaxRoiPool</a>, <a href=""https://onnx.ai/onnx/operators/onnx__MaxUnpool.html#maxunpool-22"">MaxUnpool</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Mish.html#mish-22"">Mish</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Multinomial.html#multinomial-22"">Multinomial</a>, <a href=""https://onnx.ai/onnx/operators/onnx__NegativeLogLikelihoodLoss.html#negativeloglikelihoodloss-22"">NegativeLogLikelihoodLoss</a>, <a href=""https://onnx.ai/onnx/operators/onnx__RNN.html#rnn-22"">RNN</a>, <a href=""https://onnx.ai/onnx/operators/onnx__RandomNormal.html#randomnormal-22"">RandomNormal</a>, <a href=""https://onnx.ai/onnx/operators/onnx__RandomNormalLike.html#randomnormallike-22"">RandomNormalLike</a>, <a href=""https://onnx.ai/onnx/operators/onnx__RandomUniform.html#randomuniform-22"">RandomUniform</a>, <a href=""https://onnx.ai/onnx/operators/onnx__RandomUniformLike.html#randomuniformlike-22"">RandomUniformLike</a>, <a href=""https://onnx.ai/onnx/operators/onnx__RoiAlign.html#roialign-22"">RoiAlign</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Round.html#round-22"">Round</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Selu.html#selu-22"">Selu</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Sin.html#sin-22"">Sin</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Sinh.html#sinh-22"">Sinh</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Softplus.html#softplus-22"">Softplus</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Softsign.html#softsign-22"">Softsign</a>, <a href=""https://onnx.ai/onnx/operators/onnx__Tan.html#tan-22"">Tan</a>, <a href=""https://onnx.ai/onnx/operators/onnx__ThresholdedRelu.html#thresholdedrelu-22"">ThresholdedRelu</a></li>
</ul>
</li>
</ul>
<h2>Python Changes</h2>
<ul>
<li>Support for numpy &gt;= 2.0</li>
</ul>
<h1>Bug fixes and infrastructure improvements</h1>
<ul>
<li>Fix Check URLs errors <a href=""https://redirect.github.com/onnx/onnx/pull/5972"">5972</a></li>
<li>Use CMAKE_PREFIX_PATH in finding libprotobuf <a href=""https://redirect.github.com/onnx/onnx/pull/5975"">5975</a></li>
<li>Bump main VERSION_NUMBER to 1.17.0 <a href=""https://redirect.github.com/onnx/onnx/pull/5968"">5968</a></li>
<li>Fix source and pip tar.gz builds on s390x systems <a href=""https://redirect.github.com/onnx/onnx/pull/5984"">5984</a></li>
<li>Fix unique_name <a href=""https://redirect.github.com/onnx/onnx/pull/5992"">5992</a></li>
<li>Fix SegFault bug in shape inference <a href=""https://redirect.github.com/onnx/onnx/pull/5990"">5990</a></li>
<li>Fix onnx.compose when connecting subgraphs <a href=""https://redirect.github.com/onnx/onnx/pull/5991"">5991</a></li>
<li>Fix conversion from split 11 to split 18 <a href=""https://redirect.github.com/onnx/onnx/pull/6020"">6020</a></li>
<li>Update error messages for NegativeLogLikelihoodLoss inference function <a href=""https://redirect.github.com/onnx/onnx/pull/6021"">6021</a></li>
<li>Generalize input/output number check in shape inference <a href=""https://redirect.github.com/onnx/onnx/pull/6005"">6005</a></li>
<li>Replace rank inference with shape inference for Einsum op <a href=""https://redirect.github.com/onnx/onnx/pull/6010"">6010</a></li>
<li>build from source instruction with latest cmake change <a href=""https://redirect.github.com/onnx/onnx/pull/6038"">6038</a></li>
<li>Handle OneHot's depth value during shape inference <a href=""https://redirect.github.com/onnx/onnx/pull/5963"">5963</a></li>
<li>Not to install cmake in pyproject.toml on Windows <a href=""https://redirect.github.com/onnx/onnx/pull/6045"">6045</a></li>
<li>fix a skipped shape infer code <a href=""https://redirect.github.com/onnx/onnx/pull/6049"">6049</a></li>
<li>Include the &quot;.onnxtext&quot; extension in supported serialization format <a href=""https://redirect.github.com/onnx/onnx/pull/6051"">6051</a></li>
<li>Allow ReferenceEvaluator to return intermediate results <a href=""https://redirect.github.com/onnx/onnx/pull/6066"">6066</a></li>
<li>Fix 1 typo in numpy_helper.py <a href=""https://redirect.github.com/onnx/onnx/pull/6041"">6041</a></li>
<li>Remove benchmarking code <a href=""https://redirect.github.com/onnx/onnx/pull/6076"">6076</a></li>
<li>Prevent crash on import after GCC 8 builds <a href=""https://redirect.github.com/onnx/onnx/pull/6048"">6048</a></li>
<li>Check graph outputs are defined <a href=""https://redirect.github.com/onnx/onnx/pull/6083"">6083</a></li>
<li>Enable additional ruff rules <a href=""https://redirect.github.com/onnx/onnx/pull/6032"">6032</a></li>
<li>Add missing shape inference check for DequantizeLinear <a href=""https://redirect.github.com/onnx/onnx/pull/6080"">6080</a></li>
<li>Add bfloat16 to all relevant ops <a href=""https://redirect.github.com/onnx/onnx/pull/6099"">6099</a></li>
<li>fix(ci): install python dependencies with --only-binary :all: in manylinux <a href=""https://redirect.github.com/onnx/onnx/pull/6120"">6120</a></li>
<li>fix: install google-re2 with --only-binary option <a href=""https://redirect.github.com/onnx/onnx/pull/6129"">6129</a></li>
<li>Specify axis parameter for DequantizeLinear when input rank is 1 <a href=""https://redirect.github.com/onnx/onnx/pull/6095"">6095</a></li>
<li>Pin onnxruntime to 1.17.3 for release CIs <a href=""https://redirect.github.com/onnx/onnx/pull/6143"">6143</a></li>
<li>Fix INT4 TensorProto byte size is 5x larger than expected with negative values <a href=""https://redirect.github.com/onnx/onnx/pull/6161"">6161</a></li>
<li>Mitigate tarball directory traversal risks <a href=""https://redirect.github.com/onnx/onnx/pull/6164"">6164</a></li>
<li>Fix reference implementation for ScatterND with 4D tensors <a href=""https://redirect.github.com/onnx/onnx/pull/6174"">6174</a></li>
<li>Addition of group &gt; 1 in test and in backend for ConvTranspose <a href=""https://redirect.github.com/onnx/onnx/pull/6175"">6175</a></li>
<li>Support for bfloat16 for binary, unary operators in reference implementation <a href=""https://redirect.github.com/onnx/onnx/pull/6166"">6166</a></li>
<li>Refactor windows workflow to work on standard windows <a href=""https://redirect.github.com/onnx/onnx/pull/6190"">6190</a></li>
<li>Fix a few crashes while running shape inference <a href=""https://redirect.github.com/onnx/onnx/pull/6195"">6195</a></li>
<li>Update onnx to work with numpy&gt;=2.0 <a href=""https://redirect.github.com/onnx/onnx/pull/6196"">6196</a></li>
<li>Use sets to improve performance of dfs search <a href=""https://redirect.github.com/onnx/onnx/pull/6213"">6213</a></li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/onnx/onnx/blob/main/docs/Changelog-ml.md"">onnx's changelog</a>.</em></p>
<blockquote>
<!-- raw HTML omitted -->
<h2>Operator Changelog</h2>
<p><em>This file is automatically generated from the
<a href=""https://github.com/onnx/onnx/blob/main/docs/onnx/defs"">def files</a> via <a href=""https://github.com/onnx/onnx/blob/main/docs/onnx/defs/gen_doc.py"">this script</a>.
Do not modify directly and instead edit operator definitions.</em></p>
<p>For an operator input/output's differentiability, it can be differentiable,
non-differentiable, or undefined. If a variable's differentiability
is not specified, that variable has undefined differentiability.</p>
<h1>ai.onnx.ml</h1>
<h2>Version 1 of the 'ai.onnx.ml' operator set</h2>
<h3><!-- raw HTML omitted --><!-- raw HTML omitted --><strong>ai.onnx.ml.ArrayFeatureExtractor-1</strong><!-- raw HTML omitted --></h3>
<p>Select elements of the input tensor based on the indices passed.<!-- raw HTML omitted -->
The indices are applied to the last axes of the tensor.</p>
<h4>Version</h4>
<p>This version of the operator has been available since version 1 of the 'ai.onnx.ml' operator set.</p>
<h4>Inputs</h4>
<!-- raw HTML omitted -->
<h4>Outputs</h4>
<!-- raw HTML omitted -->
<h4>Type Constraints</h4>
<!-- raw HTML omitted -->
<h3><!-- raw HTML omitted --><!-- raw HTML omitted --><strong>ai.onnx.ml.Binarizer-1</strong><!-- raw HTML omitted --></h3>
<p>Maps the values of the input tensor to either 0 or 1, element-wise, based on the outcome of a comparison against a threshold value.</p>
<h4>Version</h4>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/onnx/onnx/commit/b8baa8446686496da4cc8fda09f2b6fe65c2a02c""><code>b8baa84</code></a> Set version 1.17.0 for official release (<a href=""https://redirect.github.com/onnx/onnx/issues/6405"">#6405</a>)</li>
<li><a href=""https://github.com/onnx/onnx/commit/6d77b808217f442170d105131836aa4820c0f43f""><code>6d77b80</code></a> [Cherry-Pick] Fix main url checks (<a href=""https://redirect.github.com/onnx/onnx/issues/6312"">#6312</a>) (<a href=""https://redirect.github.com/onnx/onnx/issues/6327"">#6327</a>)</li>
<li><a href=""https://github.com/onnx/onnx/commit/174938d8b7d48f27b5c491626c6a474f5f5b829a""><code>174938d</code></a> [Cherry-Pick] Fix protobuf pkg 5.28.0 failing on Windows (<a href=""https://redirect.github.com/onnx/onnx/issues/6342"">#6342</a>) (<a href=""https://redirect.github.com/onnx/onnx/issues/6347"">#6347</a>)</li>
<li><a href=""https://github.com/onnx/onnx/commit/f18d5931adc7b44ae5a2afd74e21ed51bcf2bc63""><code>f18d593</code></a> [Cherry-Pick] Remove unused variables (<a href=""https://redirect.github.com/onnx/onnx/issues/6303"">#6303</a>) (<a href=""https://redirect.github.com/onnx/onnx/issues/6324"">#6324</a>)</li>
<li><a href=""https://github.com/onnx/onnx/commit/c58890537f466b9b294f6dd038dd826f9907e03d""><code>c588905</code></a> Set version in rel-1.17.0 to 1.17.0rc1 (<a href=""https://redirect.github.com/onnx/onnx/issues/6317"">#6317</a>)</li>
<li><a href=""https://github.com/onnx/onnx/commit/4392c2c9ae30cd10d199bd31fc7b272a6f842824""><code>4392c2c</code></a> Prepare for rel-1.17.0 (<a href=""https://redirect.github.com/onnx/onnx/issues/6281"">#6281</a>)</li>
<li><a href=""https://github.com/onnx/onnx/commit/cb54169e4f2b52861cf5ec546d244ea4b2d09964""><code>cb54169</code></a> Update ort filter to 1.20.0 to skip tests known to fail with ort 1.19.0 (<a href=""https://redirect.github.com/onnx/onnx/issues/6306"">#6306</a>)</li>
<li><a href=""https://github.com/onnx/onnx/commit/99e1fd352c05c3176770080824fd7a8c474c97c0""><code>99e1fd3</code></a> Bump reviewdog/action-misspell from 1.21.0 to 1.23.0 (<a href=""https://redirect.github.com/onnx/onnx/issues/6268"">#6268</a>)</li>
<li><a href=""https://github.com/onnx/onnx/commit/19205655059e1654ba2d44478bc3a1c75af7830f""><code>1920565</code></a> Bump ossf/scorecard-action from 2.3.3 to 2.4.0 (<a href=""https://redirect.github.com/onnx/onnx/issues/6273"">#6273</a>)</li>
<li><a href=""https://github.com/onnx/onnx/commit/2e8f2289b91d5670e1c661ab9119178b24197219""><code>2e8f228</code></a> Bump mypy from 1.10.1 to 1.11.1 (<a href=""https://redirect.github.com/onnx/onnx/issues/6275"">#6275</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/onnx/onnx/compare/v1.12.0...v1.17.0"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20795.org.readthedocs.build/en/20795/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,0,2025-05-05T01:35:07+00:00,2025-05-05T08:31:59+00:00,2025-05-05T08:31:57+00:00,ci;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3038400989,20794,"build(deps): update typing-extensions requirement from <4.11.0,>=4.4.0 to >=4.4.0,<4.14.0 in /requirements","Updates the requirements on [typing-extensions](https://github.com/python/typing_extensions) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/python/typing_extensions/releases"">typing-extensions's releases</a>.</em></p>
<blockquote>
<h2>4.13.2</h2>
<ul>
<li>Fix <code>TypeError</code> when taking the union of <code>typing_extensions.TypeAliasType</code> and a
<code>typing.TypeAliasType</code> on Python 3.12 and 3.13.
Patch by <a href=""https://github.com/jorenham"">Joren Hammudoglu</a>.</li>
<li>Backport from CPython PR <a href=""https://redirect.github.com/python/cpython/pull/132160"">#132160</a>
to avoid having user arguments shadowed in generated <code>__new__</code> by
<code>@typing_extensions.deprecated</code>.
Patch by <a href=""https://github.com/Viicos"">Victorien Plot</a>.</li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/python/typing_extensions/blob/main/CHANGELOG.md"">typing-extensions's changelog</a>.</em></p>
<blockquote>
<h1>Release 4.13.2 (April 10, 2025)</h1>
<ul>
<li>Fix <code>TypeError</code> when taking the union of <code>typing_extensions.TypeAliasType</code> and a
<code>typing.TypeAliasType</code> on Python 3.12 and 3.13.
Patch by <a href=""https://github.com/jorenham"">Joren Hammudoglu</a>.</li>
<li>Backport from CPython PR <a href=""https://redirect.github.com/python/cpython/pull/132160"">#132160</a>
to avoid having user arguments shadowed in generated <code>__new__</code> by
<code>@typing_extensions.deprecated</code>.
Patch by <a href=""https://github.com/Viicos"">Victorien Plot</a>.</li>
</ul>
<h1>Release 4.13.1 (April 3, 2025)</h1>
<p>Bugfixes:</p>
<ul>
<li>Fix regression in 4.13.0 on Python 3.10.2 causing a <code>TypeError</code> when using <code>Concatenate</code>.
Patch by <a href=""https://github.com/Daraan"">Daraan</a>.</li>
<li>Fix <code>TypeError</code> when using <code>evaluate_forward_ref</code> on Python 3.10.1-2 and 3.9.8-10.
Patch by <a href=""https://github.com/Daraan"">Daraan</a>.</li>
</ul>
<h1>Release 4.13.0 (March 25, 2025)</h1>
<p>No user-facing changes since 4.13.0rc1.</p>
<h1>Release 4.13.0rc1 (March 18, 2025)</h1>
<p>New features:</p>
<ul>
<li>Add <code>typing_extensions.TypeForm</code> from PEP 747. Patch by
Jelle Zijlstra.</li>
<li>Add <code>typing_extensions.get_annotations</code>, a backport of
<code>inspect.get_annotations</code> that adds features specified
by PEP 649. Patches by Jelle Zijlstra and Alex Waygood.</li>
<li>Backport <code>evaluate_forward_ref</code> from CPython PR
<a href=""https://redirect.github.com/python/cpython/pull/119891"">#119891</a> to evaluate <code>ForwardRef</code>s.
Patch by <a href=""https://github.com/Daraan"">Daraan</a>, backporting a CPython PR by Jelle Zijlstra.</li>
</ul>
<p>Bugfixes and changed features:</p>
<ul>
<li>Update PEP 728 implementation to a newer version of the PEP. Patch by Jelle Zijlstra.</li>
<li>Copy the coroutine status of functions and methods wrapped
with <code>@typing_extensions.deprecated</code>. Patch by Sebastian Rittau.</li>
<li>Fix bug where <code>TypeAliasType</code> instances could be subscripted even
where they were not generic. Patch by <a href=""https://github.com/Daraan"">Daraan</a>.</li>
<li>Fix bug where a subscripted <code>TypeAliasType</code> instance did not have all
attributes of the original <code>TypeAliasType</code> instance on older Python versions.
Patch by <a href=""https://github.com/Daraan"">Daraan</a> and Alex Waygood.</li>
<li>Fix bug where subscripted <code>TypeAliasType</code> instances (and some other
subscripted objects) had wrong parameters if they were directly
subscripted with an <code>Unpack</code> object.
Patch by <a href=""https://github.com/Daraan"">Daraan</a>.</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/python/typing_extensions/commit/4525e9dbbd177b4ef8a84f55ff5fe127582a071d""><code>4525e9d</code></a> Prepare release 4.13.2 (<a href=""https://redirect.github.com/python/typing_extensions/issues/583"">#583</a>)</li>
<li><a href=""https://github.com/python/typing_extensions/commit/88a0c200ceb0ccfe4329d3db8a1a863a2381e44c""><code>88a0c20</code></a> Do not shadow user arguments in generated <code>__new__</code> by <code>@deprecated</code> (<a href=""https://redirect.github.com/python/typing_extensions/issues/581"">#581</a>)</li>
<li><a href=""https://github.com/python/typing_extensions/commit/281d7b0ca6edad384e641d1066b759c280602919""><code>281d7b0</code></a> Add 3rd party tests for litestar (<a href=""https://redirect.github.com/python/typing_extensions/issues/578"">#578</a>)</li>
<li><a href=""https://github.com/python/typing_extensions/commit/8092c3996f4902ad9c74ac2d1d8dd19371ecbaa3""><code>8092c39</code></a> fix <code>TypeAliasType</code> union with <code>typing.TypeAliasType</code> (<a href=""https://redirect.github.com/python/typing_extensions/issues/575"">#575</a>)</li>
<li><a href=""https://github.com/python/typing_extensions/commit/45a8847aad979d2f1f7dff075ac52df5df7b7adb""><code>45a8847</code></a> Prepare release 4.13.1 (<a href=""https://redirect.github.com/python/typing_extensions/issues/573"">#573</a>)</li>
<li><a href=""https://github.com/python/typing_extensions/commit/f264e58146479d2d8456dd6e660d785dc07d6f26""><code>f264e58</code></a> Move CI to &quot;ubuntu-latest&quot; (round 2) (<a href=""https://redirect.github.com/python/typing_extensions/issues/570"">#570</a>)</li>
<li><a href=""https://github.com/python/typing_extensions/commit/5ce0e69b20992f8bf410849a31381cd656e3eb6b""><code>5ce0e69</code></a> Fix TypeError with evaluate_forward_ref on some 3.10 and 3.9 versions (<a href=""https://redirect.github.com/python/typing_extensions/issues/558"">#558</a>)</li>
<li><a href=""https://github.com/python/typing_extensions/commit/304f5cb17d709950ece3e9c84a76174bf7405b90""><code>304f5cb</code></a> Add SQLAlchemy to third-party daily tests (<a href=""https://redirect.github.com/python/typing_extensions/issues/561"">#561</a>)</li>
<li><a href=""https://github.com/python/typing_extensions/commit/ebe2b9405c493749429de6c82c8daddd1107c9e2""><code>ebe2b94</code></a> Fix duplicated keywords for typing._ConcatenateGenericAlias in 3.10.2 (<a href=""https://redirect.github.com/python/typing_extensions/issues/557"">#557</a>)</li>
<li><a href=""https://github.com/python/typing_extensions/commit/9f93d6fb752698504d80b1ed0c73b0a2a9d0cff6""><code>9f93d6f</code></a> Add intersphinx links for 3.13 typing features (<a href=""https://redirect.github.com/python/typing_extensions/issues/550"">#550</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/python/typing_extensions/compare/4.4.0...4.13.2"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20794.org.readthedocs.build/en/20794/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,0,2025-05-05T01:35:02+00:00,2025-05-05T08:31:50+00:00,2025-05-05T08:31:48+00:00,ci;fabric;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3038400952,20793,build(deps): bump pytest-random-order from 1.1.0 to 1.1.1 in /requirements,"Bumps [pytest-random-order](https://github.com/jbasko/pytest-random-order) from 1.1.0 to 1.1.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/jbasko/pytest-random-order/releases"">pytest-random-order's releases</a>.</em></p>
<blockquote>
<h2>v1.1.1</h2>
<p>Fix error when cacheprovider plugin disabled or missing. Thanks <a href=""https://github.com/jhanm12""><code>@​jhanm12</code></a> for reporting and suggesting the fix.</p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pytest-dev/pytest-random-order/commit/763f0f9efe914b3bf9b0343ce99128736335c509""><code>763f0f9</code></a> Fix error when cacheprovider plugin disabled or missing (<a href=""https://redirect.github.com/jbasko/pytest-random-order/issues/56"">#56</a>)</li>
<li>See full diff in <a href=""https://github.com/jbasko/pytest-random-order/compare/v1.1.0...v1.1.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-random-order&package-manager=pip&previous-version=1.1.0&new-version=1.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20793.org.readthedocs.build/en/20793/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,0,2025-05-05T01:34:59+00:00,2025-05-05T18:47:50+00:00,2025-05-05T18:47:48+00:00,ci;fabric;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3038400886,20792,"build(deps): update docutils requirement from <0.21,>=0.16 to >=0.16,<0.22 in /requirements","Updates the requirements on [docutils](https://docutils.sourceforge.io) to permit the latest version.


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20792.org.readthedocs.build/en/20792/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,0,2025-05-05T01:34:55+00:00,2025-05-05T08:31:42+00:00,2025-05-05T08:31:40+00:00,docs;ci;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3038400873,20791,build(deps): update psutil requirement from <5.9.6 to <7.0.1 in /requirements,"Updates the requirements on [psutil](https://github.com/giampaolo/psutil) to permit the latest version.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/giampaolo/psutil/blob/master/HISTORY.rst"">psutil's changelog</a>.</em></p>
<blockquote>
<h1>7.0.0</h1>
<p>2025-02-13</p>
<p><strong>Enhancements</strong></p>
<ul>
<li>669_, [Windows]: <code>net_if_addrs()</code>_ also returns the <code>broadcast</code> address
instead of <code>None</code>.</li>
<li>2480_: Python 2.7 is no longer supported. Latest version supporting Python
2.7 is psutil 6.1.X. Install it with: <code>pip2 install psutil==6.1.*</code>.</li>
<li>2490_: removed long deprecated <code>Process.memory_info_ex()</code> method. It was
deprecated in psutil 4.0.0, released 8 years ago. Substitute is
<code>Process.memory_full_info()</code>.</li>
</ul>
<p><strong>Bug fixes</strong></p>
<ul>
<li>2496_, [Linux]: Avoid segfault (a cPython bug) on <code>Process.memory_maps()</code>
for processes that use hundreds of GBs of memory.</li>
<li>2502_, [macOS]: <code>virtual_memory()</code>_ now relies on <code>host_statistics64</code>
instead of <code>host_statistics</code>. This is the same approach used by <code>vm_stat</code>
CLI tool, and should grant more accurate results.</li>
</ul>
<p><strong>Compatibility notes</strong></p>
<ul>
<li>2480_: Python 2.7 is no longer supported.</li>
<li>2490_: removed long deprecated <code>Process.memory_info_ex()</code> method.</li>
</ul>
<h1>6.1.1</h1>
<p>2024-12-19</p>
<p><strong>Enhancements</strong></p>
<ul>
<li>2471_: use Vulture CLI tool to detect dead code.</li>
</ul>
<p><strong>Bug fixes</strong></p>
<ul>
<li>2418_, [Linux]: fix race condition in case /proc/PID/stat does not exist, but
/proc/PID does, resulting in FileNotFoundError.</li>
<li>2470_, [Linux]: <code>users()</code>_ may return &quot;localhost&quot; instead of the actual IP
address of the user logged in.</li>
</ul>
<h1>6.1.0</h1>
<p>2024-10-17</p>
<p><strong>Enhancements</strong></p>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/giampaolo/psutil/commit/ea5b55605f857affa4e65fa27eb80f4f2bfebd63""><code>ea5b556</code></a> pre-release</li>
<li><a href=""https://github.com/giampaolo/psutil/commit/d6e28b7a83086ed6445666db895a6b7f889891e8""><code>d6e28b7</code></a> try to fix tests</li>
<li><a href=""https://github.com/giampaolo/psutil/commit/104bb3228bf6991f0a5bd466c6a8d8b4c2c629e0""><code>104bb32</code></a> test cpu_times() for process children</li>
<li><a href=""https://github.com/giampaolo/psutil/commit/16c091b3803d6f60c5e9d79f0696473fe82a0bc9""><code>16c091b</code></a> test cpu_times() for process children</li>
<li><a href=""https://github.com/giampaolo/psutil/commit/eee09da72a3dbff60f438b6f8153e985c59d285d""><code>eee09da</code></a> [OSX] proc.c: Fix goo.gl link in comment for source reference (<a href=""https://redirect.github.com/giampaolo/psutil/issues/2505"">#2505</a>)</li>
<li><a href=""https://github.com/giampaolo/psutil/commit/17e27801e6afe4a72d7eca9285e63f1babf822a0""><code>17e2780</code></a> ci: build aarch64 wheel on GHA aarch64 runner (<a href=""https://redirect.github.com/giampaolo/psutil/issues/2503"">#2503</a>)</li>
<li><a href=""https://github.com/giampaolo/psutil/commit/1ba8667c89d80974c37594984183ce404e53dfd9""><code>1ba8667</code></a> pin black version to 24.X, because new 25.X breaks style</li>
<li><a href=""https://github.com/giampaolo/psutil/commit/9c114a513757446d3e2b13533f458bdfac2d8881""><code>9c114a5</code></a> [OSX] use <code>host_statistics64</code> to get memory metrics (<a href=""https://redirect.github.com/giampaolo/psutil/issues/2502"">#2502</a>)</li>
<li><a href=""https://github.com/giampaolo/psutil/commit/08d7d43894e9d6916a6f83184dc491506857fbc2""><code>08d7d43</code></a> pin black version to 24.X, because new 25.X breaks style</li>
<li><a href=""https://github.com/giampaolo/psutil/commit/a509e5aa1829c0268cd4d069ac340a5d9fb4fee8""><code>a509e5a</code></a> 669 windows broadcast addr (<a href=""https://redirect.github.com/giampaolo/psutil/issues/2501"">#2501</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/giampaolo/psutil/compare/release-0.1.0...release-7.0.0"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20791.org.readthedocs.build/en/20791/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,0,2025-05-05T01:34:54+00:00,2025-05-05T08:31:34+00:00,2025-05-05T08:31:32+00:00,ci;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3038400791,20790,build(deps): update importlib-metadata requirement from <8.0.0 to <9.0.0 in /requirements,"[//]: # (dependabot-start)
⚠️  **Dependabot is rebasing this PR** ⚠️ 

Rebasing might not happen immediately, so don't worry if this takes some time.

Note: if you make any changes to this PR yourself, they will take precedence over the rebase.

---

[//]: # (dependabot-end)

Updates the requirements on [importlib-metadata](https://github.com/python/importlib_metadata) to permit the latest version.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/python/importlib_metadata/blob/main/NEWS.rst"">importlib-metadata's changelog</a>.</em></p>
<blockquote>
<h1>v8.7.0</h1>
<h2>Features</h2>
<ul>
<li><code>.metadata()</code> (and <code>Distribution.metadata</code>) can now return <code>None</code> if the metadata directory exists but not metadata file is present. (<a href=""https://redirect.github.com/python/importlib_metadata/issues/493"">#493</a>)</li>
</ul>
<h2>Bugfixes</h2>
<ul>
<li>Raise consistent ValueError for invalid EntryPoint.value (<a href=""https://redirect.github.com/python/importlib_metadata/issues/518"">#518</a>)</li>
</ul>
<h1>v8.6.1</h1>
<h2>Bugfixes</h2>
<ul>
<li>Fixed indentation logic to also honor blank lines.</li>
</ul>
<h1>v8.6.0</h1>
<h2>Features</h2>
<ul>
<li><code>python/cpython#119650</code></li>
</ul>
<h1>v8.5.0</h1>
<h2>Features</h2>
<ul>
<li>Deferred import of zipfile.Path (<a href=""https://redirect.github.com/python/importlib_metadata/issues/502"">#502</a>)</li>
<li>Deferred import of json (<a href=""https://redirect.github.com/python/importlib_metadata/issues/503"">#503</a>)</li>
<li>Rely on zipp overlay for zipfile.Path.</li>
</ul>
<h1>v8.4.0</h1>
<h2>Features</h2>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/python/importlib_metadata/commit/708dff4f1ab89bdd126e3e8c56098d04282c5809""><code>708dff4</code></a> Finalize</li>
<li><a href=""https://github.com/python/importlib_metadata/commit/b3065f03cc3395f46ed575e612e213f92a064879""><code>b3065f0</code></a> Merge pull request <a href=""https://redirect.github.com/python/importlib_metadata/issues/519"">#519</a> from python/bugfix/493-metadata-missing</li>
<li><a href=""https://github.com/python/importlib_metadata/commit/e4351c226765f53a40316fa6aab50488aee8a90f""><code>e4351c2</code></a> Add a new test capturing the new expectation.</li>
<li><a href=""https://github.com/python/importlib_metadata/commit/5a657051f7386de6f0560c200d78e941be2c8058""><code>5a65705</code></a> Refactor the casting into a wrapper for brevity and to document its purpose.</li>
<li><a href=""https://github.com/python/importlib_metadata/commit/0830c39b8a23e48024365120c0e97a6f7c36c5ec""><code>0830c39</code></a> Add news fragment.</li>
<li><a href=""https://github.com/python/importlib_metadata/commit/22bb567692d8e7bd216f864a9d8dee1272ee8674""><code>22bb567</code></a> Fix type errors where metadata could be None.</li>
<li><a href=""https://github.com/python/importlib_metadata/commit/57f31d77e18fef11dfadfd44775f253971c36920""><code>57f31d7</code></a> Allow metadata to return None when there is no metadata present.</li>
<li><a href=""https://github.com/python/importlib_metadata/commit/b9c4be4253250ad604610db66204e5fa70fa2455""><code>b9c4be4</code></a> Merge pull request <a href=""https://redirect.github.com/python/importlib_metadata/issues/518"">#518</a> from python/bugfix/488-bad-ep-value</li>
<li><a href=""https://github.com/python/importlib_metadata/commit/9f8af013635833cf3ac348413c9ac63b37caa3dd""><code>9f8af01</code></a> Prefer a cached property, as the property is likely to be retrieved at least ...</li>
<li><a href=""https://github.com/python/importlib_metadata/commit/f179e28888b2c6caf12baaf5449ff1cd82513dfe""><code>f179e28</code></a> Also raise ValueError on construction if the value is invalid.</li>
<li>Additional commits viewable in <a href=""https://github.com/python/importlib_metadata/compare/0.1...v8.7.0"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20790.org.readthedocs.build/en/20790/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,0,2025-05-05T01:34:48+00:00,2025-05-05T08:31:24+00:00,2025-05-05T08:31:22+00:00,ci;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3038400706,20789,build(deps): bump pkginfo from 1.12.0 to 1.12.1.2 in /requirements,"Bumps [pkginfo](https://code.launchpad.net/~tseaver/pkginfo/trunk) from 1.12.0 to 1.12.1.2.


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pkginfo&package-manager=pip&previous-version=1.12.0&new-version=1.12.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20789.org.readthedocs.build/en/20789/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,0,2025-05-05T01:34:44+00:00,2025-05-05T08:31:08+00:00,2025-05-05T08:31:05+00:00,ci;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3038400637,20788,build(deps): update ipython[notebook] requirement from <8.7.0 to <8.19.0 in /requirements,"Updates the requirements on [ipython[notebook]](https://github.com/ipython/ipython) to permit the latest version.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/ipython/ipython/commit/49914f93892640d150cededca16b14b20ce8663d""><code>49914f9</code></a> release 8.18.1</li>
<li><a href=""https://github.com/ipython/ipython/commit/e1c4eefc235f5222a4112bc2f922f31dd4d72dcb""><code>e1c4eef</code></a> Pin prompt_toolkit to 3.0.41+ (<a href=""https://redirect.github.com/ipython/ipython/issues/14257"">#14257</a>)</li>
<li><a href=""https://github.com/ipython/ipython/commit/965f989a21e436b06e1520843885afca2d452a35""><code>965f989</code></a> Pin prompt_toolkit to 3.0.41+</li>
<li><a href=""https://github.com/ipython/ipython/commit/c293abc5cebd8d3ee1a09221043a88a8f8ac7d39""><code>c293abc</code></a> back to dev</li>
<li><a href=""https://github.com/ipython/ipython/commit/928881c53ca837390c001e972ed2945c3309f9f3""><code>928881c</code></a> release 8.18.0</li>
<li><a href=""https://github.com/ipython/ipython/commit/4897500b0582a3ba9da61cc6cd21fef3901c9e5a""><code>4897500</code></a> whats new 8.18.0 (<a href=""https://redirect.github.com/ipython/ipython/issues/14253"">#14253</a>)</li>
<li><a href=""https://github.com/ipython/ipython/commit/d563354c03ce8721ef0b5c5e66186d9fa74bfa8b""><code>d563354</code></a> whats new 8.18.0</li>
<li><a href=""https://github.com/ipython/ipython/commit/c0a699d1432d72e687d407c3424aaf26dbff0e49""><code>c0a699d</code></a> Fix memory leak in Qt event loop integration (<a href=""https://redirect.github.com/ipython/ipython/issues/14240"">#14240</a>) (<a href=""https://redirect.github.com/ipython/ipython/issues/14251"">#14251</a>)</li>
<li><a href=""https://github.com/ipython/ipython/commit/c7aea08fe305f667e101fbde50cd3be5aec57fa1""><code>c7aea08</code></a> Fix pickleshare warning on completion (<a href=""https://redirect.github.com/ipython/ipython/issues/14252"">#14252</a>)</li>
<li><a href=""https://github.com/ipython/ipython/commit/ec51c50f300de0eb94548582888796102ff2872a""><code>ec51c50</code></a> Silence PickleShare warnings when completing root modules.</li>
<li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/rel-0.8.4...8.18.1"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20788.org.readthedocs.build/en/20788/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,0,2025-05-05T01:34:42+00:00,2025-05-05T08:30:56+00:00,2025-05-05T08:30:54+00:00,docs;ci;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3038400572,20787,build(deps): bump pytest-timeout from 2.1.0 to 2.3.1 in /requirements,"Bumps [pytest-timeout](https://github.com/pytest-dev/pytest-timeout) from 2.1.0 to 2.3.1.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pytest-dev/pytest-timeout/commit/04432f5b10eec31433482e1b191c0d71f19acff5""><code>04432f5</code></a> Some fixes to readme, bump version</li>
<li><a href=""https://github.com/pytest-dev/pytest-timeout/commit/48179d984d4a716b426dbf04e6b290d620518743""><code>48179d9</code></a> Prep release</li>
<li><a href=""https://github.com/pytest-dev/pytest-timeout/commit/38c5f24e73cb73ea8a368024bf171921e8e500e7""><code>38c5f24</code></a> Tweak docs a little</li>
<li><a href=""https://github.com/pytest-dev/pytest-timeout/commit/c6962b8194784fabe4aaa22ac5d5c2cc2a43825d""><code>c6962b8</code></a> describe session timeout better</li>
<li><a href=""https://github.com/pytest-dev/pytest-timeout/commit/a19403d3a3b72e26a939b0fe8b3ad9cee6b470a2""><code>a19403d</code></a> readme</li>
<li><a href=""https://github.com/pytest-dev/pytest-timeout/commit/eef422c62f0a2b76fbb64b7d6de9cb3b624a5fdf""><code>eef422c</code></a> docs update</li>
<li><a href=""https://github.com/pytest-dev/pytest-timeout/commit/325b40c562ee1d8bcee8a30139e5b16f734150fb""><code>325b40c</code></a> docs + config setting support + test mod</li>
<li><a href=""https://github.com/pytest-dev/pytest-timeout/commit/063f077ddff2b88133fed10f76c6ea797f820399""><code>063f077</code></a> extend test_header to include session timeout. Make test_session_timeout more...</li>
<li><a href=""https://github.com/pytest-dev/pytest-timeout/commit/333f3be20e7b328b677152030e898b14623f4f7d""><code>333f3be</code></a> suite-timeout -&gt; session-timeout</li>
<li><a href=""https://github.com/pytest-dev/pytest-timeout/commit/79dea97deb62852726cc4e46f709ec45731b35ae""><code>79dea97</code></a> move suite timeout to pytest_runtest_protocol</li>
<li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest-timeout/compare/2.1.0...2.3.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-timeout&package-manager=pip&previous-version=2.1.0&new-version=2.3.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20787.org.readthedocs.build/en/20787/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,0,2025-05-05T01:34:37+00:00,2025-05-05T08:30:46+00:00,2025-05-05T08:30:44+00:00,ci;fabric;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3038400545,20786,"build(deps): update numpy requirement from <1.27.0,>=1.17.2 to >=1.17.2,<2.1.0 in /requirements","Updates the requirements on [numpy](https://github.com/numpy/numpy) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/numpy/numpy/releases"">numpy's releases</a>.</em></p>
<blockquote>
<h2>NumPy 2.0.2 release (Aug 26, 2024)</h2>
<h1>NumPy 2.0.2 Release Notes</h1>
<p>NumPy 2.0.2 is a maintenance release that fixes bugs and regressions
discovered after the 2.0.1 release.</p>
<p>The Python versions supported by this release are 3.9-3.12.</p>
<h2>Contributors</h2>
<p>A total of 13 people contributed to this release. People with a &quot;+&quot; by
their names contributed a patch for the first time.</p>
<ul>
<li>Bruno Oliveira +</li>
<li>Charles Harris</li>
<li>Chris Sidebottom</li>
<li>Christian Heimes +</li>
<li>Christopher Sidebottom</li>
<li>Mateusz Sokół</li>
<li>Matti Picus</li>
<li>Nathan Goldbaum</li>
<li>Pieter Eendebak</li>
<li>Raghuveer Devulapalli</li>
<li>Ralf Gommers</li>
<li>Sebastian Berg</li>
<li>Yair Chuchem +</li>
</ul>
<h2>Pull requests merged</h2>
<p>A total of 19 pull requests were merged for this release.</p>
<ul>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27000"">#27000</a>: REL: Prepare for the NumPy 2.0.1 release [wheel build]</li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27001"">#27001</a>: MAINT: prepare 2.0.x for further development</li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27021"">#27021</a>: BUG: cfuncs.py: fix crash when sys.stderr is not available</li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27022"">#27022</a>: DOC: Fix migration note for <code>alltrue</code> and <code>sometrue</code></li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27061"">#27061</a>: BUG: use proper input and output descriptor in array_assign_subscript...</li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27073"">#27073</a>: BUG: Mirror VQSORT_ENABLED logic in Quicksort</li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27074"">#27074</a>: BUG: Bump Highway to latest master</li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27077"">#27077</a>: BUG: Off by one in memory overlap check</li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27122"">#27122</a>: BUG: Use the new <code>npyv_loadable_stride_</code> functions for ldexp and...</li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27126"">#27126</a>: BUG: Bump Highway to latest</li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27128"">#27128</a>: BUG: add missing error handling in public_dtype_api.c</li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27129"">#27129</a>: BUG: fix another cast setup in array_assign_subscript</li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27130"">#27130</a>: BUG: Fix building NumPy in FIPS mode</li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27131"">#27131</a>: BLD: update vendored Meson for cross-compilation patches</li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27146"">#27146</a>: MAINT: Scipy openblas 0.3.27.44.4</li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27151"">#27151</a>: BUG: Do not accidentally store dtype metadata in <code>np.save</code></li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27195"">#27195</a>: REV: Revert undef I and document it</li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27213"">#27213</a>: BUG: Fix NPY_RAVEL_AXIS on backwards compatible NumPy 2 builds</li>
<li><a href=""https://redirect.github.com/numpy/numpy/pull/27279"">#27279</a>: BUG: Fix array_equal for numeric and non-numeric scalar types</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/numpy/numpy/commit/854252ded83e6b9c21c4ee80558d354d8a72484c""><code>854252d</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/27280"">#27280</a> from charris/prepare-2.0.2</li>
<li><a href=""https://github.com/numpy/numpy/commit/cffa071f4f40a326de7fca9ec3f9b829b8aaf511""><code>cffa071</code></a> REL: Prepare for the NumPy 2.0.2 release [wheel build]</li>
<li><a href=""https://github.com/numpy/numpy/commit/16930298f0ab09ccac66235720832df2d4dbb86c""><code>1693029</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/27279"">#27279</a> from charris/backport-27275</li>
<li><a href=""https://github.com/numpy/numpy/commit/da9f9c3bbab1324cbc4d29384a93b55a6b8e7d5b""><code>da9f9c3</code></a> BUG: Fix array_equal for numeric and non-numeric scalar types</li>
<li><a href=""https://github.com/numpy/numpy/commit/ee1cf963d999eb39244e8d2b3db1c91ff27dd7c2""><code>ee1cf96</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/27213"">#27213</a> from charris/backport-27202</li>
<li><a href=""https://github.com/numpy/numpy/commit/49dec35f897f33a29a451ef3e25632b77b8d8c3e""><code>49dec35</code></a> BUG: Fix NPY_RAVEL_AXIS on backwards compatible NumPy 2 builds</li>
<li><a href=""https://github.com/numpy/numpy/commit/be56ae27aade17b8cf45421d7c4f525819493b33""><code>be56ae2</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/27195"">#27195</a> from charris/backport-27182</li>
<li><a href=""https://github.com/numpy/numpy/commit/75b039c3e7ae9057236847563ab39ce6d600fa38""><code>75b039c</code></a> REV: Revert undef I and document it</li>
<li><a href=""https://github.com/numpy/numpy/commit/428e2ba733a78e99d0bda94ac4d7bce6539693c6""><code>428e2ba</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/27151"">#27151</a> from charris/backport-27143</li>
<li><a href=""https://github.com/numpy/numpy/commit/451516de729c38677d717851590fda1d8920fa00""><code>451516d</code></a> BUG: Do not accidentally store dtype metadata in <code>np.save</code></li>
<li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.17.2...v2.0.2"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20786.org.readthedocs.build/en/20786/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,open,False,1,2025-05-05T01:34:35+00:00,2025-05-05T08:34:26+00:00,,ci;fabric;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3037689896,20785,docs: update ref to latest tutorials,"**This is automated update with the latest lighting tutorials!**
The target commit in the [publication](https://github.com/Lightning-AI/tutorials/tree/publication)
 branch is [fd70f511](https://github.com/Lightning-AI/tutorials/commit/fd70f511).

Before proceeding further double check that the PR include only submodule's head update. Eventually some additional adjustments in lightning docs may be needed.

cc @lantiga @borda",pl-ghost,75324987,closed,False,1,2025-05-04T00:31:00+00:00,2025-05-06T09:05:21+00:00,2025-05-06T09:05:19+00:00,docs;examples,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3037610732,20784,Support `grad_clip_norm_()` for FSDP,"## What does this PR do?

Adds gradient norm clipping support for FSDP. Tests fine locally.

For fun, here's a research deep dive ChatGPT came up with when comparing norm and value-based gradient clipping: https://chatgpt.com/s/dr_68168a3400988191be64b3c743a4ccf3.

Fixes #19235

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [x] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [x] Check that all items from **Before submitting** are resolved
- [x] Make sure the title is self-explanatory and the description concisely explains the PR
- [x] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20784.org.readthedocs.build/en/20784/

<!-- readthedocs-preview pytorch-lightning end -->",amorehead,7051982,open,False,2,2025-05-03T20:58:07+00:00,2025-05-10T23:43:12+00:00,,pl,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3037532146,20783,check param is of nn.Parameter type for pruning sanitization,"Pruning breaks because of non-`Parameter` types being passed through the pipeline. This came up for an LSTM module, the bias parameter is a boolean which breaks later stages of the pruning.

## What does this PR do?

I've only added a further check for the type of ""prunable parameters"" in the `sanitize_parameters_to_prune` function. I check if the parameter is of type `nn.Parameter` so it has the `to` method and `device` property.

 

<!--
Please include a summary of the change and which issue is fixed.
Please also include relevant motivation and context.
List any dependencies that are required for this change.

If we didn't discuss your PR in Github issues there's a high chance it will not be merged.

The following links the related issue to the PR (https://docs.github.com/en/free-pro-team@latest/github/managing-your-work-on-github/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword)
-->

Fixes #10835

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [x] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [ ] Check that all items from **Before submitting** are resolved
- [ ] Make sure the title is self-explanatory and the description concisely explains the PR
- [ ] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20783.org.readthedocs.build/en/20783/

<!-- readthedocs-preview pytorch-lightning end -->",chanokin,1545983,open,False,0,2025-05-03T17:50:50+00:00,2025-05-06T18:05:35+00:00,,pl,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3037499606,20782,Proposal: GPU-safe utilities for Lightning (based on Universal CUDA Tools),"### Description & Motivation

Hi Lightning team,

I'm opening this feature request based on a suggestion from the PyTorch core community (see links below). I recently proposed a small but modular utility set called **Universal CUDA Tools** that helps simplify and safeguard GPU execution in PyTorch workflows.

Although it was initially proposed for torch core (`torch.utils` / `torch.cuda`), a core contributor (ptrblck from NVIDIA) recommended that it may be more suitable for high-level libraries such as PyTorch Lightning.

References:
- PyTorch issue: https://github.com/pytorch/pytorch/issues/152679
- PyTorch forum: https://discuss.pytorch.org/t/universal-cuda-tools-gpu-safe-execution-made-simple-for-pytorch/219712/3
- Docs (EN): https://www.funeralcs.com/posts/cuda_tools_dokuman/
- Repo: https://github.com/Tunahanyrd/universal-cuda-tools

---

## What It Offers

This toolset wraps common device and memory management logic into reusable components, including:

- Safe device selection and fallback (GPU → CPU)
- AMP context management
- Automatic `.to(device)` wrapping and tensor conversion
- OOM retry handling with optional fallback
- Batch size test utilities
- Decorators and context managers for device safety

These tools are designed to minimize boilerplate in long-running training loops, especially on low-memory GPUs.

---

##  Compatibility with Lightning

Even though the original codebase is based on plain PyTorch, the components are **modular** and could be selectively adapted into Lightning utilities.

For example:

```python
@cuda(device=""cuda"", retry=1, auto_tensorize=True)
def training_step(x):
    ...
```
Or more directly:
```
with DeviceContext(""cuda"", amp=True, fallback=""cpu""):
    outputs = model(inputs)
```
Background
I’m not a native English speaker and I’m not deeply experienced with Lightning. This proposal emerged from real-world frustration during GPU-based training on limited resources, and I used AI tools (ChatGPT) to help design the API and documentation.

My goal is to open the idea for discussion and see if any part of it aligns with Lightning’s philosophy.

Thanks a lot for your time!

### Pitch
This proposal introduces a modular set of GPU-safe utilities inspired by real-world training frustrations. It focuses on simplifying repetitive device management logic in PyTorch and may be a great fit for Lightning's abstraction layer.

The core components can wrap functions or entire training steps to:
- auto-manage `.to(device)` logic
- handle CUDA OOM exceptions
- enable AMP easily
- fallback to CPU if needed



### Alternatives

Manually wrapping `.to(device)`, using try-except blocks for OOM, and manually enabling AMP are current options. However, these are repetitive, error-prone, and not reusable. Lightning offers abstractions for many of these, but utility-level tools could help simplify training step definitions even further.
### Additional context

This utility set was initially proposed for PyTorch core but was redirected here based on feedback:

- PyTorch issue: https://github.com/pytorch/pytorch/issues/152679
- PyTorch forum: https://discuss.pytorch.org/t/universal-cuda-tools-gpu-safe-execution-made-simple-for-pytorch/219712/3

Docs: https://www.funeralcs.com/posts/cuda_tools_dokuman/  
Repo: https://github.com/Tunahanyrd/universal-cuda-tools

The proposal originated from real training bottlenecks, and the code was designed with help from AI tools to be lightweight, composable, and optional.

",Tunahanyrd,92246965,open,False,2,2025-05-03T16:37:15+00:00,2025-05-09T07:49:13+00:00,,feature;needs triage,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3034873462,20781,`ModelCheckpoint`'s argument `save_on_train_epoch_end`'s documentation unclear when value is `None`,"### 📚 Documentation

Version [2.5.1](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.ModelCheckpoint.html) `ModelCheckpoint`'s argument `save_on_train_epoch_end`'s _default_ value is `None` and its description is:
```
save_on_train_epoch_end (Optional[bool])
Whether to run checkpointing at the end of the training epoch.
If this is False, then the check runs at the end of the validation.
```
It's unclear if `None` is interpreted as one of `True` or `False`, or if `None` produces an outcome distinct from `True` and `False`.

For the sake of completeness, the documentation should specify the underlying behavior if nothing is passed in.",abhishek47kashyap,11851445,open,False,0,2025-05-01T23:03:13+00:00,2025-05-01T23:05:11+00:00,,docs;needs triage,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3034385866,20780,Allow cross-device local checkpoints with `fsspec>=2025.5.0`,"## What does this PR do?

Cross-device transactions via fsspec (used for example in ModelCheckpoint) resulted in permission errors (#20270). The permission errors were caused by attempts to change file modes on different filesystem. This was fixed in fsspec 2025.5.0. This PR proposes to increase the minimum version to `fsspec>=2025.5.0`.

Fixes #20270

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- [x] Did you make sure to **update the documentation** with your changes? (if necessary)
- [x] Did you write any **new necessary tests**? (not for typos and docs)
- [x] Did you verify new and **existing tests pass** locally with your changes?
- [x] Did you list all the **breaking changes** introduced by this pull request?
- [x] Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [ ] Is this pull request ready for review? (if not, please submit in draft mode)
- [ ] Check that all items from **Before submitting** are resolved
- [ ] Make sure the title is self-explanatory and the description concisely explains the PR
- [ ] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20780.org.readthedocs.build/en/20780/

<!-- readthedocs-preview pytorch-lightning end -->",siemdejong,28396796,open,False,2,2025-05-01T18:04:19+00:00,2025-05-08T20:07:43+00:00,,fabric;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3034310805,20779,Pytorch Profiler crashes while using it with Pytorch Lightning modules,"### Bug description

Pytorch Profiler crashes while using it with pytorch-lightning. I am attempting to profile some experiments, but keep getting errors like shown below. I've searched forum and gh issues and I'm aware of the following:
* [issue](https://github.com/pytorch/pytorch/issues/98124) (not relevant -> different cause of error as sugested by message) 
* [issue](https://github.com/pytorch/pytorch/issues/68846) (not relevant -> different cause of error as sugested by message) 
* [forum post](https://discuss.pytorch.org/t/why-is-tensorboard-reporting-no-tensorcores/168473) (not relevant -> profiler runs, but output not in tensorboard)

Suspecting / judging from error message, that the problem is related to context management in profiler, I've tried 2 ways of launching it, *v1 -> distinct-context-per-stage* and *v2 -> single-context-for-experiment*, but neither have succeded. Remaining parts of experiment, like dataloaders, model, etc. are provided in the environment and so far worked correctly (listed example setup at the very end of this issue, as it's quite a lot of code). Expected behaviour is obviously ""no-crashing"" and returning / writting relevant profiling information istead.

Will be grateful for any ideas / debugging tips 🙂

### What version are you seeing the problem on?

v2.3

### How to reproduce the bug

```python
import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from torchvision.transforms import ToTensor
from torchvision.datasets import MNIST

import pytorch_lightning as pl
from torch.profiler import profile, record_function, ProfilerActivity

# Define a simple SimCLR model
class SimCLRModel(pl.LightningModule):
    def __init__(self, hidden_dim=128, lr=1e-3):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(28 * 28, 512),
            nn.ReLU(),
            nn.Linear(512, hidden_dim),
        )
        self.projection = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
        )
        self.lr = lr

    def forward(self, x):
        h = self.encoder(x.view(x.size(0), -1))
        z = self.projection(h)
        return z

    def training_step(self, batch, batch_idx):
        x, _ = batch
        z = self(x)
        # Dummy loss for demonstration purposes
        loss = torch.mean(z)
        self.log('train_loss', loss)
        return loss

    def validation_step(self, batch, batch_idx):
        x, _ = batch
        z = self(x)
        # Dummy loss for demonstration purposes
        loss = torch.mean(z)
        self.log('val_loss', loss)
        return loss

    def test_step(self, batch, batch_idx):
        x, _ = batch
        z = self(x)
        # Dummy loss for demonstration purposes
        loss = torch.mean(z)
        self.log('test_loss', loss)
        return loss

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)
        return optimizer

# Define a simple dataset (using MNIST for simplicity)
class ContrastiveMNIST(Dataset):
    def __init__(self, root, train=True, transform=ToTensor(), download=True):
        self.mnist = MNIST(root, train=train, transform=transform, download=download)

    def __len__(self):
        return len(self.mnist)

    def __getitem__(self, idx):
        img, target = self.mnist[idx]
        # Create a dummy second view for contrastive learning (same as first for simplicity)
        img_pair = img
        return img, img_pair

# --- Setup ---
# Define hyperparameters
max_epochs = 3
batch_size = 64
learning_rate = 1e-3
hidden_dimension = 128
accelerator = ""gpu""  # ""cpu"" or ""cuda""

# Create data loaders
data_dir = os.getcwd()  # Use current directory to store MNIST
train_dataset = ContrastiveMNIST(data_dir, train=True, download=True)
val_dataset = ContrastiveMNIST(data_dir, train=False, download=True)
test_dataset = ContrastiveMNIST(data_dir, train=False, download=True)

dataloader_train_simclr = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
dataloader_val_simclr = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)
dataloader_test_simclr = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)

# Initialize the model
model = SimCLRModel(hidden_dim=hidden_dimension, lr=learning_rate)


and then, I've tried this 2 options:

trainer = pl.Trainer(
    log_every_n_steps=100,
    max_epochs=max_epochs,
    devices=1,
    accelerator=accelerator,
    enable_checkpointing=False,
    num_sanity_val_steps=0,  # to avoid adding unnecessary item to validation_epoch_embedding_norms
)

###########################
# Pre-training
###########################
with profile(
    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
    record_shapes=True,
    profile_memory=True,
    with_stack=True,
) as prof:
    with record_function(""pretraining-validation""):
        # perform extra 'validation' epoch to see if untrained model does anything useful
        trainer.validate(model, dataloader_val_simclr)

###########################
# Training
###########################
    with record_function(""training-phase""):
        trainer.fit(
            model=model,
            train_dataloaders=dataloader_train_simclr,
            val_dataloaders=dataloader_val_simclr,
        )

###########################
# Testing
###########################
    with record_function(""testing-final""):
        trainer.test(
            model,
            dataloaders=dataloader_test_simclr,
        )

Code snippet v2:

trainer = pl.Trainer(
    log_every_n_steps=100,
    max_epochs=max_epochs,
    devices=1,
    accelerator=accelerator,
    enable_checkpointing=False,
    num_sanity_val_steps=0,  # to avoid adding unnecessary item to validation_epoch_embedding_norms
)

###########################
# Pre-training
###########################
with profile(
    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
    record_shapes=True,
    profile_memory=True,
    with_stack=True,
) as prof:
    with record_function(""pretraining-validation""):
        # perform extra 'validation' epoch to see if untrained model does anything useful
        trainer.validate(model, dataloader_val_simclr)

###########################
# Training
###########################
with profile(
    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
    record_shapes=True,
    profile_memory=True,
    with_stack=True,
) as prof:
    with record_function(""training-phase""):
        trainer.fit(
            model=model,
            train_dataloaders=dataloader_train_simclr,
            val_dataloaders=dataloader_val_simclr,
        )

###########################
# Testing
###########################
with profile(
    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
    record_shapes=True,
    profile_memory=True,
    with_stack=True,
) as prof:
    with record_function(""testing-final""):
        trainer.test(
            model,
            dataloaders=dataloader_test_simclr,
        )
```

### Error messages and logs

Stack traces:
```
RuntimeError                              Traceback (most recent call last)
Cell In[4], line 107
     96 trainer = pl.Trainer(
     97     log_every_n_steps=100,
     98     max_epochs=max_epochs,
   (...)
    101     num_sanity_val_steps=0,  # to avoid adding unnecessary item to validation_epoch_embedding_norms
    102 )
    104 ###########################
    105 # Pre-training (Validation before training)
    106 ###########################
--> 107 with profile(
    108     activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
    109     record_shapes=True,
    110     profile_memory=True,
    111     with_stack=True,
    112 ) as prof:
    113     with record_function(""pretraining-validation""):
    114         # perform extra 'validation' epoch to see if untrained model does anything useful
    115         trainer.validate(model, dataloader_val_simclr)

File d:\{repository_path}\venv\Lib\site-packages\torch\profiler\profiler.py:699, in profile.__exit__(self, exc_type, exc_val, exc_tb)
    698 def __exit__(self, exc_type, exc_val, exc_tb):
--> 699     self.stop()
    700     prof.KinetoStepTracker.erase_step_count(PROFILER_STEP_NAME)
    701     if self.execution_trace_observer:

File d:\{repository_path}\venv\Lib\site-packages\torch\profiler\profiler.py:715, in profile.stop(self)
    713 if self.record_steps and self.step_rec_fn:
    714     self.step_rec_fn.__exit__(None, None, None)
--> 715 self._transit_action(self.current_action, None)

File d:\{repository_path}\venv\Lib\site-packages\torch\profiler\profiler.py:744, in profile._transit_action(self, prev_action, current_action)
    742 if action_list:
    743     for action in action_list:
--> 744         action()

File d:\{repository_path}\venv\Lib\site-packages\torch\profiler\profiler.py:199, in _KinetoProfile.stop_trace(self)
    197     self.execution_trace_observer.stop()
    198 assert self.profiler is not None
--> 199 self.profiler.__exit__(None, None, None)

File d:\{repository_path}\venv\Lib\site-packages\torch\autograd\profiler.py:296, in profile.__exit__(self, exc_type, exc_val, exc_tb)
    294 if self.use_cuda:
    295     torch.cuda.synchronize()
--> 296 self.kineto_results = _disable_profiler()
    297 _run_on_profiler_stop()
    298 parsed_results = self._parse_kineto_results(self.kineto_results)

RuntimeError: !stack.empty() INTERNAL ASSERT FAILED at ""..\\torch\\csrc\\autograd\\profiler_python.cpp"":969, please report a bug to PyTorch. Python replay stack is empty.
```

Sometimes (seems random to be), I get this error:

```
RuntimeError                              Traceback (most recent call last)
Cell In[28], [line 208](vscode-notebook-cell:?execution_count=28&line=208)
    [189](vscode-notebook-cell:?execution_count=28&line=189) trainer = pl.Trainer(
    [190](vscode-notebook-cell:?execution_count=28&line=190)     log_every_n_steps=100,
    [191](vscode-notebook-cell:?execution_count=28&line=191)     max_epochs=max_epochs,
   (...)
    [202](vscode-notebook-cell:?execution_count=28&line=202)     ],
    [203](vscode-notebook-cell:?execution_count=28&line=203) )
    [205](vscode-notebook-cell:?execution_count=28&line=205) ###########################
    [206](vscode-notebook-cell:?execution_count=28&line=206) # Pre-training
    [207](vscode-notebook-cell:?execution_count=28&line=207) ###########################
--> [208](vscode-notebook-cell:?execution_count=28&line=208) with profile(
    [209](vscode-notebook-cell:?execution_count=28&line=209)     activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
    [210](vscode-notebook-cell:?execution_count=28&line=210)     record_shapes=True,
    [211](vscode-notebook-cell:?execution_count=28&line=211)     profile_memory=True,
    [212](vscode-notebook-cell:?execution_count=28&line=212)     with_stack=True,
    [213](vscode-notebook-cell:?execution_count=28&line=213) ) as prof:
    [214](vscode-notebook-cell:?execution_count=28&line=214)     with record_function(""pretraining-validation""):
    [215](vscode-notebook-cell:?execution_count=28&line=215)         # perform extra 'validation' epoch to see if untrained model does anything useful
    [216](vscode-notebook-cell:?execution_count=28&line=216)         trainer.validate(model, dataloader_val_simclr)

File d:\__repos\masters_bacter_private\venv\Lib\site-packages\torch\profiler\profiler.py:695, in profile.__enter__(self)
    [694](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:694) def __enter__(self):
--> [695](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:695)     self.start()
    [696](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:696)     return self

File d:\__repos\masters_bacter_private\venv\Lib\site-packages\torch\profiler\profiler.py:705, in profile.start(self)
    [704](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:704) def start(self):
--> [705](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:705)     self._transit_action(ProfilerAction.NONE, self.current_action)
    [706](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:706)     if self.record_steps:
    [707](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:707)         self.step_rec_fn = prof.record_function(
    [708](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:708)             ""ProfilerStep#"" + str(self.step_num)
    [709](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:709)         )

File d:\__repos\masters_bacter_private\venv\Lib\site-packages\torch\profiler\profiler.py:744, in profile._transit_action(self, prev_action, current_action)
    [742](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:742) if action_list:
    [743](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:743)     for action in action_list:
--> [744](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:744)         action()

File d:\__repos\masters_bacter_private\venv\Lib\site-packages\torch\profiler\profiler.py:155, in _KinetoProfile.prepare_trace(self)
    [141](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:141) def prepare_trace(self):
    [142](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:142)     self.profiler = prof.profile(
    [143](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:143)         use_cuda=(ProfilerActivity.CUDA in self.activities),
    [144](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:144)         use_cpu=(ProfilerActivity.CPU in self.activities),
   (...)
    [153](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:153)         experimental_config=self.experimental_config,
    [154](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:154)     )
--> [155](file:///D:/{repository_path}/venv/Lib/site-packages/torch/profiler/profiler.py:155)     self.profiler._prepare_trace()

File d:\__repos\masters_bacter_private\venv\Lib\site-packages\torch\autograd\profiler.py:284, in profile._prepare_trace(self)
    [282](file:///D:/{repository_path}/venv/Lib/site-packages/torch/autograd/profiler.py:282) def _prepare_trace(self):
    [283](file:///D:/{repository_path}/venv/Lib/site-packages/torch/autograd/profiler.py:283)     self.entered = True
--> [284](file:///D:/{repository_path}/venv/Lib/site-packages/torch/autograd/profiler.py:284)     _prepare_profiler(self.config(), self.kineto_activities)

RuntimeError: Can't disable Kineto profiler when it's not running
```

### Environment

PyTorch version: 2.3.1+cu118
Is debug build: False
CUDA used to build PyTorch: 11.8
ROCM used to build PyTorch: N/A

OS: Microsoft Windows 10 Education (10.0.19045 64-bitowy)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: N/A

Python version: 3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)] 
(64-bit runtime)
Python platform: Windows-10-10.0.19045-SP0
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3060
Nvidia driver version: 560.94
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Name: AMD Ryzen 7 5800X 8-Core Processor
Manufacturer: AuthenticAMD
Family: 107
Architecture: 9
ProcessorType: 3
DeviceID: CPU0
CurrentClockSpeed: 3801
MaxClockSpeed: 3801
L2CacheSize: 4096
L2CacheSpeed: None
Revision: 8448

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.26.3
[pip3] pytorch-lightning==2.3.3
[pip3] torch==2.3.1+cu118
[pip3] torch-tb-profiler==0.4.3
[pip3] torchmetrics==1.4.0.post0
[pip3] torchvision==0.18.1+cu118
[conda] Could not collect

### More info

_No response_",MKaczkow,79789261,open,False,0,2025-05-01T17:19:07+00:00,2025-05-01T17:19:20+00:00,,bug;needs triage;ver: 2.3.x,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3030316479,20778,Added warmup parameter to early stopping cb,"## What does this PR do?

This pull request introduces a new feature to the `EarlyStopping` callback in PyTorch Lightning, allowing users to specify the starting epoch for monitoring early stopping. Additionally, it updates imports to use the `pytorch_lightning` namespace and improves example documentation. Below is a summary of the most important changes:

### New Feature: Starting Epoch for Early Stopping

* Added a new parameter `start_from_epoch` to the `EarlyStopping` callback, allowing users to specify the epoch from which early stopping monitoring begins. Defaults to 0. [[1]](diffhunk://#diff-e11ffa0fe5fd70b9faa655717bb09d4cab51c09f305db1cf59edae7338d835d4R67-R68) [[2]](diffhunk://#diff-e11ffa0fe5fd70b9faa655717bb09d4cab51c09f305db1cf59edae7338d835d4R113) [[3]](diffhunk://#diff-e11ffa0fe5fd70b9faa655717bb09d4cab51c09f305db1cf59edae7338d835d4R129)
* Updated the `_run_early_stopping_check` method to skip the early stopping check if the current epoch is less than `start_from_epoch`.

### Namespace Update

* Updated all imports from `lightning.pytorch` to `pytorch_lightning` for consistency with the latest namespace conventions. [[1]](diffhunk://#diff-e11ffa0fe5fd70b9faa655717bb09d4cab51c09f305db1cf59edae7338d835d4L29-R32) [[2]](diffhunk://#diff-e11ffa0fe5fd70b9faa655717bb09d4cab51c09f305db1cf59edae7338d835d4L182-R190)

### Documentation Improvements

* Enhanced the example in the docstring to demonstrate how to use the new `start_from_epoch` parameter.

Fixes #\<issue_number>

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->
No breaking changes!

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [x] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [x] Check that all items from **Before submitting** are resolved
- [x] Make sure the title is self-explanatory and the description concisely explains the PR
- [x] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20778.org.readthedocs.build/en/20778/

<!-- readthedocs-preview pytorch-lightning end -->",Furkan-rgb,50831308,open,False,0,2025-04-30T06:53:04+00:00,2025-04-30T06:53:54+00:00,,pl,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3030195934,20777,LightningCLI instantiator receives values applied by instantiation links to set in hparams,"## What does this PR do?

<!--
Please include a summary of the change and which issue is fixed.
Please also include relevant motivation and context.
List any dependencies that are required for this change.

If we didn't discuss your PR in Github issues there's a high chance it will not be merged.

The following links the related issue to the PR (https://docs.github.com/en/free-pro-team@latest/github/managing-your-work-on-github/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword)
-->

Fixes `save_hyperparameters` when used through `LightningCLI` (feature introduced in #18105) so that target values of links applied for instantiation are included in hparams.

Fixes #20311
Fixes #20147

Also adds an official way to disable #18105 (parameter `load_from_checkpoint_support`), which might be desired by some people, e.g #20432, #20726

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- [x] Did you write any **new necessary tests**? (not for typos and docs)
- [x] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- [x] Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [ ] Is this pull request ready for review? (if not, please submit in draft mode)
- [ ] Check that all items from **Before submitting** are resolved
- [ ] Make sure the title is self-explanatory and the description concisely explains the PR
- [ ] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20777.org.readthedocs.build/en/20777/

<!-- readthedocs-preview pytorch-lightning end -->",mauvilsa,5780272,open,False,0,2025-04-30T05:42:44+00:00,2025-05-12T08:15:12+00:00,,has conflicts;pl;dependencies,1,0,0,0,1,0,0
Lightning-AI/pytorch-lightning,3029627919,20776,slurm env incorrectly complains about srun with salloc interactive session.,"### Bug description

I get an error message (see below) complaining that I'm not using srun, preventing me from running my parallel code. But in reality I did use srun, but I'm also in interactive mode with salloc. In order to get past this error I had to modify the file: `/u/ddeighan/miniforge3/envs/uqops/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py` to manually disable checking if the allocation was in interactive mode.

**There needs to be better sanity checking code to tell the difference between `srun -n1 --pty bash` (invalid, not really using srun) & `salloc ...; srun python train.py`** (valid, using srun properly)

### What version are you seeing the problem on?

v2.5

### How to reproduce the bug

salloc -N2 --gpus=2 ...
srun python train_parallel.py

### Error messages and logs

/u/ddeighan/miniforge3/envs/uqops/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python channel.py ...

### Environment

<details>
  <summary>Current environment</summary>

```
#- PyTorch Lightning Version (e.g., 2.5.0):
#- PyTorch Version (e.g., 2.5):
#- Python version (e.g., 3.12):
#- OS (e.g., Linux):
#- CUDA/cuDNN version:
#- GPU models and configuration:
#- How you installed Lightning(`conda`, `pip`, source):
```

</details>


### More info

_No response_",profPlum,4739054,open,False,0,2025-04-29T22:03:37+00:00,2025-04-29T22:10:19+00:00,,bug;needs triage;ver: 2.5.x,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3029235109,20775,Fix double iteration bug when resumed from a checkpoint.,"## What does this PR do?

This PR fixes the double `iter()` bug discussed in #19427

<!--
Please include a summary of the change and which issue is fixed.
Please also include relevant motivation and context.
List any dependencies that are required for this change.

If we didn't discuss your PR in Github issues there's a high chance it will not be merged.

The following links the related issue to the PR (https://docs.github.com/en/free-pro-team@latest/github/managing-your-work-on-github/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword)
-->

Fixes #19427

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [x] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [ ] Is this pull request ready for review? (if not, please submit in draft mode)
- [ ] Check that all items from **Before submitting** are resolved
- [ ] Make sure the title is self-explanatory and the description concisely explains the PR
- [ ] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20775.org.readthedocs.build/en/20775/

<!-- readthedocs-preview pytorch-lightning end -->",sudiptob2,32765701,open,False,1,2025-04-29T18:53:54+00:00,2025-05-12T08:31:49+00:00,,pl,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3028962435,20774,WandbLogger: log distributed training experiments (multi-node),"### Description & Motivation

Currently, when using PyTorch Lightning with `WandbLogger` for multi-node distributed training, **only** the system metrics (CPU/GPU utilization, memory usage, etc.) from **node 0** and logs from **rank 0** are recorded by wandb. This limits visibility into critical performance data from non-zero ranks, making it harder to debug issues like uneven resource utilization across nodes/GPUs or pinpoint hardware bottlenecks in distributed setups.

With wandb's recently added [distributed experiment tracking support](https://docs.wandb.ai/guides/track/log/distributed-training/#track-all-processes-to-a-single-run) (also [the end-to-end example report](https://wandb.ai/dimaduev/simple-cnn-ddp/reports/Distributed-Training-with-Shared-Mode--VmlldzoxMTI0NTE1NA)), it's now possible to collect system metrics and logs from all nodes. However, Lightning's `WandbLogger` does not yet leverage this capability out-of-the-box. This feature request proposes updating Lightning's wandb integration to support full distributed system monitoring.

### Pitch

Add native support in `pytorch_lightning.loggers.WandbLogger` to:

- Log system metrics (hardware telemetry) from ​​all nodes​​ in distributed training, not just node 0

This could be implemented by:

- Adding a `log_all_ranks: bool` parameter to `WandbLogger` to enable/disable this behavior
- `wandb.init(..., settings=wandb.Settings(x_label=""rank_0"", mode=""shared"", x_primary=True))` for rank 0
- `wandb.init(..., settings=wandb.Settings(x_label=f""rank_{rank}"", mode=""shared"", x_primary=False))` for non-zero ranks


### Alternatives

While users could manually override logging behavior by modifying wandb.init() parameters in non-zero ranks, this:

- Conflicts with Lightning's logger orchestration
- Risks creating multiple wandb runs unintentionally
- Requires error-prone custom code outside Lightning's abstractions

A cleaner native implementation would provide better safety and usability.

### Additional context

wandb has recently updated the feature, here is the relevant issue:

- https://github.com/wandb/wandb/issues/7470#issuecomment-2814205540

When examining the `WandbLogger` **source code**, the `@rank_zero_experiment` decorator enforces wandb initialization and logging exclusively on rank 0. This creates architectural challenges for multi-rank logging because:

- Non-zero ranks never initialize a `wandb.Run`
- Any attempt to modify the existing logger would require significant refactoring of the decorator logic

Instead of adding a `log_all_ranks` parameter to `WandbLogger`, a cleaner solution could be:

- Create a new `WandbDistributedLogger` class under `lightning.pytorch.loggers.wandb`
- Design this class to:
  - Initialize wandb runs on ​​all ranks​​ using `wandb.init(..., settings=wandb.Settings(x_label=..., mode=""shared"", x_primary=...))`
  - Bypass the `@rank_zero_experiment` restriction
  - Preserve the original `WandbLogger` behavior (e.g. `log_metrics`, `log_hyperparams`, etc.)

This approach:
- Maintains backward compatibility
- Avoids complicating the existing WandbLogger API

I would be happy to submit a PR implementing if needed.

- The new `WandbDistributedLogger` class
- Integration tests verifying multi-node metric collection


cc @lantiga @borda",guyi2000,16850027,open,False,1,2025-04-29T16:46:52+00:00,2025-04-30T16:01:21+00:00,,feature;needs triage,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3025685559,20773,`limit_val_batches` as sequence,"### Description & Motivation

Support sequence inputs to `limit_val_batches` in order to apply the limits to each val dataloader separately. E.g., `limit_val_batches=[10, 20]` could be interpreted as limit to 10 batches from the first val dataloader and 20 batches from the second.

### Pitch

No response

### Alternatives

No response

### Additional context

No response",parsiad,79781,open,False,0,2025-04-28T17:46:10+00:00,2025-04-28T17:49:44+00:00,,feature;needs triage,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3024380975,20772,Lightning is requiring packaging < 25.0,"### Bug description

Is there a reason for lightning requiring packaging < 25.0 ?

The last lightning release allowing an install with packaging==25.0 is lightning==1.8.6 (try `pip install lightning==1.8.6 packaging==25.0`, it works !)

Yet packaging 25.0 does not seem to be revolutionary...

So may be you could remove the upper limit on packaging ?

By the way, I'm not very found of upper limits in dependencies, unless you are sure there will be a problem with the next releases of your dependencies... This was probably not the case here, as the release 25.0 of packaging did not exist when you choose to set `packaging<25.0` in your dependencies...

### What version are you seeing the problem on?

v2.5, v2.4, v2.3, v2.2, v2.1

### How to reproduce the bug

```python
for example : 

pip install lightning==2.5.1.post0 packaging==25.0
```

### Error messages and logs

```
ERROR: Cannot install lightning==2.5.1.post0 and packaging==25.0 because these package versions have conflicting dependencies.

The conflict is caused by:
    The user requested packaging==25.0
    lightning 2.5.1.post0 depends on packaging<25.0 and >=20.0
```


### Environment

_No response_

### More info

_No response_",thebaptiste,19856429,open,False,0,2025-04-28T09:54:07+00:00,2025-04-28T09:56:29+00:00,,bug;needs triage;ver: 2.1.x;ver: 2.2.x;ver: 2.4.x;ver: 2.3.x;ver: 2.5.x,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3024362854,20771,add toggled_optimizer context manager,"## What does this PR do?

This PR adds support for context manager for `toggle_optimizer` and `untoggle_opimizer` methods, introducing 'toggled_optimizer' context manager.

TL;DR
Replace this

```
self.toggle_optimizer(optimizer)
optimizer.zero_grad()
DO_SOMETHING()
optimizer.step()
self.untoggle_optimizer(optimizer)
```
To this

```
with self.toggled_optimizer(optimizer):
    DO_SOMETHING()
```

Fixes #17294

<details>
  <summary><b>Before submitting</b></summary>

- [x] Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- [x] Did you make sure to **update the documentation** with your changes? (if necessary)
- [x] Did you write any **new necessary tests**? (not for typos and docs)
- [x] Did you verify new and **existing tests pass** locally with your changes?
- [x] Did you list all the **breaking changes** introduced by this pull request?
- [x] Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [ ] Is this pull request ready for review? (if not, please submit in draft mode)
- [ ] Check that all items from **Before submitting** are resolved
- [ ] Make sure the title is self-explanatory and the description concisely explains the PR
- [ ] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20771.org.readthedocs.build/en/20771/

<!-- readthedocs-preview pytorch-lightning end -->",rustamzh,8539796,open,False,0,2025-04-28T09:47:23+00:00,2025-04-28T14:01:22+00:00,,docs;pl,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3024305246,20770,drop mergify,"## What does this PR do?

seems mergify is not free for public repos any more...
![image](https://github.com/user-attachments/assets/9352bd4a-3b56-4d70-8782-e17db7d18030)


<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [x] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [x] Check that all items from **Before submitting** are resolved
- [x] Make sure the title is self-explanatory and the description concisely explains the PR
- [x] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20770.org.readthedocs.build/en/20770/

<!-- readthedocs-preview pytorch-lightning end -->",Borda,6035284,closed,False,1,2025-04-28T09:26:07+00:00,2025-04-28T12:32:41+00:00,2025-04-28T12:32:39+00:00,ci,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3024087566,20769,docs: update repo link preventing flakiness,"## What does this PR do?

alhough the old links works they can be source of flakes as it not direct link but GH had to do some redirects and also if ever `lightning` repo will be created all links broke

see flakes in https://github.com/Lightning-AI/pytorch-lightning/actions/runs/14702342250/job/41254203925?pr=20763#step:12:1950

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [x] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [x] Check that all items from **Before submitting** are resolved
- [x] Make sure the title is self-explanatory and the description concisely explains the PR
- [x] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20769.org.readthedocs.build/en/20769/

<!-- readthedocs-preview pytorch-lightning end -->",Borda,6035284,closed,False,2,2025-04-28T08:09:39+00:00,2025-04-28T12:32:56+00:00,2025-04-28T12:32:04+00:00,docs;ci;fabric;pl,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3023493620,20768,build(deps): bump pytest-cov from 4.1.0 to 6.1.1 in /requirements,"Bumps [pytest-cov](https://github.com/pytest-dev/pytest-cov) from 4.1.0 to 6.1.1.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/pytest-dev/pytest-cov/blob/master/CHANGELOG.rst"">pytest-cov's changelog</a>.</em></p>
<blockquote>
<h2>6.1.1 (2025-04-05)</h2>
<ul>
<li>Fixed breakage that occurs when <code>--cov-context</code> and the <code>no_cover</code> marker are used together.</li>
</ul>
<h2>6.1.0 (2025-04-01)</h2>
<ul>
<li>Change terminal output to use full width lines for the coverage header.
Contributed by Tsvika Shapira in <code>[#678](https://github.com/pytest-dev/pytest-cov/issues/678) &lt;https://github.com/pytest-dev/pytest-cov/pull/678&gt;</code>_.</li>
<li>Removed unnecessary CovFailUnderWarning. Fixes <code>[#675](https://github.com/pytest-dev/pytest-cov/issues/675) &lt;https://github.com/pytest-dev/pytest-cov/issues/675&gt;</code>_.</li>
<li>Fixed the term report not using the precision specified via <code>--cov-precision</code>.</li>
</ul>
<h2>6.0.0 (2024-10-29)</h2>
<ul>
<li>Updated various documentation inaccuracies, especially on subprocess handling.</li>
<li>Changed fail under checks to use the precision set in the coverage configuration.
Now it will perform the check just like <code>coverage report</code> would.</li>
<li>Added a <code>--cov-precision</code> cli option that can override the value set in your coverage configuration.</li>
<li>Dropped support for now EOL Python 3.8.</li>
</ul>
<h2>5.0.0 (2024-03-24)</h2>
<ul>
<li>Removed support for xdist rsync (now deprecated).
Contributed by Matthias Reichenbach in <code>[#623](https://github.com/pytest-dev/pytest-cov/issues/623) &lt;https://github.com/pytest-dev/pytest-cov/pull/623&gt;</code>_.</li>
<li>Switched docs theme to Furo.</li>
<li>Various legacy Python cleanup and CI improvements.
Contributed by Christian Clauss and Hugo van Kemenade in
<code>[#630](https://github.com/pytest-dev/pytest-cov/issues/630) &lt;https://github.com/pytest-dev/pytest-cov/pull/630&gt;</code><em>,
<code>[#631](https://github.com/pytest-dev/pytest-cov/issues/631) &lt;https://github.com/pytest-dev/pytest-cov/pull/631&gt;</code></em>,
<code>[#632](https://github.com/pytest-dev/pytest-cov/issues/632) &lt;https://github.com/pytest-dev/pytest-cov/pull/632&gt;</code>_ and
<code>[#633](https://github.com/pytest-dev/pytest-cov/issues/633) &lt;https://github.com/pytest-dev/pytest-cov/pull/633&gt;</code>_.</li>
<li>Added a <code>pyproject.toml</code> example in the docs.
Contributed by Dawn James in <code>[#626](https://github.com/pytest-dev/pytest-cov/issues/626) &lt;https://github.com/pytest-dev/pytest-cov/pull/626&gt;</code>_.</li>
<li>Modernized project's pre-commit hooks to use ruff. Initial POC contributed by
Christian Clauss in <code>[#584](https://github.com/pytest-dev/pytest-cov/issues/584) &lt;https://github.com/pytest-dev/pytest-cov/pull/584&gt;</code>_.</li>
<li>Dropped support for Python 3.7.</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pytest-dev/pytest-cov/commit/9463242e3a7bc18a56b8f18c01b4dfb50087e5ed""><code>9463242</code></a> Bump version: 6.1.0 → 6.1.1</li>
<li><a href=""https://github.com/pytest-dev/pytest-cov/commit/7f2781b47fc9bd4a8e94ff86b4f69f5959c3d907""><code>7f2781b</code></a> Update changelog.</li>
<li><a href=""https://github.com/pytest-dev/pytest-cov/commit/a59548f3adcb757ea8afcb40d8d849af49f6e925""><code>a59548f</code></a> Allow the context plugin to check if the controller is running or not. Fixes ...</li>
<li><a href=""https://github.com/pytest-dev/pytest-cov/commit/10f8cde38c3b0aaf2c75d9ed62d4f333d8809d96""><code>10f8cde</code></a> Bump version: 6.0.0 → 6.1.0</li>
<li><a href=""https://github.com/pytest-dev/pytest-cov/commit/10b14afffcd53b19967785c0b3e8b35ebac70b6f""><code>10b14af</code></a> Update changelog.</li>
<li><a href=""https://github.com/pytest-dev/pytest-cov/commit/aa57aed273475b4f9975cc9a8a1662b336718662""><code>aa57aed</code></a> Refactor a bit the internals to be a bit less boilerplatey and have more clar...</li>
<li><a href=""https://github.com/pytest-dev/pytest-cov/commit/e760099a7fd5f49c235dc798bf7f222c0372b7e3""><code>e760099</code></a> Make sure the CLI precision is used when creating report. Fixes <a href=""https://redirect.github.com/pytest-dev/pytest-cov/issues/674"">#674</a>.</li>
<li><a href=""https://github.com/pytest-dev/pytest-cov/commit/44540e1e9f02f3b69b62834636cf3057edc960d6""><code>44540e1</code></a> Remove unnecessary CovFailUnderWarning. Closes <a href=""https://redirect.github.com/pytest-dev/pytest-cov/issues/675"">#675</a>.</li>
<li><a href=""https://github.com/pytest-dev/pytest-cov/commit/204af146f8f4ff03076825a693ee6aef587deb6b""><code>204af14</code></a> Update changelog.</li>
<li><a href=""https://github.com/pytest-dev/pytest-cov/commit/089e7bb5c16dcfdedd54f27fda094ccb3eeaae2c""><code>089e7bb</code></a> Upgrade ruff.</li>
<li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest-cov/compare/v4.1.0...v6.1.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-cov&package-manager=pip&previous-version=4.1.0&new-version=6.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20768.org.readthedocs.build/en/20768/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,2,2025-04-28T01:48:57+00:00,2025-04-28T08:30:57+00:00,2025-04-28T08:30:24+00:00,ci;fabric;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3023493586,20767,"build(deps): update fsspec[http] requirement from <2024.4.0,>=2022.5.0 to >=2022.5.0,<2025.4.0 in /requirements","Updates the requirements on [fsspec[http]](https://github.com/fsspec/filesystem_spec) to permit the latest version.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/fsspec/filesystem_spec/commit/c2f8c6356a97918506cb040bc6d59f1c35f6666f""><code>c2f8c63</code></a> changelog (<a href=""https://redirect.github.com/fsspec/filesystem_spec/issues/1818"">#1818</a>)</li>
<li><a href=""https://github.com/fsspec/filesystem_spec/commit/07fe4c6f4dce6ef633efaf5183ec4edb4e74fd46""><code>07fe4c6</code></a> Project metadata: Increase minimum Python version to say &gt;=3.9 (<a href=""https://redirect.github.com/fsspec/filesystem_spec/issues/1817"">#1817</a>)</li>
<li><a href=""https://github.com/fsspec/filesystem_spec/commit/8d314c01d0eb8a6d75d353f1825ddc6ac2c65cbb""><code>8d314c0</code></a> changelog (<a href=""https://redirect.github.com/fsspec/filesystem_spec/issues/1815"">#1815</a>)</li>
<li><a href=""https://github.com/fsspec/filesystem_spec/commit/c71058119e5ae9dad27c8c60df646217beb6aa36""><code>c710581</code></a> Call cat_ranges in blockcache for async filesystems (<a href=""https://redirect.github.com/fsspec/filesystem_spec/issues/1336"">#1336</a>)</li>
<li><a href=""https://github.com/fsspec/filesystem_spec/commit/c0d1034f5edb3623b42ee890212e4fa31cd7bdc7""><code>c0d1034</code></a> .json should not be a property in the requests shim (<a href=""https://redirect.github.com/fsspec/filesystem_spec/issues/1814"">#1814</a>)</li>
<li><a href=""https://github.com/fsspec/filesystem_spec/commit/961412dc83cb242728860f8637ab234485962f40""><code>961412d</code></a> rework github _open() implementation to support LFS (<a href=""https://redirect.github.com/fsspec/filesystem_spec/issues/1810"">#1810</a>)</li>
<li><a href=""https://github.com/fsspec/filesystem_spec/commit/6b85a471733124de6e30edf4e16425ee8d30291d""><code>6b85a47</code></a> Automatically clean thread and loop on fork (<a href=""https://redirect.github.com/fsspec/filesystem_spec/issues/1790"">#1790</a>)</li>
<li><a href=""https://github.com/fsspec/filesystem_spec/commit/d1aaebf630c38611f26cb10253a464789774e0c4""><code>d1aaebf</code></a> Do not force registry err (<a href=""https://redirect.github.com/fsspec/filesystem_spec/issues/1804"">#1804</a>)</li>
<li><a href=""https://github.com/fsspec/filesystem_spec/commit/7e4da5164454e6e883bb65bba114a517f5174bae""><code>7e4da51</code></a> protocol configs (<a href=""https://redirect.github.com/fsspec/filesystem_spec/issues/1806"">#1806</a>)</li>
<li><a href=""https://github.com/fsspec/filesystem_spec/commit/50c5a2e161d85413e19e9e10d42de8b3cf56a921""><code>50c5a2e</code></a> changelog (<a href=""https://redirect.github.com/fsspec/filesystem_spec/issues/1803"">#1803</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/fsspec/filesystem_spec/compare/2022.5.0...2025.3.2"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20767.org.readthedocs.build/en/20767/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,0,2025-04-28T01:48:54+00:00,2025-04-28T07:08:10+00:00,2025-04-28T07:08:08+00:00,ci;fabric;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3023493527,20766,"build(deps): update awscli requirement from <1.31.0,>=1.30.0 to >=1.30.0,<1.41.0 in /requirements","Updates the requirements on [awscli](https://github.com/aws/aws-cli) to permit the latest version.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/aws/aws-cli/commit/b0bb8d2296178e6ddd32d9492db5662a564a1950""><code>b0bb8d2</code></a> Merge branch 'release-1.40.2'</li>
<li><a href=""https://github.com/aws/aws-cli/commit/ee97e795c2e1f494e9bbe8ce87f831cf58b1d140""><code>ee97e79</code></a> Bumping version to 1.40.2</li>
<li><a href=""https://github.com/aws/aws-cli/commit/919703cd2273895087c0e3b99801630a3285df59""><code>919703c</code></a> Update changelog based on model updates</li>
<li><a href=""https://github.com/aws/aws-cli/commit/98d1ab963269bafa0275a06b6da3a79ed67565fa""><code>98d1ab9</code></a> Merge branch 'release-1.40.1'</li>
<li><a href=""https://github.com/aws/aws-cli/commit/a887a3efbafe7d1fa908d190c568043fd466d464""><code>a887a3e</code></a> Merge branch 'release-1.40.1' into develop</li>
<li><a href=""https://github.com/aws/aws-cli/commit/1d7fc31e43abe56f4d3e3fe39be6957ce3d910c2""><code>1d7fc31</code></a> Bumping version to 1.40.1</li>
<li><a href=""https://github.com/aws/aws-cli/commit/cbf047cf0dd4d78c7e036af5472ab80a9f1f2f0b""><code>cbf047c</code></a> Update changelog based on model updates</li>
<li><a href=""https://github.com/aws/aws-cli/commit/84b010dcb048d43ed8165f842c93e67a0a34c65c""><code>84b010d</code></a> Alias socialmessaging command (<a href=""https://redirect.github.com/aws/aws-cli/issues/9450"">#9450</a>)</li>
<li><a href=""https://github.com/aws/aws-cli/commit/d8cc92fa291213228c068cc624345673c1a44ad4""><code>d8cc92f</code></a> Merge branch 'release-1.40.0'</li>
<li><a href=""https://github.com/aws/aws-cli/commit/888e8b19f68d69434f0f7515b5f4c6a4994551bb""><code>888e8b1</code></a> Merge branch 'release-1.40.0' into develop</li>
<li>Additional commits viewable in <a href=""https://github.com/aws/aws-cli/compare/1.30.0...1.40.2"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20766.org.readthedocs.build/en/20766/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,0,2025-04-28T01:48:51+00:00,2025-04-28T07:08:24+00:00,2025-04-28T07:08:21+00:00,ci;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3023493335,20765,build(deps): bump torch from 2.6.0 to 2.7.0 in /requirements,"Bumps [torch](https://github.com/pytorch/pytorch) from 2.6.0 to 2.7.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pytorch/pytorch/releases"">torch's releases</a>.</em></p>
<blockquote>
<h1>PyTorch 2.7.0 Release Notes</h1>
<ul>
<li><a href=""https://github.com/pytorch/pytorch/blob/HEAD/#highlights"">Highlights</a></li>
<li><a href=""https://github.com/pytorch/pytorch/blob/HEAD/#tracked-regressions"">Tracked Regressions</a></li>
<li><a href=""https://github.com/pytorch/pytorch/blob/HEAD/#backwards-incompatible-changes"">Backwards Incompatible Changes</a></li>
<li><a href=""https://github.com/pytorch/pytorch/blob/HEAD/#deprecations"">Deprecations</a></li>
<li><a href=""https://github.com/pytorch/pytorch/blob/HEAD/#new-features"">New Features</a></li>
<li><a href=""https://github.com/pytorch/pytorch/blob/HEAD/#improvements"">Improvements</a></li>
<li><a href=""https://github.com/pytorch/pytorch/blob/HEAD/#bug-fixes"">Bug fixes</a></li>
<li><a href=""https://github.com/pytorch/pytorch/blob/HEAD/#performance"">Performance</a></li>
<li><a href=""https://github.com/pytorch/pytorch/blob/HEAD/#documentation"">Documentation</a></li>
<li><a href=""https://github.com/pytorch/pytorch/blob/HEAD/#developers"">Developers</a></li>
</ul>
<h1>Highlights</h1>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pytorch/pytorch/commit/134179474539648ba7dee1317959529fbd0e7f89""><code>1341794</code></a> Gracefully handle optree less than minimum version, part 2 (<a href=""https://redirect.github.com/pytorch/pytorch/issues/151323"">#151323</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/073912749d667fcfb2de1c15e1e664dc0ccd3460""><code>0739127</code></a> Gracefully handle optree less than minimum version (<a href=""https://redirect.github.com/pytorch/pytorch/issues/150977"">#150977</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/0c236f3c722abc8e76fc16fae90946af9a895ce5""><code>0c236f3</code></a> Update triton wheel build, setuptools pin (<a href=""https://redirect.github.com/pytorch/pytorch/issues/150953"">#150953</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/c7ff78dfc0c38847bf5daa78ab8b3669e1734246""><code>c7ff78d</code></a> Fix inplacing with multiple, fused uses (<a href=""https://redirect.github.com/pytorch/pytorch/issues/150892"">#150892</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/894909a6139ff38d056d3ca5cfa33a020c7602c1""><code>894909a</code></a> Revert &quot;[CUDA] Only use vec128 if CUDA version is newer than 12.8&quot; (<a href=""https://redirect.github.com/pytorch/pytorch/issues/150855"">#150855</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/ef2b1390ed5fda1f50843bf5977e5f8cf5e40493""><code>ef2b139</code></a> [Manylinux 2.28] Correct Linux aarch64 cuda binaries wheel name (<a href=""https://redirect.github.com/pytorch/pytorch/issues/150820"">#150820</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/3f236f19032ff6424160018c024478c83b6ad6b9""><code>3f236f1</code></a> [CUDA] Only use vec128 if CUDA version is newer than 12.8 (<a href=""https://redirect.github.com/pytorch/pytorch/issues/150818"">#150818</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/35f1e7621254da1dcc8b24797059e9d010d49196""><code>35f1e76</code></a> Reland of &quot;[ROCm] change preferred blas lib defaults (<a href=""https://redirect.github.com/pytorch/pytorch/issues/150249"">#150249</a>)&quot;&quot; (<a href=""https://redirect.github.com/pytorch/pytorch/issues/150707"">#150707</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/a6321d62273dd281a08b1c4ec87ce3edd5b330dc""><code>a6321d6</code></a> Revert &quot;Dont exclude constant_pad_nd in prologue fusion&quot; (<a href=""https://redirect.github.com/pytorch/pytorch/issues/150699"">#150699</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/1cc51c640a717335b7bc48c11e28a1f5391b99e1""><code>1cc51c6</code></a> [CUDA][avgpool2d] Fix backward launch bounds again for <code>sm100</code>, <code>sm120</code> (<a href=""https://redirect.github.com/pytorch/pytorch/issues/150"">#150</a>...</li>
<li>Additional commits viewable in <a href=""https://github.com/pytorch/pytorch/compare/v2.6.0...v2.7.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=torch&package-manager=pip&previous-version=2.6.0&new-version=2.7.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20765.org.readthedocs.build/en/20765/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,2,2025-04-28T01:48:39+00:00,2025-04-28T09:06:41+00:00,2025-04-28T09:06:16+00:00,ci;fabric;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3023493190,20764,"build(deps): update pandas requirement from <2.2.0,>1.0 to >1.0,<2.3.0 in /requirements","Updates the requirements on [pandas](https://github.com/pandas-dev/pandas) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pandas-dev/pandas/releases"">pandas's releases</a>.</em></p>
<blockquote>
<h2>Pandas 2.2.3</h2>
<p>We are pleased to announce the release of pandas 2.2.3.
This release includes some new features, bug fixes, and performance improvements. We recommend that all users upgrade to this version.</p>
<p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/2.2.3/whatsnew/v2.2.3.html"">full whatsnew</a> for a list of all the changes.
Pandas 2.2.3 supports Python 3.9 and higher.</p>
<p>The release will be available on the defaults and conda-forge channels:</p>
<pre><code>conda install pandas
</code></pre>
<p>Or via PyPI:</p>
<pre><code>python3 -m pip install --upgrade pandas
</code></pre>
<p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>
<p>Thanks to all the contributors who made this release possible.</p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pandas-dev/pandas/commit/0691c5cf90477d3503834d983f69350f250a6ff7""><code>0691c5c</code></a> RLS: 2.2.3</li>
<li><a href=""https://github.com/pandas-dev/pandas/commit/658dfddaec7548151db4c832a8472d732b1afec9""><code>658dfdd</code></a> relax cython bound</li>
<li><a href=""https://github.com/pandas-dev/pandas/commit/6891e90c4ed2a5c9843acbdb26a295faf1bfe386""><code>6891e90</code></a> Backport PR <a href=""https://redirect.github.com/pandas-dev/pandas/issues/59847"">#59847</a>: BLD: Build wheels for Python 3.13 on aarch64 as well</li>
<li><a href=""https://github.com/pandas-dev/pandas/commit/f108468a42932476754b359f33197da9faa06cd6""><code>f108468</code></a> RLS: 2.2.3</li>
<li><a href=""https://github.com/pandas-dev/pandas/commit/69587385668f0ce61c7fbfc7946a187f8835b194""><code>6958738</code></a> Backport PR <a href=""https://redirect.github.com/pandas-dev/pandas/issues/59840"">#59840</a>: BLD: Final release prep for 2.2.3 (<a href=""https://redirect.github.com/pandas-dev/pandas/issues/59842"">#59842</a>)</li>
<li><a href=""https://github.com/pandas-dev/pandas/commit/0bd98feb952d678dcd6da090529c7457db11ca1b""><code>0bd98fe</code></a> Backport PR <a href=""https://redirect.github.com/pandas-dev/pandas/issues/59136"">#59136</a> on branch 2.2.x (Upload 3.13 &amp; free-threaded nightly wheel...</li>
<li><a href=""https://github.com/pandas-dev/pandas/commit/8d67e77d6aa1b13611c27a63b87f5912fe938f85""><code>8d67e77</code></a> Backport PR <a href=""https://redirect.github.com/pandas-dev/pandas/issues/59836"">#59836</a> on branch 2.2.x (BLD: Fix bad Cython annotation) (<a href=""https://redirect.github.com/pandas-dev/pandas/issues/59837"">#59837</a>)</li>
<li><a href=""https://github.com/pandas-dev/pandas/commit/f7b63786ace286fa8bd0fee1a75589d41883b6df""><code>f7b6378</code></a> Assorted backports for 2.2.x (<a href=""https://redirect.github.com/pandas-dev/pandas/issues/59785"">#59785</a>)</li>
<li><a href=""https://github.com/pandas-dev/pandas/commit/2127b4207abdbb355dbe32c66cfd50c16ff253b3""><code>2127b42</code></a> Backport <a href=""https://redirect.github.com/pandas-dev/pandas/issues/59144"">#59144</a> on 2.2.x / 2.3.x (remove ops div class to solve <a href=""https://redirect.github.com/pandas-dev/pandas/issues/2137"">#2137</a>) (<a href=""https://redirect.github.com/pandas-dev/pandas/issues/59535"">#59535</a>)</li>
<li><a href=""https://github.com/pandas-dev/pandas/commit/4a20adbd7d707f73491b930fe9a51e1607a7e070""><code>4a20adb</code></a> Backport PR <a href=""https://redirect.github.com/pandas-dev/pandas/issues/59813"">#59813</a> on branch 2.2.x (CI: Debug failing ARM builds) (<a href=""https://redirect.github.com/pandas-dev/pandas/issues/59828"">#59828</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.0.1...v2.2.3"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20764.org.readthedocs.build/en/20764/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,0,2025-04-28T01:48:32+00:00,2025-04-28T09:06:34+00:00,2025-04-28T09:06:32+00:00,ci;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3023493122,20763,build(deps): update wheel requirement from <0.44.0 to <0.46.0 in /requirements,"Updates the requirements on [wheel](https://github.com/pypa/wheel) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/wheel/releases"">wheel's releases</a>.</em></p>
<blockquote>
<h2>0.45.1</h2>
<ul>
<li>Fixed pure Python wheels converted from eggs and wininst files having the ABI tag in the file name</li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/wheel/blob/main/docs/news.rst"">wheel's changelog</a>.</em></p>
<blockquote>
<h1>Release Notes</h1>
<p><strong>UNRELEASED</strong></p>
<ul>
<li>Restored the <code>bdist_wheel</code> command for compatibility with <code>setuptools</code> older than
v70.1</li>
<li>Importing <code>wheel.bdist_wheel</code> now emits a <code>FutureWarning</code> instead of a
<code>DeprecationWarning</code></li>
</ul>
<p><strong>0.46.1 (2025-04-08)</strong></p>
<ul>
<li>Temporarily restored the <code>wheel.macosx_libfile</code> module
(<code>[#659](https://github.com/pypa/wheel/issues/659) &lt;https://github.com/pypa/wheel/issues/659&gt;</code>_)</li>
</ul>
<p><strong>0.46.0 (2025-04-03)</strong></p>
<ul>
<li>Dropped support for Python 3.8</li>
<li>Removed the <code>bdist_wheel</code> setuptools command implementation and entry point.
The <code>wheel.bdist_wheel</code> module is now just an alias to
<code>setuptools.command.bdist_wheel</code>, emitting a deprecation warning on import.</li>
<li>Removed vendored <code>packaging</code> in favor of a run-time dependency on it</li>
<li>Made the <code>wheel.metadata</code> module private (with a deprecation warning if it's
imported</li>
<li>Made the <code>wheel.cli</code> package private (no deprecation warning)</li>
<li>Fixed an exception when calling the <code>convert</code> command with an empty description
field</li>
</ul>
<p><strong>0.45.1 (2024-11-23)</strong></p>
<ul>
<li>Fixed pure Python wheels converted from eggs and wininst files having the ABI tag in
the file name</li>
</ul>
<p><strong>0.45.0 (2024-11-08)</strong></p>
<ul>
<li>
<p>Refactored the <code>convert</code> command to not need setuptools to be installed</p>
</li>
<li>
<p>Don't configure setuptools logging unless running <code>bdist_wheel</code></p>
</li>
<li>
<p>Added a redirection from <code>wheel.bdist_wheel.bdist_wheel</code> to
<code>setuptools.command.bdist_wheel.bdist_wheel</code> to improve compatibility with
<code>setuptools</code>' latest fixes.</p>
<p>Projects are still advised to migrate away from the deprecated  module and import
the <code>setuptools</code>' implementation explicitly. (PR by <a href=""https://github.com/abravalheri""><code>@​abravalheri</code></a>)</p>
</li>
</ul>
<p><strong>0.44.0 (2024-08-04)</strong></p>
<ul>
<li>Canonicalized requirements in METADATA file (PR by Wim Jeantine-Glenn)</li>
<li>Deprecated the <code>bdist_wheel</code> module, as the code was migrated to <code>setuptools</code>
itself</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pypa/wheel/commit/7855525de4093257e7bfb434877265e227356566""><code>7855525</code></a> Created a new release</li>
<li><a href=""https://github.com/pypa/wheel/commit/d343391c20f8f6cc89a61a6f1573522c59d3d7a3""><code>d343391</code></a> Fixed wrong wheel file names in converted pure-Python eggs/wininsts</li>
<li><a href=""https://github.com/pypa/wheel/commit/d78f0e372199f8294556345d867af4d3cf118418""><code>d78f0e3</code></a> Created a new release</li>
<li><a href=""https://github.com/pypa/wheel/commit/f064c699209e36ec2948537b7cadabf84a110c30""><code>f064c69</code></a> Added license files for vendored <code>packaging</code></li>
<li><a href=""https://github.com/pypa/wheel/commit/68387afcd33cb514a4da811d2fc5de73c8797e48""><code>68387af</code></a> Only configure setuptools logging if bdist_wheel is imported (<a href=""https://redirect.github.com/pypa/wheel/issues/641"">#641</a>)</li>
<li><a href=""https://github.com/pypa/wheel/commit/c81f5c954a8ca7698e6df9de39cf0013295949fa""><code>c81f5c9</code></a> Refactored the <code>wheel convert</code> command to not require setuptools (<a href=""https://redirect.github.com/pypa/wheel/issues/640"">#640</a>)</li>
<li><a href=""https://github.com/pypa/wheel/commit/e43464d32feaddddb235ffe21b4bf13c1193465d""><code>e43464d</code></a> Adjusted target Python versions in GitHub CI</li>
<li><a href=""https://github.com/pypa/wheel/commit/e9894e71bc62e5808710bc8c2c268de51aef52d4""><code>e9894e7</code></a> Tweaked pytest settings to make the tracebacks easier to read</li>
<li><a href=""https://github.com/pypa/wheel/commit/baf6bf89562cb42a0ca71cc1e804600b161952eb""><code>baf6bf8</code></a> Removed Cirrus CI configuration</li>
<li><a href=""https://github.com/pypa/wheel/commit/28c1ba1e2a6d08edc03c73e29293a571888981f9""><code>28c1ba1</code></a> Improved compatibility with future versions of <code>setuptools</code> (<a href=""https://redirect.github.com/pypa/wheel/issues/638"">#638</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/pypa/wheel/compare/0.5...0.45.1"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20763.org.readthedocs.build/en/20763/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,1,2025-04-28T01:48:27+00:00,2025-04-28T09:03:28+00:00,2025-04-28T09:03:24+00:00,ci;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3023493075,20762,build(deps): update requests requirement from <2.32.0 to <2.33.0 in /requirements,"Updates the requirements on [requests](https://github.com/psf/requests) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/psf/requests/releases"">requests's releases</a>.</em></p>
<blockquote>
<h2>v2.32.3</h2>
<h2>2.32.3 (2024-05-29)</h2>
<p><strong>Bugfixes</strong></p>
<ul>
<li>Fixed bug breaking the ability to specify custom SSLContexts in sub-classes of
HTTPAdapter. (<a href=""https://redirect.github.com/psf/requests/issues/6716"">#6716</a>)</li>
<li>Fixed issue where Requests started failing to run on Python versions compiled
without the <code>ssl</code> module. (<a href=""https://redirect.github.com/psf/requests/issues/6724"">#6724</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/psf/requests/blob/main/HISTORY.md"">requests's changelog</a>.</em></p>
<blockquote>
<h2>2.32.3 (2024-05-29)</h2>
<p><strong>Bugfixes</strong></p>
<ul>
<li>Fixed bug breaking the ability to specify custom SSLContexts in sub-classes of
HTTPAdapter. (<a href=""https://redirect.github.com/psf/requests/issues/6716"">#6716</a>)</li>
<li>Fixed issue where Requests started failing to run on Python versions compiled
without the <code>ssl</code> module. (<a href=""https://redirect.github.com/psf/requests/issues/6724"">#6724</a>)</li>
</ul>
<h2>2.32.2 (2024-05-21)</h2>
<p><strong>Deprecations</strong></p>
<ul>
<li>
<p>To provide a more stable migration for custom HTTPAdapters impacted
by the CVE changes in 2.32.0, we've renamed <code>_get_connection</code> to
a new public API, <code>get_connection_with_tls_context</code>. Existing custom
HTTPAdapters will need to migrate their code to use this new API.
<code>get_connection</code> is considered deprecated in all versions of Requests&gt;=2.32.0.</p>
<p>A minimal (2-line) example has been provided in the linked PR to ease
migration, but we strongly urge users to evaluate if their custom adapter
is subject to the same issue described in CVE-2024-35195. (<a href=""https://redirect.github.com/psf/requests/issues/6710"">#6710</a>)</p>
</li>
</ul>
<h2>2.32.1 (2024-05-20)</h2>
<p><strong>Bugfixes</strong></p>
<ul>
<li>Add missing test certs to the sdist distributed on PyPI.</li>
</ul>
<h2>2.32.0 (2024-05-20)</h2>
<p><strong>Security</strong></p>
<ul>
<li>Fixed an issue where setting <code>verify=False</code> on the first request from a
Session will cause subsequent requests to the <em>same origin</em> to also ignore
cert verification, regardless of the value of <code>verify</code>.
(<a href=""https://github.com/psf/requests/security/advisories/GHSA-9wx4-h78v-vm56"">https://github.com/psf/requests/security/advisories/GHSA-9wx4-h78v-vm56</a>)</li>
</ul>
<p><strong>Improvements</strong></p>
<ul>
<li><code>verify=True</code> now reuses a global SSLContext which should improve
request time variance between first and subsequent requests. It should
also minimize certificate load time on Windows systems when using a Python
version built with OpenSSL 3.x. (<a href=""https://redirect.github.com/psf/requests/issues/6667"">#6667</a>)</li>
<li>Requests now supports optional use of character detection
(<code>chardet</code> or <code>charset_normalizer</code>) when repackaged or vendored.
This enables <code>pip</code> and other projects to minimize their vendoring
surface area. The <code>Response.text()</code> and <code>apparent_encoding</code> APIs
will default to <code>utf-8</code> if neither library is present. (<a href=""https://redirect.github.com/psf/requests/issues/6702"">#6702</a>)</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/psf/requests/commit/0e322af87745eff34caffe4df68456ebc20d9068""><code>0e322af</code></a> v2.32.3</li>
<li><a href=""https://github.com/psf/requests/commit/e18879932287c2bf4bcee4ddf6ccb8a69b6fc656""><code>e188799</code></a> Don't create default SSLContext if ssl module isn't present (<a href=""https://redirect.github.com/psf/requests/issues/6724"">#6724</a>)</li>
<li><a href=""https://github.com/psf/requests/commit/145b5399486b56e00250204f033441f3fdf2f3c9""><code>145b539</code></a> Merge pull request <a href=""https://redirect.github.com/psf/requests/issues/6716"">#6716</a> from sigmavirus24/bug/6715</li>
<li><a href=""https://github.com/psf/requests/commit/b1d73ddb509a3a2d3e10744e85f9cdebdbde90f0""><code>b1d73dd</code></a> Don't use default SSLContext with custom poolmanager kwargs</li>
<li><a href=""https://github.com/psf/requests/commit/6badbac6e0d6b5a53872f26401761ad37a9002b8""><code>6badbac</code></a> Update HISTORY.md</li>
<li><a href=""https://github.com/psf/requests/commit/a62a2d35d918baa8e793f7aa4fb41527644dfca5""><code>a62a2d3</code></a> Allow for overriding of specific pool key params</li>
<li><a href=""https://github.com/psf/requests/commit/88dce9d854797c05d0ff296b70e0430535ef8aaf""><code>88dce9d</code></a> v2.32.2</li>
<li><a href=""https://github.com/psf/requests/commit/c98e4d133ef29c46a9b68cd783087218a8075e05""><code>c98e4d1</code></a> Merge pull request <a href=""https://redirect.github.com/psf/requests/issues/6710"">#6710</a> from nateprewitt/api_rename</li>
<li><a href=""https://github.com/psf/requests/commit/92075b330a30b9883f466a43d3f7566ab849f91b""><code>92075b3</code></a> Add deprecation warning</li>
<li><a href=""https://github.com/psf/requests/commit/aa1461b68aa73e2f6ec0e78c8853b635c76fd099""><code>aa1461b</code></a> Move _get_connection to get_connection_with_tls_context</li>
<li>Additional commits viewable in <a href=""https://github.com/psf/requests/compare/v0.2.0...v2.32.3"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20762.org.readthedocs.build/en/20762/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,0,2025-04-28T01:48:24+00:00,2025-04-28T07:09:03+00:00,2025-04-28T07:08:59+00:00,ci;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3023493015,20761,"build(deps): update lightning-habana requirement from <1.3.0,>=1.2.0 to >=1.2.0,<1.6.0 in /requirements","Updates the requirements on [lightning-habana](https://github.com/Lightning-AI/lightning-habana) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/Lightning-AI/lightning-habana/releases"">lightning-habana's releases</a>.</em></p>
<blockquote>
<h2>Lightning Habana 1.5.0</h2>
<h2>New Features and Enhancements</h2>
<ul>
<li>Added fp8 inference support <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/162"">Lightning-AI/lightning-Habana#162</a></li>
<li>Added experimental FSDP support <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/174"">Lightning-AI/lightning-Habana#174</a>, <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/182"">Lightning-AI/lightning-Habana#182</a></li>
<li>Added support for Intel Gaudi Profiler <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/158"">Lightning-AI/lightning-Habana#158</a>, <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/172"">Lightning-AI/lightning-Habana#172</a></li>
<li>Added fp8 training and inference support to deepspeed strategy <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/176"">Lightning-AI/lightning-Habana#176</a></li>
<li>Fixed tests failing on Gaudi2 <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/154"">Lightning-AI/lightning-Habana#154</a></li>
<li>Fixed contextmanager to be compatible with Python 3.8 <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/155"">Lightning-AI/lightning-Habana#155</a></li>
<li>Replaced HPUParallelStrategy with HPUDDPStrategy <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/160"">Lightning-AI/lightning-Habana#160</a></li>
<li>Upgraded to Intel Gaudi Release 1.15.1 <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/171"">Lightning-AI/lightning-Habana#171</a>, <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/166"">Lightning-AI/lightning-Habana#166</a></li>
<li>Updated dynamic shape tests to use metric APIs <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/163"">Lightning-AI/lightning-Habana#163</a></li>
<li>Code restructure and added more profiler tests <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/159"">Lightning-AI/lightning-Habana#159</a></li>
<li>Updated document with transformer engine support <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/165"">Lightning-AI/lightning-Habana#165</a></li>
<li>Updated infrastructure <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/156"">Lightning-AI/lightning-Habana#156</a>, <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/157"">Lightning-AI/lightning-Habana#157</a>, <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/161"">Lightning-AI/lightning-Habana#161</a>, <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/167"">Lightning-AI/lightning-Habana#167</a>, <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/169"">Lightning-AI/lightning-Habana#169</a>, <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/168"">Lightning-AI/lightning-Habana#168</a>, <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/170"">Lightning-AI/lightning-Habana#170</a>, <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/173"">Lightning-AI/lightning-Habana#173</a>, <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/177"">Lightning-AI/lightning-Habana#177</a>, <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/180"">Lightning-AI/lightning-Habana#180</a>, <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/179"">Lightning-AI/lightning-Habana#179</a>, <a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/178"">Lightning-AI/lightning-Habana#178</a></li>
</ul>
<p>For more information on Intel Habana Synapse AI release, refer to <a href=""https://docs.habana.ai/en/latest/Release_Notes/GAUDI_Release_Notes.html"">Gaudi release notes</a></p>
<h2>Contributors</h2>
<p><a href=""https://github.com/ankitgola005""><code>@​ankitgola005</code></a> <a href=""https://github.com/jyothisambolu""><code>@​jyothisambolu</code></a> <a href=""https://github.com/Borda""><code>@​Borda</code></a> <a href=""https://github.com/jerome-habana""><code>@​jerome-habana</code></a></p>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/Lightning-AI/lightning-Habana/compare/1.4.0...1.5.0"">https://github.com/Lightning-AI/lightning-Habana/compare/1.4.0...1.5.0</a></p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/Lightning-AI/lightning-Habana/blob/main/CHANGELOG.md"">lightning-habana's changelog</a>.</em></p>
<blockquote>
<h2>[1.5.0] - 2024-05-03</h2>
<h3>Added</h3>
<ul>
<li>Added support for Intel Gaudi Profiler. Deprecate <code>HABANA_PROFILE</code> environment variable from HPUProfiler. (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/158"">#158</a>)</li>
<li>Added support for FP8 inference. (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/162"">#162</a>)</li>
<li>Added support for LightningCLI. (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/173"">#173</a>)</li>
<li>Added experimental support for FSDP on HPU. (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/174"">#174</a>)</li>
<li>Added support for FP8 inference with DeepSpeed. (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/176"">#176</a>)</li>
<li>Updated the lightning version check for using FSDP. (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/182"">#182</a>)</li>
</ul>
<h3>Changed</h3>
<ul>
<li>Changed HPUParallelStrategy to HPUDDPStrategy (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/160"">#160</a>)</li>
<li>Changed HPU docker image based on Synapse AI release 1.15.0 (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/166"">#166</a>)</li>
<li>Updated to Intel Gaudi software Release 1.15.1 (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/171"">#171</a>)</li>
</ul>
<h3>Fixed</h3>
<ul>
<li>Fixed &quot;No profiler activity found&quot; error with HPUProfiler. (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/172"">#172</a>)</li>
</ul>
<h3>Removed</h3>
<ul>
<li></li>
</ul>
<h3>Deprecated</h3>
<ul>
<li></li>
</ul>
<h2>[1.4.0] - 2024-02-16</h2>
<h3>Added</h3>
<ul>
<li>Added DeepSpeed precision plugin for HPU (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/147"">#147</a>)</li>
<li>Added support for fp8 training. (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/149"">#149</a>)</li>
</ul>
<h3>Changed</h3>
<ul>
<li>Decoupled return strings of firmware, synapse version helper (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/137"">#137</a>)</li>
<li>Changed HPU docker image based on Synapse AI release 1.14.0 (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/140"">#140</a>)</li>
</ul>
<h3>Fixed</h3>
<ul>
<li>Fixed fabric imports for HPU strategies (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/126"">#126</a>)</li>
<li>Enabling tests and examples of fabric with HPU (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/139"">#139</a>)</li>
<li>Fixes an API break due to non-strict loading in Trainer (<a href=""https://redirect.github.com/Lightning-AI/lightning-Habana/pull/150"">#150</a>)</li>
</ul>
<h3>Removed</h3>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/Lightning-AI/lightning-Habana/commit/7f4e93071677c0f130ff337cfb53885684c6f7ea""><code>7f4e930</code></a> Updated lightning version requirement for FSDP (<a href=""https://redirect.github.com/Lightning-AI/lightning-habana/issues/182"">#182</a>)</li>
<li><a href=""https://github.com/Lightning-AI/lightning-Habana/commit/34b57fdf24bb70c5c307cda4b908adab7e1ef5ce""><code>34b57fd</code></a> build(deps): bump JamesIves/github-pages-deploy-action (<a href=""https://redirect.github.com/Lightning-AI/lightning-habana/issues/178"">#178</a>)</li>
<li><a href=""https://github.com/Lightning-AI/lightning-Habana/commit/9fa3d12661524d7635131559a74a5ab412448977""><code>9fa3d12</code></a> build(deps): bump pytorch-lightning from 2.2.1 to 2.2.3 (<a href=""https://redirect.github.com/Lightning-AI/lightning-habana/issues/179"">#179</a>)</li>
<li><a href=""https://github.com/Lightning-AI/lightning-Habana/commit/d625a73686f644da844b1c007e490d51740ced84""><code>d625a73</code></a> build(deps): bump mypy from 1.9.0 to 1.10.0 (<a href=""https://redirect.github.com/Lightning-AI/lightning-habana/issues/180"">#180</a>)</li>
<li><a href=""https://github.com/Lightning-AI/lightning-Habana/commit/50293a3a637ac1a73ab0ffd60b3fb4fa7bf9ecec""><code>50293a3</code></a> Prepare for LH 1.5.0 (<a href=""https://redirect.github.com/Lightning-AI/lightning-habana/issues/177"">#177</a>)</li>
<li><a href=""https://github.com/Lightning-AI/lightning-Habana/commit/5916b0cf9e40e1143766eece72baa08d997c026c""><code>5916b0c</code></a> releasing update</li>
<li><a href=""https://github.com/Lightning-AI/lightning-Habana/commit/c4bd00555e0eb2b5b6f57010640d0a2cb6974634""><code>c4bd005</code></a> Adding experimental FSDP support on HPU (<a href=""https://redirect.github.com/Lightning-AI/lightning-habana/issues/174"">#174</a>)</li>
<li><a href=""https://github.com/Lightning-AI/lightning-Habana/commit/6ebdafad6da3ae94cd4d6d04a0f2980d05f3916a""><code>6ebdafa</code></a> Add fp8 training and inference support to deepspeed (<a href=""https://redirect.github.com/Lightning-AI/lightning-habana/issues/176"">#176</a>)</li>
<li><a href=""https://github.com/Lightning-AI/lightning-Habana/commit/4d69418b3d9c82824fdab06f0a26feb66cf9df4f""><code>4d69418</code></a> Enable fp8 inference support (<a href=""https://redirect.github.com/Lightning-AI/lightning-habana/issues/162"">#162</a>)</li>
<li><a href=""https://github.com/Lightning-AI/lightning-Habana/commit/6d4d6fdd529f5a280d4184655620f53189eaf10d""><code>6d4d6fd</code></a> Add tests and docs update for LightningCLI with Lightning habana (<a href=""https://redirect.github.com/Lightning-AI/lightning-habana/issues/173"">#173</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/Lightning-AI/lightning-habana/compare/1.2.0...1.5.0"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20761.org.readthedocs.build/en/20761/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,1,2025-04-28T01:48:21+00:00,2025-04-28T07:27:57+00:00,2025-04-28T07:27:39+00:00,ci;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3023492958,20760,"build(deps): update scikit-learn requirement from <1.4.0,>0.22.1 to >0.22.1,<1.7.0 in /requirements","Updates the requirements on [scikit-learn](https://github.com/scikit-learn/scikit-learn) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/scikit-learn/scikit-learn/releases"">scikit-learn's releases</a>.</em></p>
<blockquote>
<h2>Scikit-learn 1.6.1</h2>
<p>We're happy to announce the 1.6.1 release.</p>
<p>This release contains fixes for a few regressions introduced in 1.6.</p>
<p>You can see the changelog here: <a href=""https://scikit-learn.org/stable/whats_new/v1.6.html#version-1-6-1"">https://scikit-learn.org/stable/whats_new/v1.6.html#version-1-6-1</a></p>
<p>You can upgrade with pip as usual:</p>
<pre><code>pip install -U scikit-learn
</code></pre>
<p>The conda-forge builds can be installed using:</p>
<pre><code>conda install -c conda-forge scikit-learn
</code></pre>
<p>Thanks to everyone who contributed to this release !</p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/scikit-learn/scikit-learn/commit/f159b78dc59f250cdde8fe391a21f0bc871960ad""><code>f159b78</code></a> trigger wheel builder [cd build]</li>
<li><a href=""https://github.com/scikit-learn/scikit-learn/commit/73cca70befaa3167903f1fbe15e81df587598f11""><code>73cca70</code></a> generate changelog</li>
<li><a href=""https://github.com/scikit-learn/scikit-learn/commit/afaa07062bfd77c5ec15cfc62f0102c257092563""><code>afaa070</code></a> bump version</li>
<li><a href=""https://github.com/scikit-learn/scikit-learn/commit/1f43fd2307c13593ea5ba194dcc5e7a814cfade9""><code>1f43fd2</code></a> DOC: Updates to Macro vs micro-averaging in plot_roc.py (<a href=""https://redirect.github.com/scikit-learn/scikit-learn/issues/29845"">#29845</a>)</li>
<li><a href=""https://github.com/scikit-learn/scikit-learn/commit/ea8a7259f53c2cd78c1a8341bdab228e621dd2ba""><code>ea8a725</code></a> :lock: :robot: CI Update lock files for main CI build(s) :lock: :robot: (<a href=""https://redirect.github.com/scikit-learn/scikit-learn/issues/30593"">#30593</a>)</li>
<li><a href=""https://github.com/scikit-learn/scikit-learn/commit/bc291f1030aa4f122187d5334a426ab1848a7ee6""><code>bc291f1</code></a> :lock: :robot: CI Update lock files for scipy-dev CI build(s) :lock: :robot: ...</li>
<li><a href=""https://github.com/scikit-learn/scikit-learn/commit/f5f2b9c7b725a957caf8089d254f9176e8fabda9""><code>f5f2b9c</code></a> :lock: :robot: CI Update lock files for free-threaded CI build(s) :lock: :rob...</li>
<li><a href=""https://github.com/scikit-learn/scikit-learn/commit/acbb8621c816f12f0648f175edf8acb561768ec5""><code>acbb862</code></a> TST Fix doctest due to GradientBoostingClassifier difference with scipy 1.15 ...</li>
<li><a href=""https://github.com/scikit-learn/scikit-learn/commit/42831e522f9f08f34e01cd85d60aa852914b135d""><code>42831e5</code></a> FIX warn if an estimator does have a concrete <strong>sklearn_tags</strong> implementation...</li>
<li><a href=""https://github.com/scikit-learn/scikit-learn/commit/0d2ce432de05b1f0c3b055572c08bee332c37724""><code>0d2ce43</code></a> FIX change FutureWarnings to DeprecationWarnings for the tags (<a href=""https://redirect.github.com/scikit-learn/scikit-learn/issues/30573"">#30573</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/scikit-learn/scikit-learn/compare/0.22.2...1.6.1"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20760.org.readthedocs.build/en/20760/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,1,2025-04-28T01:48:18+00:00,2025-04-28T09:07:53+00:00,2025-04-28T09:07:51+00:00,ci;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3023492852,20759,build(deps): bump mypy from 1.11.0 to 1.15.0 in /requirements,"Bumps [mypy](https://github.com/python/mypy) from 1.11.0 to 1.15.0.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/python/mypy/blob/master/CHANGELOG.md"">mypy's changelog</a>.</em></p>
<blockquote>
<h1>Mypy Release Notes</h1>
<h2>Next Release</h2>
<h3>Different Property Getter and Setter Types</h3>
<p>Mypy now supports using different types for property getter and setter.</p>
<pre lang=""python""><code>class A:
    value: int
<pre><code>@property
def f(self) -&amp;gt; int:
    return self.value
@f.setter
def f(self, x: str | int) -&amp;gt; None:
    try:
        self.value = int(x)
    except ValueError:
        raise Exception(f&amp;quot;'{x}' is not a valid value for 'f'&amp;quot;)
</code></pre>
<p></code></pre></p>
<p>Contributed by Ivan Levkivskyi (PR <a href=""https://redirect.github.com/python/mypy/pull/18510"">18510</a>)</p>
<h3>Selectively Disable Deprecated Warnings</h3>
<p>It's now possible to selectively disable warnings generated from
<a href=""https://docs.python.org/3/library/warnings.html#warnings.deprecated""><code>warnings.deprecated</code></a>
using the <a href=""https://mypy.readthedocs.io/en/stable/command_line.html#cmdoption-mypy-deprecated-calls-exclude""><code>--deprecated-calls-exclude</code></a>
option.</p>
<pre lang=""python""><code># mypy --enable-error-code deprecated
#      --deprecated-calls-exclude=foo.A
import foo
<p>foo.A().func()  # OK, the deprecated warning is ignored</p>
<h1>file foo.py</h1>
<p>from typing_extensions import deprecated<br />
class A:<br />
<a href=""https://github.com/deprecated""><code>@​deprecated</code></a>(&quot;Use A.func2 instead&quot;)<br />
def func(self): pass<br />
</code></pre></p>
<p>Contributed by Marc Mueller (PR <a href=""https://redirect.github.com/python/mypy/pull/18641"">18641</a>)</p>
<h2>Mypy 1.15</h2>
<p>We’ve just uploaded mypy 1.15 to the Python Package Index (<a href=""https://pypi.org/project/mypy/"">PyPI</a>).</p>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/python/mypy/commit/9397454fb5aead107461b089e7cf190bf538d20a""><code>9397454</code></a> remove +dev from version ahead of final release</li>
<li><a href=""https://github.com/python/mypy/commit/686b591a69db216f714ad50698db785f4ac63eb0""><code>686b591</code></a> remove &quot;unreleased&quot; from 1.15 changelog entry</li>
<li><a href=""https://github.com/python/mypy/commit/cb4b243a5d9e03173e3e7275e5b92b98afaefb60""><code>cb4b243</code></a> Various small updates to 1.15 changelog (<a href=""https://redirect.github.com/python/mypy/issues/18599"">#18599</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/1a265024f901399c701a772e8c1f9e6e110f45e6""><code>1a26502</code></a> Prepare changelog for 1.15 release (<a href=""https://redirect.github.com/python/mypy/issues/18583"">#18583</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/d4515e4ad3eee6318744c64cf2eab0ea0b5b7562""><code>d4515e4</code></a> Fix a few PR links in the changelog (<a href=""https://redirect.github.com/python/mypy/issues/18586"">#18586</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/f83b6435b0c07a327f6b567dfb5e79ffa36708a2""><code>f83b643</code></a> Add object self-type to tuple test fixture (<a href=""https://redirect.github.com/python/mypy/issues/18592"">#18592</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/ebc2cb8befbadfc10b962af018b3fa3842d3fd87""><code>ebc2cb8</code></a> Prevent crash on generic NamedTuple with unresolved typevar bound (<a href=""https://redirect.github.com/python/mypy/issues/18585"">#18585</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/63c251e249e52256629dbe8b8334937a092f792d""><code>63c251e</code></a> empty commit to trigger wheel rebuild</li>
<li><a href=""https://github.com/python/mypy/commit/c30573e7b95eef9d057ff42ebfd326438dac3c42""><code>c30573e</code></a> Fix literal context for ternary expressions (for real) (<a href=""https://redirect.github.com/python/mypy/issues/18545"">#18545</a>)</li>
<li><a href=""https://github.com/python/mypy/commit/23d862dd6fbb905a69bcb31e88746dc7a1eb4a43""><code>23d862d</code></a> Fix isinstance with explicit (non generic) type alias (<a href=""https://redirect.github.com/python/mypy/issues/18512"">#18512</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/python/mypy/compare/v1.11...v1.15.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mypy&package-manager=pip&previous-version=1.11.0&new-version=1.15.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20759.org.readthedocs.build/en/20759/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,2,2025-04-28T01:48:12+00:00,2025-04-28T12:33:52+00:00,2025-04-28T12:33:15+00:00,ci;fabric;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3023383787,20758,Can we have an LLM.txt?,"### Description & Motivation

Can we have an LLM.txt? which can instruct most LLMs how to refactor their code according to lightning with overarching examples? Especially for callbacks this would be super useful allowing us to port models faster.

### Pitch

_No response_

### Alternatives

_No response_

### Additional context

_No response_

cc @lantiga @borda",Geeks-Sid,20500704,open,False,0,2025-04-27T23:23:41+00:00,2025-04-27T23:24:00+00:00,,feature;needs triage,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3022997251,20757,enqueue.cc:1556 NCCL WARN Cuda failure 700 'an illegal memory access was encountered',"### Bug description

When I use DDP to train the model on two 5090 GPUS, this error will occur.  

enqueue.cc:1556 NCCL WARN Cuda failure 700 'an illegal memory access was encountered'

But if I just use one GPU, the training will start successfully.

### What version are you seeing the problem on?

v2.5

### How to reproduce the bug

```python
I try to use:
export NCCL_DEBUG=INFO
export PYTHONFAULTHANDLER=1
export NCCL_P2P_DISABLE=1
export CUDA_LAUNCH_BLOCKING=1
to track the error.
```

### Error messages and logs

```
user-MH53-G40-001:10225:10225 [0] NCCL INFO Bootstrap: Using enp1s0f0np0:10.70.59.78<0>
user-MH53-G40-001:10225:10225 [0] NCCL INFO cudaDriverVersion 12080
user-MH53-G40-001:10225:10225 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
user-MH53-G40-001:10225:10225 [0] NCCL INFO Comm config Blocking set to 1
user-MH53-G40-001:10225:10549 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
user-MH53-G40-001:10225:10549 [0] NCCL INFO NET/IB : No device found.
user-MH53-G40-001:10225:10549 [0] NCCL INFO NET/IB : Using [RO]; OOB enp1s0f0np0:10.70.59.78<0>
user-MH53-G40-001:10225:10549 [0] NCCL INFO NET/Socket : Using [0]enp1s0f0np0:10.70.59.78<0>
user-MH53-G40-001:10225:10549 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
user-MH53-G40-001:10225:10549 [0] NCCL INFO Using network Socket
user-MH53-G40-001:10225:10549 [0] NCCL INFO ncclCommInitRankConfig comm 0x1ca810c0 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 81000 commId 0xb5061c20698dde7e - Init START
user-MH53-G40-001:10225:10549 [0] NCCL INFO RAS client listening socket at 127.0.0.1<28028>
user-MH53-G40-001:10225:10549 [0] NCCL INFO Bootstrap timings total 0.020280 (create 0.000026, send 0.000094, recv 0.019841, ring 0.000048, delay 0.000000)
user-MH53-G40-001:10225:10549 [0] NCCL INFO NCCL_P2P_DISABLE set by environment to 1
user-MH53-G40-001:10225:10549 [0] NCCL INFO comm 0x1ca810c0 rank 0 nRanks 2 nNodes 1 localRanks 2 localRank 0 MNNVL 0
user-MH53-G40-001:10225:10549 [0] NCCL INFO Channel 00/04 : 0 1
user-MH53-G40-001:10225:10549 [0] NCCL INFO Channel 01/04 : 0 1
user-MH53-G40-001:10225:10549 [0] NCCL INFO Channel 02/04 : 0 1
user-MH53-G40-001:10225:10549 [0] NCCL INFO Channel 03/04 : 0 1
user-MH53-G40-001:10225:10549 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1 [2] 1/-1/-1->0->-1 [3] -1/-1/-1->0->1
user-MH53-G40-001:10225:10549 [0] NCCL INFO P2P Chunksize set to 131072
user-MH53-G40-001:10225:10549 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 0 directMode 0
user-MH53-G40-001:10225:10554 [0] NCCL INFO [Proxy Service] Device 0 CPU core 22
user-MH53-G40-001:10225:10556 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 34
user-MH53-G40-001:10225:10549 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
user-MH53-G40-001:10225:10549 [0] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
user-MH53-G40-001:10225:10549 [0] NCCL INFO CC Off, workFifoBytes 1048576
user-MH53-G40-001:10225:10549 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
user-MH53-G40-001:10225:10549 [0] NCCL INFO ncclCommInitRankConfig comm 0x1ca810c0 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 81000 commId 0xb5061c20698dde7e - Init COMPLETE
user-MH53-G40-001:10225:10549 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 2 total 0.55 (kernels 0.52, alloc 0.00, bootstrap 0.02, allgathers 0.00, topo 0.00, graphs 0.00, connections 0.00, rest 0.00)
user-MH53-G40-001:10225:10558 [0] NCCL INFO Channel 00 : 0[0] -> 1[1] via SHM/direct/direct
user-MH53-G40-001:10225:10558 [0] NCCL INFO Channel 01 : 0[0] -> 1[1] via SHM/direct/direct
user-MH53-G40-001:10225:10558 [0] NCCL INFO Channel 02 : 0[0] -> 1[1] via SHM/direct/direct
user-MH53-G40-001:10225:10558 [0] NCCL INFO Channel 03 : 0[0] -> 1[1] via SHM/direct/direct
user-MH53-G40-001:10225:10558 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]

[2025-04-27 20:37:53] user-MH53-G40-001:10225:10225 [0] enqueue.cc:1556 NCCL WARN Cuda failure 700 'an illegal memory access was encountered'
user-MH53-G40-001:10225:10225 [0] NCCL INFO group.cc:241 -> 1
user-MH53-G40-001:10225:10225 [0] NCCL INFO group.cc:478 -> 1
user-MH53-G40-001:10225:10225 [0] NCCL INFO group.cc:581 -> 1
user-MH53-G40-001:10225:10225 [0] NCCL INFO enqueue.cc:2299 -> 1
Fatal Python error: Aborted

Thread 0x0000742af2ffd6c0 (most recent call first):
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/threading.py"", line 324 in wait
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/queue.py"", line 180 in get
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/tensorboard/summary/writer/event_file_writer.py"", line 269 in _run
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/tensorboard/summary/writer/event_file_writer.py"", line 244 in run
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/threading.py"", line 1016 in _bootstrap_inner
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/threading.py"", line 973 in _bootstrap

Thread 0x0000742c9edde6c0 (most recent call first):
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/fabric/strategies/launchers/subprocess_script.py"", line 204 in run
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/threading.py"", line 1016 in _bootstrap_inner
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/threading.py"", line 973 in _bootstrap

Thread 0x0000742ca7fff6c0 (most recent call first):
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/threading.py"", line 324 in wait
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/threading.py"", line 607 in wait
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/tqdm/_monitor.py"", line 60 in run
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/threading.py"", line 1016 in _bootstrap_inner
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/threading.py"", line 973 in _bootstrap

Current thread 0x0000742ec57cc600 (most recent call first):
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/torch/distributed/utils.py"", line 322 in _sync_params_and_buffers
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/torch/distributed/utils.py"", line 311 in _sync_module_states
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/torch/nn/parallel/distributed.py"", line 837 in __init__
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py"", line 195 in _setup_model
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py"", line 283 in configure_ddp
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py"", line 171 in setup
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py"", line 963 in _run
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py"", line 580 in _fit_impl
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py"", line 105 in launch
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py"", line 43 in _call_and_handle_interrupt
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py"", line 544 in fit
  File ""/mnt/sda/yingshu/R2GenGPT/train.py"", line 44 in train
  File ""/mnt/sda/yingshu/R2GenGPT/train.py"", line 51 in main
  File ""/mnt/sda/yingshu/R2GenGPT/train.py"", line 55 in <module>

Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, scipy._lib._ccallback_c, scipy.signal._sigtools, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, charset_normalizer.md, scipy.linalg._solve_toeplitz, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg._matfuncs_expm, scipy.linalg._linalg_pythran, scipy.linalg.cython_blas, scipy.linalg._decomp_update, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.linalg._propack._spropack, scipy.sparse.linalg._propack._dpropack, scipy.sparse.linalg._propack._cpropack, scipy.sparse.linalg._propack._zpropack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, scipy.special._ufuncs_cxx, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, scipy._lib._uarray._uarray, scipy.signal._max_len_seq_inner, scipy.signal._upfirdn_apply, scipy.signal._spline, scipy.spatial._ckdtree, scipy._lib.messagestream, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._distance_wrap, scipy.spatial._hausdorff, scipy.spatial.transform._rotation, scipy.interpolate._fitpack, scipy.interpolate._dfitpack, scipy.optimize._group_columns, scipy.optimize._trlib._trlib, scipy.optimize._lbfgsb, _moduleTNC, scipy.optimize._moduleTNC, scipy.optimize._cobyla, scipy.optimize._slsqp, scipy.optimize._minpack, scipy.optimize._lsq.givens_elimination, scipy.optimize._zeros, scipy.optimize._cython_nnls, scipy.linalg._decomp_interpolative, scipy.optimize._bglu_dense, scipy.optimize._lsap, scipy.optimize._direct, scipy.interpolate._dierckx, scipy.interpolate._ppoly, scipy.interpolate._interpnd, scipy.interpolate._rbfinterp_pythran, scipy.interpolate._rgi_cython, scipy.interpolate._bspl, scipy.ndimage._nd_image, scipy.ndimage._rank_filter_1d, _ni_label, scipy.ndimage._ni_label, scipy.signal._sosfilt, scipy.integrate._odepack, scipy.integrate._quadpack, scipy.integrate._vode, scipy.integrate._dop, scipy.integrate._lsoda, scipy.special.cython_special, scipy.stats._stats, scipy.stats._sobol, scipy.stats._qmc_cy, scipy.stats._biasedurn, scipy.stats._stats_pythran, scipy.stats._levy_stable.levyst, scipy.stats._ansari_swilk_statistics, scipy.stats._mvn, scipy.stats._rcont.rcont, scipy.signal._peak_finding_utils, PIL._imaging, PIL._imagingft, regex._regex, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, simsimd, stringzilla, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, psutil._psutil_linux, psutil._psutil_posix, google._upb._message (total: 164)
Fatal Python error: Aborted

Thread 0x0000766a215fe6c0 (most recent call first):
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/threading.py"", line 324 in wait
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/threading.py"", line 607 in wait
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/tqdm/_monitor.py"", line 60 in run
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/threading.py"", line 1016 in _bootstrap_inner
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/threading.py"", line 973 in _bootstrap

Current thread 0x0000766c3a667740 (most recent call first):
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/torch/distributed/utils.py"", line 322 in _sync_params_and_buffers
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/torch/distributed/utils.py"", line 311 in _sync_module_states
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/torch/nn/parallel/distributed.py"", line 837 in __init__
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py"", line 195 in _setup_model
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py"", line 283 in configure_ddp
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py"", line 171 in setup
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py"", line 963 in _run
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py"", line 580 in _fit_impl
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py"", line 105 in launch
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py"", line 43 in _call_and_handle_interrupt
  File ""/home/yingshu/.conda/envs/r2gen/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py"", line 544 in fit
  File ""/mnt/sda/yingshu/R2GenGPT/train.py"", line 44 in train
  File ""/mnt/sda/yingshu/R2GenGPT/train.py"", line 51 in main
  File ""/mnt/sda/yingshu/R2GenGPT/train.py"", line 55 in <module>

Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, scipy._lib._ccallback_c, scipy.signal._sigtools, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, charset_normalizer.md, scipy.linalg._solve_toeplitz, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg._matfuncs_expm, scipy.linalg._linalg_pythran, scipy.linalg.cython_blas, scipy.linalg._decomp_update, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.linalg._propack._spropack, scipy.sparse.linalg._propack._dpropack, scipy.sparse.linalg._propack._cpropack, scipy.sparse.linalg._propack._zpropack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, scipy.special._ufuncs_cxx, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, scipy._lib._uarray._uarray, scipy.signal._max_len_seq_inner, scipy.signal._upfirdn_apply, scipy.signal._spline, scipy.spatial._ckdtree, scipy._lib.messagestream, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._distance_wrap, scipy.spatial._hausdorff, scipy.spatial.transform._rotation, scipy.interpolate._fitpack, scipy.interpolate._dfitpack, scipy.optimize._group_columns, scipy.optimize._trlib._trlib, scipy.optimize._lbfgsb, _moduleTNC, scipy.optimize._moduleTNC, scipy.optimize._cobyla, scipy.optimize._slsqp, scipy.optimize._minpack, scipy.optimize._lsq.givens_elimination, scipy.optimize._zeros, scipy.optimize._cython_nnls, scipy.linalg._decomp_interpolative, scipy.optimize._bglu_dense, scipy.optimize._lsap, scipy.optimize._direct, scipy.interpolate._dierckx, scipy.interpolate._ppoly, scipy.interpolate._interpnd, scipy.interpolate._rbfinterp_pythran, scipy.interpolate._rgi_cython, scipy.interpolate._bspl, scipy.ndimage._nd_image, scipy.ndimage._rank_filter_1d, _ni_label, scipy.ndimage._ni_label, scipy.signal._sosfilt, scipy.integrate._odepack, scipy.integrate._quadpack, scipy.integrate._vode, scipy.integrate._dop, scipy.integrate._lsoda, scipy.special.cython_special, scipy.stats._stats, scipy.stats._sobol, scipy.stats._qmc_cy, scipy.stats._biasedurn, scipy.stats._stats_pythran, scipy.stats._levy_stable.levyst, scipy.stats._ansari_swilk_statistics, scipy.stats._mvn, scipy.stats._rcont.rcont, scipy.signal._peak_finding_utils, PIL._imaging, PIL._imagingft, regex._regex, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, simsimd, stringzilla, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, psutil._psutil_linux, psutil._psutil_posix (total: 163)
```


### Environment

<details>
  <summary>Current environment</summary>

```
#- PyTorch Lightning Version (e.g., 2.5.0): 2.5.1.post0
#- PyTorch Version (e.g., 2.5): 2.7.0+cu128
#- Python version (e.g., 3.12): 3.10
#- OS (e.g., Linux): ubuntu
#- CUDA/cuDNN version: 12.8
#- GPU models and configuration:
#- How you installed Lightning(`conda`, `pip`, source):
```

</details>


### More info

_No response_",Yingshu-Li,62641802,open,False,3,2025-04-27T10:43:54+00:00,2025-05-04T18:07:41+00:00,,bug;needs triage;ver: 2.5.x,3,2,0,0,0,0,0
Lightning-AI/pytorch-lightning,3020968905,20756,Adding test for legacy checkpoint created with 2.5.1.post0,"**This is automated addition of created checkpoints with the latest `lightning` release!**

cc @lantiga @borda",pl-ghost,75324987,closed,False,3,2025-04-25T20:25:52+00:00,2025-04-28T12:13:51+00:00,2025-04-28T12:13:27+00:00,checkpointing;tests;pl,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3020685149,20755,update last release with `.post` [rebase & merge],"## What does this PR do?

minor patch

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [x] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [x] Check that all items from **Before submitting** are resolved
- [x] Make sure the title is self-explanatory and the description concisely explains the PR
- [x] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20755.org.readthedocs.build/en/20755/

<!-- readthedocs-preview pytorch-lightning end -->",Borda,6035284,closed,False,2,2025-04-25T17:58:18+00:00,2025-04-25T18:58:31+00:00,2025-04-25T18:58:22+00:00,docs;ci;release;fabric;pl;package,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3020546626,20754,bump: testing latest PT on GPU to `2.7`,"## What does this PR do?

post-release compatibility update

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [x] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [x] Check that all items from **Before submitting** are resolved
- [x] Make sure the title is self-explanatory and the description concisely explains the PR
- [x] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20754.org.readthedocs.build/en/20754/

<!-- readthedocs-preview pytorch-lightning end -->",Borda,6035284,closed,False,1,2025-04-25T16:44:03+00:00,2025-04-25T18:29:35+00:00,2025-04-25T18:29:33+00:00,ci;dockers,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3017418343,20753,update model message,"## What does this PR do?

suggested by @nohalon 

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [ ] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [x] Check that all items from **Before submitting** are resolved
- [x] Make sure the title is self-explanatory and the description concisely explains the PR
- [x] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20753.org.readthedocs.build/en/20753/

<!-- readthedocs-preview pytorch-lightning end -->

cc @borda @lantiga @justusschock",Borda,6035284,closed,False,2,2025-04-24T14:05:49+00:00,2025-04-25T17:49:55+00:00,2025-04-25T17:49:45+00:00,ready;docs;ci;fabric;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3016673451,20752,release preparation,"## What does this PR do?

requested

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [ ] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [x] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [x] Check that all items from **Before submitting** are resolved
- [x] Make sure the title is self-explanatory and the description concisely explains the PR
- [x] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20752.org.readthedocs.build/en/20752/

<!-- readthedocs-preview pytorch-lightning end -->",Borda,6035284,closed,False,1,2025-04-24T09:48:21+00:00,2025-04-24T10:04:14+00:00,2025-04-24T10:04:12+00:00,ci,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3015533073,20749,fabric FSDP strategy save/load checkpoint does not support s3 url,"### Bug description

Other ParallelStrategy implementations support saving and loading checkpoints from an S3 URL using fsspec. Fabric’s FSDP strategy also uses torch.load and torch.save, which support S3 URLs as well. However, the FSDP wrapper in Fabric [converts the input path](https://github.com/Lightning-AI/pytorch-lightning/blob/0c9d4147e3569e24bf6130e78ae21b136562766e/src/lightning/fabric/strategies/fsdp.py#L440) to a pathlib.Path object. This conversion changes a valid URL like s3://bucket/xxx into an invalid format like s3:/bucket/xxx, effectively breaking the path.

To resolve this issue, path manipulation should be handled using os.path instead—[as done in TorchCheckpointIO](https://github.com/Lightning-AI/pytorch-lightning/blob/0c9d4147e3569e24bf6130e78ae21b136562766e/src/lightning/fabric/plugins/io/torch_io.py#L57).

### What version are you seeing the problem on?

v2.5

### How to reproduce the bug

```python
- Use FSDP as the strategy for fabric.
- Save a checkpoint with `fabric.save(""s3://xxx"")`
```

### Error messages and logs

```
# Error messages and logs here please
```


### Environment

_No response_

### More info

_No response_",likesum,20542235,open,False,0,2025-04-24T00:18:20+00:00,2025-04-24T00:18:34+00:00,,bug;needs triage;ver: 2.5.x,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3011179981,20747,"BUG: Without internet, neptune gets stuck in multi-gpu pytorch lightning and crashes the run","### Bug description

### Describe the bug

If the neptune client loses connection to the neptune server for any reason, it waits forever on GPU0 to get the connection back. This crashes the training run at the end of the training epoch.

### Reproduction

Train anything with PyTorch Lightning in a multi-gpu settings.

Use neptune as a logger.

Have an internet connection that stalls forever (e.g. blocked ports).

At the end of the training epoch wait another 30 min until you get a NCCL TIMEOUT where the GPUs 1-7 get tired of waiting for GPU 0 and crash.

### Expected behavior

The client should somehow gracefully store data locally instead of tearing everything down.

### Traceback

If applicable, add traceback or log output/screenshots to help explain your problem.

### Environment

**The output of `pip list`:**

```
Package                   Version        Editable project location
------------------------- -------------- -------------------------------
accelerate                1.4.0
aiohappyeyeballs          2.5.0
aiohttp                   3.11.13
aiosignal                 1.3.2
annotated-types           0.7.0
antlr4-python3-runtime    4.9.3
anyio                     4.8.0
argon2-cffi               23.1.0
argon2-cffi-bindings      21.2.0
arrow                     1.3.0
astroid                   3.3.9
asttokens                 3.0.0
async-lru                 2.0.4
attrs                     25.1.0
babel                     2.17.0
beautifulsoup4            4.13.3
bitsandbytes              0.45.3
black                     25.1.0
bleach                    6.2.0
blinker                   1.9.0
blis                      1.2.0
boto3                     1.37.9
botocore                  1.37.9
braceexpand               0.1.7
bravado                   11.1.0
bravado-core              6.1.1
cachetools                5.5.2
cairocffi                 1.7.1
CairoSVG                  2.7.1
catalogue                 2.0.10
certifi                   2025.1.31
cffi                      1.17.1
cfgv                      3.4.0
chardet                   5.2.0
charset-normalizer        3.4.1
click                     8.1.8
cloudpathlib              0.21.0
comm                      0.2.2
confection                0.1.5
contourpy                 1.3.1
coverage                  7.6.12
cssselect2                0.8.0
cycler                    0.12.1
cymem                     2.0.11
dash                      2.18.2
dash-bootstrap-components 1.7.1
dash-core-components      2.0.0
dash-html-components      2.0.0
dash-table                5.0.0
datasets                  3.3.2
debugpy                   1.8.14
decorator                 5.2.1
defusedxml                0.7.1
Deprecated                1.2.18
dill                      0.3.8
distlib                   0.3.9
executing                 2.2.0
fastjsonschema            2.21.1
fasttext-numpy2           0.10.4
filelock                  3.17.0
Flask                     3.0.3
flask-sock                0.7.0
fonttools                 4.56.0
fqdn                      1.5.1
frozenlist                1.5.0
fsspec                    2024.12.0
ftfy                      6.3.1
future                    1.0.0
gitdb                     4.0.12
GitPython                 3.1.44
google-api-core           2.24.1
google-api-python-client  2.163.0
google-auth               2.38.0
google-auth-httplib2      0.2.0
googleapis-common-protos  1.69.1
greenlet                  3.1.1
h11                       0.14.0
h5py                      3.13.0
httpcore                  1.0.7
httplib2                  0.22.0
httpx                     0.28.1
huggingface-hub           0.29.2
identify                  2.6.9
idna                      3.10
importlib_metadata        8.6.1
importlib_resources       6.5.2
iniconfig                 2.0.0
ipdb                      0.13.13
ipykernel                 6.29.5
ipython                   9.0.2
ipython_pygments_lexers   1.1.1
ipywidgets                8.1.5
isoduration               20.11.0
isort                     6.0.1
itables                   2.2.5
itsdangerous              2.2.0
jedi                      0.19.2
Jinja2                    3.1.6
jmespath                  1.0.1
joblib                    1.4.2
json5                     0.10.0
jsonpointer               3.0.0
jsonref                   1.1.0
jsonschema                4.23.0
jsonschema-specifications 2024.10.1
jupyter                   1.1.1
jupyter_client            8.6.3
jupyter-console           6.6.3
jupyter_core              5.7.2
jupyter-events            0.12.0
jupyter-lsp               2.2.5
jupyter_server            2.15.0
jupyter_server_terminals  0.5.3
jupyterlab                4.3.5
jupyterlab_pygments       0.3.0
jupyterlab_server         2.27.3
jupyterlab_widgets        3.0.13
kiwisolver                1.4.8
langcodes                 3.5.0
language_data             1.3.0
lightning                 2.5.0.post0
lightning-utilities       0.14.0
lmdb                      1.6.2
loguru                    0.7.3
lxml                      5.3.1
marisa-trie               1.2.1
markdown-it-py            3.0.0
MarkupSafe                3.0.2
matplotlib                3.10.1
matplotlib-inline         0.1.7
maturin                   1.8.2
mccabe                    0.7.0
mdurl                     0.1.2
memory-tempfile           2.2.3
mistune                   3.1.2
monotonic                 1.6
mpmath                    1.3.0
msgpack                   1.1.0
multidict                 6.1.0
multiprocess              0.70.16
murmurhash                1.0.12
mypy-extensions           1.0.0
narwhals                  1.29.1
natsort                   8.4.0
nbclient                  0.10.2
nbconvert                 7.16.6
nbformat                  5.10.4
neptune                   1.13.0
nest-asyncio              1.6.0
networkx                  3.4.2
nibabel                   5.3.2
nilearn                   0.11.1
nltk                      3.9.1
nodeenv                   1.9.1
notebook                  7.3.2
notebook_shim             0.2.4
numpy                     2.2.3
nvidia-cublas-cu12        12.4.5.8
nvidia-cuda-cupti-cu12    12.4.127
nvidia-cuda-nvrtc-cu12    12.4.127
nvidia-cuda-runtime-cu12  12.4.127
nvidia-cudnn-cu12         9.1.0.70
nvidia-cufft-cu12         11.2.1.3
nvidia-curand-cu12        10.3.5.147
nvidia-cusolver-cu12      11.6.1.9
nvidia-cusparse-cu12      12.3.1.170
nvidia-cusparselt-cu12    0.6.2
nvidia-ml-py              12.570.86
nvidia-ml-py3             7.352.0
nvidia-nccl-cu12          2.21.5
nvidia-nvjitlink-cu12     12.4.127
nvidia-nvtx-cu12          12.4.127
oauthlib                  3.2.2
omegaconf                 2.3.0
overrides                 7.7.0
packaging                 24.2
pandas                    2.2.3
pandocfilters             1.5.1
parso                     0.8.4
pathspec                  0.12.1
peft                      0.14.0
pexpect                   4.9.0
pillow                    11.1.0
pillow-avif-plugin        1.5.0
pip                       25.0.1
platformdirs              4.3.6
plotly                    6.0.0
pluggy                    1.5.0
pre_commit                4.1.0
preshed                   3.0.9
prometheus_client         0.21.1
prompt_toolkit            3.0.50
propcache                 0.3.0
proto-plus                1.26.0
protobuf                  5.29.3
psutil                    7.0.0
psycopg2-binary           2.9.10
ptyprocess                0.7.0
pure_eval                 0.2.3
pyarrow                   19.0.1
pyasn1                    0.6.1
pyasn1_modules            0.4.1
pybind11                  2.13.6
pycocoevalcap             1.2
pycocotools               2.0.8
pycparser                 2.22
pydantic                  2.10.6
pydantic_core             2.27.2
pydub                     0.25.1
Pygments                  2.19.1
pyinstrument              5.0.1
PyJWT                     2.10.1
pylint                    3.3.5
pyparsing                 3.2.1
pytest                    8.3.5
pytest-cov                6.0.0
python-dateutil           2.9.0.post0
python-dotenv             1.0.1
python-json-logger        3.3.0
pytorch-lightning         2.5.0.post0
PyTurboJPEG               1.7.7
pytz                      2025.1
PyYAML                    6.0.2
pyzmq                     26.2.1
referencing               0.36.2
regex                     2024.11.6
requests                  2.32.3
requests-oauthlib         2.0.0
retrying                  1.3.4
rfc3339-validator         0.1.4
rfc3986-validator         0.1.1
rich                      13.9.4
rpds-py                   0.23.1
rsa                       4.9
s3transfer                0.11.4
safetensors               0.5.3
scikit-learn              1.6.1
scipy                     1.15.2
seaborn                   0.13.2
Send2Trash                1.8.3
sentencepiece             0.2.0
setuptools                75.8.2
shellingham               1.5.4
simple-websocket          1.1.0
simplejson                3.20.1
six                       1.17.0
smart-open                7.1.0
smmap                     5.0.2
sniffio                   1.3.1
soupsieve                 2.6
spacy                     3.8.4
spacy-legacy              3.0.12
spacy-loggers             1.0.5
SQLAlchemy                2.0.38
srsly                     2.5.1
stack-data                0.6.3
swagger-spec-validator    3.0.4
sympy                     1.13.1
tabulate                  0.9.0
termcolor                 2.5.0
terminado                 0.18.1
thinc                     8.3.4
threadpoolctl             3.5.0
timm                      1.0.15
tinycss2                  1.4.0
tokenize_rt               6.1.0
tokenizers                0.21.0
tomlkit                   0.13.2
torch                     2.6.0
torchaudio                2.6.0
torchmetrics              1.6.2
torchvision               0.21.0
tornado                   6.4.2
tqdm                      4.67.1
traitlets                 5.14.3
transformers              4.49.0
treelib                   1.7.1
triton                    3.2.0
typer                     0.15.2
types-python-dateutil     2.9.0.20241206
typing_extensions         4.12.2
tzdata                    2025.1
uri-template              1.3.0
uritemplate               4.1.1
urllib3                   2.3.0
virtualenv                20.29.3
wasabi                    1.1.3
wcwidth                   0.2.13
weasel                    0.4.1
webcolors                 24.11.1
webdataset                0.2.111
webencodings              0.5.1
websocket-client          1.8.0
Werkzeug                  3.0.6
wheel                     0.45.1
widgetsnbextension        4.0.13
wrapt                     1.17.2
wsproto                   1.2.0
xxhash                    3.5.0
yarl                      1.18.3
zipp                      3.21.0
zstandard                 0.23.0
```

**The operating system you're using:**

Ubuntu 22.04

**The output of `python --version`:**

Python 3.12.9

### Additional context

Training on a SLURM cluster.


### What version are you seeing the problem on?

v2.5

### How to reproduce the bug

```python

```

### Error messages and logs

_No response_

### Environment

_No response_

### More info

neptune-client team asked me to move this issue to pytorch-lightning

https://github.com/neptune-ai/neptune-client/issues/1918",simon-ging,47286792,open,False,0,2025-04-22T13:56:26+00:00,2025-04-22T13:56:41+00:00,,bug;needs triage;ver: 2.5.x,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3010640199,20746,ci: try to supress false failing check for create legacy checkpoint,"## What does this PR do?

remove false failing check for `dryrun` when uploading legacy checkpoint helps navigate what PRs are ready to land which need some more care

```yaml
jobs:
  example-job:
    runs-on: ubuntu-latest
    steps:
      - name: Check if secret is available
        if: secrets.MY_SECRET != ''
        run: echo ""Secret is available, performing secure steps""

      - name: Skip secure steps
        if: secrets.MY_SECRET == ''
        run: echo ""Secret is not available, skipping secure steps""
```

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [x] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [x] Check that all items from **Before submitting** are resolved
- [x] Make sure the title is self-explanatory and the description concisely explains the PR
- [x] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20746.org.readthedocs.build/en/20746/

<!-- readthedocs-preview pytorch-lightning end -->",Borda,6035284,closed,False,1,2025-04-22T10:22:58+00:00,2025-04-22T13:09:38+00:00,2025-04-22T13:09:36+00:00,ci,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3010561007,20745,ci: try to suppress false failing check for create legacy checkpoint,"## What does this PR do?

remove false failing check for `dryrun` when uploading legacy checkpoint helps navigate what PRs are ready to land which need some more care

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [ ] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [x] Check that all items from **Before submitting** are resolved
- [x] Make sure the title is self-explanatory and the description concisely explains the PR
- [x] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20745.org.readthedocs.build/en/20745/

<!-- readthedocs-preview pytorch-lightning end -->",Borda,6035284,closed,False,1,2025-04-22T09:51:09+00:00,2025-04-22T09:57:42+00:00,2025-04-22T09:57:40+00:00,ci,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3008318390,20744,RTX5090d:ImportError: cannot import name 'EPOCH_OUTPUT' from 'pytorch_lightning.utilities.types',"### Description & Motivation

RTX5090d can only install the nightly versions of CUDA12.8 and torch2.8. Is there a corresponding PyTorch_lightning  version for CUDA12.8 and torch2.8 that can be installed？

### Pitch

![Image](https://github.com/user-attachments/assets/2638cb84-488e-4849-ab3c-3aa8da927227)

### Alternatives

_No response_

### Additional context

Versions

PyTorch version: 2.8.0.dev20250416+cu128
Is debug build: False
CUDA used to build PyTorch: 12.8
ROCM used to build PyTorch: N/A

OS: Ubuntu 22.04.5 LTS (x86_64)
GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.35

Python version: 3.9.21 (main, Dec 11 2024, 16:24:11) [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-6.8.0-57-generic-x86_64-with-glibc2.35
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 5090 D
Nvidia driver version: 570.133.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
架构： x86_64
CPU 运行模式： 32-bit, 64-bit
Address sizes: 39 bits physical, 48 bits virtual
字节序： Little Endian
CPU: 32
在线 CPU 列表： 0-31
厂商 ID： GenuineIntel
型号名称： Intel(R) Core(TM) i9-14900KF
CPU 系列： 6
型号： 183
每个核的线程数： 2
每个座的核数： 24
座： 1
步进： 1
CPU 最大 MHz： 6000.0000
CPU 最小 MHz： 800.0000
BogoMIPS： 6374.40
标记： fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tart arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb intel_pt sha_ni xsaveopt xsavec xgetbv1 xsaves split_lock_detect user_shstk avx_vnni dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp hwp_pkg_req hfi vnmi umip pku ospke waitpkg gfni vaes vpclmulqdq rdpid movdiri movdir64b fsrm md_clear serialize arch_lbr ibt flush_l1d arch_capabilities
虚拟化： VT-x
L1d 缓存： 896 KiB (24 instances)
L1i 缓存： 1.3 MiB (24 instances)
L2 缓存： 32 MiB (12 instances)
L3 缓存： 36 MiB (1 instance)
NUMA 节点： 1
NUMA 节点0 CPU： 0-31
Vulnerability Gather data sampling: Not affected
Vulnerability Itlb multihit: Not affected
Vulnerability L1tf: Not affected
Vulnerability Mds: Not affected
Vulnerability Meltdown: Not affected
Vulnerability Mmio stale data: Not affected
Vulnerability Reg file data sampling: Mitigation; Clear Register File
Vulnerability Retbleed: Not affected
Vulnerability Spec rstack overflow: Not affected
Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl
Vulnerability Spectre v1: Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2: Mitigation; Enhanced / Automatic IBRS; IBPB conditional; RSB filling; PBRSB-eIBRS SW sequence; BHI BHI_DIS_S
Vulnerability Srbds: Not affected
Vulnerability Tsx async abort: Not affected

Versions of relevant libraries:
[pip3] numpy==1.26.4
[pip3] nvidia-cublas-cu12==12.8.3.14
[pip3] nvidia-cuda-cupti-cu12==12.8.57
[pip3] nvidia-cuda-nvrtc-cu12==12.8.61
[pip3] nvidia-cuda-runtime-cu12==12.8.57
[pip3] nvidia-cudnn-cu12==9.8.0.87
[pip3] nvidia-cufft-cu12==11.3.3.41
[pip3] nvidia-curand-cu12==10.3.9.55
[pip3] nvidia-cusolver-cu12==11.7.2.55
[pip3] nvidia-cusparse-cu12==12.5.7.53
[pip3] nvidia-cusparselt-cu12==0.6.3
[pip3] nvidia-nccl-cu12==2.26.2
[pip3] nvidia-nvjitlink-cu12==12.8.61
[pip3] nvidia-nvtx-cu12==12.8.55
[pip3] pytorch-lightning==2.5.1
[pip3] pytorch-msssim==1.0.0
[pip3] pytorch-triton==3.3.0+git96316ce5
[pip3] torch==2.8.0.dev20250416+cu128
[pip3] torch-geometric==2.6.1
[pip3] torchaudio==2.6.0.dev20250416+cu128
[pip3] torchmetrics==1.7.1
[pip3] torchvision==0.22.0.dev20250416+cu128
[conda] numpy 1.26.4 pypi_0 pypi
[conda] nvidia-cublas-cu12 12.8.3.14 pypi_0 pypi
[conda] nvidia-cuda-cupti-cu12 12.8.57 pypi_0 pypi
[conda] nvidia-cuda-nvrtc-cu12 12.8.61 pypi_0 pypi
[conda] nvidia-cuda-runtime-cu12 12.8.57 pypi_0 pypi
[conda] nvidia-cudnn-cu12 9.8.0.87 pypi_0 pypi
[conda] nvidia-cufft-cu12 11.3.3.41 pypi_0 pypi
[conda] nvidia-curand-cu12 10.3.9.55 pypi_0 pypi
[conda] nvidia-cusolver-cu12 11.7.2.55 pypi_0 pypi
[conda] nvidia-cusparse-cu12 12.5.7.53 pypi_0 pypi
[conda] nvidia-cusparselt-cu12 0.6.3 pypi_0 pypi
[conda] nvidia-nccl-cu12 2.26.2 pypi_0 pypi
[conda] nvidia-nvjitlink-cu12 12.8.61 pypi_0 pypi
[conda] nvidia-nvtx-cu12 12.8.55 pypi_0 pypi
[conda] pytorch-lightning 2.5.1 pypi_0 pypi
[conda] pytorch-msssim 1.0.0 pypi_0 pypi
[conda] pytorch-triton 3.3.0+git96316ce5 pypi_0 pypi
[conda] torch 2.8.0.dev20250416+cu128 pypi_0 pypi
[conda] torch-geometric 2.6.1 pypi_0 pypi
[conda] torchaudio 2.6.0.dev20250416+cu128 pypi_0 pypi
[conda] torchmetrics 1.7.1 pypi_0 pypi
[conda] torchvision 0.22.0.dev20250416+cu128 pypi_0 pypi



cc @lantiga @borda",paomian001,153172845,open,False,6,2025-04-21T12:29:22+00:00,2025-05-02T06:58:09+00:00,,feature;needs triage,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3007849326,20743,Allow customized parameter grouping for automatic optimzier configuration,"### Description & Motivation

I personally rewrite the CLI's `_add_configure_optimizers_to_model`: replace `self.model.parameters()` with an additional method `_get_model_parameters`. The default behavior of this method is just returning `self.model.parameters()`. But after this change, I can directly inherit a new subclass from LightningCLI, change what happens in `_get_model_parameters`, to allow optimizers get parameter names and values together.

In this case, I can write a new optimizer to allow applying weight decay to different groups of parameters, while not manually write `configure_optimizers` method in my LightningModule, nor worrying about CLI config files or anything else.

What I'm current doing is:

1. Write a new optimizer interface:
```[python]
class AutoDetachBiasDecay(Optimizer):

    def __new__(
        cls,
        /,
        named_params: Iterator[tuple[str, Parameter]],
        optimizer_class: type[Optimizer],
        lr: float = 1.0e-3,
        weight_decay: float = 1.0e-2,
        **kwargs,
    ):
        decay, no_decay = [], []
        for name, param in named_params:
            if not param.requires_grad:
                continue
            if ""bias"" in name or ""Norm"" in name:
                no_decay.append(param)
            else:
                decay.append(param)

        grouped_params = [
            {""params"": decay, ""weight_decay"": weight_decay, ""lr"": lr},
            {""params"": no_decay, ""weight_decay"": 0.0, ""lr"": 5 * lr},
        ]

        return optimizer_class(grouped_params, **kwargs)
```

2. Changed the cli.py file
Before:
```[python]
        optimizer = instantiate_class(self.model.parameters(), optimizer_init)
        lr_scheduler = instantiate_class(optimizer, lr_scheduler_init) if lr_scheduler_init else None
        fn = partial(self.configure_optimizers, optimizer=optimizer, lr_scheduler=lr_scheduler)
        update_wrapper(fn, self.configure_optimizers)  # necessary for `is_overridden`
        # override the existing method
        self.model.configure_optimizers = MethodType(fn, self.model)
```
After:
```[python]
        optimizer = instantiate_class(self._get_parameters(), optimizer_init)
        lr_scheduler = instantiate_class(optimizer, lr_scheduler_init) if lr_scheduler_init else None
        fn = partial(self.configure_optimizers, optimizer=optimizer, lr_scheduler=lr_scheduler)
        update_wrapper(fn, self.configure_optimizers)  # necessary for `is_overridden`
        # override the existing method
        self.model.configure_optimizers = MethodType(fn, self.model)

    def _get_parameters(self) -> dict[str, Any]:
        return self.model.parameters()
```

3. Write a new subclass of CLI
```[python]
class NamedParamsCLI(LightningCLI):
    model: torch.nn.Module

    def _get_parameters(self):
        return self.model.named_parameters()
```

4. Replace the optimizer config yaml file from
```[yaml]
class_path: AdamW
init_args: something
```
to
```[yaml]
class_path: path.to.AutoDetachBiasDecay
init_args:
  optimizer_class: torch.optim.AdamW
  lr: 1.e-4
  weight_decay: 1.e-2
```

I'm not quite sure if this proposal does not conflict with what `configure_optimizers` should do. But in my point of view, this change make it quite easy for me to add different parameters to separate groups, and applying different optimization parameters to them, WITHOUT the need of writing a bunch of codes in the `configure_optimizers`, nor writing additional parameters to pass into my `LightningModule` class.

But also I admit there are several problems. One would be that, different optimizers may want different initialization arguments, and `jsonargparse` will check argument name. Therefore, in my simple case, users cannot define other arguments. And currently, I'm not working with other arguments, so I did not put much time finding out solutions for this problem. And I would be happy to hear anyone giving feedback or suggestions on this feature.

### Pitch

After this change to the `cli.py` file, users can write a very simple `.py` file to create their own optimizer interface, adding different parameters into groups, and applying different optimization parameters to different groups. E.g., in my case, different `weight_decay` and `learning_rate`
The only thing user should do is to start training from the `NamedParamsCLI` instead of `LightningCLI` (no change would be better), and copying the `optimizer_interface.py` code to their machine, change the `optimizer` -> `class_path` to the new file, and specify which optimizer they would like to use in the config file.

### Alternatives

_No response_

### Additional context

_No response_

cc @lantiga @borda",SeanZhang99,53940993,open,False,1,2025-04-21T08:02:27+00:00,2025-04-27T06:39:12+00:00,,feature;needs triage,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3007812089,20742,[Not finished] Allow customized parameter grouping for automatic optimzier configuration.,"Make a minor change during automatic optimizer configuration
 - replace self.model.parameters() with an additional method
 - The behavior is stay unchanged, but this change may allow users customizing their own CLI, with different parameters given to to optimizer.

E.g.
If one want to add weight decay to `weight` groups only (L2 regularization), he/she can usually use named_parameters to iterate over the model parameter to determine if one parameter should be put into the `weight`ed group, or remain unregulated. However, this seems impossible when using CLI for automatic configuration. Although one can still write the `configure_optimizers` him/herself, but I think making this minor change would give users a faster path to do such things without creating a bunch of codes.

## What does this PR do?

As shown in the commit message, this PR changes the src/lightning/pytorch/cli.py, adding a new separate private object method, `LightningCLI._get_model_parameters()`. The return of this method is exactly `self.model.parameters()`. And during the automatic optimizer configuration, instead of getting model parameters directly, CLI object will use this method to obtain the model parameters.

The default behavior is just as the original: get model parameters directly.

However, if one would like to create an optimizer receiving named_parameters (e.g. giving learning rate or L2 factor to different parameter groups), it could customize its own CLI class, just overriding this method, and write his own optimizer. At the same time, it does not need to write a bunch of codes in `configure_optimizers` of the LightningModule, nor caring about parameter passing in.

And for users who do not rely on this functionality, the default behavior remains unchanged. 




- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [ ] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [ ] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [ ] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [ ] Is this pull request ready for review? (if not, please submit in draft mode)
- [ ] Check that all items from **Before submitting** are resolved
- [ ] Make sure the title is self-explanatory and the description concisely explains the PR
- [ ] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20742.org.readthedocs.build/en/20742/

<!-- readthedocs-preview pytorch-lightning end -->",SeanZhang99,53940993,open,False,0,2025-04-21T07:39:57+00:00,2025-04-21T07:40:09+00:00,,pl,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3007404447,20741,trainer.predict() raise error when using custom batch sampler,"### Bug description

As title mentioned, there are error when using custom batch sampler in trainer.predict(), but trainer.fit() and trainer.test() works fine.

### What version are you seeing the problem on?

v2.5

### How to reproduce the bug

here is my custom batch sampler
```python
class MILSampler(torch.utils.data.BatchSampler):
    ''' this is a batch sampler '''
    weights: torch.Tensor

    def __init__(
        self,
        sampler,
        batch_size: int,
        drop_last: bool,
        data_source: Dataset,
        shuffle: bool = False,
        weights: Sequence[float] | None = None,
    ):
        super().__init__(None, 2, False)
        self.bag_images = data_source.bag_images
        self.batch_size = batch_size
        self.shuffle = shuffle

        # for exp: limit bag size
        # self.data_source = data_source
        self.limit_bag_size = 20

        self.length = 0
        for bag in self.bag_images.values():
            d, i = divmod(min(len(bag), self.limit_bag_size), self.batch_size)
            self.length += d + (i > 0)

        if weights is not None:
            weights = torch.as_tensor(weights, dtype=torch.double)
            if len(weights.shape) != 1:
                raise ValueError(
                    ""weights should be a 1d sequence but given ""
                    f""weights have shape {tuple(weights.shape)}""
                )
            if len(weights) != len(self.bag_images):
                raise ValueError(
                    ""weights should have the same length as bag_images ""
                    f""but given weights have length {len(weights)} ""
                    f""and bag_images have length {len(self.bag_images)}""
                )
        self.weights = weights

    @property
    def num_samples(self) -> int:
        return sum(len(bag) for bag in self.bag_images.values())

    def __len__(self) -> int:
        return self.length

    def __iter__(self) -> Iterator[list[int]]:

        if self.weights is not None:
            bag_indexes = torch.multinomial(
                self.weights, self.num_samples, replacement=True
            )
        else:
            bag_indexes = (
                torch.randperm(len(self.bag_images))
                if self.shuffle
                else torch.arange(len(self.bag_images))
            )

        for bag_index in bag_indexes.tolist():
            bag = self.bag_images[bag_index]
            if len(bag) > self.limit_bag_size:
                bag = random.sample(bag, self.limit_bag_size)
            
            data  = [None for _ in range(len(bag))]
            for i in range(len(bag)):
                data[i] = (bag[i], False)
                if i == len(bag) - 1:
                    data[i] = (bag[i], True)
        
            for idx in range(0, len(bag), self.batch_size):
                yield data[idx : idx + self.batch_size]
```

### Error messages and logs

```
File ""main_mil_v1.py"", line 122, in main
    res = trainer.predict(model=pipeline, dataloaders=val_dl)
  File ""d:\uv_envs\smt2\lib\site-packages\lightning\pytorch\trainer\trainer.py"", line 887, in predict
    return call._call_and_handle_interrupt(
  File ""d:\uv_envs\smt2\lib\site-packages\lightning\pytorch\trainer\call.py"", line 48, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File ""d:\uv_envs\smt2\lib\site-packages\lightning\pytorch\trainer\trainer.py"", line 928, in _predict_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File ""d:\uv_envs\smt2\lib\site-packages\lightning\pytorch\trainer\trainer.py"", line 1012, in _run
    results = self._run_stage()
  File ""d:\uv_envs\smt2\lib\site-packages\lightning\pytorch\trainer\trainer.py"", line 1051, in _run_stage
    return self.predict_loop.run()
  File ""d:\uv_envs\smt2\lib\site-packages\lightning\pytorch\loops\utilities.py"", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
  File ""d:\uv_envs\smt2\lib\site-packages\lightning\pytorch\loops\prediction_loop.py"", line 105, in run
    self.setup_data()
  File ""d:\uv_envs\smt2\lib\site-packages\lightning\pytorch\loops\prediction_loop.py"", line 158, in setup_data
    dl = _process_dataloader(trainer, trainer_fn, stage, dl)
  File ""d:\uv_envs\smt2\lib\site-packages\lightning\pytorch\trainer\connectors\data_connector.py"", line 485, in _process_dataloader
    dataloader = trainer._data_connector._prepare_dataloader(dataloader, shuffle=is_shuffled, mode=stage)
  File ""d:\uv_envs\smt2\lib\site-packages\lightning\pytorch\trainer\connectors\data_connector.py"", line 191, in _prepare_dataloader
    return _update_dataloader(dataloader, sampler, mode=mode)
  File ""d:\uv_envs\smt2\lib\site-packages\lightning\pytorch\utilities\data.py"", line 135, in _update_dataloader
    dl_args, dl_kwargs = _get_dataloader_init_args_and_kwargs(dataloader, sampler, mode)
  File ""d:\uv_envs\smt2\lib\site-packages\lightning\pytorch\utilities\data.py"", line 194, in _get_dataloader_init_args_and_kwargs
    dl_kwargs.update(_dataloader_init_kwargs_resolve_sampler(dataloader, sampler, mode))
  File ""d:\uv_envs\smt2\lib\site-packages\lightning\pytorch\utilities\data.py"", line 284, in _dataloader_init_kwargs_resolve_sampler
    batch_sampler = batch_sampler_cls(
TypeError: MILSampler.__init__() missing 1 required positional argument: 'data_source'
```


### Environment

<details>
  <summary>Current environment</summary>

```
PyTorch Lightning Version (e.g., 2.5.0): 2.5.1
PyTorch Version (e.g., 2.5): 2.5.1+cu121
Python version (e.g., 3.12): 3.10
```

</details>


### More info

_No response_",vb123er951,15091938,open,False,0,2025-04-21T02:17:22+00:00,2025-04-22T08:14:31+00:00,,bug;needs triage;ver: 2.5.x,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3007389722,20740,"build(deps): update cloudpickle requirement from <2.3.0,>=1.3 to >=1.3,<3.2.0 in /requirements","Updates the requirements on [cloudpickle](https://github.com/cloudpipe/cloudpickle) to permit the latest version.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/cloudpipe/cloudpickle/blob/master/CHANGES.md"">cloudpickle's changelog</a>.</em></p>
<blockquote>
<h1>3.1.1</h1>
<ul>
<li>Various fixes to support for Python 3.14 ([PR <a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/545"">#545</a>](
<a href=""https://redirect.github.com/cloudpipe/cloudpickle/pull/545"">cloudpipe/cloudpickle#545</a>)).</li>
</ul>
<h1>3.1.0</h1>
<ul>
<li>
<p>Some improvements to make cloudpickle more deterministic when pickling
dynamic functions and classes, in particular with CPython 3.13.
([PR <a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/524"">#524</a>](<a href=""https://redirect.github.com/cloudpipe/cloudpickle/pull/524"">cloudpipe/cloudpickle#524</a>) and
[PR <a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/534"">#534</a>](<a href=""https://redirect.github.com/cloudpipe/cloudpickle/pull/534"">cloudpipe/cloudpickle#534</a>))</p>
</li>
<li>
<p>Fix a problem with the joint usage of cloudpickle's <code>_whichmodule</code> and
<code>multiprocessing</code>.
([PR <a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/529"">#529</a>](<a href=""https://redirect.github.com/cloudpipe/cloudpickle/pull/529"">cloudpipe/cloudpickle#529</a>))</p>
</li>
</ul>
<h1>3.0.0</h1>
<ul>
<li>
<p>Officially support Python 3.12 and drop support for Python 3.6 and 3.7.
Dropping support for older Python versions made it possible to simplify the
code base significantly, hopefully making it easier to contribute to and
maintain the project.
([PR <a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/517"">#517</a>](<a href=""https://redirect.github.com/cloudpipe/cloudpickle/pull/517"">cloudpipe/cloudpickle#517</a>))</p>
</li>
<li>
<p>Fix pickling of dataclasses and their instances.
([issue <a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/386"">#386</a>](<a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/386"">cloudpipe/cloudpickle#386</a>),
[PR <a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/513"">#513</a>](<a href=""https://redirect.github.com/cloudpipe/cloudpickle/pull/513"">cloudpipe/cloudpickle#513</a>))</p>
</li>
<li>
<p>Any color you like as long as it's black.
([PR <a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/521"">#521</a>](<a href=""https://redirect.github.com/cloudpipe/cloudpickle/pull/521"">cloudpipe/cloudpickle#521</a>))</p>
</li>
<li>
<p>Drop <code>setup.py</code> and <code>setuptools</code> in favor of <code>pyproject.toml</code> and <code>flit</code>.
([PR <a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/521"">#521</a>](<a href=""https://redirect.github.com/cloudpipe/cloudpickle/pull/521"">cloudpipe/cloudpickle#521</a>))</p>
</li>
</ul>
<h1>2.2.1</h1>
<ul>
<li>Fix pickling of NamedTuple in Python 3.9+.
([issue <a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/460"">#460</a>](<a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/460"">cloudpipe/cloudpickle#460</a>))</li>
</ul>
<h1>2.2.0</h1>
<ul>
<li>Fix support of PyPy 3.8 and later.
([issue <a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/455"">#455</a>](<a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/455"">cloudpipe/cloudpickle#455</a>))</li>
</ul>
<p>2.1.0</p>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/cloudpipe/cloudpickle/commit/ff54d93221082d4ce22630ecdb8fbbccc60f3b62""><code>ff54d93</code></a> MAINT prepare bugfix release 3.1.1 (<a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/553"">#553</a>)</li>
<li><a href=""https://github.com/cloudpipe/cloudpickle/commit/e3f213a860164729abd9f9a2c203263a8201a21f""><code>e3f213a</code></a> MAINT skip-existing in testpypi publishing (<a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/552"">#552</a>)</li>
<li><a href=""https://github.com/cloudpipe/cloudpickle/commit/4dd09484597f0ead3e123a4ebfebec01e952acdf""><code>4dd0948</code></a> MAINT verbose testpypi publishing (<a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/551"">#551</a>)</li>
<li><a href=""https://github.com/cloudpipe/cloudpickle/commit/a6d227cb9f6ce10c4f7ba88d6981e8eb94c973e3""><code>a6d227c</code></a> MAINT fix placeholder with correct package name in test.pypi.org publishing c...</li>
<li><a href=""https://github.com/cloudpipe/cloudpickle/commit/12f9891d98ac47e8088a8fbb5dea12dabd37895d""><code>12f9891</code></a> Trigger testpypi publishing workflow (<a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/549"">#549</a>)</li>
<li><a href=""https://github.com/cloudpipe/cloudpickle/commit/f739facce13df5bdb77cc408733a5c452928c9ec""><code>f739fac</code></a> Trigger testpypi publishing workflow</li>
<li><a href=""https://github.com/cloudpipe/cloudpickle/commit/73598f667a01577a9c98f6219f8636767f3845c5""><code>73598f6</code></a> MAINT automate the pypi release process with CI and trusted publishing (<a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/548"">#548</a>)</li>
<li><a href=""https://github.com/cloudpipe/cloudpickle/commit/f3901923f89b4c25f6d4438792c7d9efa19dc429""><code>f390192</code></a> Update whichmodule tests in cloudpickle to work with numpy 2.2. (<a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/546"">#546</a>)</li>
<li><a href=""https://github.com/cloudpipe/cloudpickle/commit/7468d7284c79ba11dedc99afa72218ca6b7abf49""><code>7468d72</code></a> Fix <a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/544"">#544</a>: Port to Python 3.14 (<a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/545"">#545</a>)</li>
<li><a href=""https://github.com/cloudpipe/cloudpickle/commit/caf55dfc9d6c933a743cac2020f10334ba263221""><code>caf55df</code></a> Fix numpy _whichmodule (<a href=""https://redirect.github.com/cloudpipe/cloudpickle/issues/547"">#547</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/cloudpipe/cloudpickle/compare/v1.3.0...v3.1.1"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20740.org.readthedocs.build/en/20740/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,1,2025-04-21T02:00:18+00:00,2025-04-22T17:30:18+00:00,2025-04-22T17:30:17+00:00,ci;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3007389353,20739,"build(deps): update torchmetrics requirement from <1.5.0,>=0.10.0 to >=0.10.0,<1.8.0 in /requirements","Updates the requirements on [torchmetrics](https://github.com/Lightning-AI/torchmetrics) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/Lightning-AI/torchmetrics/releases"">torchmetrics's releases</a>.</em></p>
<blockquote>
<h2>Minor patch release</h2>
<h2>[1.7.1] - 2025-04-06</h2>
<h3>Changed</h3>
<ul>
<li>Enhance Support Adding a <code>MetricCollection</code> to Another <code>MetricCollection</code> in <code>add_metrics</code> Function (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/issues/3032"">#3032</a>)</li>
</ul>
<h3>Fixed</h3>
<ul>
<li>Fixed absent class <code>MeanIOU</code> (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/issues/2892"">#2892</a>)</li>
<li>Fixed detection IoU ignores predictions without ground truth (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/issues/3025"">#3025</a>)</li>
<li>Fixed error raised in <code>MulticlassAccuracy</code> when top_k&gt;1 (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/issues/3039"">#3039</a>)</li>
</ul>
<hr />
<h3>Key Contributors</h3>
<p><a href=""https://github.com/Isalia20""><code>@​Isalia20</code></a>, <a href=""https://github.com/rittik9""><code>@​rittik9</code></a>, <a href=""https://github.com/SkafteNicki""><code>@​SkafteNicki</code></a></p>
<p><em>If we forgot someone due to not matching commit email with GitHub account, let us know :]</em></p>
<hr />
<p><strong>Full Changelog</strong>: <a href=""https://github.com/Lightning-AI/torchmetrics/compare/v1.7.0...v1.7.1"">https://github.com/Lightning-AI/torchmetrics/compare/v1.7.0...v1.7.1</a></p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/Lightning-AI/torchmetrics/blob/master/CHANGELOG.md"">torchmetrics's changelog</a>.</em></p>
<blockquote>
<h2>[1.7.1] - 2025-04-06</h2>
<h3>Changed</h3>
<ul>
<li>Enhance Support Adding a <code>MetricCollection</code> to Another <code>MetricCollection</code> in <code>add_metrics</code> Function (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/3032"">#3032</a>)</li>
</ul>
<h3>Fixed</h3>
<ul>
<li>Fixed absent class <code>MeanIOU</code> (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/2892"">#2892</a>)</li>
<li>Fixed detection IoU ignores predictions without ground truth (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/3025"">#3025</a>)</li>
<li>Fixed error raised in <code>MulticlassAccuracy</code> when top_k&gt;1 (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/3039"">#3039</a>)</li>
</ul>
<h2>[1.7.0] - 2025-03-20</h2>
<h3>Added</h3>
<ul>
<li>Additions to image domain:
<ul>
<li>Added <code>ARNIQA</code> metric (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/2953"">#2953</a>)</li>
<li>Added <code>DeepImageStructureAndTextureSimilarity</code> (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/2993"">#2993</a>)</li>
<li>Added support for more models and processors in <code>CLIPScore</code> (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/2978"">#2978</a>)</li>
</ul>
</li>
<li>Added <code>JensenShannonDivergence</code> metric to regression package (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/2992"">#2992</a>)</li>
<li>Added <code>ClusterAccuracy</code> metric to cluster package (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/2777"">#2777</a>)</li>
<li>Added <code>Equal Error Rate (EER)</code> to classification package (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/3013"">#3013</a>)</li>
<li>Added functional interface to <code>MeanAveragePrecision</code> metric (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/3011"">#3011</a>)</li>
</ul>
<h3>Changed</h3>
<ul>
<li>Making <code>num_classes</code> optional for <code>one-hot</code> inputs in <code>MeanIoU</code> (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/3012"">#3012</a>)</li>
</ul>
<h3>Removed</h3>
<ul>
<li>Removed <code>Dice</code> from classification (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/3017"">#3017</a>)</li>
</ul>
<h3>Fixed</h3>
<ul>
<li>Fixed edge case in integration between class-wise wrapper and metric tracker (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/3008"">#3008</a>)</li>
<li>Fixed <code>IndexError</code> in <code>MultiClassAccuracy</code> when using <code>top_k</code> with single sample  (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/3021"">#3021</a>)</li>
</ul>
<hr />
<h2>[1.6.3] - 2024-03-13</h2>
<h3>Fixed</h3>
<ul>
<li>Fixed logic in how metric states referencing is handled in <code>MetricCollection</code> (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/2990"">#2990</a>)</li>
<li>Fixed integration between class-wise wrapper and metric tracker (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/pull/3004"">#3004</a>)</li>
</ul>
<h2>[1.6.2] - 2024-02-28</h2>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/Lightning-AI/torchmetrics/commit/41aaba3e9f0aa61e9e1000acc1df990ff9dcbfba""><code>41aaba3</code></a> releasing <code>1.7.1</code></li>
<li><a href=""https://github.com/Lightning-AI/torchmetrics/commit/64eaa2661fd8df8bb1f7ede015de6f0e32b2e1b6""><code>64eaa26</code></a> docs: fix link to MultiScaleSSIM (pub) (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/issues/3045"">#3045</a>)</li>
<li><a href=""https://github.com/Lightning-AI/torchmetrics/commit/8ff985149dceaf4928af0cacaccee0266997b85c""><code>8ff9851</code></a> Bugfix in top_k (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/issues/3039"">#3039</a>)</li>
<li><a href=""https://github.com/Lightning-AI/torchmetrics/commit/f1c4020e218f32ec21e94df190f44a9243e6816f""><code>f1c4020</code></a> build(deps): bump Lightning-AI/utilities from 0.13.1 to 0.14.2 (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/issues/3038"">#3038</a>)</li>
<li><a href=""https://github.com/Lightning-AI/torchmetrics/commit/b254b62be2b1784c9ffa383d60b2229949e7bb02""><code>b254b62</code></a> Improve testing of wrappers (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/issues/3040"">#3040</a>)</li>
<li><a href=""https://github.com/Lightning-AI/torchmetrics/commit/31722d49bb2c03c79c20526073eac7677ce7bc51""><code>31722d4</code></a> build(deps): update coverage requirement from ==7.7.* to ==7.8.* in /requirem...</li>
<li><a href=""https://github.com/Lightning-AI/torchmetrics/commit/ec5fe1612ff2bd5fdc11a0730155b5a5f5eee941""><code>ec5fe16</code></a> build(deps): update huggingface-hub requirement from &lt;0.30 to &lt;0.31 in /requi...</li>
<li><a href=""https://github.com/Lightning-AI/torchmetrics/commit/36122c6e6487df2f73014a1b21afc253aa313b3f""><code>36122c6</code></a> Enhance Support Adding a <code>MetricCollection</code> to Another <code>MetricCollection</code> in ...</li>
<li><a href=""https://github.com/Lightning-AI/torchmetrics/commit/44543b2f37ef6c9f0da7d5014d76005347f020c5""><code>44543b2</code></a> Absent class miou fix (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/issues/2892"">#2892</a>)</li>
<li><a href=""https://github.com/Lightning-AI/torchmetrics/commit/8dc3f78833debc3136a3e5fe9691e29fabd11c0a""><code>8dc3f78</code></a> fix Detection IoU ignores predictions without ground truth (<a href=""https://redirect.github.com/Lightning-AI/torchmetrics/issues/3025"">#3025</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/Lightning-AI/torchmetrics/compare/v0.10.0...v1.7.1"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20739.org.readthedocs.build/en/20739/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,1,2025-04-21T01:59:53+00:00,2025-04-22T13:12:37+00:00,2025-04-22T13:12:35+00:00,ci;fabric;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3007389213,20738,"build(deps): update onnxruntime requirement from <1.19.0,>=1.12.0 to >=1.12.0,<1.21.0 in /requirements","Updates the requirements on [onnxruntime](https://github.com/microsoft/onnxruntime) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/microsoft/onnxruntime/releases"">onnxruntime's releases</a>.</em></p>
<blockquote>
<h2>ONNX Runtime v1.20.1</h2>
<h1>What's new?</h1>
<h2>Python Quantization Tool</h2>
<ul>
<li>Prevent int32 quantized bias from clipping by adjusting the weight's scale (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22020"">#22020</a>) - <a href=""https://github.com/adrianlizarraga""><code>@​adrianlizarraga</code></a></li>
<li>Update QDQ Pad, Slice, Softmax (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22676"">#22676</a>) - <a href=""https://github.com/adrianlizarraga""><code>@​adrianlizarraga</code></a></li>
<li>Introduce get_qdq_config() helper to get QDQ configurations (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22677"">#22677</a>) - <a href=""https://github.com/adrianlizarraga""><code>@​adrianlizarraga</code></a></li>
<li>Add reduce_range option to get_qdq_config() (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22782"">#22782</a>) - <a href=""https://github.com/adrianlizarraga""><code>@​adrianlizarraga</code></a></li>
<li>Flaky test due to Pad reflect bug (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22798"">#22798</a>) - <a href=""https://github.com/adrianlizarraga""><code>@​adrianlizarraga</code></a></li>
</ul>
<h2>CPU EP</h2>
<ul>
<li>Refactor SkipLayerNorm implementation to address issues (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22719"">#22719</a>, <a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22862"">#22862</a>) - <a href=""https://github.com/amarin16""><code>@​amarin16</code></a>, <a href=""https://github.com/liqunfu""><code>@​liqunfu</code></a></li>
</ul>
<h2>QNN EP</h2>
<ul>
<li>Add QNN SDK v2.28.2 support (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22724"">#22724</a>, <a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22844"">#22844</a>) - <a href=""https://github.com/HectorSVC""><code>@​HectorSVC</code></a>, <a href=""https://github.com/adrianlizarraga""><code>@​adrianlizarraga</code></a></li>
</ul>
<h2>TensorRT EP</h2>
<ul>
<li>Exclude DDS ops from running on TRT (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22875"">#22875</a>) - <a href=""https://github.com/chilo-ms""><code>@​chilo-ms</code></a></li>
</ul>
<h2>Packaging</h2>
<ul>
<li>Rework the native library usage so that a pre-built ORT native package can be easily used (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22345"">#22345</a>) - <a href=""https://github.com/skottmckay""><code>@​skottmckay</code></a></li>
<li>Fix Maven Sha256 Checksum Issue (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22600"">#22600</a>) - <a href=""https://github.com/idiskyle""><code>@​idiskyle</code></a></li>
</ul>
<h2>Contributions</h2>
<p>Big thank you to the release manager <a href=""https://github.com/yf711""><code>@​yf711</code></a>, along with <a href=""https://github.com/adrianlizarraga""><code>@​adrianlizarraga</code></a>, <a href=""https://github.com/HectorSVC""><code>@​HectorSVC</code></a>, <a href=""https://github.com/jywu-msft""><code>@​jywu-msft</code></a>, and everyone else who helped to make this patch release process a smooth one!</p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/microsoft/onnxruntime/commit/5c1b7ccbff7e5141c1da7a9d963d660e5741c319""><code>5c1b7cc</code></a> [ORT 1.20.1 Release] Cherry pick 2nd round (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22845"">#22845</a>)</li>
<li><a href=""https://github.com/microsoft/onnxruntime/commit/c6156c17bc83804a61e37dfdef41fcafc2943f55""><code>c6156c1</code></a> [ORT 1.20.1 Release] Cherry pick 1st round (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22785"">#22785</a>)</li>
<li><a href=""https://github.com/microsoft/onnxruntime/commit/c4fb724e810bb496165b9015c77f402727392933""><code>c4fb724</code></a> ORT 1.20.0 release preparation: Cherry pick round 2 (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22643"">#22643</a>)</li>
<li><a href=""https://github.com/microsoft/onnxruntime/commit/2d00351d7b4975a4d03f6a437772b6976726a252""><code>2d00351</code></a> ORT 1.20.0 Release: Cherry pick round 1 (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22526"">#22526</a>)</li>
<li><a href=""https://github.com/microsoft/onnxruntime/commit/f9e623e4d1cf0998e5499053d96ab5f77ddff6d0""><code>f9e623e</code></a> Update CMake to 3.31.0rc1 (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22433"">#22433</a>)</li>
<li><a href=""https://github.com/microsoft/onnxruntime/commit/691de83892e72f38bffd39c47777980a6c362b97""><code>691de83</code></a> Enable BrowserStack tests (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22457"">#22457</a>)</li>
<li><a href=""https://github.com/microsoft/onnxruntime/commit/bf604428aa4b9faf84ce99f735ad6402a6d6f886""><code>bf60442</code></a> [ROCm] Update ROCm Nuget pipeline to ROCm 6.2 (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22461"">#22461</a>)</li>
<li><a href=""https://github.com/microsoft/onnxruntime/commit/2b8fc5529bce4d815d2e71e9c8258c29db377c87""><code>2b8fc55</code></a> Enable RunMatMulTest all test cases support FP16 (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22440"">#22440</a>)</li>
<li><a href=""https://github.com/microsoft/onnxruntime/commit/af00a20f8aeba17a68ea8a7c5f41df2c27d96116""><code>af00a20</code></a> Change ORT nightly python packages' name (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22450"">#22450</a>)</li>
<li><a href=""https://github.com/microsoft/onnxruntime/commit/a5e85a950c2fab5729c46e7362a60765caa4b999""><code>a5e85a9</code></a> Fix training artifacts for 2GB+ models and <code>MSELoss</code> (<a href=""https://redirect.github.com/microsoft/onnxruntime/issues/22414"">#22414</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/microsoft/onnxruntime/compare/v1.12.0...v1.20.1"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20738.org.readthedocs.build/en/20738/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,1,2025-04-21T01:59:45+00:00,2025-04-22T17:39:17+00:00,2025-04-22T17:39:15+00:00,ci;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3007389121,20737,"build(deps): update lightning-utilities requirement from <0.12.0,>=0.11.1 to >=0.11.1,<0.15.0 in /requirements","Updates the requirements on [lightning-utilities](https://github.com/Lightning-AI/utilities) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/Lightning-AI/utilities/releases"">lightning-utilities's releases</a>.</em></p>
<blockquote>
<h2>Fixed parsing Azure schema</h2>
<h2>What's Changed</h2>
<ul>
<li>CI: fix parsing Azure schema by <a href=""https://github.com/Borda""><code>@​Borda</code></a> in <a href=""https://redirect.github.com/Lightning-AI/utilities/pull/384"">Lightning-AI/utilities#384</a></li>
<li>script: update usage of coverage in standalone by <a href=""https://github.com/Borda""><code>@​Borda</code></a> in <a href=""https://redirect.github.com/Lightning-AI/utilities/pull/383"">Lightning-AI/utilities#383</a></li>
</ul>
<ul>
<li>docs: fix building rtfd by <a href=""https://github.com/Borda""><code>@​Borda</code></a> in <a href=""https://redirect.github.com/Lightning-AI/utilities/pull/379"">Lightning-AI/utilities#379</a></li>
<li>build(deps): update coverage requirement from ==7.6.* to ==7.7.* in /requirements by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://redirect.github.com/Lightning-AI/utilities/pull/378"">Lightning-AI/utilities#378</a></li>
<li>build(deps): update setuptools requirement from ==76.0.* to ==78.0.* in /requirements by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://redirect.github.com/Lightning-AI/utilities/pull/377"">Lightning-AI/utilities#377</a></li>
</ul>
<hr />
<p><strong>Full Changelog</strong>: <a href=""https://github.com/Lightning-AI/utilities/compare/v0.14.2...v0.14.3"">https://github.com/Lightning-AI/utilities/compare/v0.14.2...v0.14.3</a></p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/Lightning-AI/utilities/blob/main/CHANGELOG.md"">lightning-utilities's changelog</a>.</em></p>
<blockquote>
<h2>[0.14.3] - 2025-04-03</h2>
<h3>Changed</h3>
<ul>
<li>script: update usage of coverage in standalone (<a href=""https://redirect.github.com/Lightning-AI/utilities/pull/383"">#383</a>)</li>
</ul>
<h3>Fixed</h3>
<ul>
<li>CI: fix parsing Azure schema (<a href=""https://redirect.github.com/Lightning-AI/utilities/pull/384"">#384</a>)</li>
</ul>
<h2>[0.14.2] - 2025-03-20</h2>
<h3>Fixed</h3>
<ul>
<li>CI: fix using schema action (<a href=""https://redirect.github.com/Lightning-AI/utilities/pull/376"">#376</a>)</li>
</ul>
<h2>[0.14.1] - 2025-03-14</h2>
<h3>Fixed</h3>
<ul>
<li>Fixed python version parsing for logging <code>stacklevel</code> (<a href=""https://redirect.github.com/Lightning-AI/utilities/pull/375"">#375</a>)</li>
</ul>
<h2>[0.14.0] - 2025-03-07</h2>
<h3>Added</h3>
<ul>
<li>CLI: replace package name in requirements (<a href=""https://redirect.github.com/Lightning-AI/utilities/pull/372"">#372</a>)</li>
</ul>
<hr />
<h2>[0.13.1] - 2025-03-04</h2>
<h3>Changed</h3>
<ul>
<li>CI: enable <code>azure-schema-version</code> forAzure schema check (<a href=""https://redirect.github.com/Lightning-AI/utilities/pull/369"">#369</a>)</li>
</ul>
<h2>[0.13.0] - 2025-03-04</h2>
<h3>Changed</h3>
<ul>
<li>CI: bump all runners from <code>20.04</code> to <code>24.04</code> (<a href=""https://redirect.github.com/Lightning-AI/utilities/pull/368"">#368</a>)</li>
</ul>
<h3>Fixed</h3>
<ul>
<li>Fixed resetting dataclass's <code>cached_property</code> once <code>apply_to_collection</code> is called (<a href=""https://redirect.github.com/Lightning-AI/utilities/pull/363"">#363</a>)</li>
</ul>
<hr />
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/Lightning-AI/utilities/commit/905e09bbd7e32c116a3a6d89d55131d9e5544b25""><code>905e09b</code></a> releasing <code>0.14.3</code></li>
<li><a href=""https://github.com/Lightning-AI/utilities/commit/e7ace56d5ff7cfc617da615d13900e918196d730""><code>e7ace56</code></a> ci: fix parsing Azure schema (<a href=""https://redirect.github.com/Lightning-AI/utilities/issues/384"">#384</a>)</li>
<li><a href=""https://github.com/Lightning-AI/utilities/commit/5e9608389d2a3ec242bf19534892c39a1ca698ea""><code>5e96083</code></a> update coverage the standalone script (<a href=""https://redirect.github.com/Lightning-AI/utilities/issues/383"">#383</a>)</li>
<li><a href=""https://github.com/Lightning-AI/utilities/commit/8f0e3132154fbc70c594bf73a491cbd8d7d979d7""><code>8f0e313</code></a> build(deps): update check-jsonschema requirement from ==0.31.* to ==0.32.* in...</li>
<li><a href=""https://github.com/Lightning-AI/utilities/commit/f44ac3cb11b77dc12a81a9c2875d7aafc6dd460a""><code>f44ac3c</code></a> build(deps): update coverage requirement from ==7.7.* to ==7.8.* in /requirem...</li>
<li><a href=""https://github.com/Lightning-AI/utilities/commit/4c5f44c6bd2c13197f2305c91189c3f016dc7ae0""><code>4c5f44c</code></a> build(deps): update setuptools requirement from ==78.0.* to ==78.1.* in /requ...</li>
<li><a href=""https://github.com/Lightning-AI/utilities/commit/36f6d61b352e898ff671e864a2483e8dd30d712a""><code>36f6d61</code></a> build(deps): update setuptools requirement from ==76.0.* to ==78.0.* in /requ...</li>
<li><a href=""https://github.com/Lightning-AI/utilities/commit/9597ce4e901bd4c78650ca27b3ff6659d7f05c88""><code>9597ce4</code></a> build(deps): update coverage requirement from ==7.6.* to ==7.7.* in /requirem...</li>
<li><a href=""https://github.com/Lightning-AI/utilities/commit/424b075b51ef6bd5d0abbbb7de7d4fea61397f3c""><code>424b075</code></a> docs: fix building rtfd (<a href=""https://redirect.github.com/Lightning-AI/utilities/issues/379"">#379</a>)</li>
<li><a href=""https://github.com/Lightning-AI/utilities/commit/3e4e3782c2ec41ff6426a2670d69e87a17c91d26""><code>3e4e378</code></a> releasing <code>0.14.2</code></li>
<li>Additional commits viewable in <a href=""https://github.com/Lightning-AI/utilities/compare/v0.11.1...v0.14.3"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20737.org.readthedocs.build/en/20737/

<!-- readthedocs-preview pytorch-lightning end -->

cc @lantiga @borda @justusschock",dependabot[bot],49699333,closed,False,3,2025-04-21T01:59:39+00:00,2025-04-22T18:55:22+00:00,2025-04-22T18:55:05+00:00,docs;ci;fabric;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3007389108,20736,"build(deps): update torchvision requirement from <0.21.0,>=0.16.0 to >=0.16.0,<0.22.0 in /requirements","Updates the requirements on [torchvision](https://github.com/pytorch/vision) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pytorch/vision/releases"">torchvision's releases</a>.</em></p>
<blockquote>
<h2>Torchvision 0.21 release</h2>
<h1>Highlights</h1>
<h1>Detailed changes</h1>
<h2>Image decoding</h2>
<p>Torchvision continues to improve its image decoding capabilities. For this version, we added support for HEIC and AVIF image formats. Things are a bit different this time: to enable it, you'll need to <code>pip install torchvision-extra-decoders</code>, and the decoders are available in torchvision as <code>torchvision.io.decode_heic()</code> and <code>torchvision.io.decode_avif()</code>. This is still experimental / BETA, so let us know if you encounter any issue.</p>
<p>Read more in our <a href=""https://pytorch.org/vision/stable/io.html"">docs</a>!</p>
<h2>New Features</h2>
<p>[io] Add support for decoding AVIF and HEIC image formats (<a href=""https://redirect.github.com/pytorch/vision/issues/8671"">#8671</a>)</p>
<h2>Improvements</h2>
<p>[datasets] Don't error when dataset is already downloaded (<a href=""https://redirect.github.com/pytorch/vision/issues/8691"">#8691</a>)
[datasets] Don't print when dataset is already downloaded (<a href=""https://redirect.github.com/pytorch/vision/issues/8681"">#8681</a>)
[datasets] remove printing info in datasets (<a href=""https://redirect.github.com/pytorch/vision/issues/8683"">#8683</a>)
[utils] Add <code>label_colors</code> argument to <code>draw_bounding_boxes</code> (<a href=""https://redirect.github.com/pytorch/vision/issues/8578"">#8578</a>)
[models] Add <code>__deepcopy__</code> support for <code>DualGraphModule</code> (<a href=""https://redirect.github.com/pytorch/vision/issues/8708"">#8708</a>)
[Docs] Various documentation improvements (<a href=""https://redirect.github.com/pytorch/vision/issues/8798"">#8798</a>, <a href=""https://redirect.github.com/pytorch/vision/issues/8709"">#8709</a>, <a href=""https://redirect.github.com/pytorch/vision/issues/8576"">#8576</a>, <a href=""https://redirect.github.com/pytorch/vision/issues/8620"">#8620</a>, <a href=""https://redirect.github.com/pytorch/vision/issues/8846"">#8846</a>, <a href=""https://redirect.github.com/pytorch/vision/issues/8758"">#8758</a>)
[Code quality] Various code quality improvements (<a href=""https://redirect.github.com/pytorch/vision/issues/8757"">#8757</a>, <a href=""https://redirect.github.com/pytorch/vision/issues/8755"">#8755</a>, <a href=""https://redirect.github.com/pytorch/vision/issues/8754"">#8754</a>, <a href=""https://redirect.github.com/pytorch/vision/issues/8689"">#8689</a>, <a href=""https://redirect.github.com/pytorch/vision/issues/8719"">#8719</a>, <a href=""https://redirect.github.com/pytorch/vision/issues/8772"">#8772</a>, <a href=""https://redirect.github.com/pytorch/vision/issues/8774"">#8774</a>, <a href=""https://redirect.github.com/pytorch/vision/issues/8791"">#8791</a>, <a href=""https://redirect.github.com/pytorch/vision/issues/8705"">#8705</a>)</p>
<h2>Bug Fixes</h2>
<p>[io] Fix memory leak in <code>decode_webp</code> (<a href=""https://redirect.github.com/pytorch/vision/issues/8712"">#8712</a>)
[io] Fix pyav 14 compatibility error (<a href=""https://redirect.github.com/pytorch/vision/issues/8776"">#8776</a>)
[models] Fix order of auxiliary networks in googlenet.py (<a href=""https://redirect.github.com/pytorch/vision/issues/8743"">#8743</a>)
[transforms] Fix <code>adjust_hue</code> on ARM (<a href=""https://redirect.github.com/pytorch/vision/issues/8618"">#8618</a>)
[reference scripts] Fix error when loading the cached dataset in video classification reference(<a href=""https://redirect.github.com/pytorch/vision/issues/8727"">#8727</a>)
[build] fix CUDA build with NVCC_FLAGS in env (<a href=""https://redirect.github.com/pytorch/vision/issues/8692"">#8692</a>)</p>
<h2>Tracked Regressions</h2>
<p>[build] aarch64 builds are build with manylinux_2_34_aarch64 tag according to auditwheel check (<a href=""https://redirect.github.com/pytorch/vision/issues/8883"">#8883</a>)</p>
<h2>Contributors</h2>
<p>We're grateful for our community, which helps us improve torchvision by submitting issues and PRs, and providing feedback and suggestions. The following persons have contributed patches for this release:</p>
<p>amdfaa Andreas Floros, Andrey Talman , Beh Chuen Yang, David Miguel Susano Pinto, GdoongMathew, Jason Chou, Li-Huai (Allan) Lin, Maohua Li, Nicolas Hug , pblwk, R. Yao, sclarkson, vfdev, Ștefan Talpalaru</p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pytorch/vision/commit/7af698794eded568735f9519593603c1ec889eba""><code>7af6987</code></a> [Cherry-Pick] Update Requires-Python: &gt;=3.9 (<a href=""https://redirect.github.com/pytorch/vision/issues/8886"">#8886</a>)</li>
<li><a href=""https://github.com/pytorch/vision/commit/eafc2930ee25a72442ae5308da1b48d90b7eda99""><code>eafc293</code></a> [Cherry-pick for 0.21] Migrate avif and heic decoders to torchvision-extra-de...</li>
<li><a href=""https://github.com/pytorch/vision/commit/2f3a43fbca2070ca6f0a863e7e92fcd750eb0c1a""><code>2f3a43f</code></a> [Cherry-pick for 0.21] Fix doc of masks_to_boxes (<a href=""https://redirect.github.com/pytorch/vision/issues/8798"">#8798</a>) (<a href=""https://redirect.github.com/pytorch/vision/issues/8799"">#8799</a>)</li>
<li><a href=""https://github.com/pytorch/vision/commit/b411ffcf63bd2bbf721bc8541275f0a1af38835f""><code>b411ffc</code></a> [0.21 release] Use release/2.6 branch of test-infra (<a href=""https://redirect.github.com/pytorch/vision/issues/8795"">#8795</a>)</li>
<li><a href=""https://github.com/pytorch/vision/commit/821740195eee36ab3e3acfebe4996e4370b62892""><code>8217401</code></a> [release/0.21] set version to 0.21.0 (<a href=""https://redirect.github.com/pytorch/vision/issues/8797"">#8797</a>)</li>
<li><a href=""https://github.com/pytorch/vision/commit/a1c7f8e71fd0ef5934c30b66e8ca6f488db33b82""><code>a1c7f8e</code></a> [release 0.21] remove prototype stuff (<a href=""https://redirect.github.com/pytorch/vision/issues/8794"">#8794</a>)</li>
<li><a href=""https://github.com/pytorch/vision/commit/a9a726a5bde11fc2f1dc2067399e36755b809cb3""><code>a9a726a</code></a> Make v2 transforms authoring public (<a href=""https://redirect.github.com/pytorch/vision/issues/8787"">#8787</a>)</li>
<li><a href=""https://github.com/pytorch/vision/commit/48f01de2013085cb937b212fa1b7f9992fd0aec8""><code>48f01de</code></a> Ignore mypy for maxvit (<a href=""https://redirect.github.com/pytorch/vision/issues/8791"">#8791</a>)</li>
<li><a href=""https://github.com/pytorch/vision/commit/6279faa88a3fe7de49bf58284d31e3941b768522""><code>6279faa</code></a> Fix pyav 14 error (<a href=""https://redirect.github.com/pytorch/vision/issues/8776"">#8776</a>)</li>
<li><a href=""https://github.com/pytorch/vision/commit/36e219bfa38eca99af48ed08046935eb44649da1""><code>36e219b</code></a> mypy again (<a href=""https://redirect.github.com/pytorch/vision/issues/8774"">#8774</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/pytorch/vision/compare/v0.16.0...v0.21.0"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20736.org.readthedocs.build/en/20736/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,1,2025-04-21T01:59:38+00:00,2025-04-22T13:32:50+00:00,2025-04-22T13:32:49+00:00,ci;fabric;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3007389080,20735,"build(deps): update tensorboard requirement from <2.15.0,>=2.9.1 to >=2.9.1,<2.20.0 in /requirements","Updates the requirements on [tensorboard](https://github.com/tensorflow/tensorboard) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/tensorflow/tensorboard/releases"">tensorboard's releases</a>.</em></p>
<blockquote>
<h2>TensorBoard 2.19.0</h2>
<p>The 2.19 minor series tracks TensorFlow 2.19.</p>
<p>This release contains only internal cleanups, with no particular new features or bug fixes.</p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/tensorflow/tensorboard/blob/master/RELEASE.md"">tensorboard's changelog</a>.</em></p>
<blockquote>
<h1>Release 2.19.0</h1>
<p>The 2.19 minor series tracks TensorFlow 2.19.</p>
<p>This release contains only internal cleanups, with no particular new features or bug fixes.</p>
<h1>Release 2.18.0</h1>
<p>The 2.18 minor series tracks TensorFlow 2.18.</p>
<h2>Features</h2>
<ul>
<li>Compatibility updates for changes in Numpy 2.0 (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6871"">#6871</a>)</li>
<li>Relax <code>protobuf</code> restriction to work with versions <!-- raw HTML omitted -->= 5.0.0) (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6888"">#6888</a>)</li>
</ul>
<h2>Bug Fixes</h2>
<ul>
<li>Fixes a floating menu disappearing immediately after right-clicking on the trigger point. (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6891"">#6891</a>)</li>
</ul>
<h1>Release 2.17.1</h1>
<h2>Bug Fixes</h2>
<ul>
<li>Relax restriction on protobuf dependency (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6887"">#6887</a>)</li>
<li>Update usage of numpy to reflect numpy 2.0 changes (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6871"">#6871</a>)</li>
<li>Fix stacking of notification dot (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6875"">#6875</a>, thanks <a href=""https://github.com/crisbeto""><code>@​crisbeto</code></a>)</li>
<li>Fix setting dialog styling regression (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6885"">#6885</a>)</li>
</ul>
<h1>Release 2.17.0</h1>
<p>The 2.17 minor series tracks TensorFlow 2.17.</p>
<h2>Features</h2>
<ul>
<li>Enable adding hparams columns in scalar data tables in Time Series dashboard (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6737"">#6737</a> accidentally omitted from notes in release 2.16.0)</li>
<li>Usability improvements for runs table and hparams in Time Series dashboard (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6837"">#6837</a>, <a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6839"">#6839</a>)</li>
<li>Global pins: Store pinned cards in local storage, so they’d be pinned when similar experiments are loaded. (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6850"">#6850</a>, <a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6819"">#6819</a>, <a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6821"">#6821</a>, etc)</li>
<li>Handle large number of Hparams (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6777"">#6777</a>, <a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6780"">#6780</a>, <a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6807"">#6807</a>)</li>
<li>Infra: Reduce binary size of <a href=""http://pypi.org/project/tensorboard-data-server/""><code>tensorboard-data-server</code></a> (aka “Rustboard”). (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6765"">#6765</a>, thanks <a href=""https://github.com/Corwinpro""><code>@​Corwinpro</code></a>)</li>
</ul>
<h2>Bug Fixes</h2>
<ul>
<li>Text plugin: Preserve whitespace. (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6833"">#6833</a>)</li>
<li>Hparams plugin: load metrics when run name is “.” (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6822"">#6822</a>)</li>
<li>Resolved Graph plugin compatibility issues with Keras 3. (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6759"">#6759</a>, <a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6823"">#6823</a>, <a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6761"">#6761</a>, <a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6857"">#6857</a>, etc. thanks <a href=""https://github.com/mloc""><code>@​mloc</code></a>)</li>
<li>Restricts the protobuf dependency to be &lt; 5.0.0, due to a recent breaking change (see <a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6808"">#6808</a> for details).</li>
<li>Fixes internal flag wrapper class to not crash when its <code>__class__</code> attribute is accessed, which was blocking debugging with pyCharm (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6751"">#6751</a>, thanks <a href=""https://github.com/lostinplace""><code>@​lostinplace</code></a>)</li>
</ul>
<h1>Release 2.16.2</h1>
<h2>Bug Fixes</h2>
<ul>
<li>Remove dependency on tf-keras pip package. (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6759"">#6759</a>)</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/tensorflow/tensorboard/commit/3fceda6da03fa38cc00ccc3acd13259c0407ec5a""><code>3fceda6</code></a> TensorBoard 2.19.0</li>
<li><a href=""https://github.com/tensorflow/tensorboard/commit/8ff3478a488ecdc51582713a91a315fde3dac442""><code>8ff3478</code></a> Release notes for TensorBoard 2.19.0</li>
<li><a href=""https://github.com/tensorflow/tensorboard/commit/24f8dd2d7a6546c4cb8b6b05a503791d50f09197""><code>24f8dd2</code></a> Pin TF for 2.19 branch</li>
<li><a href=""https://github.com/tensorflow/tensorboard/commit/e31a6f8022adb3ec211ce9b84462e0b985f01aac""><code>e31a6f8</code></a> Update TF compat protos.</li>
<li><a href=""https://github.com/tensorflow/tensorboard/commit/9742d3da2bc37afeaf826e0c56431f83dbcded13""><code>9742d3d</code></a> Updates proto-update script to match new reference to 'tsl' dir</li>
<li><a href=""https://github.com/tensorflow/tensorboard/commit/5ca702910cce7bde806890b1c7ebfc08fc6eeeb9""><code>5ca7029</code></a> Escapes curly braces in str.format() to fix broken error message.</li>
<li><a href=""https://github.com/tensorflow/tensorboard/commit/a7178f4f622a786463d23ef645e0f16f6ea7a1cb""><code>a7178f4</code></a> Updates deprecated alias 'assertEquals' with non-deprecated method name (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6970"">#6970</a>)</li>
<li><a href=""https://github.com/tensorflow/tensorboard/commit/862a9da9b6b8dd5523b829278eb57648cd060e34""><code>862a9da</code></a> Removes reference to Fairness Indicators plugin (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6966"">#6966</a>)</li>
<li><a href=""https://github.com/tensorflow/tensorboard/commit/4dec80d712ea7e61db7f42d4cc67f67ae1f49a03""><code>4dec80d</code></a> Updates missed GH upload-artifact action to v4 (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6961"">#6961</a>)</li>
<li><a href=""https://github.com/tensorflow/tensorboard/commit/84bf02e7efdfe6f63ddbf583fc0835a429736e68""><code>84bf02e</code></a> Bump nanoid from 3.3.6 to 3.3.8 (<a href=""https://redirect.github.com/tensorflow/tensorboard/issues/6962"">#6962</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/tensorflow/tensorboard/compare/2.9.1...2.19.0"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20735.org.readthedocs.build/en/20735/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,0,2025-04-21T01:59:36+00:00,2025-04-21T18:34:42+00:00,2025-04-21T18:34:40+00:00,ci;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3007388978,20734,build(deps): update packaging requirement from <24.2 to <25.1 in /requirements,"Updates the requirements on [packaging](https://github.com/pypa/packaging) to permit the latest version.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/packaging/releases"">packaging's releases</a>.</em></p>
<blockquote>
<h2>25.0</h2>
<h2>What's Changed</h2>
<ul>
<li>Re-add a test for Unicode file name parsing by <a href=""https://github.com/Siddhesh-Agarwal""><code>@​Siddhesh-Agarwal</code></a> in <a href=""https://redirect.github.com/pypa/packaging/pull/863"">pypa/packaging#863</a></li>
<li>Upgrade to ruff 0.9.1 by <a href=""https://github.com/DimitriPapadopoulos""><code>@​DimitriPapadopoulos</code></a> in <a href=""https://redirect.github.com/pypa/packaging/pull/865"">pypa/packaging#865</a></li>
<li>Add support for PEP 738 Android tags by <a href=""https://github.com/mhsmith""><code>@​mhsmith</code></a> in <a href=""https://redirect.github.com/pypa/packaging/pull/880"">pypa/packaging#880</a></li>
<li>feat(markers): support 'extras' and 'dependency_groups' markers by <a href=""https://github.com/frostming""><code>@​frostming</code></a> in <a href=""https://redirect.github.com/pypa/packaging/pull/888"">pypa/packaging#888</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/Siddhesh-Agarwal""><code>@​Siddhesh-Agarwal</code></a> made their first contribution in <a href=""https://redirect.github.com/pypa/packaging/pull/863"">pypa/packaging#863</a></li>
<li><a href=""https://github.com/mhsmith""><code>@​mhsmith</code></a> made their first contribution in <a href=""https://redirect.github.com/pypa/packaging/pull/880"">pypa/packaging#880</a></li>
<li><a href=""https://github.com/frostming""><code>@​frostming</code></a> made their first contribution in <a href=""https://redirect.github.com/pypa/packaging/pull/888"">pypa/packaging#888</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/pypa/packaging/compare/24.2...25.0"">https://github.com/pypa/packaging/compare/24.2...25.0</a></p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/packaging/blob/main/CHANGELOG.rst"">packaging's changelog</a>.</em></p>
<blockquote>
<p>25.0 - 2025-04-19</p>
<pre><code>
* PEP 751: Add support for ``extras`` and ``dependency_groups`` markers. (:issue:`885`)
* PEP 738: Add support for Android platform tags. (:issue:`880`)
<p>24.2 - 2024-11-08<br />
</code></pre></p>
<ul>
<li>PEP 639: Implement License-Expression and License-File (:issue:<code>828</code>)</li>
<li>Use <code>!r</code> formatter for error messages with filenames (:issue:<code>844</code>)</li>
<li>Add support for PEP 730 iOS tags (:issue:<code>832</code>)</li>
<li>Fix prerelease detection for <code>&gt;</code> and <code>&lt;</code> (:issue:<code>794</code>)</li>
<li>Fix uninformative error message (:issue:<code>830</code>)</li>
<li>Refactor <code>canonicalize_version</code> (:issue:<code>793</code>)</li>
<li>Patch python_full_version unconditionally (:issue:<code>825</code>)</li>
<li>Fix doc for <code>canonicalize_version</code> to mention <code>strip_trailing_zero</code> and a typo in a docstring (:issue:<code>801</code>)</li>
<li>Fix typo in Version <code>__str__</code> (:issue:<code>817</code>)</li>
<li>Support creating a <code>SpecifierSet</code> from an iterable of <code>Specifier</code> objects (:issue:<code>775</code>)</li>
</ul>
<p>24.1 - 2024-06-10</p>
<pre><code>
* Document ``markers.default_environment()`` (:issue:`753`).
* Add support for Python 3.13 (:issue:`783`).
* Modernise type annotations (:issue:`785`).
* Work around ``platform.python_version()`` returning non PEP 440 compliant version
  for non-tagged CPython builds (:issue:`802`).
<p>24.0 - 2024-03-10<br />
</code></pre></p>
<ul>
<li>Do specifier matching correctly when the specifier contains an epoch number
and has more components than the version (:issue:<code>683</code>)</li>
<li>Support the experimental <code>--disable-gil</code> builds in packaging.tags
(:issue:<code>727</code>)</li>
<li>BREAKING: Make optional <code>metadata.Metadata</code> attributes default to <code>None</code> (:issue:<code>733</code>)</li>
<li>Fix errors when trying to access the <code>description_content_type</code>, <code>keywords</code>,
and <code>requires_python</code> attributes on <code>metadata.Metadata</code> when those values
have not been provided (:issue:<code>733</code>)</li>
<li>Fix a bug preventing the use of the built in <code>ExceptionGroup</code> on versions of
Python that support it (:issue:<code>725</code>)</li>
</ul>
<p>23.2 - 2023-10-01</p>
<pre><code>
* Document calendar-based versioning scheme (:issue:`716`)
* Enforce that the entire marker string is parsed (:issue:`687`)
* Requirement parsing no longer automatically validates the URL (:issue:`120`)
* Canonicalize names for requirements comparison (:issue:`644`)
&lt;/tr&gt;&lt;/table&gt; 
</code></pre>
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pypa/packaging/commit/f58537628042c7f29780b9d33f31597e7fc9d664""><code>f585376</code></a> Bump for release</li>
<li><a href=""https://github.com/pypa/packaging/commit/600ecea15b2388037b8dc94883504ca612947576""><code>600ecea</code></a> Add changelog entries</li>
<li><a href=""https://github.com/pypa/packaging/commit/3910129009b25dd1aa1fe32e644bc891188c56fe""><code>3910129</code></a> support 'extras' and 'dependency_groups' markers (<a href=""https://redirect.github.com/pypa/packaging/issues/888"">#888</a>)</li>
<li><a href=""https://github.com/pypa/packaging/commit/8e49b4373731bffb110c9583e64ad802cb67c7ea""><code>8e49b43</code></a> Add support for PEP 738 Android tags (<a href=""https://redirect.github.com/pypa/packaging/issues/880"">#880</a>)</li>
<li><a href=""https://github.com/pypa/packaging/commit/e624d8edfaa28865de7b5a7da8bd59fd410e5331""><code>e624d8e</code></a> Bump the github-actions group with 3 updates (<a href=""https://redirect.github.com/pypa/packaging/issues/886"">#886</a>)</li>
<li><a href=""https://github.com/pypa/packaging/commit/71f38d872a6e88b28da9d1b270f8512475bc90d4""><code>71f38d8</code></a> Bump the github-actions group with 2 updates (<a href=""https://redirect.github.com/pypa/packaging/issues/878"">#878</a>)</li>
<li><a href=""https://github.com/pypa/packaging/commit/9b4922dd3c26c8522d716bec79d7e0ed408631c1""><code>9b4922d</code></a> Bump the github-actions group with 3 updates (<a href=""https://redirect.github.com/pypa/packaging/issues/870"">#870</a>)</li>
<li><a href=""https://github.com/pypa/packaging/commit/8510bd9d3bab5571974202ec85f6ef7b0359bfaf""><code>8510bd9</code></a> Upgrade to ruff 0.9.1 (<a href=""https://redirect.github.com/pypa/packaging/issues/865"">#865</a>)</li>
<li><a href=""https://github.com/pypa/packaging/commit/9375ec2eff48257967c97d331b9a76019e95bdb0""><code>9375ec2</code></a> Re-add tests for Unicode file name parsing (<a href=""https://redirect.github.com/pypa/packaging/issues/863"">#863</a>)</li>
<li><a href=""https://github.com/pypa/packaging/commit/2256ed4ac261309a09daa04cc801abd7cff2e6f0""><code>2256ed4</code></a> Bump the github-actions group across 1 directory with 2 updates (<a href=""https://redirect.github.com/pypa/packaging/issues/864"">#864</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/pypa/packaging/compare/20.0...25.0"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20734.org.readthedocs.build/en/20734/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,1,2025-04-21T01:59:28+00:00,2025-04-22T17:43:46+00:00,2025-04-22T17:43:44+00:00,ci;fabric;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3007388904,20733,build(deps): update ipython[all] requirement from <8.15.0 to <8.19.0 in /requirements,"Updates the requirements on [ipython[all]](https://github.com/ipython/ipython) to permit the latest version.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/ipython/ipython/commit/49914f93892640d150cededca16b14b20ce8663d""><code>49914f9</code></a> release 8.18.1</li>
<li><a href=""https://github.com/ipython/ipython/commit/e1c4eefc235f5222a4112bc2f922f31dd4d72dcb""><code>e1c4eef</code></a> Pin prompt_toolkit to 3.0.41+ (<a href=""https://redirect.github.com/ipython/ipython/issues/14257"">#14257</a>)</li>
<li><a href=""https://github.com/ipython/ipython/commit/965f989a21e436b06e1520843885afca2d452a35""><code>965f989</code></a> Pin prompt_toolkit to 3.0.41+</li>
<li><a href=""https://github.com/ipython/ipython/commit/c293abc5cebd8d3ee1a09221043a88a8f8ac7d39""><code>c293abc</code></a> back to dev</li>
<li><a href=""https://github.com/ipython/ipython/commit/928881c53ca837390c001e972ed2945c3309f9f3""><code>928881c</code></a> release 8.18.0</li>
<li><a href=""https://github.com/ipython/ipython/commit/4897500b0582a3ba9da61cc6cd21fef3901c9e5a""><code>4897500</code></a> whats new 8.18.0 (<a href=""https://redirect.github.com/ipython/ipython/issues/14253"">#14253</a>)</li>
<li><a href=""https://github.com/ipython/ipython/commit/d563354c03ce8721ef0b5c5e66186d9fa74bfa8b""><code>d563354</code></a> whats new 8.18.0</li>
<li><a href=""https://github.com/ipython/ipython/commit/c0a699d1432d72e687d407c3424aaf26dbff0e49""><code>c0a699d</code></a> Fix memory leak in Qt event loop integration (<a href=""https://redirect.github.com/ipython/ipython/issues/14240"">#14240</a>) (<a href=""https://redirect.github.com/ipython/ipython/issues/14251"">#14251</a>)</li>
<li><a href=""https://github.com/ipython/ipython/commit/c7aea08fe305f667e101fbde50cd3be5aec57fa1""><code>c7aea08</code></a> Fix pickleshare warning on completion (<a href=""https://redirect.github.com/ipython/ipython/issues/14252"">#14252</a>)</li>
<li><a href=""https://github.com/ipython/ipython/commit/ec51c50f300de0eb94548582888796102ff2872a""><code>ec51c50</code></a> Silence PickleShare warnings when completing root modules.</li>
<li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/rel-0.8.4...8.18.1"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20733.org.readthedocs.build/en/20733/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,0,2025-04-21T01:59:23+00:00,2025-04-22T09:05:19+00:00,2025-04-22T09:05:18+00:00,ci;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3007388691,20732,build(deps): bump pytest from 7.4.0 to 8.3.5 in /requirements,"Bumps [pytest](https://github.com/pytest-dev/pytest) from 7.4.0 to 8.3.5.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pytest-dev/pytest/releases"">pytest's releases</a>.</em></p>
<blockquote>
<h2>8.3.5</h2>
<h1>pytest 8.3.5 (2025-03-02)</h1>
<h2>Bug fixes</h2>
<ul>
<li><a href=""https://redirect.github.com/pytest-dev/pytest/issues/11777"">#11777</a>: Fixed issue where sequences were still being shortened even with <code>-vv</code> verbosity.</li>
<li><a href=""https://redirect.github.com/pytest-dev/pytest/issues/12888"">#12888</a>: Fixed broken input when using Python 3.13+ and a <code>libedit</code> build of Python, such as on macOS or with uv-managed Python binaries from the <code>python-build-standalone</code> project. This could manifest e.g. by a broken prompt when using <code>Pdb</code>, or seeing empty inputs with manual usage of <code>input()</code> and suspended capturing.</li>
<li><a href=""https://redirect.github.com/pytest-dev/pytest/issues/13026"">#13026</a>: Fixed <code>AttributeError</code>{.interpreted-text role=&quot;class&quot;} crash when using <code>--import-mode=importlib</code> when top-level directory same name as another module of the standard library.</li>
<li><a href=""https://redirect.github.com/pytest-dev/pytest/issues/13053"">#13053</a>: Fixed a regression in pytest 8.3.4 where, when using <code>--import-mode=importlib</code>, a directory containing py file with the same name would cause an <code>ImportError</code></li>
<li><a href=""https://redirect.github.com/pytest-dev/pytest/issues/13083"">#13083</a>: Fixed issue where pytest could crash if one of the collected directories got removed during collection.</li>
</ul>
<h2>Improved documentation</h2>
<ul>
<li>
<p><a href=""https://redirect.github.com/pytest-dev/pytest/issues/12842"">#12842</a>: Added dedicated page about using types with pytest.</p>
<p>See <code>types</code>{.interpreted-text role=&quot;ref&quot;} for detailed usage.</p>
</li>
</ul>
<h2>Contributor-facing changes</h2>
<ul>
<li><a href=""https://redirect.github.com/pytest-dev/pytest/issues/13112"">#13112</a>: Fixed selftest failures in <code>test_terminal.py</code> with Pygments &gt;= 2.19.0</li>
<li><a href=""https://redirect.github.com/pytest-dev/pytest/issues/13256"">#13256</a>: Support for Towncrier versions released in 2024 has been re-enabled
when building Sphinx docs -- by <code>webknjaz</code>{.interpreted-text role=&quot;user&quot;}.</li>
</ul>
<h2>8.3.4</h2>
<h1>pytest 8.3.4 (2024-12-01)</h1>
<h2>Bug fixes</h2>
<ul>
<li>
<p><a href=""https://redirect.github.com/pytest-dev/pytest/issues/12592"">#12592</a>: Fixed <code>KeyError</code>{.interpreted-text role=&quot;class&quot;} crash when using <code>--import-mode=importlib</code> in a directory layout where a directory contains a child directory with the same name.</p>
</li>
<li>
<p><a href=""https://redirect.github.com/pytest-dev/pytest/issues/12818"">#12818</a>: Assertion rewriting now preserves the source ranges of the original instructions, making it play well with tools that deal with the <code>AST</code>, like <a href=""https://github.com/alexmojaki/executing"">executing</a>.</p>
</li>
<li>
<p><a href=""https://redirect.github.com/pytest-dev/pytest/issues/12849"">#12849</a>: ANSI escape codes for colored output now handled correctly in <code>pytest.fail</code>{.interpreted-text role=&quot;func&quot;} with [pytrace=False]{.title-ref}.</p>
</li>
<li>
<p><a href=""https://redirect.github.com/pytest-dev/pytest/issues/9353"">#9353</a>: <code>pytest.approx</code>{.interpreted-text role=&quot;func&quot;} now uses strict equality when given booleans.</p>
</li>
</ul>
<h2>Improved documentation</h2>
<ul>
<li>
<p><a href=""https://redirect.github.com/pytest-dev/pytest/issues/10558"">#10558</a>: Fix ambiguous docstring of <code>pytest.Config.getoption</code>{.interpreted-text role=&quot;func&quot;}.</p>
</li>
<li>
<p><a href=""https://redirect.github.com/pytest-dev/pytest/issues/10829"">#10829</a>: Improve documentation on the current handling of the <code>--basetemp</code> option and its lack of retention functionality (<code>temporary directory location and retention</code>{.interpreted-text role=&quot;ref&quot;}).</p>
</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pytest-dev/pytest/commit/b55ab2aabb68c0ce94c3903139b062d0c2790152""><code>b55ab2a</code></a> Prepare release version 8.3.5</li>
<li><a href=""https://github.com/pytest-dev/pytest/commit/e217726d2a0edfaf58eae95bf835b85834b96da3""><code>e217726</code></a> Added dedicated page about using types with pytest <a href=""https://redirect.github.com/pytest-dev/pytest/issues/12842"">#12842</a> (<a href=""https://redirect.github.com/pytest-dev/pytest/issues/12963"">#12963</a>) (<a href=""https://redirect.github.com/pytest-dev/pytest/issues/13260"">#13260</a>)</li>
<li><a href=""https://github.com/pytest-dev/pytest/commit/2fa3f8306c3da4aad7f7349a4947ac37ba6c652f""><code>2fa3f83</code></a> Add more resources and studies to flaky tests page in docs (<a href=""https://redirect.github.com/pytest-dev/pytest/issues/13250"">#13250</a>) (<a href=""https://redirect.github.com/pytest-dev/pytest/issues/13259"">#13259</a>)</li>
<li><a href=""https://github.com/pytest-dev/pytest/commit/e5c2efe3c36199731b41fd68bbf4df5e21404a8b""><code>e5c2efe</code></a> Merge pull request <a href=""https://redirect.github.com/pytest-dev/pytest/issues/13256"">#13256</a> from webknjaz/maintenance/towncrier-bump (<a href=""https://redirect.github.com/pytest-dev/pytest/issues/13258"">#13258</a>)</li>
<li><a href=""https://github.com/pytest-dev/pytest/commit/3419674225a3a7b7d6f93650d75f6de52fe637d5""><code>3419674</code></a> Merge pull request <a href=""https://redirect.github.com/pytest-dev/pytest/issues/13187"">#13187</a> from pytest-dev/patchback/backports/8.3.x/b4009b319...</li>
<li><a href=""https://github.com/pytest-dev/pytest/commit/b75cfb162dbb927739698effa3fbcf279655da49""><code>b75cfb1</code></a> Add readline workaround for libedit (<a href=""https://redirect.github.com/pytest-dev/pytest/issues/13176"">#13176</a>)</li>
<li><a href=""https://github.com/pytest-dev/pytest/commit/edbfff72a4051ed9c5f3d9b5d6f316b407cb6961""><code>edbfff7</code></a> doc: Clarify capturing .readouterr() return value (<a href=""https://redirect.github.com/pytest-dev/pytest/issues/13222"">#13222</a>) (<a href=""https://redirect.github.com/pytest-dev/pytest/issues/13225"">#13225</a>)</li>
<li><a href=""https://github.com/pytest-dev/pytest/commit/2ebba0063c66b77a7bd171221de059f3b3e47b86""><code>2ebba00</code></a> Merge pull request <a href=""https://redirect.github.com/pytest-dev/pytest/issues/13199"">#13199</a> from jakkdl/tox_docs_no_fetch (<a href=""https://redirect.github.com/pytest-dev/pytest/issues/13200"">#13200</a>)</li>
<li><a href=""https://github.com/pytest-dev/pytest/commit/eb6496b79759f9acde581ed9d7a0777a49b5f820""><code>eb6496b</code></a> doc: Change training to remote only (<a href=""https://redirect.github.com/pytest-dev/pytest/issues/13196"">#13196</a>) (<a href=""https://redirect.github.com/pytest-dev/pytest/issues/13197"">#13197</a>)</li>
<li><a href=""https://github.com/pytest-dev/pytest/commit/78cf1f67f707fc07372a89775fd10d2065b5f17a""><code>78cf1f6</code></a> ci: Bump build-and-inspect-python-package (<a href=""https://redirect.github.com/pytest-dev/pytest/issues/13188"">#13188</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest/compare/7.4.0...8.3.5"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest&package-manager=pip&previous-version=7.4.0&new-version=8.3.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20732.org.readthedocs.build/en/20732/

<!-- readthedocs-preview pytorch-lightning end -->",dependabot[bot],49699333,closed,False,3,2025-04-21T01:59:07+00:00,2025-04-22T19:11:48+00:00,2025-04-22T19:11:11+00:00,ci;fabric;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3007019195,20731,fix: `overfit_batches` uses same batch for train and val,"Here's a commit message in the requested format for our changes:

## What does this PR do?

This PR fixes the issue where `overfit_batches=1` uses different batches for training and validation. It ensures that the same batch is used for both training and validation steps when overfitting.

Fixes #15021

### Key Changes:
- Modified `_resolve_overfit_batches` to use the same batch for both training and validation
- Added comprehensive test to verify identical batches are used
- Added TensorFlow and TPU-related environment variables to test allowlist
- Fixed test failures related to environment variable leaks

### Before submitting

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
  - Yes, discussed in #15021
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
  - No documentation changes needed as this fixes a bug in existing functionality
- Did you write any **new necessary tests**? (not for typos and docs)
  - Yes, added test to verify identical batches are used
- [x] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
  - No breaking changes
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)
  - Yes, will add entry for overfit_batches fix

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [x] Check that all items from **Before submitting** are resolved
- [x] Make sure the title is self-explanatory and the description concisely explains the PR
- [x] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Yes, it was interesting to work on fixing the overfit_batches behavior and ensuring consistent batch usage! 🙃

-->

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20731.org.readthedocs.build/en/20731/

<!-- readthedocs-preview pytorch-lightning end -->
",ved1beta,146507396,open,False,5,2025-04-20T13:22:44+00:00,2025-04-28T16:19:46+00:00,,docs;pl,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3006993794,20730,Cpu memory accumulation bug,"## What does this PR do?

This PR addresses the memory leak issue during prediction in PyTorch Lightning. It adds proper memory management when `return_predictions=False` and includes comprehensive tests to verify the fix.

Fixes #19398

### Key Changes:
- Added garbage collection in prediction loop when `return_predictions=False`
- Implemented memory leak tests with large dataset simulation
- Added environment variable cleanup in tests
- Fixed pre-commit formatting issues

### Before submitting

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
  - Yes, discussed in #19398
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
  - No documentation changes needed
- Did you write any **new necessary tests**? (not for typos and docs)
  - Yes, added memory leak tests
- [x] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
  - No breaking changes
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)
  - Yes, will add entry for memory leak fix

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [x] Check that all items from **Before submitting** are resolved
- [x] Make sure the title is self-explanatory and the description concisely explains the PR
- [x] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Yes, it was interesting to work on memory optimization and testing! 🙃

-->

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20730.org.readthedocs.build/en/20730/

<!-- readthedocs-preview pytorch-lightning end -->",ved1beta,146507396,open,False,1,2025-04-20T12:26:31+00:00,2025-04-23T04:49:55+00:00,,pl,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3005729952,20729,Allow one to skip training steps during distributed training,"## What does this PR do?

* Allows one to skip training steps during distributed training once again, this time issuing a warning instead of raising an exception.

Adjusts https://github.com/Lightning-AI/pytorch-lightning/pull/19918.

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [ ] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [ ] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [x] Check that all items from **Before submitting** are resolved
- [x] Make sure the title is self-explanatory and the description concisely explains the PR
- [x] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20729.org.readthedocs.build/en/20729/

<!-- readthedocs-preview pytorch-lightning end -->",amorehead,7051982,closed,False,1,2025-04-18T20:51:53+00:00,2025-05-03T21:05:40+00:00,2025-05-03T21:05:39+00:00,waiting on author;pl,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3005504164,20728,"build(deps): bump `torch` from 2.5.1 to 2.6.0 & `torchvision` from <0.21.0,>=0.16.0 to >=0.16.0,<0.22.0 in /requirements","Bumps [torch](https://github.com/pytorch/pytorch) from 2.5.1 to 2.6.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pytorch/pytorch/releases"">torch's releases</a>.</em></p>
<blockquote>
<h2>PyTorch 2.6.0 Release</h2>
<ul>
<li>Highlights</li>
<li>Tracked Regressions</li>
<li>Backwards Incompatible Change</li>
<li>Deprecations</li>
<li>New Features</li>
<li>Improvements</li>
<li>Bug fixes</li>
<li>Performance</li>
<li>Documentation</li>
<li>Developers</li>
</ul>
<h2><strong>Highlights</strong></h2>
<p>We are excited to announce the release of PyTorch® 2.6 (<a href=""https://github.com/pytorch/pytorch/releases/tag/v2.6.0"">release notes</a>)! This release features multiple improvements for PT2: <code>torch.compile</code> can now be used with Python 3.13; new performance-related knob <code>torch.compiler.set_stance</code>; several AOTInductor enhancements. Besides the PT2 improvements, another highlight is FP16 support on X86 CPUs.</p>
<p>NOTE: Starting with this release we are not going to publish on Conda, please see <a href=""https://redirect.github.com/pytorch/pytorch/issues/138506"">[Announcement] Deprecating PyTorch’s official Anaconda channel</a> for the details.</p>
<p>For this release the experimental Linux binaries shipped with CUDA 12.6.3 (as well as Linux Aarch64,  Linux ROCm 6.2.4, and Linux XPU binaries) are built with CXX11_ABI=1 and are <a href=""https://dev-discuss.pytorch.org/t/pytorch-linux-wheels-switching-to-new-wheel-build-platform-manylinux-2-28-on-november-12-2024/2581"">using the Manylinux 2.28 build platform</a>. If you build PyTorch extensions with custom C++ or CUDA extensions, please update these builds to use CXX_ABI=1 as well and report any issues you are seeing. For the next PyTorch 2.7 release we plan to switch all Linux builds to Manylinux 2.28 and CXX11_ABI=1, please see <a href=""https://redirect.github.com/pytorch/pytorch/issues/123649"">[RFC] PyTorch next wheel build platform: manylinux-2.28</a> for the details and discussion.</p>
<p>Also in this release as an important security improvement measure we have changed the default value for <code>weights_only</code> parameter of <code>torch.load</code>. This is a backward compatibility-breaking change, please see <a href=""https://dev-discuss.pytorch.org/t/bc-breaking-change-torch-load-is-being-flipped-to-use-weights-only-true-by-default-in-the-nightlies-after-137602/2573"">this forum post</a> for more details.</p>
<p>This release is composed of 3892 commits from 520 contributors since PyTorch 2.5. We want to sincerely thank our dedicated community for your contributions. As always, we encourage you to try these out and report any issues as we improve PyTorch. More information about how to get started with the PyTorch 2-series can be found at our <a href=""https://pytorch.org/get-started/pytorch-2.0/"">Getting Started</a> page.</p>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pytorch/pytorch/commit/1eba9b3aa3c43f86f4a2c807ac8e12c4a7767340""><code>1eba9b3</code></a> change the test wheel to release wheel when release wheel available (<a href=""https://redirect.github.com/pytorch/pytorch/issues/145884"">#145884</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/2236df1770800ffea5697b11b0bb0d910b2e59e1""><code>2236df1</code></a> [CUDA] Change slim-wheel libraries load order (<a href=""https://redirect.github.com/pytorch/pytorch/issues/145662"">#145662</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/32070409668513144e48390380a3911fc5cd03e0""><code>3207040</code></a> [CD] Fix slim-wheel cuda_nvrtc import problem (<a href=""https://redirect.github.com/pytorch/pytorch/issues/145614"">#145614</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/ca3c3a63b8087d405babf95fcce263cf1b8dd35e""><code>ca3c3a6</code></a> [Release-Only] Remove ptx from Linux CUDA 12.6 binary builds (<a href=""https://redirect.github.com/pytorch/pytorch/issues/145616"">#145616</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/7be6b5db475a5885379751953f67656ca1ce6edd""><code>7be6b5d</code></a> Fix IdentationError of code example (<a href=""https://redirect.github.com/pytorch/pytorch/issues/145525"">#145525</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/dcb8ad070f15e8444dcb4e415bde38142cda5e9d""><code>dcb8ad0</code></a> update get start xpu (<a href=""https://redirect.github.com/pytorch/pytorch/issues/145286"">#145286</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/8d4b8a920a2172523deb95bf20e8e52d50649c04""><code>8d4b8a9</code></a> Prevent legacy_load when weights_only=True (correctly) (<a href=""https://redirect.github.com/pytorch/pytorch/issues/145111"">#145111</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/9c34a2076b37c040b1b9a48b729656fe9e992949""><code>9c34a20</code></a> Revert &quot;Prevent _legacy_load with weights_only=True (<a href=""https://redirect.github.com/pytorch/pytorch/issues/144993"">#144993</a>)&quot;</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/cd15d7b29fea0886d1ae655da9bec767caa8c672""><code>cd15d7b</code></a> Prevent _legacy_load with weights_only=True (<a href=""https://redirect.github.com/pytorch/pytorch/issues/144993"">#144993</a>)</li>
<li><a href=""https://github.com/pytorch/pytorch/commit/a2639bc255cd9eb93250c3bd1aea01f74538ad76""><code>a2639bc</code></a> [Release/2.6] Enable python-3.13t aarch64 builds (<a href=""https://redirect.github.com/pytorch/pytorch/issues/144878"">#144878</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/pytorch/pytorch/compare/v2.5.1...v2.6.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=torch&package-manager=pip&previous-version=2.5.1&new-version=2.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/Lightning-AI/pytorch-lightning/network/alerts).

</details>

<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20728.org.readthedocs.build/en/20728/

<!-- readthedocs-preview pytorch-lightning end -->

cc @borda @lantiga @justusschock",dependabot[bot],49699333,closed,False,3,2025-04-18T18:19:48+00:00,2025-04-23T09:29:10+00:00,2025-04-23T09:28:36+00:00,ready;ci;fabric;pl;dependencies,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3003669869,20726,Incorrect `.hparams` when using `LightningCLI` with `Callable`,"### Bug description

The `.hparams` attribute of a `Lightning(Data)Module` should store the hyperparameters passed for its initialization. However, when using the `LightningCLI` it seems that it stores a `dict` (config-like) object instead of the instantiated object.


### What version are you seeing the problem on?

v2.5

### How to reproduce the bug

```python
# litmodel.py
import torch
import lightning as L
from collections.abc import Callable


class Model(L.LightningModule):
    def __init__(self, mycallable: Callable):
        super().__init__()
        self.save_hyperparameters()

        print(self.hparams)
        exit()

    def traininig_step(self, batch, batch_idx):
        pass
    
    def configure_optimizers(self):
        pass


if __name__ == '__main__':
    Model(torch.nn.Identity())
```

```python
# main.py
from lightning.pytorch.cli import LightningCLI
from litmodel import Model
from lightning.pytorch.demos.boring_classes import BoringDataModule


def cli_main():
    return LightningCLI(Model, BoringDataModule)


if __name__ == '__main__':
    cli_main()
```

```yaml
# config.yaml
model:
  mycallable:
    class_path: torch.nn.Identity
```

### Error messages and logs

```
$ python litmodel.py 
/home/asarikas/venvir/common/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'mycallable' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['mycallable'])`.
""mycallable"": Identity()
```

```
$ python main.py fit -c config.yaml
/home/asarikas/venvir/common/lib/python3.12/site-packages/lightning/fabric/utilities/seed.py:42: No seed found, seed set to 0
Seed set to 0
""_instantiator"": lightning.pytorch.cli.instantiate_module
""mycallable"":    {'class_path': 'torch.nn.Identity'}

```


### Environment

/home/asarikas/temp/lightning_cli_bug/collect_env_details.py:24: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
  import pkg_resources
<details>
  <summary>Current environment</summary>

* CUDA:
	- GPU:
		- NVIDIA GeForce RTX 4090
	- available:         True
	- version:           12.4
* Lightning:
	- lightning:         2.5.0.post0
	- lightning-utilities: 0.11.9
	- pytorch-lightning: 2.5.0.post0
	- pytorch3d:         0.7.8
	- torch:             2.5.1
	- torch-geometric:   2.6.1
	- torchmetrics:      1.6.1
	- torchvision:       0.20.1
* Packages:
	- absl-py:           2.1.0
	- aenum:             3.1.15
	- aidsorb:           1.0.1.dev59+g0187fc7
	- aiohappyeyeballs:  2.4.4
	- aiohttp:           3.11.11
	- aiosignal:         1.3.2
	- annotated-types:   0.7.0
	- antlr4-python3-runtime: 4.9.3
	- anyio:             4.7.0
	- argon2-cffi:       23.1.0
	- argon2-cffi-bindings: 21.2.0
	- arrow:             1.3.0
	- ase:               3.23.0
	- astroid:           3.3.8
	- asttokens:         3.0.0
	- async-lru:         2.0.4
	- attrs:             24.3.0
	- autocommand:       2.2.2
	- babel:             2.16.0
	- backports.tarfile: 1.2.0
	- beautifulsoup4:    4.12.3
	- bleach:            6.2.0
	- bokeh-sampledata:  2024.2
	- certifi:           2024.12.14
	- cffi:              1.17.1
	- charset-normalizer: 3.4.1
	- comm:              0.2.2
	- contourpy:         1.3.1
	- cycler:            0.12.1
	- debugpy:           1.8.11
	- decorator:         5.1.1
	- defusedxml:        0.7.1
	- dill:              0.3.9
	- docstring-parser:  0.16
	- et-xmlfile:        2.0.0
	- executing:         2.1.0
	- fastjsonschema:    2.21.1
	- filelock:          3.16.1
	- fire:              0.7.0
	- fonttools:         4.55.3
	- fqdn:              1.5.1
	- frozenlist:        1.5.0
	- fsspec:            2024.12.0
	- grpcio:            1.70.0
	- h11:               0.14.0
	- httpcore:          1.0.7
	- httpx:             0.28.1
	- hydra-core:        1.3.2
	- icalendar:         6.1.0
	- idna:              3.10
	- importlib-metadata: 8.0.0
	- importlib-resources: 6.5.2
	- inflect:           7.3.1
	- iopath:            0.1.10
	- ipykernel:         6.29.5
	- ipython:           8.31.0
	- ipywidgets:        8.1.5
	- isoduration:       20.11.0
	- isort:             6.0.0
	- jaraco.collections: 5.1.0
	- jaraco.context:    5.3.0
	- jaraco.functools:  4.0.1
	- jaraco.text:       3.12.1
	- jedi:              0.19.2
	- jinja2:            3.1.5
	- joblib:            1.4.2
	- json5:             0.10.0
	- jsonargparse:      4.37.0
	- jsonpointer:       3.0.0
	- jsonschema:        4.23.0
	- jsonschema-specifications: 2024.10.1
	- jupyter-client:    8.6.3
	- jupyter-core:      5.7.2
	- jupyter-events:    0.11.0
	- jupyter-lsp:       2.2.5
	- jupyter-server:    2.15.0
	- jupyter-server-proxy: 4.4.0
	- jupyter-server-terminals: 0.5.3
	- jupyterlab:        4.3.4
	- jupyterlab-pygments: 0.3.0
	- jupyterlab-server: 2.27.3
	- jupyterlab-vim:    4.1.4
	- jupyterlab-widgets: 3.0.13
	- kiwisolver:        1.4.8
	- latexcodec:        3.0.0
	- lightly:           1.5.19
	- lightly-utils:     0.0.2
	- lightning:         2.5.0.post0
	- lightning-utilities: 0.11.9
	- llvmlite:          0.44.0
	- markdown:          3.7
	- markupsafe:        3.0.2
	- matplotlib:        3.10.0
	- matplotlib-inline: 0.1.7
	- mccabe:            0.7.0
	- mistune:           3.1.0
	- mofdb-client:      0.10.0
	- mofx2csv:          0.1.dev4+g07b461f
	- monty:             2025.1.9
	- more-itertools:    10.6.0
	- mpmath:            1.3.0
	- msgpack:           1.1.0
	- multidict:         6.1.0
	- nbclient:          0.10.2
	- nbconvert:         7.16.5
	- nbformat:          5.10.4
	- nest-asyncio:      1.6.0
	- networkx:          3.4.2
	- notebook-shim:     0.2.4
	- numba:             0.61.0
	- numpy:             1.26.4
	- nvidia-cublas-cu12: 12.4.5.8
	- nvidia-cuda-cupti-cu12: 12.4.127
	- nvidia-cuda-nvrtc-cu12: 12.4.127
	- nvidia-cuda-runtime-cu12: 12.4.127
	- nvidia-cudnn-cu12: 9.1.0.70
	- nvidia-cufft-cu12: 11.2.1.3
	- nvidia-curand-cu12: 10.3.5.147
	- nvidia-cusolver-cu12: 11.6.1.9
	- nvidia-cusparse-cu12: 12.3.1.170
	- nvidia-nccl-cu12:  2.21.5
	- nvidia-nvjitlink-cu12: 12.4.127
	- nvidia-nvtx-cu12:  12.4.127
	- omegaconf:         2.3.0
	- openpyxl:          3.1.5
	- overrides:         7.7.0
	- packaging:         24.2
	- palettable:        3.3.3
	- pandas:            2.2.3
	- pandocfilters:     1.5.1
	- parso:             0.8.4
	- pexpect:           4.9.0
	- pillow:            11.1.0
	- pip:               25.0.1
	- platformdirs:      4.3.6
	- plotly:            5.24.1
	- pooch:             1.8.2
	- portalocker:       3.1.1
	- prometheus-client: 0.21.1
	- prompt-toolkit:    3.0.48
	- propcache:         0.2.1
	- protobuf:          5.29.3
	- psutil:            6.1.1
	- ptyprocess:        0.7.0
	- pure-eval:         0.2.3
	- pybtex:            0.24.0
	- pycparser:         2.22
	- pycryptodome:      3.21.0
	- pydantic:          2.10.6
	- pydantic-core:     2.27.2
	- pygments:          2.18.0
	- pylint:            3.3.4
	- pymatgen:          2025.1.9
	- pymatviz:          0.15.0
	- pymoxel:           0.4.0
	- pynndescent:       0.5.13
	- pyparsing:         3.2.1
	- python-dateutil:   2.9.0.post0
	- python-json-logger: 3.2.1
	- pytorch-lightning: 2.5.0.post0
	- pytorch3d:         0.7.8
	- pytz:              2024.2
	- pyvista:           0.44.2
	- pyyaml:            6.0.2
	- pyzmq:             26.2.0
	- referencing:       0.35.1
	- requests:          2.32.3
	- retnext:           0.1.dev1+gef403b0
	- rfc3339-validator: 0.1.4
	- rfc3986-validator: 0.1.1
	- roma:              1.5.1
	- rpds-py:           0.22.3
	- ruamel.yaml:       0.18.10
	- ruamel.yaml.clib:  0.2.12
	- scikit-learn:      1.6.1
	- scipy:             1.15.0
	- scooby:            0.10.0
	- seaborn:           0.13.2
	- send2trash:        1.8.3
	- sentry-sdk:        1.45.1
	- setuptools:        78.0.2
	- simpervisor:       1.0.0
	- six:               1.17.0
	- sniffio:           1.3.1
	- soupsieve:         2.6
	- spglib:            2.5.0
	- stack-data:        0.6.3
	- stream-inflate:    0.0.41
	- stream-unzip:      0.0.99
	- sympy:             1.13.1
	- tabulate:          0.9.0
	- tenacity:          9.0.0
	- tensorboard:       2.19.0
	- tensorboard-data-server: 0.7.2
	- termcolor:         2.5.0
	- terminado:         0.18.1
	- threadpoolctl:     3.5.0
	- tinycss2:          1.4.0
	- tomli:             2.0.1
	- tomlkit:           0.13.2
	- torch:             2.5.1
	- torch-geometric:   2.6.1
	- torchmetrics:      1.6.1
	- torchvision:       0.20.1
	- tornado:           6.4.2
	- tqdm:              4.67.1
	- traitlets:         5.14.3
	- trame:             3.8.1
	- trame-client:      3.6.1
	- trame-server:      3.4.0
	- trame-vtk:         2.8.15
	- trame-vuetify:     2.9.0
	- triton:            3.1.0
	- typeguard:         4.3.0
	- types-python-dateutil: 2.9.0.20241206
	- typeshed-client:   2.7.0
	- typing-extensions: 4.12.2
	- tzdata:            2024.2
	- umap-learn:        0.5.7
	- uncertainties:     3.2.2
	- uri-template:      1.3.0
	- urllib3:           2.3.0
	- vtk:               9.3.1
	- wcwidth:           0.2.13
	- webcolors:         24.11.1
	- webencodings:      0.5.1
	- websocket-client:  1.8.0
	- werkzeug:          3.1.3
	- wheel:             0.45.1
	- widgetsnbextension: 4.0.13
	- wslink:            2.3.3
	- xyzservices:       2024.9.0
	- yarl:              1.18.3
	- zipp:              3.19.2
* System:
	- OS:                Linux
	- architecture:
		- 64bit
		- ELF
	- processor:         
	- python:            3.12.7
	- release:           6.12.4-arch1-1
	- version:           #1 SMP PREEMPT_DYNAMIC Mon, 09 Dec 2024 14:31:57 +0000

</details>

### More info

_No response_",adosar,110358278,open,False,2,2025-04-18T00:29:40+00:00,2025-04-30T05:53:01+00:00,,bug;needs triage;ver: 2.5.x,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3001864683,20725,checkpoints do not go to `default_root_dir`,"### 📚 Documentation

The [documentation about check pointing](https://lightning.ai/docs/pytorch/stable/common/checkpointing_basic.html) claims:

> To change the checkpoint path use the default_root_dir argument:
>         \# saves checkpoints to 'some/path/' at every epoch end
>         trainer = Trainer(default_root_dir=""some/path/"")

However, if a logger is configured, the checkpoints go magically to the path of the logger and **not to default_root_dir**:

```py
trainer = L.Trainer(
  max_epochs=EPOCHS,
  logger=CSVLogger(""save_dir"", ""exp_name""),
  default_root_dir=""default_root_dir""
)
trainer.fit(...)
```

![Image](https://github.com/user-attachments/assets/03d91553-88d6-43fb-96ba-e295eac33a57)

It's even more magic when you add several loggers (seems to take the path of the first logger)

I'm missing such thinks in the documentation...

cc @lantiga @borda",turbotimon,57718207,open,False,0,2025-04-17T08:53:27+00:00,2025-04-17T08:54:53+00:00,,docs;needs triage,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3001821172,20724,CSVLogger missing information about yaml,"### 📚 Documentation

The [CSVLogger](https://lightning.ai/docs/pytorch/stable/extensions/generated/lightning.pytorch.loggers.CSVLogger.html) claims to ""Log to local file system in **yaml and CSV** format"" but missing any usually information on how to configure it for yaml?

cc @lantiga @borda",turbotimon,57718207,open,False,0,2025-04-17T08:35:02+00:00,2025-04-17T08:35:25+00:00,,docs;needs triage,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3000628468,20723,hard to read documentation with dark mode,"### 📚 Documentation

![Image](https://github.com/user-attachments/assets/9074eb00-8bf2-4198-820a-cd45cb6eac42)

Going through the first tutorial (https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/01-introduction-to-pytorch.html) and it's very hard to make out the formatted text. I have turned my browsers dark mode off, but the lightning page remains dark and I haven't been able to change this.

cc @lantiga @borda",dominicdill,97637822,open,False,0,2025-04-16T20:05:58+00:00,2025-04-16T20:06:19+00:00,,docs;needs triage,1,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,3000148814,20722,Running LightningCLI from Python cannot pass a config.yaml file,"### Bug description

I want to import my LightningCLI (defined in `main.py`) from a second file `run_multiple_seeds.py` to execute multiple `fit()` runs with each slightly different configurations. As a baseline configuration, I want to have a `config.yaml` file and adjust this in a loop.

Calling the `cli_main()` from Python should be supported as stated [here](https://lightning.ai/docs/pytorch/stable/cli/lightning_cli_advanced_3.html#run-from-python) in the docs. Moreover, the docs state there that:
> All the features that are supported from the command line can be used when giving args as a list of strings. It is also possible to provide a dict or [jsonargparse.Namespace](https://jsonargparse.readthedocs.io/en/stable/#jsonargparse.Namespace).

I interpret this that it also supports parsing the `config.yaml` including any fancy `${other.param}` interpolation.

**Expected behavior**:
1. Calling `main.py` with command line arguments `-c config.yaml fit` successfully fits the model.
2. Calling `run_multiple_seeds.py` without any command line arguments successfully fits the model three times.

**Actual behavior**:
(1) works.

(2): With `failure_mode = ""PASSING_CONFIG_AS_FILE_REFERENCE""`:
This throws a lightning fabric exception `lightning.fabric.utilities.exceptions.MisconfigurationException: No configure_optimizers() method defined`, indicating that the entire `config.yaml` wasn't parsed at all (since this would contain the necessary optimizer configuration).

(2): With `failure_mode = ""PASSING_CONFIG_AS_DICT""`:
This throws an argparse ArgumentError `Expected a <class 'int'>. Got value: ${trainer.max_epochs}`, indicating that the `omegaconf` variable interpolation didn't work on the passed dict.
Note: Replacing `${trainer.max_epochs}` with `5` fixes the issue.

### What version are you seeing the problem on?

v2.4 & 2.5.1

### How to reproduce the bug

**File `main.py`:**
```python
import torch
from lightning import LightningModule
from lightning.pytorch.cli import ArgsType, LightningCLI
from lightning.pytorch.demos.boring_classes import BoringDataModule


class BoringModel(LightningModule):
    def __init__(self, out_dim: int = 10):
        super().__init__()
        self.l1 = torch.nn.Linear(32, out_dim)

    def forward(self, x):
        return torch.relu(self.l1(x.view(x.size(0), -1)))

    def training_step(self, batch, batch_nb):
        x = batch
        x = self(x)
        return x.sum()


class MyLightningCLI(LightningCLI):
    pass


def cli_main(args: ArgsType = None):
    # noinspection PyUnusedLocal
    cli = MyLightningCLI(
        BoringModel,
        BoringDataModule,
        args=args,
        parser_kwargs={""parser_mode"": ""omegaconf""},
        run=args is None,
    )
    return cli


if __name__ == ""__main__"":
    cli_main()
```

**File `run_multiple_seeds.py`:**
```python
import yaml

from main import cli_main

if __name__ == '__main__':
    failure_mode = ""PASSING_CONFIG_AS_FILE_REFERENCE""

    if failure_mode == ""PASSING_CONFIG_AS_DICT"":
        with open(""config.yaml"", ""r"") as f:
            config = yaml.safe_load(f)

    elif failure_mode == ""PASSING_CONFIG_AS_FILE_REFERENCE"":
        config = {""config"": ""config.yaml""}

    for seed in [42, 43, 44]:
        # Modify the seed value in the configuration
        config[""seed_everything""] = seed
        cli = cli_main(args=config)
        cli.trainer.fit(cli.model, cli.datamodule)
```

**File `config.yaml`:**
```yaml
# lightning.pytorch==2.4.0.post0
trainer:
  max_epochs: 5
optimizer:
  class_path: torch.optim.Adam
  init_args:
    lr: 0.003
lr_scheduler:
  class_path: torch.optim.lr_scheduler.CosineAnnealingLR
  init_args:
    T_max: ${trainer.max_epochs}
```

### Error messages and logs

Error with `failure_mode = ""PASSING_CONFIG_AS_DICT""`:
```
2025-04-16 17:54:57,872 - LightningArgumentParser - DEBUG - Loaded parser defaults: Namespace(config=None, seed_everything=True, trainer=Namespace(accelerator='auto', strategy='auto', devices='auto', num_nodes=1, precision=None, logger=None, callbacks=None, fast_dev_run=False, max_epochs=None, min_epochs=None, max_steps=-1, min_steps=None, max_time=None, limit_train_batches=None, limit_val_batches=None, limit_test_batches=None, limit_predict_batches=None, overfit_batches=0.0, val_check_interval=None, check_val_every_n_epoch=1, num_sanity_val_steps=None, log_every_n_steps=None, enable_checkpointing=None, enable_progress_bar=None, enable_model_summary=None, accumulate_grad_batches=1, gradient_clip_val=None, gradient_clip_algorithm=None, deterministic=None, benchmark=None, inference_mode=True, use_distributed_sampler=True, profiler=None, detect_anomaly=False, barebones=False, plugins=None, sync_batchnorm=False, reload_dataloaders_every_n_epochs=0, default_root_dir=None), model=Namespace(out_dim=10), optimizer=None, lr_scheduler=None)
2025-04-16 17:54:57,878 - LightningArgumentParser - DEBUG - Skipping parameter ""params"" from ""torch.optim.Adam.__init__"" because of: Parameter requested to be skipped.
2025-04-16 17:54:57,880 - LightningArgumentParser - DEBUG - Parsed object: Namespace()
2025-04-16 17:54:57,897 - LightningArgumentParser - DEBUG - Skipping parameter ""optimizer"" from ""torch.optim.lr_scheduler.CosineAnnealingLR.__init__"" because of: Parameter requested to be skipped.
2025-04-16 17:54:57,898 - LightningArgumentParser - ERROR - Parser key ""T_max"":
  Expected a <class 'int'>. Got value: ${trainer.max_epochs}
2025-04-16 17:54:57,898 - LightningArgumentParser - ERROR - Parser key ""lr_scheduler"":
  Does not validate against any of the Union subtypes
  Subtypes: [<class 'NoneType'>, <class 'torch.optim.lr_scheduler.LRScheduler'>, <class 'lightning.pytorch.cli.ReduceLROnPlateau'>]
  Errors:
    - Expected a <class 'NoneType'>
    - Problem with given class_path 'torch.optim.lr_scheduler.CosineAnnealingLR':
        Parser key ""T_max"":
          Expected a <class 'int'>. Got value: ${trainer.max_epochs}
    - Import path torch.optim.lr_scheduler.CosineAnnealingLR does not correspond to a subclass of ReduceLROnPlateau
  Given value type: <class 'dict'>
  Given value: {'class_path': 'torch.optim.lr_scheduler.CosineAnnealingLR', 'init_args': {'T_max': '${trainer.max_epochs}'}}
2025-04-16 17:54:57,898 - LightningArgumentParser - DEBUG - Debug enabled, thus raising exception instead of exit.
Traceback (most recent call last):
  File ""C:\my_project\.venv\Lib\site-packages\jsonargparse\_typehints.py"", line 838, in adapt_typehints
    vals.append(adapt_typehints(val, subtype, **adapt_kwargs))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\my_project\.venv\Lib\site-packages\jsonargparse\_typehints.py"", line 787, in adapt_typehints
    raise_unexpected_value(f""Expected a {typehint}"", val)
  File ""C:\my_project\.venv\Lib\site-packages\jsonargparse\_typehints.py"", line 718, in raise_unexpected_value
    raise ValueError(message) from exception
ValueError: Expected a <class 'NoneType'>. Got value: {'class_path': 'torch.optim.lr_scheduler.CosineAnnealingLR', 'init_args': {'T_max': '${trainer.max_epochs}'}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""C:\my_project\.venv\Lib\site-packages\jsonargparse\_typehints.py"", line 597, in _check_type
    raise ex
  File ""C:\my_project\.venv\Lib\site-packages\jsonargparse\_typehints.py"", line 582, in _check_type
    val = adapt_typehints(val, self._typehint, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\my_project\.venv\Lib\site-packages\jsonargparse\_typehints.py"", line 846, in adapt_typehints
    raise_union_unexpected_value(sorted_subtypes, val, vals)
  File ""C:\my_project\.venv\Lib\site-packages\jsonargparse\_typehints.py"", line 725, in raise_union_unexpected_value
    raise ValueError(
ValueError: Does not validate against any of the Union subtypes
Subtypes: [<class 'NoneType'>, <class 'torch.optim.lr_scheduler.LRScheduler'>, <class 'lightning.pytorch.cli.ReduceLROnPlateau'>]
Errors:
  - Expected a <class 'NoneType'>
  - Problem with given class_path 'torch.optim.lr_scheduler.CosineAnnealingLR':
      Parser key ""T_max"":
        Expected a <class 'int'>. Got value: ${trainer.max_epochs}
  - Import path torch.optim.lr_scheduler.CosineAnnealingLR does not correspond to a subclass of ReduceLROnPlateau
Given value type: <class 'dict'>
Given value: {'class_path': 'torch.optim.lr_scheduler.CosineAnnealingLR', 'init_args': {'T_max': '${trainer.max_epochs}'}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""C:\my_project\.venv\Lib\site-packages\jsonargparse\_core.py"", line 505, in parse_object
    cfg_apply = self._apply_actions(cfg_obj, prev_cfg=cfg)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\my_project\.venv\Lib\site-packages\jsonargparse\_core.py"", line 1372, in _apply_actions
    value = self._check_value_key(action, value, action_dest, prev_cfg)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\my_project\.venv\Lib\site-packages\jsonargparse\_core.py"", line 1424, in _check_value_key
    value = action._check_type_(value, cfg=cfg)  # type: ignore[attr-defined]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\my_project\.venv\Lib\site-packages\jsonargparse\_common.py"", line 333, in _check_type_
    return self._check_type(value, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\my_project\.venv\Lib\site-packages\jsonargparse\_typehints.py"", line 610, in _check_type
    raise TypeError(f'Parser key ""{self.dest}""{elem}:\n{error}') from ex
TypeError: Parser key ""lr_scheduler"":
  Does not validate against any of the Union subtypes
  Subtypes: [<class 'NoneType'>, <class 'torch.optim.lr_scheduler.LRScheduler'>, <class 'lightning.pytorch.cli.ReduceLROnPlateau'>]
  Errors:
    - Expected a <class 'NoneType'>
    - Problem with given class_path 'torch.optim.lr_scheduler.CosineAnnealingLR':
        Parser key ""T_max"":
          Expected a <class 'int'>. Got value: ${trainer.max_epochs}
    - Import path torch.optim.lr_scheduler.CosineAnnealingLR does not correspond to a subclass of ReduceLROnPlateau
  Given value type: <class 'dict'>
  Given value: {'class_path': 'torch.optim.lr_scheduler.CosineAnnealingLR', 'init_args': {'T_max': '${trainer.max_epochs}'}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""C:\my_project\run_multiple_seeds.py"", line 18, in <module>
    cli = cli_main(args=config)
          ^^^^^^^^^^^^^^^^^^^^^
  File ""C:\my_project\main.py"", line 27, in cli_main
    cli = MyLightningCLI(
          ^^^^^^^^^^^^^^^
  File ""C:\my_project\.venv\Lib\site-packages\lightning\pytorch\cli.py"", line 383, in __init__
    self.parse_arguments(self.parser, args)
  File ""C:\my_project\.venv\Lib\site-packages\lightning\pytorch\cli.py"", line 532, in parse_arguments
    self.config = parser.parse_object(args)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\my_project\.venv\Lib\site-packages\jsonargparse\_deprecated.py"", line 123, in patched_parse
    cfg = parse_method(*args, _skip_validation=_skip_validation, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\my_project\.venv\Lib\site-packages\jsonargparse\_core.py"", line 518, in parse_object
    self.error(str(ex), ex)
  File ""C:\my_project\.venv\Lib\site-packages\jsonargparse\_core.py"", line 1065, in error
    raise argument_error(message) from ex
argparse.ArgumentError: Parser key ""lr_scheduler"":
  Does not validate against any of the Union subtypes
  Subtypes: [<class 'NoneType'>, <class 'torch.optim.lr_scheduler.LRScheduler'>, <class 'lightning.pytorch.cli.ReduceLROnPlateau'>]
  Errors:
    - Expected a <class 'NoneType'>
    - Problem with given class_path 'torch.optim.lr_scheduler.CosineAnnealingLR':
        Parser key ""T_max"":
          Expected a <class 'int'>. Got value: ${trainer.max_epochs}
    - Import path torch.optim.lr_scheduler.CosineAnnealingLR does not correspond to a subclass of ReduceLROnPlateau
  Given value type: <class 'dict'>
  Given value: {'class_path': 'torch.optim.lr_scheduler.CosineAnnealingLR', 'init_args': {'T_max': '${trainer.max_epochs}'}}
```

---

Error with `failure_mode = ""PASSING_CONFIG_AS_FILE_REFERENCE""`:
```
2025-04-16 18:01:33,959 - LightningArgumentParser - DEBUG - Loaded parser defaults: Namespace(config=None, seed_everything=True, trainer=Namespace(accelerator='auto', strategy='auto', devices='auto', num_nodes=1, precision=None, logger=None, callbacks=None, fast_dev_run=False, max_epochs=None, min_epochs=None, max_steps=-1, min_steps=None, max_time=None, limit_train_batches=None, limit_val_batches=None, limit_test_batches=None, limit_predict_batches=None, overfit_batches=0.0, val_check_interval=None, check_val_every_n_epoch=1, num_sanity_val_steps=None, log_every_n_steps=None, enable_checkpointing=None, enable_progress_bar=None, enable_model_summary=None, accumulate_grad_batches=1, gradient_clip_val=None, gradient_clip_algorithm=None, deterministic=None, benchmark=None, inference_mode=True, use_distributed_sampler=True, profiler=None, detect_anomaly=False, barebones=False, plugins=None, sync_batchnorm=False, reload_dataloaders_every_n_epochs=0, default_root_dir=None), model=Namespace(out_dim=10), optimizer=None, lr_scheduler=None)
2025-04-16 18:01:33,965 - LightningArgumentParser - DEBUG - Parsed object: {'config': 'config.yaml', 'seed_everything': 42}
Seed set to 42
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
C:\my_project\.venv\Lib\site-packages\lightning\pytorch\loops\utilities.py:72: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.
Traceback (most recent call last):
  File ""C:\my_project\run_multiple_seeds.py"", line 23, in <module>
    cli.trainer.fit(cli.model, cli.datamodule)
  File ""C:\my_project\.venv\Lib\site-packages\lightning\pytorch\trainer\trainer.py"", line 538, in fit
    call._call_and_handle_interrupt(
  File ""C:\my_project\.venv\Lib\site-packages\lightning\pytorch\trainer\call.py"", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\my_project\.venv\Lib\site-packages\lightning\pytorch\trainer\trainer.py"", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File ""C:\my_project\.venv\Lib\site-packages\lightning\pytorch\trainer\trainer.py"", line 931, in _run
    _verify_loop_configurations(self)
  File ""C:\my_project\.venv\Lib\site-packages\lightning\pytorch\trainer\configuration_validator.py"", line 36, in _verify_loop_configurations
    __verify_train_val_loop_configuration(trainer, model)
  File ""C:\my_project\.venv\Lib\site-packages\lightning\pytorch\trainer\configuration_validator.py"", line 59, in __verify_train_val_loop_configuration
    raise MisconfigurationException(
lightning.fabric.utilities.exceptions.MisconfigurationException: No `configure_optimizers()` method defined. Lightning `Trainer` expects as minimum a `training_step()`, `train_dataloader()` and `configure_optimizers()` to be defined.
```

### Environment

<details>
  <summary>Current environment</summary>

* CUDA:
	- GPU:
		- NVIDIA GeForce RTX 3060
	- available:         True
	- version:           12.1
* Lightning:
	- lightning:         2.5.1
	- lightning-utilities: 0.11.8
	- pytorch-lightning: 2.4.0
	- pytorch-model-summary: 0.1.2
	- torch:             2.5.1+cu121
	- torchinfo:         1.8.0
	- torchmetrics:      1.5.1
	- torchvision:       0.20.1
* Packages:
	- absl-py:           2.1.0
	- accelerate:        1.1.0
	- aiohappyeyeballs:  2.4.3
	- aiohttp:           3.10.10
	- aiosignal:         1.3.1
	- antlr4-python3-runtime: 4.9.3
	- anyio:             4.6.2.post1
	- argon2-cffi:       23.1.0
	- argon2-cffi-bindings: 21.2.0
	- arrow:             1.3.0
	- asttokens:         3.0.0
	- astunparse:        1.6.3
	- async-lru:         2.0.4
	- attrs:             25.3.0
	- autocommand:       2.2.2
	- babel:             2.16.0
	- backports.tarfile: 1.2.0
	- beautifulsoup4:    4.12.3
	- black:             25.1.0
	- bleach:            6.1.0
	- blinker:           1.9.0
	- boxcutterdata:     3.1.0
	- build:             1.2.2.post1
	- certifi:           2025.1.31
	- cffi:              1.17.1
	- charset-normalizer: 3.4.1
	- click:             8.1.8
	- colorama:          0.4.6
	- comm:              0.2.2
	- configargparse:    1.7
	- contourpy:         1.3.0
	- cycler:            0.12.1
	- dash:              3.0.0
	- dash-core-components: 2.0.0
	- dash-html-components: 2.0.0
	- dash-table:        5.0.0
	- debugpy:           1.8.7
	- decorator:         5.2.1
	- defusedxml:        0.7.1
	- dm-tree:           0.1.8
	- docstring-parser:  0.16
	- etils:             1.10.0
	- executing:         2.2.0
	- fastjsonschema:    2.21.1
	- filelock:          3.16.1
	- flask:             3.0.3
	- flatbuffers:       24.3.25
	- fonttools:         4.54.1
	- fqdn:              1.5.1
	- frozenlist:        1.5.0
	- fsspec:            2024.10.0
	- gast:              0.6.0
	- google-pasta:      0.2.0
	- googleapis-common-protos: 1.66.0
	- grad-cam:          1.5.4
	- grpcio:            1.67.1
	- h11:               0.14.0
	- h5py:              3.12.1
	- httpcore:          1.0.6
	- httpx:             0.27.2
	- huggingface-hub:   0.26.2
	- idna:              3.10
	- imageio:           2.36.1
	- immutabledict:     4.2.1
	- importlib-metadata: 8.6.1
	- importlib-resources: 6.4.5
	- inflect:           7.3.1
	- ipykernel:         6.29.5
	- ipympl:            0.9.4
	- ipynbname:         2024.1.0.0
	- ipython:           9.0.2
	- ipython-genutils:  0.2.0
	- ipython-pygments-lexers: 1.1.1
	- ipywidgets:        8.1.5
	- isoduration:       20.11.0
	- isort:             6.0.1
	- itsdangerous:      2.2.0
	- jaraco.collections: 5.1.0
	- jaraco.context:    5.3.0
	- jaraco.functools:  4.0.1
	- jaraco.text:       3.12.1
	- jedi:              0.19.2
	- jinja2:            3.1.6
	- joblib:            1.4.2
	- json5:             0.9.25
	- jsonargparse:      4.38.0
	- jsonpointer:       3.0.0
	- jsonschema:        4.23.0
	- jsonschema-specifications: 2024.10.1
	- jupyter-client:    8.6.3
	- jupyter-core:      5.7.2
	- jupyter-events:    0.10.0
	- jupyter-lsp:       2.2.5
	- jupyter-server:    2.14.2
	- jupyter-server-terminals: 0.5.3
	- jupyterlab:        4.2.5
	- jupyterlab-pygments: 0.3.0
	- jupyterlab-server: 2.27.3
	- jupyterlab-widgets: 3.0.13
	- jupytext:          1.16.4
	- kagglehub:         0.3.4
	- keras:             3.6.0
	- keras-core:        0.1.7
	- kiwisolver:        1.4.7
	- lazy-loader:       0.4
	- libclang:          18.1.1
	- lightning:         2.5.1
	- lightning-utilities: 0.11.8
	- llvmlite:          0.43.0
	- markdown:          3.7
	- markdown-it-py:    3.0.0
	- markupsafe:        3.0.2
	- matplotlib:        3.9.2
	- matplotlib-inline: 0.1.7
	- mdit-py-plugins:   0.4.2
	- mdurl:             0.1.2
	- mistune:           3.0.2
	- ml-dtypes:         0.4.1
	- more-itertools:    10.3.0
	- mpmath:            1.3.0
	- multidict:         6.1.0
	- mypy-extensions:   1.0.0
	- namex:             0.0.8
	- narwhals:          1.31.0
	- nbclient:          0.10.0
	- nbconvert:         7.16.4
	- nbformat:          5.10.4
	- nest-asyncio:      1.6.0
	- networkx:          3.4.2
	- notebook-shim:     0.2.4
	- numba:             0.60.0
	- numpy:             1.26.4
	- omegaconf:         2.3.0
	- open3d:            0.19.0
	- opencv-python:     4.10.0.84
	- opt-einsum:        3.4.0
	- optree:            0.13.1
	- overrides:         7.7.0
	- packaging:         24.2
	- pandas:            2.2.3
	- pandocfilters:     1.5.1
	- parso:             0.8.4
	- pathspec:          0.12.1
	- pillow:            11.1.0
	- pip:               24.0
	- pip-tools:         7.4.1
	- platformdirs:      4.3.7
	- plotly:            6.0.1
	- prometheus-client: 0.21.0
	- promise:           2.3
	- prompt-toolkit:    3.0.50
	- propcache:         0.2.0
	- protobuf:          5.28.3
	- psutil:            6.1.0
	- pure-eval:         0.2.3
	- pyarrow:           18.0.0
	- pycparser:         2.22
	- pygments:          2.19.1
	- pyparsing:         3.2.0
	- pyproject-hooks:   1.2.0
	- pyqt6:             6.8.1
	- pyqt6-qt6:         6.8.2
	- pyqt6-sip:         13.10.0
	- pyside6-addons:    6.8.0.2
	- pyside6-essentials: 6.8.0.2
	- python-dateutil:   2.9.0.post0
	- python-json-logger: 2.0.7
	- pytorch-lightning: 2.4.0
	- pytorch-model-summary: 0.1.2
	- pytz:              2025.1
	- pywin32:           310
	- pywinpty:          2.0.14
	- pyyaml:            6.0.2
	- pyzmq:             26.2.0
	- referencing:       0.36.2
	- regex:             2024.9.11
	- requests:          2.32.3
	- retrying:          1.3.4
	- rfc3339-validator: 0.1.4
	- rfc3986-validator: 0.1.1
	- rich:              13.9.4
	- rpds-py:           0.23.1
	- safetensors:       0.4.5
	- scikit-image:      0.25.0
	- scikit-learn:      1.5.2
	- scipy:             1.14.1
	- seaborn:           0.13.2
	- send2trash:        1.8.3
	- setuptools:        77.0.3
	- shiboken6:         6.8.0.2
	- simple-parsing:    0.1.6
	- six:               1.17.0
	- sknw:              0.15
	- sniffio:           1.3.1
	- soupsieve:         2.6
	- stack-data:        0.6.3
	- stringcase:        1.2.0
	- sympy:             1.13.1
	- tenacity:          9.0.0
	- tensorboard:       2.18.0
	- tensorboard-data-server: 0.7.2
	- tensorflow:        2.18.0
	- tensorflow-datasets: 4.9.7
	- tensorflow-intel:  2.18.0
	- tensorflow-io-gcs-filesystem: 0.31.0
	- tensorflow-metadata: 1.16.1
	- termcolor:         2.5.0
	- terminado:         0.18.1
	- threadpoolctl:     3.5.0
	- tifffile:          2025.1.10
	- timm:              1.0.11
	- tinycss2:          1.4.0
	- tokenizers:        0.20.1
	- toml:              0.10.2
	- tomli:             2.0.1
	- torch:             2.5.1+cu121
	- torchinfo:         1.8.0
	- torchmetrics:      1.5.1
	- torchvision:       0.20.1
	- tornado:           6.4.1
	- tqdm:              4.66.6
	- traitlets:         5.14.3
	- transformers:      4.46.1
	- ttach:             0.0.3
	- typeguard:         4.3.0
	- types-python-dateutil: 2.9.0.20241003
	- typeshed-client:   2.7.0
	- typing-extensions: 4.12.2
	- tzdata:            2025.1
	- uri-template:      1.3.0
	- urllib3:           2.3.0
	- wcwidth:           0.2.13
	- webcolors:         24.8.0
	- webencodings:      0.5.1
	- websocket-client:  1.8.0
	- werkzeug:          3.0.6
	- wheel:             0.44.0
	- widgetsnbextension: 4.0.13
	- wrapt:             1.16.0
	- yarl:              1.17.1
	- zipp:              3.21.0
	- zivid:             2.13.1.2.13.1
	- zividexploratory:  0.0.1
* System:
	- OS:                Windows
	- architecture:
		- 64bit
		- WindowsPE
	- processor:         Intel64 Family 6 Model 158 Stepping 10, GenuineIntel
	- python:            3.11.9
	- release:           10
	- version:           10.0.22631

</details>",scy-helbling,186681653,closed,False,3,2025-04-16T16:23:55+00:00,2025-04-28T07:29:14+00:00,2025-04-28T07:29:13+00:00,bug;needs triage;ver: 2.4.x,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,2999989221,20721,model update API for checkpointing,"## What does this PR do?

aligning with the next version... for https://github.com/Lightning-AI/LitModels/pull/94

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [ ] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [x] Check that all items from **Before submitting** are resolved
- [x] Make sure the title is self-explanatory and the description concisely explains the PR
- [x] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20721.org.readthedocs.build/en/20721/

<!-- readthedocs-preview pytorch-lightning end -->",Borda,6035284,closed,False,2,2025-04-16T15:21:48+00:00,2025-04-17T17:43:52+00:00,2025-04-17T17:43:10+00:00,pl,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,2999198831,20720,updating issue template,"## What does this PR do?

By required sharing functional/reproducible example we will better understand what is happening and also we can revisit these studios later with each release to validate if the issue still exists...

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [ ] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [x] Check that all items from **Before submitting** are resolved
- [x] Make sure the title is self-explanatory and the description concisely explains the PR
- [x] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20720.org.readthedocs.build/en/20720/

<!-- readthedocs-preview pytorch-lightning end -->

cc @borda @lantiga",Borda,6035284,closed,False,2,2025-04-16T10:27:07+00:00,2025-05-08T14:17:28+00:00,2025-05-08T14:17:26+00:00,ci,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,2998867031,20719,ci: bump dead ubuntu 20.04,"## What does this PR do?

ubuntu 20.04 was removed from all runners so we need to bump to 22.04

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [x] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [x] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [x] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [x] Is this pull request ready for review? (if not, please submit in draft mode)
- [x] Check that all items from **Before submitting** are resolved
- [x] Make sure the title is self-explanatory and the description concisely explains the PR
- [x] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20719.org.readthedocs.build/en/20719/

<!-- readthedocs-preview pytorch-lightning end -->",Borda,6035284,closed,False,2,2025-04-16T08:22:16+00:00,2025-04-16T08:55:17+00:00,2025-04-16T08:54:33+00:00,docs;ci,0,0,0,0,0,0,0
Lightning-AI/pytorch-lightning,2998756808,20718,feat: add tests for `save_hyperparameters` with `ignore` behavior and composition handling,"## What does this PR do?

<!--
Please include a summary of the change and which issue is fixed.
Please also include relevant motivation and context.
List any dependencies that are required for this change.

If we didn't discuss your PR in Github issues there's a high chance it will not be merged.

The following links the related issue to the PR (https://docs.github.com/en/free-pro-team@latest/github/managing-your-work-on-github/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword)
-->

Adds tests to check if `save_hyperparameter` respects `ignore` in `normal` and `composition` mode.

Fixes #19761 
Closes: #20213

<!-- Does your PR introduce any breaking changes? If yes, please list them. -->

<details>
  <summary><b>Before submitting</b></summary>

- Was this **discussed/agreed** via a GitHub issue? (not for typos and docs)
- [ ] Did you read the [contributor guideline](https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md), **Pull Request** section?
- [ ] Did you make sure your **PR does only one thing**, instead of bundling different changes together?
- Did you make sure to **update the documentation** with your changes? (if necessary)
- Did you write any **new necessary tests**? (not for typos and docs)
- [ ] Did you verify new and **existing tests pass** locally with your changes?
- Did you list all the **breaking changes** introduced by this pull request?
- Did you **update the CHANGELOG**? (not for typos, docs, test updates, or minor internal changes/refactors)

<!-- In the CHANGELOG, separate each item in the unreleased section by a blank line to reduce collisions -->

</details>

## PR review

Anyone in the community is welcome to review the PR.
Before you start reviewing, make sure you have read the [review guidelines](https://github.com/Lightning-AI/lightning/wiki/Review-guidelines). In short, see the following bullet-list:

<details>
  <summary>Reviewer checklist</summary>

- [ ] Is this pull request ready for review? (if not, please submit in draft mode)
- [ ] Check that all items from **Before submitting** are resolved
- [ ] Make sure the title is self-explanatory and the description concisely explains the PR
- [ ] Add labels and milestones (and optionally projects) to the PR so it can be classified

</details>

<!--

Did you have fun?

Make sure you had fun coding 🙃

-->


<!-- readthedocs-preview pytorch-lightning start -->
----
📚 Documentation preview 📚: https://pytorch-lightning--20718.org.readthedocs.build/en/20718/

<!-- readthedocs-preview pytorch-lightning end -->",deependujha,76887609,closed,False,0,2025-04-16T07:37:59+00:00,2025-04-17T18:12:44+00:00,2025-04-17T17:46:02+00:00,pl,0,0,0,0,0,0,0
