repo_full_name,issue_id,number,title,body,user_login,user_id,state,locked,comments_count,created_at,updated_at,closed_at,labels,reactions_total,reactions_plus1,reactions_minus1,reactions_laugh,reactions_hooray,reactions_confused,reactions_heart
recommenders-team/recommenders,3055212837,2232,Resolve warnings of Logger library,"### Description
This PR resolves the deprecation warnings of the `logger` library:
```python
DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
```
### Related Issues



### References


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [x] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [x] This PR is being made to `staging branch` AND NOT TO `main branch`.
",emmanuel-ferdman,35470921,closed,False,0,2025-05-11T20:44:56+00:00,2025-05-12T13:35:06+00:00,2025-05-12T13:35:05+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,3048343514,2231,Staging to main: fixed issue with wikidata,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2025-05-08T09:14:11+00:00,2025-05-08T19:01:52+00:00,2025-05-08T19:01:52+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,3039793401,2230,[BUG] Mismatch between the streaming logs that we get from azure-ai-ml and the log file we download at the end,"### Description
<!--- Describe your issue/bug/request in detail -->
See details https://github.com/recommenders-team/recommenders/pull/2223

Also related to https://github.com/recommenders-team/recommenders/issues/2210

We thought we fixed this issue in #2223 but it is still happening. See https://github.com/recommenders-team/recommenders/actions/runs/14809177082/job/41598022202


### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
",miguelgfierro,3491412,open,False,1,2025-05-05T14:06:15+00:00,2025-05-06T05:38:18+00:00,,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,3039746205,2229,Skip wikidata notebooks due to the API being unstable,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2025-05-05T13:50:17+00:00,2025-05-06T05:35:45+00:00,2025-05-06T05:35:41+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,3036266782,2228,Feature/pytorch embedding ranker v4,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",demoncoder-crypto,174311533,open,False,1,2025-05-02T15:15:19+00:00,2025-05-03T08:23:05+00:00,,,0,0,0,0,0,0,0
recommenders-team/recommenders,3035624751,2227,Improve knowledge graph notebook and wikidata function,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
Trying to provide better logging, retries and cache in the notebook and library

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
#2226

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,4,2025-05-02T09:51:02+00:00,2025-05-03T08:27:40+00:00,2025-05-03T08:27:35+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,3021370617,2226,[BUG] Empty result error from wikidata query,"### Description
<!--- Describe your issue/bug/request in detail -->

The error is from running the tests in `tests/data_validation/examples/test_wikidata.py::test_wikidata_runs` and `tests/data_validation/examples/test_wikidata.py::test_wikidata_values` which run the notebook [`examples/01_prepare_data/wikidata_knowledge_graph.ipynb`](https://github.com/recommenders-team/recommenders/blob/main/examples/01_prepare_data/wikidata_knowledge_graph.ipynb).  When [`results_list`](https://github.com/recommenders-team/recommenders/blob/main/examples/01_prepare_data/wikidata_knowledge_graph.ipynb?short_path=1feabc6#L220) is empty, we will get the error.

<img width=""872"" alt=""Screenshot 2025-04-26 at 09 50 02"" src=""https://github.com/user-attachments/assets/295e94ba-babb-4689-bf3c-1ae321a6f3b0"" />

And the same issue occurs in the following code as well when [`result`](https://github.com/recommenders-team/recommenders/blob/main/examples/01_prepare_data/wikidata_knowledge_graph.ipynb?short_path=1feabc6#L487) is empty.

<img width=""817"" alt=""Screenshot 2025-04-26 at 09 59 29"" src=""https://github.com/user-attachments/assets/728e1e79-f766-4164-91f9-fe01820a9cdb"" />


### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->

Create a GitHub Codespace, and run the notebook `examples/01_prepare_data/wikidata_knowledge_graph.ipynb` multiple times until [`results_list`](https://github.com/recommenders-team/recommenders/blob/main/examples/01_prepare_data/wikidata_knowledge_graph.ipynb?short_path=1feabc6#L220) is empty.

<img width=""496"" alt=""Image"" src=""https://github.com/user-attachments/assets/b92bb076-5e9f-4d39-b80b-c988857df4b0"" />

Or run it locally by the following steps:

1. Setup

   ```
   cd recommenders
   conda create -n reco python=3.11
   conda activate reco
   pip install .[dev]
   ```

1. Run the [`examples/01_prepare_data/wikidata_knowledge_graph.ipynb`](https://github.com/recommenders-team/recommenders/blob/main/examples/01_prepare_data/wikidata_knowledge_graph.ipynb) in VS Code multiple times until [`results_list`](https://github.com/recommenders-team/recommenders/blob/main/examples/01_prepare_data/wikidata_knowledge_graph.ipynb?short_path=1feabc6#L220) is empty.

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

[`results_list`](https://github.com/recommenders-team/recommenders/blob/main/examples/01_prepare_data/wikidata_knowledge_graph.ipynb?short_path=1feabc6#L220) and [`result`](https://github.com/recommenders-team/recommenders/blob/main/examples/01_prepare_data/wikidata_knowledge_graph.ipynb?short_path=1feabc6#L487) in the notebook [`examples/01_prepare_data/wikidata_knowledge_graph.ipynb`](https://github.com/recommenders-team/recommenders/blob/main/examples/01_prepare_data/wikidata_knowledge_graph.ipynb) should not be empty.

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
",SimonYansenZhao,6165588,open,False,3,2025-04-26T02:11:48+00:00,2025-05-02T13:03:20+00:00,,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,3018747848,2225,Set NumPy < 2.0.0,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
The file [`surprise/similarities.pyx`](https://github.com/NicolasHug/Surprise/blob/master/surprise/similarities.pyx) in the package [`scikit-surprise`](https://pypi.org/project/scikit-surprise/) doesn't work with NumPy 2.x.  This PR sets `numpy<2.0.0` to resolve the issue.  This constraint needs to be removed after a newer version of `scimitar-surprise` is released.

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
* https://github.com/recommenders-team/recommenders/issues/2224

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [X] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [x] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [X] This PR is being made to `staging branch` AND NOT TO `main branch`.
",SimonYansenZhao,6165588,closed,False,0,2025-04-25T01:04:45+00:00,2025-04-25T08:21:44+00:00,2025-04-25T08:21:39+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,3013307612,2224,[BUG] Issue with Surprise and numpy,"### Description
<!--- Describe your issue/bug/request in detail -->
```
tests/unit/examples/test_notebooks_python.py ...                         [ 16%]
  tests/unit/recommenders/utils/test_notebook_utils.py ..........          [ 72%]
  tests/unit/examples/test_notebooks_python.py F...s                       [100%]
  
  =================================== FAILURES ===================================
  _________________________ test_surprise_deep_dive_runs _________________________
  
  notebooks = {'als_deep_dive': '/mnt/azureml/cr/j/5ed508dda20e47b895e20bab18b52515/exe/wd/examples/02_model_collaborative_filtering...rk_movielens': '/mnt/azureml/cr/j/5ed508dda20e47b895e20bab18b52515/exe/wd/examples/06_benchmarks/movielens.ipynb', ...}
  output_notebook = 'output.ipynb', kernel_name = 'python3'
  
      @pytest.mark.notebooks
      def test_surprise_deep_dive_runs(notebooks, output_notebook, kernel_name):
          notebook_path = notebooks[""surprise_svd_deep_dive""]
  >       execute_notebook(
              notebook_path,
              output_notebook,
              kernel_name=kernel_name,
              parameters=dict(MOVIELENS_DATA_SIZE=""mock100""),
          )
  
  tests/unit/examples/test_notebooks_python.py:52: 
  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
  recommenders/utils/notebook_utils.py:102: in execute_notebook
      executed_notebook, _ = execute_preprocessor.preprocess(
  /root/conda/envs/Recommenders/lib/python3.9/site-packages/nbconvert/preprocessors/execute.py:103: in preprocess
      self.preprocess_cell(cell, resources, index)
  /root/conda/envs/Recommenders/lib/python3.9/site-packages/nbconvert/preprocessors/execute.py:124: in preprocess_cell
      cell = self.execute_cell(cell, index, store_history=True)
  /root/conda/envs/Recommenders/lib/python3.9/site-packages/jupyter_core/utils/__init__.py:165: in wrapped
      return loop.run_until_complete(inner)
  /root/conda/envs/Recommenders/lib/python3.9/asyncio/base_events.py:647: in run_until_complete
      return future.result()
  /root/conda/envs/Recommenders/lib/python3.9/site-packages/nbclient/client.py:1062: in async_execute_cell
      await self._check_raise_for_error(cell, cell_index, exec_reply)
  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
  
  self = <nbconvert.preprocessors.execute.ExecutePreprocessor object at 0x1[484](https://github.com/recommenders-team/recommenders/actions/runs/14613915457/job/40997694256#step:3:493)dc8ad2e0>
  cell = {'cell_type': 'code', 'execution_count': 1, 'metadata': {'execution': {'iopub.status.busy': '2025-04-23T09:11:25.94351...ort store_metadata\n\n\nprint(f""System version: {sys.version}"")\nprint(f""Surprise version: {surprise.__version__}"")\n'}
  cell_index = 5
  exec_reply = {'buffers': [], 'content': {'ename': 'ImportError', 'engine_info': {'engine_id': -1, 'engine_uuid': '8e367c2f-9e06-4c8...e, 'engine': '8e367c2f-9e06-4c8e-be60-a8c12b5b648f', 'started': '2025-04-23T09:11:25.943705Z', 'status': 'error'}, ...}
  
      async def _check_raise_for_error(
          self, cell: NotebookNode, cell_index: int, exec_reply: dict[str, t.Any] | None
      ) -> None:
          if exec_reply is None:
              return None
      
          exec_reply_content = exec_reply[""content""]
          if exec_reply_content[""status""] != ""error"":
              return None
      
          cell_allows_errors = (not self.force_raise_errors) and (
              self.allow_errors
              or exec_reply_content.get(""ename"") in self.allow_error_names
              or ""raises-exception"" in cell.metadata.get(""tags"", [])
          )
          await run_hook(
              self.on_cell_error, cell=cell, cell_index=cell_index, execute_reply=exec_reply
          )
          if not cell_allows_errors:
  >           raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
  E           nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
  E           ------------------
  E           import sys
  E           import surprise
  E           
  E           from recommenders.utils.timer import Timer
  E           from recommenders.datasets import movielens
  E           from recommenders.datasets.python_splitters import python_random_split
  E           from recommenders.evaluation.python_evaluation import (
  E               rmse,
  E               mae,
  E               rsquared,
  E               exp_var,
  E               map_at_k,
  E               ndcg_at_k,
  E               precision_at_k,
  E               recall_at_k,
  E               get_top_k_items,
  E           )
  E           from recommenders.models.surprise.surprise_utils import (
  E               predict,
  E               compute_ranking_predictions,
  E           )
  E           from recommenders.utils.notebook_utils import store_metadata
  E           
  E           
  E           print(f""System version: {sys.version}"")
  E           print(f""Surprise version: {surprise.__version__}"")
  E           
  E           ------------------
  E           
  E           ----- stderr -----
  E           
  E           A module that was compiled using NumPy 1.x cannot be run in
  E           NumPy 2.0.2 as it may crash. To support both 1.x and 2.x
  E           versions of NumPy, modules must be compiled with NumPy 2.0.
  E           Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.
  E           
  E           If you are a user of the module, the easiest solution will be to
  E           downgrade to 'numpy<2' or try to upgrade the affected module.
  E           We expect that some modules will need time to support NumPy 2.
  E           
  E           Traceback (most recent call last):  File ""/root/conda/envs/Recommenders/lib/python3.9/runpy.py"", line 197, in _run_module_as_main
  E               return _run_code(code, main_globals, None,
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/runpy.py"", line 87, in _run_code
  E               exec(code, run_globals)
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/ipykernel_launcher.py"", line 18, in <module>
  E               app.launch_new_instance()
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/traitlets/config/application.py"", line 1075, in launch_instance
  E               app.start()
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/ipykernel/kernelapp.py"", line 739, in start
  E               self.io_loop.start()
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/tornado/platform/asyncio.py"", line 205, in start
  E               self.asyncio_loop.run_forever()
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/asyncio/base_events.py"", line 601, in run_forever
  E               self._run_once()
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/asyncio/base_events.py"", line 1905, in _run_once
  E               handle._run()
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/asyncio/events.py"", line 80, in _run
  E               self._context.run(self._callback, *self._args)
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/ipykernel/kernelbase.py"", line 545, in dispatch_queue
  E               await self.process_one()
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/ipykernel/kernelbase.py"", line 534, in process_one
  E               await dispatch(*args)
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/ipykernel/kernelbase.py"", line 437, in dispatch_shell
  E               await result
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/ipykernel/ipkernel.py"", line 362, in execute_request
  E               await super().execute_request(stream, ident, parent)
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/ipykernel/kernelbase.py"", line 778, in execute_request
  E               reply_content = await reply_content
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/ipykernel/ipkernel.py"", line 449, in do_execute
  E               res = shell.run_cell(
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/ipykernel/zmqshell.py"", line 549, in run_cell
  E               return super().run_cell(*args, **kwargs)
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3048, in run_cell
  E               result = self._run_cell(
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3103, in _run_cell
  E               result = runner(coro)
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/IPython/core/async_helpers.py"", line 129, in _pseudo_sync_runner
  E               coro.send(None)
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3308, in run_cell_async
  E               has_raised = await self.run_ast_nodes(code_ast.body, cell_name,
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3[490](https://github.com/recommenders-team/recommenders/actions/runs/14613915457/job/40997694256#step:3:499), in run_ast_nodes
  E               if await self.run_code(code, result, async_=asy):
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3550, in run_code
  E               exec(code_obj, self.user_global_ns, self.user_ns)
  E             File ""/tmp/ipykernel_415/2308614522.py"", line 2, in <module>
  E               import surprise
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/surprise/__init__.py"", line 6, in <module>
  E               from .prediction_algorithms import (
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/surprise/prediction_algorithms/__init__.py"", line 23, in <module>
  E               from .algo_base import AlgoBase
  E             File ""/root/conda/envs/Recommenders/lib/python3.9/site-packages/surprise/prediction_algorithms/algo_base.py"", line 8, in <module>
  E               from .. import similarities as sims
  E           ------------------
  E           
  E           ---------------------------------------------------------------------------
  E           ImportError                               Traceback (most recent call last)
  E           Cell In[1], line 2
  E                 1 import sys
  E           ----> 2 import surprise
  E                 4 from recommenders.utils.timer import Timer
  E                 5 from recommenders.datasets import movielens
  E           
  E           File ~/conda/envs/Recommenders/lib/python3.9/site-packages/surprise/__init__.py:6
  E                 2 from .builtin_datasets import get_dataset_dir
  E                 4 from .dataset import Dataset
  E           ----> 6 from .prediction_algorithms import (
  E                 7     AlgoBase,
  E                 8     BaselineOnly,
  E                 9     CoClustering,
  E                10     KNNBaseline,
  E                11     KNNBasic,
  E                12     KNNWithMeans,
  E                13     KNNWithZScore,
  E                14     NMF,
  E                15     NormalPredictor,
  E                16     Prediction,
  E                17     PredictionImpossible,
  E                18     SlopeOne,
  E                19     SVD,
  E                20     SVDpp,
  E                21 )
  E                22 from .reader import Reader
  E                23 from .trainset import Trainset
  E           
  E           File ~/conda/envs/Recommenders/lib/python3.9/site-packages/surprise/prediction_algorithms/__init__.py:23
  E                 1 """"""
  E                 2 The :mod:`prediction_algorithms` package includes the prediction algorithms
  E                 3 available for recommendation.
  E              (...)
  E                20     co_clustering.CoClustering
  E                21 """"""
  E           ---> 23 from .algo_base import AlgoBase
  E                24 from .baseline_only import BaselineOnly
  E                25 from .co_clustering import CoClustering
  E           
  E           File ~/conda/envs/Recommenders/lib/python3.9/site-packages/surprise/prediction_algorithms/algo_base.py:8
  E                 1 """"""
  E                 2 The :mod:`surprise.prediction_algorithms.algo_base` module defines the base
  E                 3 class :class:`AlgoBase` from which every single prediction algorithm has to
  E                 4 inherit.
  E                 5 """"""
  E                 6 import heapq
  E           ----> 8 from .. import similarities as sims
  E                 9 from .optimize_baselines import baseline_als, baseline_sgd
  E                10 from .predictions import Prediction, PredictionImpossible
  E           
  E           File ~/conda/envs/Recommenders/lib/python3.9/site-packages/surprise/similarities.pyx:1, in init surprise.similarities()
  E           
  E           ImportError: numpy.core.multiarray failed to import (auto-generated because you didn't call 'numpy.import_array()' after cimporting numpy; use '<void>numpy._import_array' to disable if you are certain you don't need it).
```



### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->
https://github.com/recommenders-team/recommenders/actions/runs/14613915457/job/40997694256

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
",miguelgfierro,3491412,open,False,3,2025-04-23T09:25:12+00:00,2025-05-12T14:04:12+00:00,,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,3008475385,2223,mismatch between the streaming logs that we get from azure-ai-ml and the log file we download at the end ,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
Related to https://github.com/recommenders-team/recommenders/pull/2222#issuecomment-2818458801

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,8,2025-04-21T13:58:57+00:00,2025-04-24T15:26:10+00:00,2025-04-24T15:26:07+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2993180249,2222,Staging to main,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,5,2025-04-14T14:03:07+00:00,2025-05-05T13:55:59+00:00,2025-05-05T13:55:59+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2991181558,2221,20k stars announcement,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2025-04-13T10:29:20+00:00,2025-04-14T14:02:23+00:00,2025-04-14T14:02:16+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2976845682,2220,Feature/pytorch embedding ranker,"Fixes #2205: [FEATURE] Add embedding ranker in PyTorch
References
TensorFlow Recommenders basic ranking example: https://www.tensorflow.org/recommenders/examples/basic_ranking
PyTorch documentation: https://pytorch.org/docs/stable/index.html
Checklist:
[x] I have followed the contribution guidelines and code style for this project.
[x] I have added tests covering my contributions (tests included in model implementation).
[x] I have updated the documentation accordingly (added docstrings).
[ ] I have signed the commits, e.g. git commit -s -m ""your commit message"".
[x] This PR is being made to staging branch AND NOT TO main branch.",demoncoder-crypto,174311533,closed,False,9,2025-04-07T13:19:40+00:00,2025-05-02T15:16:03+00:00,2025-05-02T15:16:03+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2975084313,2219,[FEATURE] Implement R-Precision with PySpark #2087,"### Description
This pull request implements the R-Precision evaluation metric for PySpark within the `SparkRankingEvaluation` class.

This change is required to provide a standard ranking evaluation metric for recommendation models evaluated using PySpark, addressing feature request #2087 and achieving parity with potential implementations for other frameworks (related to #2086). It allows users to measure the fraction of relevant items within the top R recommendations, where R is the total number of relevant items for a user.

### Related Issues
- Addresses issue #2087: [FEATURE] Implement R-Precision with PySpark #2087

### References
- R-Precision is a standard metric for evaluating ranked retrieval results.

### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [x] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly. (Note: Docstrings were added, but no higher-level documentation files were modified).
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. (Note: The commit was not signed).
- [x] This PR is being made to `staging branch` AND NOT TO `main branch`. (Assuming `staging` is the target development branch for this repository).
",demoncoder-crypto,174311533,open,False,9,2025-04-06T17:21:22+00:00,2025-05-03T08:06:02+00:00,,,0,0,0,0,0,0,0
recommenders-team/recommenders,2960587434,2218,Criteo error with sample URL,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
Fix https://github.com/recommenders-team/recommenders/issues/2215

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,1,2025-03-31T13:57:40+00:00,2025-04-01T05:19:06+00:00,2025-04-01T05:19:03+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2909829893,2217,Update setup.py,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",Harshupadhyay221,142519913,open,False,0,2025-03-11T09:41:12+00:00,2025-03-11T09:41:14+00:00,,,0,0,0,0,0,0,0
recommenders-team/recommenders,2907549215,2216,Issue with ipthon autoreload,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
#2214

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,open,False,2,2025-03-10T14:53:42+00:00,2025-03-10T15:19:56+00:00,,,0,0,0,0,0,0,0
recommenders-team/recommenders,2902966493,2215,[BUG] Issue with CRITEO test,"### Description
<!--- Describe your issue/bug/request in detail -->
https://github.com/recommenders-team/recommenders/actions/runs/13688085985/job/38278524136


### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->
```
============================= test session starts ==============================
platform linux -- Python 3.11.11, pytest-8.3.5, pluggy-1.5.0
rootdir: /mnt/azureml/cr/j/575a65daf6cf4be7ab8dfb03fdf4becb/exe/wd
configfile: pyproject.toml
plugins: hypothesis-6.127.7, anyio-4.8.0, cov-6.0.0, typeguard-4.4.2, mock-3.14.0
collected 11 items

tests/data_validation/recommenders/datasets/test_criteo.py FFF.          [ 36%]
tests/smoke/examples/test_notebooks_python.py .                          [ 45%]
tests/functional/examples/test_notebooks_python.py ..s                   [ 72%]
tests/smoke/examples/test_notebooks_python.py s                          [ 81%]
tests/functional/examples/test_notebooks_python.py ss                    [100%]

=================================== FAILURES ===================================
_________________________ test_download_criteo_sample __________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_download_criteo_sample0')

    def test_download_criteo_sample(tmp_path):
        filepath = criteo.download_criteo(size=""sample"", work_directory=tmp_path)
        statinfo = os.stat(filepath)
>       assert statinfo.st_size == 8787154
E       assert 234999 == 8787154
E        +  where 234999 = os.stat_result(st_mode=33188, st_ino=5243586, st_dev=2049, st_nlink=1, st_uid=0, st_gid=0, st_size=234999, st_atime=1741225214, st_mtime=1741225214, st_ctime=1741225214).st_size

tests/data_validation/recommenders/datasets/test_criteo.py:15: AssertionError
----------------------------- Captured stderr call -----------------------------

0.00KB [00:00, ?KB/s]
42.0KB [00:00, 10.9kKB/s]
__________________________ test_extract_criteo_sample __________________________

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_extract_criteo_sample0')

    def test_extract_criteo_sample(tmp_path):
        filepath = criteo.download_criteo(size=""sample"", work_directory=tmp_path)
>       filename = criteo.extract_criteo(size=""sample"", compressed_file=filepath)

tests/data_validation/recommenders/datasets/test_criteo.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
recommenders/datasets/criteo.py:159: in extract_criteo
    with tarfile.open(compressed_file) as tar:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'tarfile.TarFile'>
name = '/tmp/pytest-of-root/pytest-0/test_extract_criteo_sample0/dac_sample.tar.gz'
mode = 'r', fileobj = None, bufsize = 10240, kwargs = {}
not_compressed = <function TarFile.open.<locals>.not_compressed at 0x154d07bbf740>
error_msgs = [""- method gz: ReadError('not a gzip file')"", ""- method bz2: ReadError('not a bzip2 file')"", ""- method xz: ReadError('not an lzma file')"", ""- method tar: ReadError('invalid header')""]
comptype = 'tar'
func = <bound method TarFile.taropen of <class 'tarfile.TarFile'>>
error_msgs_summary = ""- method gz: ReadError('not a gzip file')\n- method bz2: ReadError('not a bzip2 file')\n- method xz: ReadError('not an lzma file')\n- method tar: ReadError('invalid header')""

    @classmethod
    def open(cls, name=None, mode=""r"", fileobj=None, bufsize=RECORDSIZE, **kwargs):
        """"""Open a tar archive for reading, writing or appending. Return
           an appropriate TarFile class.
    
           mode:
           'r' or 'r:*' open for reading with transparent compression
           'r:'         open for reading exclusively uncompressed
           'r:gz'       open for reading with gzip compression
           'r:bz2'      open for reading with bzip2 compression
           'r:xz'       open for reading with lzma compression
           'a' or 'a:'  open for appending, creating the file if necessary
           'w' or 'w:'  open for writing without compression
           'w:gz'       open for writing with gzip compression
           'w:bz2'      open for writing with bzip2 compression
           'w:xz'       open for writing with lzma compression
    
           'x' or 'x:'  create a tarfile exclusively without compression, raise
                        an exception if the file is already created
           'x:gz'       create a gzip compressed tarfile, raise an exception
                        if the file is already created
           'x:bz2'      create a bzip2 compressed tarfile, raise an exception
                        if the file is already created
           'x:xz'       create an lzma compressed tarfile, raise an exception
                        if the file is already created
    
           'r|*'        open a stream of tar blocks with transparent compression
           'r|'         open an uncompressed stream of tar blocks for reading
           'r|gz'       open a gzip compressed stream of tar blocks
           'r|bz2'      open a bzip2 compressed stream of tar blocks
           'r|xz'       open an lzma compressed stream of tar blocks
           'w|'         open an uncompressed stream for writing
           'w|gz'       open a gzip compressed stream for writing
           'w|bz2'      open a bzip2 compressed stream for writing
           'w|xz'       open an lzma compressed stream for writing
        """"""
    
        if not name and not fileobj:
            raise ValueError(""nothing to open"")
    
        if mode in (""r"", ""r:*""):
            # Find out which *open() is appropriate for opening the file.
            def not_compressed(comptype):
                return cls.OPEN_METH[comptype] == 'taropen'
            error_msgs = []
            for comptype in sorted(cls.OPEN_METH, key=not_compressed):
                func = getattr(cls, cls.OPEN_METH[comptype])
                if fileobj is not None:
                    saved_pos = fileobj.tell()
                try:
                    return func(name, ""r"", fileobj, **kwargs)
                except (ReadError, CompressionError) as e:
                    error_msgs.append(f'- method {comptype}: {e!r}')
                    if fileobj is not None:
                        fileobj.seek(saved_pos)
                    continue
            error_msgs_summary = '\n'.join(error_msgs)
>           raise ReadError(f""file could not be opened successfully:\n{error_msgs_summary}"")
E           tarfile.ReadError: file could not be opened successfully:
E           - method gz: ReadError('not a gzip file')
E           - method bz2: ReadError('not a bzip2 file')
E           - method xz: ReadError('not an lzma file')
E           - method tar: ReadError('invalid header')

/root/conda/envs/Recommenders/lib/python3.11/tarfile.py:1841: ReadError
----------------------------- Captured stderr call -----------------------------

0.00KB [00:00, ?KB/s]
42.0KB [00:00, 8.94kKB/s]
______________________ test_criteo_load_pandas_df_sample _______________________

criteo_first_row = {'cat00': '68fd1e64', 'cat01': '80e26c9b', 'cat02': 'fb936136', 'cat03': '7b4723c4', ...}

    def test_criteo_load_pandas_df_sample(criteo_first_row):
>       df = criteo.load_pandas_df(size=""sample"")

tests/data_validation/recommenders/datasets/test_criteo.py:26: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
recommenders/datasets/criteo.py:59: in load_pandas_df
    filepath = extract_criteo(size, filepath)
recommenders/datasets/criteo.py:159: in extract_criteo
    with tarfile.open(compressed_file) as tar:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'tarfile.TarFile'>, name = '/tmp/tmppfkb_vcy/dac_sample.tar.gz'
mode = 'r', fileobj = None, bufsize = 10240, kwargs = {}
not_compressed = <function TarFile.open.<locals>.not_compressed at 0x154d09c37f60>
error_msgs = [""- method gz: ReadError('not a gzip file')"", ""- method bz2: ReadError('not a bzip2 file')"", ""- method xz: ReadError('not an lzma file')"", ""- method tar: ReadError('invalid header')""]
comptype = 'tar'
func = <bound method TarFile.taropen of <class 'tarfile.TarFile'>>
error_msgs_summary = ""- method gz: ReadError('not a gzip file')\n- method bz2: ReadError('not a bzip2 file')\n- method xz: ReadError('not an lzma file')\n- method tar: ReadError('invalid header')""

    @classmethod
    def open(cls, name=None, mode=""r"", fileobj=None, bufsize=RECORDSIZE, **kwargs):
        """"""Open a tar archive for reading, writing or appending. Return
           an appropriate TarFile class.
    
           mode:
           'r' or 'r:*' open for reading with transparent compression
           'r:'         open for reading exclusively uncompressed
           'r:gz'       open for reading with gzip compression
           'r:bz2'      open for reading with bzip2 compression
           'r:xz'       open for reading with lzma compression
           'a' or 'a:'  open for appending, creating the file if necessary
           'w' or 'w:'  open for writing without compression
           'w:gz'       open for writing with gzip compression
           'w:bz2'      open for writing with bzip2 compression
           'w:xz'       open for writing with lzma compression
    
           'x' or 'x:'  create a tarfile exclusively without compression, raise
                        an exception if the file is already created
           'x:gz'       create a gzip compressed tarfile, raise an exception
                        if the file is already created
           'x:bz2'      create a bzip2 compressed tarfile, raise an exception
                        if the file is already created
           'x:xz'       create an lzma compressed tarfile, raise an exception
                        if the file is already created
    
           'r|*'        open a stream of tar blocks with transparent compression
           'r|'         open an uncompressed stream of tar blocks for reading
           'r|gz'       open a gzip compressed stream of tar blocks
           'r|bz2'      open a bzip2 compressed stream of tar blocks
           'r|xz'       open an lzma compressed stream of tar blocks
           'w|'         open an uncompressed stream for writing
           'w|gz'       open a gzip compressed stream for writing
           'w|bz2'      open a bzip2 compressed stream for writing
           'w|xz'       open an lzma compressed stream for writing
        """"""
    
        if not name and not fileobj:
            raise ValueError(""nothing to open"")
    
        if mode in (""r"", ""r:*""):
            # Find out which *open() is appropriate for opening the file.
            def not_compressed(comptype):
                return cls.OPEN_METH[comptype] == 'taropen'
            error_msgs = []
            for comptype in sorted(cls.OPEN_METH, key=not_compressed):
                func = getattr(cls, cls.OPEN_METH[comptype])
                if fileobj is not None:
                    saved_pos = fileobj.tell()
                try:
                    return func(name, ""r"", fileobj, **kwargs)
                except (ReadError, CompressionError) as e:
                    error_msgs.append(f'- method {comptype}: {e!r}')
                    if fileobj is not None:
                        fileobj.seek(saved_pos)
                    continue
            error_msgs_summary = '\n'.join(error_msgs)
>           raise ReadError(f""file could not be opened successfully:\n{error_msgs_summary}"")
E           tarfile.ReadError: file could not be opened successfully:
E           - method gz: ReadError('not a gzip file')
E           - method bz2: ReadError('not a bzip2 file')
E           - method xz: ReadError('not an lzma file')
E           - method tar: ReadError('invalid header')

/root/conda/envs/Recommenders/lib/python3.11/tarfile.py:1841: ReadError
----------------------------- Captured stderr call -----------------------------

0.00KB [00:00, ?KB/s]
42.0KB [00:00, 18.0kKB/s]
=============================== warnings summary ===============================
../../../../../../../root/conda/envs/Recommenders/lib/python3.11/site-packages/jupyter_client/connect.py:22
  /root/conda/envs/Recommenders/lib/python3.11/site-packages/jupyter_client/connect.py:22: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs
  given by the platformdirs library.  To remove this warning and
  see the appropriate new directories, set the environment variable
  `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.
  The use of platformdirs will be the default in `jupyter_core` v6
    from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
============================== slowest durations ===============================
473.71s call     tests/data_validation/recommenders/datasets/test_criteo.py::test_criteo_load_pandas_df_full
299.50s call     tests/functional/examples/test_notebooks_python.py::test_sar_single_node_functional[10m-expected_values1]
19.73s call     tests/functional/examples/test_notebooks_python.py::test_sar_single_node_functional[1m-expected_values0]
4.66s call     tests/smoke/examples/test_notebooks_python.py::test_sar_single_node_smoke
1.10s call     tests/data_validation/recommenders/datasets/test_criteo.py::test_extract_criteo_sample
0.84s call     tests/data_validation/recommenders/datasets/test_criteo.py::test_download_criteo_sample
0.64s call     tests/data_validation/recommenders/datasets/test_criteo.py::test_criteo_load_pandas_df_sample

(22 durations < 0.005s hidden.  Use -vv to show these durations.)
=========================== short test summary info ============================
FAILED tests/data_validation/recommenders/datasets/test_criteo.py::test_download_criteo_sample
FAILED tests/data_validation/recommenders/datasets/test_criteo.py::test_extract_criteo_sample
FAILED tests/data_validation/recommenders/datasets/test_criteo.py::test_criteo_load_pandas_df_sample
======== 3 failed, 4 passed, 4 skipped, 1 warning in 801.57s (0:13:21) =========

```

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
",miguelgfierro,3491412,closed,False,3,2025-03-07T13:06:04+00:00,2025-04-01T05:22:25+00:00,2025-04-01T05:22:25+00:00,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2902957587,2214,[BUG] Issue with GPU test and autoreload in Jupyter notebook,"### Description
<!--- Describe your issue/bug/request in detail -->
There is a new ipython version 9 https://pypi.org/project/ipython/#history and we saw an error in one of the tests https://github.com/recommenders-team/recommenders/actions/runs/13598630129/job/38020796411, but a few days later, it worked https://github.com/recommenders-team/recommenders/actions/runs/13688072472/job/38275884422 


### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->
```
============================= test session starts ==============================
platform linux -- Python 3.11.11, pytest-8.3.4, pluggy-1.5.0
rootdir: /mnt/azureml/cr/j/99f29d5508a94f7c8234c64164d5d64b/exe/wd
configfile: pyproject.toml
plugins: anyio-4.8.0, mock-3.14.0, hypothesis-6.127.3, typeguard-4.4.2, cov-6.0.0
collected 3 items

tests/unit/examples/test_notebooks_gpu.py .                              [ 33%]
tests/functional/examples/test_notebooks_gpu.py F                        [ 66%]
tests/smoke/recommenders/models/test_newsrec_model.py .                  [100%]

=================================== FAILURES ===================================
_______ test_benchmark_movielens_gpu[size0-algos0-expected_values_ndcg0] _______

notebooks = {'als_deep_dive': '/mnt/azureml/cr/j/99f29d5508a94f7c8234c64164d5d64b/exe/wd/examples/02_model_collaborative_filtering...rk_movielens': '/mnt/azureml/cr/j/99f29d5508a94f7c8234c64164d5d64b/exe/wd/examples/06_benchmarks/movielens.ipynb', ...}
output_notebook = 'output.ipynb', kernel_name = 'python3', size = ['100k']
algos = ['ncf', 'fastai', 'bivae', 'lightgcn']
expected_values_ndcg = [0.382793, 0.147583, 0.471722, 0.412664]

    @pytest.mark.gpu
    @pytest.mark.notebooks
    @pytest.mark.parametrize(
        ""size, algos, expected_values_ndcg"",
        [
            (
                [""100k""],
                [""ncf"", ""fastai"", ""bivae"", ""lightgcn""],
                [0.382793, 0.147583, 0.471722, 0.412664],
            ),
        ],
    )
    def test_benchmark_movielens_gpu(
        notebooks, output_notebook, kernel_name, size, algos, expected_values_ndcg
    ):
        notebook_path = notebooks[""benchmark_movielens""]
>       execute_notebook(
            notebook_path,
            output_notebook,
            kernel_name=kernel_name,
            parameters=dict(data_sizes=size, algorithms=algos),
        )

tests/functional/examples/test_notebooks_gpu.py:673: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
recommenders/utils/notebook_utils.py:102: in execute_notebook
    executed_notebook, _ = execute_preprocessor.preprocess(
/root/conda/envs/Recommenders/lib/python3.11/site-packages/nbconvert/preprocessors/execute.py:103: in preprocess
    self.preprocess_cell(cell, resources, index)
/root/conda/envs/Recommenders/lib/python3.11/site-packages/nbconvert/preprocessors/execute.py:124: in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
/root/conda/envs/Recommenders/lib/python3.11/site-packages/jupyter_core/utils/__init__.py:165: in wrapped
    return loop.run_until_complete(inner)
/root/conda/envs/Recommenders/lib/python3.11/asyncio/base_events.py:654: in run_until_complete
    return future.result()
/root/conda/envs/Recommenders/lib/python3.11/site-packages/nbclient/client.py:1062: in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <nbconvert.preprocessors.execute.ExecutePreprocessor object at 0x14a37af38750>
cell = {'cell_type': 'code', 'execution_count': 2, 'metadata': {'execution': {'iopub.status.busy': '2025-03-01T00:54:11.75570...pt NameError:\n    pass  # skip this import if we are not in a GPU environment\n\n%load_ext autoreload\n%autoreload 2'}
cell_index = 4
exec_reply = {'buffers': [], 'content': {'ename': 'ModuleNotFoundError', 'engine_info': {'engine_id': -1, 'engine_uuid': '2107f785-...e, 'engine': '2107f785-c2a8-4f76-851f-794398525fbe', 'started': '2025-03-01T00:54:11.756066Z', 'status': 'error'}, ...}

    async def _check_raise_for_error(
        self, cell: NotebookNode, cell_index: int, exec_reply: dict[str, t.Any] | None
    ) -> None:
        if exec_reply is None:
            return None
    
        exec_reply_content = exec_reply[""content""]
        if exec_reply_content[""status""] != ""error"":
            return None
    
        cell_allows_errors = (not self.force_raise_errors) and (
            self.allow_errors
            or exec_reply_content.get(""ename"") in self.allow_error_names
            or ""raises-exception"" in cell.metadata.get(""tags"", [])
        )
        await run_hook(
            self.on_cell_error, cell=cell, cell_index=cell_index, execute_reply=exec_reply
        )
        if not cell_allows_errors:
>           raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
E           nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
E           ------------------
E           import os
E           import sys
E           import numpy as np
E           import pandas as pd
E           import surprise
E           import cornac
E           
E           try:
E               import pyspark
E           except ImportError:
E               pass  # skip this import if we are not in a Spark environment
E           
E           try:
E               import tensorflow as tf # NOTE: TF needs to be imported before PyTorch, otherwise we get an error
E               tf.get_logger().setLevel('ERROR') # only show error messages
E               import torch
E               import fastai
E           except ImportError:
E               pass  # skip this import if we are not in a GPU environment
E           
E           current_path = os.path.join(os.getcwd(), ""examples"", ""06_benchmarks"") # To execute the notebook programmatically from root folder
E           sys.path.append(current_path)
E           from benchmark_utils import * 
E           
E           from recommenders.datasets import movielens
E           from recommenders.utils.general_utils import get_number_processors
E           from recommenders.datasets.python_splitters import python_stratified_split
E           try:
E               from recommenders.utils.spark_utils import start_or_get_spark
E           except ImportError:
E               pass  # skip this import if we are not in a Spark environment
E           try:
E               from recommenders.utils.gpu_utils import get_cuda_version, get_cudnn_version
E               from recommenders.models.fastai.fastai_utils import hide_fastai_progress_bar
E               hide_fastai_progress_bar()
E           except ImportError:
E               pass  # skip this import if we are not in a GPU environment
E           from recommenders.utils.notebook_utils import store_metadata
E           
E           
E           print(f""System version: {sys.version}"")
E           print(f""Number of cores: {get_number_processors()}"")
E           print(f""NumPy version: {np.__version__}"")
E           print(f""Pandas version: {pd.__version__}"")
E           print(f""Surprise version: {surprise.__version__}"")
E           print(f""Cornac version: {cornac.__version__}"")
E           try:
E               print(f""PySpark version: {pyspark.__version__}"")
E           except NameError:
E               pass  # skip this import if we are not in a Spark environment
E           try:
E               print(f""CUDA version: {get_cuda_version()}"")
E               print(f""CuDNN version: {get_cudnn_version()}"")
E               print(f""TensorFlow version: {tf.__version__}"")
E               print(f""PyTorch version: {torch.__version__}"")
E               print(f""Fast AI version: {fastai.__version__}"")
E           except NameError:
E               pass  # skip this import if we are not in a GPU environment
E           
E           %load_ext autoreload
E           %autoreload 2
E           ------------------
E           
E           ----- stdout -----
E           System version: 3.11.11 | packaged by conda-forge | (main, Dec  5 2024, 14:17:24) [GCC 13.3.0]
E           Number of cores: 8
E           NumPy version: 1.26.4
E           Pandas version: 2.2.3
E           Surprise version: 1.1.4
E           Cornac version: 2.3.0
E           CUDA version: 12.4
E           CuDNN version: 90100
E           TensorFlow version: 2.15.1
E           PyTorch version: 2.5.1+cu124
E           Fast AI version: 2.7.18
E           ------------------
E           
E           [31m---------------------------------------------------------------------------[39m
E           [31mModuleNotFoundError[39m                       Traceback (most recent call last)
E           [36mFile [39m[32m~/conda/envs/Recommenders/lib/python3.11/site-packages/IPython/core/extensions.py:62[39m, in [36mExtensionManager.load_extension[39m[34m(self, module_str)[39m
E           [32m     61[39m [38;5;28;01mtry[39;00m:
E           [32m---> [39m[32m62[39m     [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[43m.[49m[43m_load_extension[49m[43m([49m[43mmodule_str[49m[43m)[49m
E           [32m     63[39m [38;5;28;01mexcept[39;00m [38;5;167;01mModuleNotFoundError[39;00m:
E           
E           [36mFile [39m[32m~/conda/envs/Recommenders/lib/python3.11/site-packages/IPython/core/extensions.py:77[39m, in [36mExtensionManager._load_extension[39m[34m(self, module_str)[39m
E           [32m     76[39m [38;5;28;01mif[39;00m module_str [38;5;129;01mnot[39;00m [38;5;129;01min[39;00m sys.modules:
E           [32m---> [39m[32m77[39m     mod = [43mimport_module[49m[43m([49m[43mmodule_str[49m[43m)[49m
E           [32m     78[39m mod = sys.modules[module_str]
E           
E           [36mFile [39m[32m~/conda/envs/Recommenders/lib/python3.11/importlib/__init__.py:126[39m, in [36mimport_module[39m[34m(name, package)[39m
E           [32m    125[39m         level += [32m1[39m
E           [32m--> [39m[32m126[39m [38;5;28;01mreturn[39;00m [43m_bootstrap[49m[43m.[49m[43m_gcd_import[49m[43m([49m[43mname[49m[43m[[49m[43mlevel[49m[43m:[49m[43m][49m[43m,[49m[43m [49m[43mpackage[49m[43m,[49m[43m [49m[43mlevel[49m[43m)[49m
E           
E           [36mFile [39m[32m<frozen importlib._bootstrap>:1204[39m, in [36m_gcd_import[39m[34m(name, package, level)[39m
E           
E           [36mFile [39m[32m<frozen importlib._bootstrap>:1176[39m, in [36m_find_and_load[39m[34m(name, import_)[39m
E           
E           [36mFile [39m[32m<frozen importlib._bootstrap>:1140[39m, in [36m_find_and_load_unlocked[39m[34m(name, import_)[39m
E           
E           [31mModuleNotFoundError[39m: No module named 'autoreload'
E           
E           During handling of the above exception, another exception occurred:
E           
E           [31mModuleNotFoundError[39m                       Traceback (most recent call last)
E           [36mCell[39m[36m [39m[32mIn[2][39m[32m, line 60[39m
E           [32m     57[39m [38;5;28;01mexcept[39;00m [38;5;167;01mNameError[39;00m:
E           [32m     58[39m     [38;5;28;01mpass[39;00m  [38;5;66;03m# skip this import if we are not in a GPU environment[39;00m
E           [32m---> [39m[32m60[39m [43mget_ipython[49m[43m([49m[43m)[49m[43m.[49m[43mrun_line_magic[49m[43m([49m[33;43m'[39;49m[33;43mload_ext[39;49m[33;43m'[39;49m[43m,[49m[43m [49m[33;43m'[39;49m[33;43mautoreload[39;49m[33;43m'[39;49m[43m)[49m
E           [32m     61[39m get_ipython().run_line_magic([33m'[39m[33mautoreload[39m[33m'[39m, [33m'[39m[33m2[39m[33m'[39m)
E           
E           [36mFile [39m[32m~/conda/envs/Recommenders/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2478[39m, in [36mInteractiveShell.run_line_magic[39m[34m(self, magic_name, line, _stack_depth)[39m
E           [32m   2476[39m     kwargs[[33m'[39m[33mlocal_ns[39m[33m'[39m] = [38;5;28mself[39m.get_local_scope(stack_depth)
E           [32m   2477[39m [38;5;28;01mwith[39;00m [38;5;28mself[39m.builtin_trap:
E           [32m-> [39m[32m2478[39m     result = [43mfn[49m[43m([49m[43m*[49m[43margs[49m[43m,[49m[43m [49m[43m*[49m[43m*[49m[43mkwargs[49m[43m)[49m
E           [32m   2480[39m [38;5;66;03m# The code below prevents the output from being displayed[39;00m
E           [32m   2481[39m [38;5;66;03m# when using magics with decorator @output_can_be_silenced[39;00m
E           [32m   2482[39m [38;5;66;03m# when the last Python token in the expression is a ';'.[39;00m
E           [32m   2483[39m [38;5;28;01mif[39;00m [38;5;28mgetattr[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, [38;5;28;01mFalse[39;00m):
E           
E           [36mFile [39m[32m~/conda/envs/Recommenders/lib/python3.11/site-packages/IPython/core/magics/extension.py:33[39m, in [36mExtensionMagics.load_ext[39m[34m(self, module_str)[39m
E           [32m     31[39m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m module_str:
E           [32m     32[39m     [38;5;28;01mraise[39;00m UsageError([33m'[39m[33mMissing module name.[39m[33m'[39m)
E           [32m---> [39m[32m33[39m res = [38;5;28;43mself[39;49m[43m.[49m[43mshell[49m[43m.[49m[43mextension_manager[49m[43m.[49m[43mload_extension[49m[43m([49m[43mmodule_str[49m[43m)[49m
E           [32m     35[39m [38;5;28;01mif[39;00m res == [33m'[39m[33malready loaded[39m[33m'[39m:
E           [32m     36[39m     [38;5;28mprint[39m([33m""[39m[33mThe [39m[38;5;132;01m%s[39;00m[33m extension is already loaded. To reload it, use:[39m[33m""[39m % module_str)
E           
E           [36mFile [39m[32m~/conda/envs/Recommenders/lib/python3.11/site-packages/IPython/core/extensions.py:66[39m, in [36mExtensionManager.load_extension[39m[34m(self, module_str)[39m
E           [32m     64[39m [38;5;28;01mif[39;00m module_str [38;5;129;01min[39;00m BUILTINS_EXTS:
E           [32m     65[39m     BUILTINS_EXTS[module_str] = [38;5;28;01mTrue[39;00m
E           [32m---> [39m[32m66[39m     [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[43m.[49m[43m_load_extension[49m[43m([49m[33;43m""[39;49m[33;43mIPython.extensions.[39;49m[33;43m""[39;49m[43m [49m[43m+[49m[43m [49m[43mmodule_str[49m[43m)[49m
E           [32m     67[39m [38;5;28;01mraise[39;00m
E           
E           [36mFile [39m[32m~/conda/envs/Recommenders/lib/python3.11/site-packages/IPython/core/extensions.py:77[39m, in [36mExtensionManager._load_extension[39m[34m(self, module_str)[39m
E           [32m     75[39m [38;5;28;01mwith[39;00m [38;5;28mself[39m.shell.builtin_trap:
E           [32m     76[39m     [38;5;28;01mif[39;00m module_str [38;5;129;01mnot[39;00m [38;5;129;01min[39;00m sys.modules:
E           [32m---> [39m[32m77[39m         mod = [43mimport_module[49m[43m([49m[43mmodule_str[49m[43m)[49m
E           [32m     78[39m     mod = sys.modules[module_str]
E           [32m     79[39m     [38;5;28;01mif[39;00m [38;5;28mself[39m._call_load_ipython_extension(mod):
E           
E           [36mFile [39m[32m~/conda/envs/Recommenders/lib/python3.11/importlib/__init__.py:126[39m, in [36mimport_module[39m[34m(name, package)[39m
E           [32m    124[39m             [38;5;28;01mbreak[39;00m
E           [32m    125[39m         level += [32m1[39m
E           [32m--> [39m[32m126[39m [38;5;28;01mreturn[39;00m [43m_bootstrap[49m[43m.[49m[43m_gcd_import[49m[43m([49m[43mname[49m[43m[[49m[43mlevel[49m[43m:[49m[43m][49m[43m,[49m[43m [49m[43mpackage[49m[43m,[49m[43m [49m[43mlevel[49m[43m)[49m
E           
E           [36mFile [39m[32m<frozen importlib._bootstrap>:1204[39m, in [36m_gcd_import[39m[34m(name, package, level)[39m
E           
E           [36mFile [39m[32m<frozen importlib._bootstrap>:1176[39m, in [36m_find_and_load[39m[34m(name, import_)[39m
E           
E           [36mFile [39m[32m<frozen importlib._bootstrap>:1147[39m, in [36m_find_and_load_unlocked[39m[34m(name, import_)[39m
E           
E           [36mFile [39m[32m<frozen importlib._bootstrap>:690[39m, in [36m_load_unlocked[39m[34m(spec)[39m
E           
E           [36mFile [39m[32m<frozen importlib._bootstrap_external>:940[39m, in [36mexec_module[39m[34m(self, module)[39m
E           
E           [36mFile [39m[32m<frozen importlib._bootstrap>:241[39m, in [36m_call_with_frames_removed[39m[34m(f, *args, **kwds)[39m
E           
E           [36mFile [39m[32m~/conda/envs/Recommenders/lib/python3.11/site-packages/IPython/extensions/autoreload.py:110[39m
E           [32m    108[39m [38;5;28;01mfrom[39;00m[38;5;250m [39m[34;01mIPython[39;00m[34;01m.[39;00m[34;01mcore[39;00m[38;5;250m [39m[38;5;28;01mimport[39;00m magic_arguments
E           [32m    109[39m [38;5;28;01mfrom[39;00m[38;5;250m [39m[34;01mIPython[39;00m[34;01m.[39;00m[34;01mcore[39;00m[34;01m.[39;00m[34;01mmagic[39;00m[38;5;250m [39m[38;5;28;01mimport[39;00m Magics, magics_class, line_magic
E           [32m--> [39m[32m110[39m [38;5;28;01mfrom[39;00m[38;5;250m [39m[34;01mIPython[39;00m[34;01m.[39;00m[34;01mextensions[39;00m[34;01m.[39;00m[34;01mdeduperreload[39;00m[34;01m.[39;00m[34;01mdeduperreload[39;00m[38;5;250m [39m[38;5;28;01mimport[39;00m DeduperReloader
E           [32m    112[39m __skip_doctest__ = [38;5;28;01mTrue[39;00m
E           [32m    114[39m [38;5;66;03m# -----------------------------------------------------------------------------[39;00m
E           [32m    115[39m [38;5;66;03m#  Copyright (C) 2000 Thomas Heller[39;00m
E           [32m    116[39m [38;5;66;03m#  Copyright (C) 2008 Pauli Virtanen <pav@iki.fi>[39;00m
E           [32m   (...)[39m[32m    127[39m [38;5;66;03m# Imports[39;00m
E           [32m    128[39m [38;5;66;03m# -----------------------------------------------------------------------------[39;00m
E           
E           [31mModuleNotFoundError[39m: No module named 'IPython.extensions.deduperreload'

/root/conda/envs/Recommenders/lib/python3.11/site-packages/nbclient/client.py:918: CellExecutionError
=============================== warnings summary ===============================
../../../../../../../root/conda/envs/Recommenders/lib/python3.11/site-packages/jupyter_client/connect.py:22
  /root/conda/envs/Recommenders/lib/python3.11/site-packages/jupyter_client/connect.py:22: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs
  given by the platformdirs library.  To remove this warning and
  see the appropriate new directories, set the environment variable
  `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.
  The use of platformdirs will be the default in `jupyter_core` v6
    from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write

tests/smoke/recommenders/models/test_newsrec_model.py::test_model_lstur
  /root/conda/envs/Recommenders/lib/python3.11/site-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
    super().__init__(name, **kwargs)

tests/smoke/recommenders/models/test_newsrec_model.py::test_model_lstur
  /root/conda/envs/Recommenders/lib/python3.11/site-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
    updates=self.state_updates,

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
============================== slowest durations ===============================
95.83s call     tests/smoke/recommenders/models/test_newsrec_model.py::test_model_lstur
7.83s call     tests/functional/examples/test_notebooks_gpu.py::test_benchmark_movielens_gpu[size0-algos0-expected_values_ndcg0]
1.63s call     tests/unit/examples/test_notebooks_gpu.py::test_gpu_vm

(6 durations < 0.005s hidden.  Use -vv to show these durations.)
=========================== short test summary info ============================
FAILED tests/functional/examples/test_notebooks_gpu.py::test_benchmark_movielens_gpu[size0-algos0-expected_values_ndcg0]
============= 1 failed, 2 passed, 3 warnings in 108.78s (0:01:48) ==============

```

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
",miguelgfierro,3491412,open,False,2,2025-03-07T13:02:02+00:00,2025-03-10T14:59:41+00:00,,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2902915169,2213,ARPU and ARPPU metrics,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,1,2025-03-07T12:42:23+00:00,2025-04-14T14:02:01+00:00,2025-04-14T14:01:57+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2891441032,2212,[BUG] Issue in the GPU test due to exception with trivy image scan,"### Description
<!--- Describe your issue/bug/request in detail -->
```
2025-03-01T00:33:56: #### Image for post-processing commands: 978a92daa2ad4447aae1b21196dd4a9b.azurecr.io/azureml/azureml_7327894ab5e1ceb2de0475dff6c71a71:latest
  2025-03-01T00:33:56: #### Image digest: sha256:079686fc47f696aa7d68c7d0099f74bb25e3f0259f57c96560b889b98f67506f
  2025-03-01T00:33:56: #### Calling generate_sbom_and_call_ems
  2025-03-01T00:33:56: #### Calling generate_sbom
  2025-03-01T00:33:56: #### Generating SBOM 
  2025-03-01T00:33:56: #### Image digest: sha256:079686fc47f696aa7d68c7d0099f74bb25e3f0259f57c96560b889b98f67506f
  2025-03-01T00:33:56: #### Image name: 978a92daa2ad4447aae1b21196dd4a9b.azurecr.io/azureml/azureml_7327894ab5e1ceb2de0475dff6c71a71:latest
  2025-03-01T00:33:56: #### Running command: trivy image --no-progress --format spdx-json --skip-db-update --skip-java-db-update --offline-scan --output image-details.json 978a92daa2ad4447aae1b21196dd4a9b.azurecr.io/azureml/azureml_7327894ab5e1ceb2de0475dff6c71a71:latest --timeout 10m0s
  2025-03-01T00:33:57Z	INFO	""--format spdx-json"" disables security scanning. Specify ""--scanners vuln"" explicitly if you want to include vulnerabilities in the ""spdx-json"" report.
  2025-03-01T00:40:39Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""Brotli"" version=""1.0.9""
  2025-03-01T00:40:39Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""Pygments"" version=""2.15.1""
  2025-03-01T00:40:39Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""archspec"" version=""0.2.3""
  2025-03-01T00:40:39Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""boltons"" version=""24.1.0""
  2025-03-01T00:40:39Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""certifi"" version=""2025.1.31""
  2025-03-01T00:40:39Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""cffi"" version=""1.17.1""
  2025-03-01T00:40:39Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""charset-normalizer"" version=""3.3.2""
  2025-03-01T00:40:39Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""conda"" version=""25.1.1""
  2025-03-01T00:40:39Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""conda-content-trust"" version=""0.2.0""
  2025-03-01T00:40:39Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""conda-libmamba-solver"" version=""25.1.1""
  2025-03-01T00:40:40Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""pip"" version=""25.0.1""
  2025-03-01T00:40:40Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""autocommand"" version=""2.2.2""
  2025-03-01T00:40:40Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""typeguard"" version=""4.3.0""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""cryptography"" version=""43.0.3""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""distro"" version=""1.9.0""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""frozendict"" version=""2.4.2""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""jsonpatch"" version=""1.33""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""jsonpointer"" version=""2.1""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""pip"" version=""25.0""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""pluggy"" version=""1.5.0""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""pycparser"" version=""2.21""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""pydantic_core"" version=""2.27.1""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""requests"" version=""2.32.3""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""rich"" version=""13.9.4""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""ruamel.yaml"" version=""0.18.6""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""ruamel.yaml.clib"" version=""0.2.8""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""autocommand"" version=""2.2.2""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""typeguard"" version=""4.3.0""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""tqdm"" version=""4.67.1""
  2025-03-01T00:40:41Z	INFO	[python] License acquired from METADATA classifiers may be subject to additional terms	name=""zstandard"" version=""0.23.0""
  2025-03-01T00:41:30Z	ERROR	[javadb] The first run cannot skip downloading Java DB
  2025-03-01T00:41:32Z	FATAL	Fatal error	image scan error: scan error: scan failed: failed analysis: analyze error: pipeline error: failed to analyze layer (sha256:60bf2d79fbfc426bd200659f1194eae7b6a57f5f3754f94a69c4a4d33d8bde48): post analysis error: post analysis error: Unable to initialize the Java DB: Java DB update failed: '--skip-java-db-update' cannot be specified on the first run
  2025-03-01T00:41:32: Call failed with error:
  
  2025-03-01T00:41:32: #### Exception encountered when generating sbom: Command '['trivy', 'image', '--no-progress', '--format', 'spdx-json', '--skip-db-update', '--skip-java-db-update', '--offline-scan', '--output', 'image-details.json', '978a92daa2ad4447aae1b21196dd4a9b.azurecr.io/azureml/azureml_7327894ab5e1ceb2de0475dff6c71a71:latest', '--timeout', '10m0s']' returned non-zero exit status 1.
  2025-03-01T00:41:32: 
  
  #### send_dependencies.py not found in current directory or its subdirectories.
  2025-03-01T00:41:32: #### Cleaning up local image cache
  2025-03-01T00:41:32: Deleting 978a92daa2ad4447aae1b21196dd4a9b.azurecr.io/azureml/azureml_7327894ab5e1ceb2de0475dff6c71a71 from local machine
  2025-03-01T00:41:32: Error response from daemon: page not found
  
  
  2025-03-01T00:41:32: Logging out of Docker registry: 978a92daa2ad4447aae1b21196dd4a9b.azurecr.io
  2025-03-01T00:41:32: Removing login credentials for https://index.docker.io/v1/
  
  
  2025-03-01T00:41:32: Logging out of Docker registry: 978a92daa2ad4447aae1b21196dd4a9b.azurecr.io
  2025-03-01T00:41:32: Removing login credentials for https://index.docker.io/v1/
  
  
  Traceback (most recent call last):
  
  Execution Summary
  =================
  RunId: polite_hominy_twxxhk7fvw
  Web View: https://ml.azure.com/runs/polite_hominy_twxxhk7fvw?wsid=/subscriptions/***/resourcegroups/recommenders_project_resources/workspaces/azureml-test-workspace
  
  Warnings:
  AzureMLCompute job failed
  ExecutionFailed: [REDACTED]
  	exit_codes: 1
  	Appinsights Reachable: Some(true)
  
    File ""/home/runner/work/recommenders/recommenders/tests/ci/azureml_tests/submit_groupwise_azureml_pytest.py"", line 171, in <module>
      run_tests(
    File ""/home/runner/work/recommenders/recommenders/tests/ci/azureml_tests/aml_utils.py"", line 142, in run_tests
      client.jobs.stream(job.name)
    File ""/opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/azure/core/tracing/decorator.py"", line 116, in wrapper_use_tracer
      return func(*args, **kwargs)
    File ""/opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py"", line 288, in wrapper
      return f(*args, **kwargs)
    File ""/opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py"", line 838, in stream
      self._stream_logs_until_completion(
    File ""/opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/azure/ai/ml/operations/_job_ops_helper.py"", line 334, in stream_logs_until_completion
      raise JobException(
  azure.ai.ml.exceptions.JobException: Exception : 
   {
      ""error"": {
          ""code"": ""UserError"",
          ""message"": ""Execution failed. User process 'python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error:     from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n\ntests/smoke/recommenders/models/test_newsrec_model.py::test_model_lstur\n  /root/conda/envs/Recommenders/lib/python3.11/site-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n    super().__init__(name, **kwargs)\n\ntests/smoke/recommenders/models/test_newsrec_model.py::test_model_lstur\n  /root/conda/envs/Recommenders/lib/python3.11/site-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n    updates=self.state_updates,\n\n-- Docs: [https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n==============================](https://docs.pytest.org/en/stable/how-to/capture-warnings.html/n==============================) slowest durations ===============================\n95.83s call     tests/smoke/recommenders/models/test_newsrec_model.py::test_model_lstur\n7.83s call     tests/functional/examples/test_notebooks_gpu.py::test_benchmark_movielens_gpu[size0-algos0-expected_values_ndcg0]\n1.63s call     tests/unit/examples/test_notebooks_gpu.py::test_gpu_vm\n\n(6 durations < 0.005s hidden.  Use -vv to show these durations.)\n=========================== short test summary info ============================\nFAILED tests/functional/examples/test_notebooks_gpu.py::test_benchmark_movielens_gpu[size0-algos0-expected_values_ndcg0]\n============= 1 failed, 2 passed, 3 warnings in 108.78s (0:01:48) ==============\n"",
          ""message_parameters"": {},
          ""details"": []
      },
      ""time"": ""0001-01-01T00:00:00.000Z"",
      ""component_name"": ""CommonRuntime""
  } 
  Error: Process completed with exit code 1.
```


### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->
https://github.com/recommenders-team/recommenders/actions/runs/13598630129/job/38020796411

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
",miguelgfierro,3491412,closed,False,13,2025-03-03T14:39:41+00:00,2025-04-01T05:21:34+00:00,2025-04-01T05:21:34+00:00,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2875318887,2211,[BUG] Error in PySpark tests,"### Description
<!--- Describe your issue/bug/request in detail -->
Spark tests breaking: https://github.com/recommenders-team/recommenders/actions/runs/13447063630/job/37574622335

```
2025-02-21T01:39:23Z	ERROR	The first run cannot skip downloading Java DB
  2025-02-21T01:39:24Z	FATAL	Fatal error	image scan error: scan error: scan failed: failed analysis: analyze error: pipeline error: failed to analyze layer (sha256:b09e82ba08eb33253154a30bdf386082168ded70dd2b200ccf6044153de91aaa): post analysis error: post analysis error: Unable to initialize the Java DB: Java DB update failed: '--skip-java-db-update' cannot be specified on the first run
  2025-02-21T01:39:24: Call failed with error:
  
  2025-02-21T01:39:24: #### Exception encountered when generating sbom: Command '['trivy', 'image', '--no-progress', '--format', 'spdx-json', '--skip-db-update', '--skip-java-db-update', '--offline-scan', '--output', 'image-details.json', '978a92daa2ad4447aae1b21196dd4a9b.azurecr.io/azureml/azureml_773345bc36a2cce558dfeaaf5d474adf', '--timeout', '10m0s']' returned non-zero exit status 1.
  2025-02-21T01:39:24: The push refers to repository [978a92daa2ad4447aae1b21196dd4a9b.azurecr.io/azureml/azureml_773345bc36a2cce558dfeaaf5d474adf]
  2025-02-21T01:39:24: b09e82ba08eb: Preparing
  2025-02-21T01:39:24: d2596f004fd8: Preparing
  2025-02-21T01:39:24: da9cf28542bf: Preparing
  2025-02-21T01:39:24: 4053f9139ccd: Preparing
  2025-02-21T01:39:24: 1e3547805ea3: Preparing
  2025-02-21T01:39:24: eac9efed49d3: Preparing
  2025-02-21T01:39:24: 2bf0156340ce: Preparing
  2025-02-21T01:39:24: f36fd4bb7334: Preparing
  2025-02-21T01:39:24: 2bf0156340ce: Waiting
  2025-02-21T01:39:24: eac9efed49d3: Waiting
  2025-02-21T01:39:24: f36fd4bb7334: Waiting
  2025-02-21T01:39:24: b09e82ba08eb: Layer already exists
  2025-02-21T01:39:24: d2596f004fd8: Layer already exists
  2025-02-21T01:39:24: da9cf28542bf: Layer already exists
  2025-02-21T01:39:24: 1e3547805ea3: Layer already exists
  2025-02-21T01:39:24: 4053f9139ccd: Layer already exists
  2025-02-21T01:39:24: eac9efed49d3: Layer already exists
  2025-02-21T01:39:24: 2bf0156340ce: Layer already exists
  2025-02-21T01:39:24: f36fd4bb7334: Layer already exists
  2025-02-21T01:39:24: 1: digest: sha256:f9a87aa0f05832939d7e545ff7656368c5003c045346d3e19502a22e094c5c33 size: 2018
  
  
  2025-02-21T01:39:24: #### Image digest: sha256:f9a87aa0f05832939d7e545ff7656368c5003c045346d3e19502a22e094c5c33
  2025-02-21T01:39:24: #### Calling generate_sbom
  2025-02-21T01:39:24: #### Generating SBOM 
  2025-02-21T01:39:24: #### Running command: trivy image --no-progress --format spdx-json --skip-db-update --skip-java-db-update --offline-scan --output image-details.json 978a92daa2ad4447aae1b21196dd4a9b.azurecr.io/azureml/azureml_773345bc36a2cce558dfeaaf5d474adf:1 --timeout 10m0s
  2025-02-21T01:39:25Z	INFO	""--format spdx"" and ""--format spdx-json"" disable security scanning
  2025-02-21T01:40:24Z	ERROR	The first run cannot skip downloading Java DB
  2025-02-21T01:40:24Z	FATAL	Fatal error	image scan error: scan error: scan failed: failed analysis: analyze error: pipeline error: failed to analyze layer (sha256:b09e82ba08eb33253154a30bdf386082168ded70dd2b200ccf6044153de91aaa): post analysis error: post analysis error: Unable to initialize the Java DB: Java DB update failed: '--skip-java-db-update' cannot be specified on the first run
  2025-02-21T01:40:24: Call failed with error:
  
  2025-02-21T01:40:24: #### Exception encountered when generating sbom: Command '['trivy', 'image', '--no-progress', '--format', 'spdx-json', '--skip-db-update', '--skip-java-db-update', '--offline-scan', '--output', 'image-details.json', '978a92daa2ad4447aae1b21196dd4a9b.azurecr.io/azureml/azureml_773345bc36a2cce558dfeaaf5d474adf:1', '--timeout', '10m0s']' returned non-zero exit status 1.
  2025-02-21T01:40:24: #### Cleaning up local image cache
  2025-02-21T01:40:24: Deleting 978a92daa2ad4447aae1b21196dd4a9b.azurecr.io/azureml/azureml_773345bc36a2cce558dfeaaf5d474adf from local machine
  2025-02-21T01:40:24: Error response from daemon: page not found
  
  
  2025-02-21T01:40:24: Logging out of Docker registry: 978a92daa2ad4447aae1b21196dd4a9b.azurecr.io
  2025-02-21T01:40:25: Removing login credentials for https://index.docker.io/v1/
  
  
  2025-02-21T01:40:25: Logging out of Docker registry: 978a92daa2ad4447aae1b21196dd4a9b.azurecr.io
  2025-02-21T01:40:25: Removing login credentials for https://index.docker.io/v1/
  
  
  Traceback (most recent call last):
  
    File ""/home/runner/work/recommenders/recommenders/tests/ci/azureml_tests/submit_groupwise_azureml_pytest.py"", line 171, in <module>
      run_tests(
    File ""/home/runner/work/recommenders/recommenders/tests/ci/azureml_tests/aml_utils.py"", line 142, in run_tests
  Execution Summary
  =================
  RunId: elated_owl_wth18ktmd9
  Web View: https://ml.azure.com/runs/elated_owl_wth18ktmd9?wsid=/subscriptions/***/resourcegroups/recommenders_project_resources/workspaces/azureml-test-workspace
  
  Warnings:
  AzureMLCompute job failed
  ExecutionFailed: [REDACTED]
  	exit_codes: 1
  	Appinsights Reachable: Some(true)
  
      client.jobs.stream(job.name)
    File ""/opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/azure/core/tracing/decorator.py"", line 116, in wrapper_use_tracer
      return func(*args, **kwargs)
    File ""/opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py"", line 288, in wrapper
      return f(*args, **kwargs)
    File ""/opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py"", line 838, in stream
      self._stream_logs_until_completion(
    File ""/opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/azure/ai/ml/operations/_job_ops_helper.py"", line 334, in stream_logs_until_completion
      raise JobException(
  azure.ai.ml.exceptions.JobException: Exception : 
   {
      ""error"": {
          ""code"": ""UserError"",
          ""message"": ""Execution failed. User process 'python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: 329.43s call     tests/data_validation/recommenders/datasets/test_criteo.py::test_criteo_load_spark_df_full\n70.65s call     tests/data_validation/recommenders/datasets/test_movielens.py::test_load_spark_df[20m-20000263-27278-1-Toy Story (1995)-Adventure|Animation|Children|Comedy|Fantasy-1995]\n65.50s call     tests/functional/examples/test_notebooks_pyspark.py::test_als_pyspark_functional\n50.93s call     tests/data_validation/recommenders/datasets/test_movielens.py::test_load_spark_df[10m-10000054-10681-1-Toy Story (1995)-Adventure|Animation|Children|Comedy|Fantasy-1995]\n31.99s call     tests/functional/examples/test_notebooks_pyspark.py::test_benchmark_movielens_pyspark[size0-algos0-expected_values_ndcg0]\n26.83s call     tests/smoke/examples/test_notebooks_pyspark.py::test_als_pyspark_smoke\n23.94s call     tests/smoke/examples/test_notebooks_pyspark.py::test_mmlspark_lightgbm_criteo_smoke\n12.09s call     tests/data_validation/recommenders/datasets/test_movielens.py::test_load_spark_df[1m-1000209-3883-1-Toy Story (1995)-Animation|Children's|Comedy-1995]\n7.95s call     tests/data_validation/recommenders/datasets/test_movielens.py::test_load_spark_df[100k-100000-1682-1-Toy Story (1995)-Animation|Children's|Comedy-1995]\n2.29s setup    tests/data_validation/recommenders/datasets/test_movielens.py::test_load_spark_df[100k-100000-1682-1-Toy Story (1995)-Animation|Children's|Comedy-1995]\n0.78s call     tests/data_validation/recommenders/datasets/test_criteo.py::test_criteo_load_spark_df_sample\n0.56s teardown tests/functional/examples/test_notebooks_pyspark.py::test_benchmark_movielens_pyspark[size0-algos0-expected_values_ndcg0]\n0.08s teardown tests/data_validation/recommenders/datasets/test_movielens.py::test_load_spark_df[20m-20000263-27278-1-Toy Story (1995)-Adventure|Animation|Children|Comedy|Fantasy-1995]\n0.03s teardown tests/data_validation/recommenders/datasets/test_movielens.py::test_load_spark_df[10m-10000054-10681-1-Toy Story (1995)-Adventure|Animation|Children|Comedy|Fantasy-1995]\n\n(18 durations < 0.005s hidden.  Use -vv to show these durations.)\n=========================== short test summary info ============================\nFAILED tests/data_validation/recommenders/datasets/test_criteo.py::test_criteo_load_spark_df_sample\nFAILED tests/smoke/examples/test_notebooks_pyspark.py::test_mmlspark_lightgbm_criteo_smoke\n======== 2 failed, 8 passed, 1 skipped, 5 warnings in 624.55s (0:10:24) ========\n"",
          ""message_parameters"": {},
          ""details"": []
      },
      ""time"": ""0001-01-01T00:00:00.000Z"",
      ""component_name"": ""CommonRuntime""
  } 
  Error: Process completed with exit code 1.
```
However, the tests run correctly:
```
============================= test session starts ==============================
  platform linux -- Python 3.11.9, pytest-8.3.2, pluggy-1.5.0
  rootdir: /mnt/azureml/cr/j/7e7d45a36a84448fa692cde5f8c6215b/exe/wd
  configfile: pyproject.toml
  plugins: cov-5.0.0, hypothesis-6.108.5, mock-3.14.0, typeguard-4.3.0, anyio-4.4.0
  collected 11 items
  
  tests/data_validation/recommenders/datasets/test_movielens.py ....       [ 36%]
  tests/data_validation/recommenders/datasets/test_criteo.py ..            [ 54%]
  tests/smoke/examples/test_notebooks_pyspark.py .                         [ 63%]
  tests/functional/examples/test_notebooks_pyspark.py s                    [ 72%]
  tests/smoke/examples/test_notebooks_pyspark.py .                         [ 81%]
  tests/functional/examples/test_notebooks_pyspark.py ..                   [100%]
 ============================== slowest durations ===============================
  420.11s call     tests/data_validation/recommenders/datasets/test_criteo.py::test_criteo_load_spark_df_full
  77.86s call     tests/functional/examples/test_notebooks_pyspark.py::test_als_pyspark_functional
  71.30s call     tests/data_validation/recommenders/datasets/test_movielens.py::test_load_spark_df[20m-20000263-27278-1-Toy Story (1995)-Adventure|Animation|Children|Comedy|Fantasy-1995]
  46.24s call     tests/data_validation/recommenders/datasets/test_movielens.py::test_load_spark_df[10m-10000054-10681-1-Toy Story (1995)-Adventure|Animation|Children|Comedy|Fantasy-1995]
  42.53s call     tests/functional/examples/test_notebooks_pyspark.py::test_benchmark_movielens_pyspark[size0-algos0-expected_values_ndcg0]
  36.71s call     tests/smoke/examples/test_notebooks_pyspark.py::test_mmlspark_lightgbm_criteo_smoke
  33.70s call     tests/smoke/examples/test_notebooks_pyspark.py::test_als_pyspark_smoke
  11.91s call     tests/data_validation/recommenders/datasets/test_movielens.py::test_load_spark_df[1m-1000209-3883-1-Toy Story (1995)-Animation|Children's|Comedy-1995]
  10.10s call     tests/data_validation/recommenders/datasets/test_movielens.py::test_load_spark_df[100k-100000-1682-1-Toy Story (1995)-Animation|Children's|Comedy-1995]
  3.33s setup    tests/data_validation/recommenders/datasets/test_movielens.py::test_load_spark_df[100k-100000-1682-1-Toy Story (1995)-Animation|Children's|Comedy-1995]
  2.10s call     tests/data_validation/recommenders/datasets/test_criteo.py::test_criteo_load_spark_df_sample
  1.01s teardown tests/functional/examples/test_notebooks_pyspark.py::test_benchmark_movielens_pyspark[size0-algos0-expected_values_ndcg0]
  0.08s teardown tests/data_validation/recommenders/datasets/test_movielens.py::test_load_spark_df[20m-20000263-27278-1-Toy Story (1995)-Adventure|Animation|Children|Comedy|Fantasy-1995]
  0.04s teardown tests/data_validation/recommenders/datasets/test_movielens.py::test_load_spark_df[10m-10000054-10681-1-Toy Story (1995)-Adventure|Animation|Children|Comedy|Fantasy-1995]
  
  (18 durations < 0.005s hidden.  Use -vv to show these durations.)
  ============ 10 passed, 1 skipped, 5 warnings in 758.54s (0:12:38) =============
```


### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
any suggestion why this could be failing? @anargyri  @SimonYansenZhao ",miguelgfierro,3491412,open,False,1,2025-02-24T15:15:29+00:00,2025-02-24T18:17:35+00:00,,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2875231572,2210,[BUG] Test are breaking for restricted access to the MIND blob,"### Description
<!--- Describe your issue/bug/request in detail -->
```

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_download_mind_large0')

    def test_download_mind_large(tmp_path):
>       train_path, valid_path = download_mind(size=""large"", dest_path=tmp_path)

tests/data_validation/recommenders/datasets/test_mind.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
recommenders/datasets/mind.py:66: in download_mind
    train_path = maybe_download(url=url_train, work_directory=path)
/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/retrying.py:56: in wrapped_f
    return Retrying(*dargs, **dkw).call(f, *args, **kw)
/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/retrying.py:266: in call
    raise attempt.get()
/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/retrying.py:301: in get
    six.reraise(self.value[0], self.value[1], self.value[2])
/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/six.py:719: in reraise
    raise value
/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/retrying.py:251: in call
    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)
recommenders/datasets/download_utils.py:52: in maybe_download
    r.raise_for_status()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Response [409]>

    def raise_for_status(self):
        """"""Raises :class:`HTTPError`, if one occurred.""""""
    
        http_error_msg = """"
        if isinstance(self.reason, bytes):
            # We attempt to decode utf-8 first because some servers
            # choose to localize their reason strings. If the string
            # isn't utf-8, we fall back to iso-8859-1 for all other
            # encodings. (See PR #3538)
            try:
                reason = self.reason.decode(""utf-8"")
            except UnicodeDecodeError:
                reason = self.reason.decode(""iso-8859-1"")
        else:
            reason = self.reason
    
        if 400 <= self.status_code < 500:
            http_error_msg = (
                f""{self.status_code} Client Error: {reason} for url: {self.url}""
            )
    
        elif 500 <= self.status_code < 600:
            http_error_msg = (
                f""{self.status_code} Server Error: {reason} for url: {self.url}""
            )
    
        if http_error_msg:
>           raise HTTPError(http_error_msg, response=self)
E           requests.exceptions.HTTPError: 409 Client Error: Public access is not permitted on this storage account. for url: https://mind201910small.blob.core.windows.net/release/MINDlarge_train.zip

/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/requests/models.py:1024: HTTPError
------------------------------ Captured log call -------------------------------
ERROR    recommenders.datasets.download_utils:download_utils.py:51 Problem downloading https://mind201910small.blob.core.windows.net/release/MINDlarge_train.zip
ERROR    recommenders.datasets.download_utils:download_utils.py:51 Problem downloading https://mind201910small.blob.core.windows.net/release/MINDlarge_train.zip
ERROR    recommenders.datasets.download_utils:download_utils.py:51 Problem downloading https://mind201910small.blob.core.windows.net/release/MINDlarge_train.zip
ERROR    recommenders.datasets.download_utils:download_utils.py:51 Problem downloading https://mind201910small.blob.core.windows.net/release/MINDlarge_train.zip
ERROR    recommenders.datasets.download_utils:download_utils.py:51 Problem downloading https://mind201910small.blob.core.windows.net/release/MINDlarge_train.zip
___________________________ test_extract_mind_large ____________________________

tmp = '/tmp/pytest-of-root/pytest-0/tmptwsi8df7'

    def test_extract_mind_large(tmp):
>       train_zip, valid_zip = download_mind(size=""large"", dest_path=tmp)

tests/data_validation/recommenders/datasets/test_mind.py:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
recommenders/datasets/mind.py:66: in download_mind
    train_path = maybe_download(url=url_train, work_directory=path)
/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/retrying.py:56: in wrapped_f
    return Retrying(*dargs, **dkw).call(f, *args, **kw)
/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/retrying.py:266: in call
    raise attempt.get()
/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/retrying.py:301: in get
    six.reraise(self.value[0], self.value[1], self.value[2])
/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/six.py:719: in reraise
    raise value
/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/retrying.py:251: in call
    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)
recommenders/datasets/download_utils.py:52: in maybe_download
    r.raise_for_status()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Response [409]>

    def raise_for_status(self):
        """"""Raises :class:`HTTPError`, if one occurred.""""""
    
        http_error_msg = """"
        if isinstance(self.reason, bytes):
            # We attempt to decode utf-8 first because some servers
            # choose to localize their reason strings. If the string
            # isn't utf-8, we fall back to iso-8859-1 for all other
            # encodings. (See PR #3538)
            try:
                reason = self.reason.decode(""utf-8"")
            except UnicodeDecodeError:
                reason = self.reason.decode(""iso-8859-1"")
        else:
            reason = self.reason
    
        if 400 <= self.status_code < 500:
            http_error_msg = (
                f""{self.status_code} Client Error: {reason} for url: {self.url}""
            )
    
        elif 500 <= self.status_code < 600:
            http_error_msg = (
                f""{self.status_code} Server Error: {reason} for url: {self.url}""
            )
    
        if http_error_msg:
>           raise HTTPError(http_error_msg, response=self)
E           requests.exceptions.HTTPError: 409 Client Error: Public access is not permitted on this storage account. for url: https://mind201910small.blob.core.windows.net/release/MINDlarge_train.zip

/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/requests/models.py:1024: HTTPError
------------------------------ Captured log call -------------------------------
ERROR    recommenders.datasets.download_utils:download_utils.py:51 Problem downloading https://mind201910small.blob.core.windows.net/release/MINDlarge_train.zip
ERROR    recommenders.datasets.download_utils:download_utils.py:51 Problem downloading https://mind201910small.blob.core.windows.net/release/MINDlarge_train.zip
ERROR    recommenders.datasets.download_utils:download_utils.py:51 Problem downloading https://mind201910small.blob.core.windows.net/release/MINDlarge_train.zip
ERROR    recommenders.datasets.download_utils:download_utils.py:51 Problem downloading https://mind201910small.blob.core.windows.net/release/MINDlarge_train.zip
ERROR    recommenders.datasets.download_utils:download_utils.py:51 Problem downloading https://mind201910small.blob.core.windows.net/release/MINDlarge_train.zip
_____________________________ test_mind_utils_runs _____________________________

notebooks = {'als_deep_dive': '/mnt/azureml/cr/j/0ff71de6470e4f4eb33b284cd911e6c9/exe/wd/examples/02_model_collaborative_filtering...rk_movielens': '/mnt/azureml/cr/j/0ff71de6470e4f4eb33b284cd911e6c9/exe/wd/examples/06_benchmarks/movielens.ipynb', ...}
output_notebook = 'output.ipynb', kernel_name = 'python3'
tmp = '/tmp/pytest-of-root/pytest-0/tmpnb2e_a7h'

    def test_mind_utils_runs(notebooks, output_notebook, kernel_name, tmp):
        notebook_path = notebooks[""mind_utils""]
>       execute_notebook(
            notebook_path,
            output_notebook,
            kernel_name=kernel_name,
            parameters=dict(mind_type=""small"", word_embedding_dim=300),
        )

tests/data_validation/examples/test_mind.py:9: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
recommenders/utils/notebook_utils.py:102: in execute_notebook
    executed_notebook, _ = execute_preprocessor.preprocess(
/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/nbconvert/preprocessors/execute.py:103: in preprocess
    self.preprocess_cell(cell, resources, index)
/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/nbconvert/preprocessors/execute.py:124: in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/jupyter_core/utils/__init__.py:165: in wrapped
    return loop.run_until_complete(inner)
/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/asyncio/base_events.py:649: in run_until_complete
    return future.result()
/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/nbclient/client.py:1062: in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <nbconvert.preprocessors.execute.ExecutePreprocessor object at 0x145c1b978d00>
cell = {'cell_type': 'code', 'execution_count': 3, 'metadata': {'execution': {'iopub.status.busy': '2024-08-01T02:06:38.72166...lid'), clean_zip_file=False)\noutput_path = os.path.join(data_path, 'utils')\nos.makedirs(output_path, exist_ok=True)""}
cell_index = 4
exec_reply = {'buffers': [], 'content': {'ename': 'HTTPError', 'engine_info': {'engine_id': -1, 'engine_uuid': 'ff776c0c-0b2d-4c00-...e, 'engine': 'ff776c0c-0b2d-4c00-8284-f504cc9cd4c9', 'started': '2024-08-01T02:06:38.722124Z', 'status': 'error'}, ...}

    async def _check_raise_for_error(
        self, cell: NotebookNode, cell_index: int, exec_reply: dict[str, t.Any] | None
    ) -> None:
        if exec_reply is None:
            return None
    
        exec_reply_content = exec_reply[""content""]
        if exec_reply_content[""status""] != ""error"":
            return None
    
        cell_allows_errors = (not self.force_raise_errors) and (
            self.allow_errors
            or exec_reply_content.get(""ename"") in self.allow_error_names
            or ""raises-exception"" in cell.metadata.get(""tags"", [])
        )
        await run_hook(
            self.on_cell_error, cell=cell, cell_index=cell_index, execute_reply=exec_reply
        )
        if not cell_allows_errors:
>           raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
E           nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
E           ------------------
E           tmpdir = TemporaryDirectory()
E           data_path = tmpdir.name
E           train_zip, valid_zip = download_mind(size=mind_type, dest_path=data_path)
E           unzip_file(train_zip, os.path.join(data_path, 'train'), clean_zip_file=False)
E           unzip_file(valid_zip, os.path.join(data_path, 'valid'), clean_zip_file=False)
E           output_path = os.path.join(data_path, 'utils')
E           os.makedirs(output_path, exist_ok=True)
E           ------------------
E           
E           ----- stderr -----
E           Problem downloading https://mind201910small.blob.core.windows.net/release/MINDsmall_train.zip
E           ----- stderr -----
E           Problem downloading https://mind201910small.blob.core.windows.net/release/MINDsmall_train.zip
E           ----- stderr -----
E           Problem downloading https://mind201910small.blob.core.windows.net/release/MINDsmall_train.zip
E           ----- stderr -----
E           Problem downloading https://mind201910small.blob.core.windows.net/release/MINDsmall_train.zip
E           ----- stderr -----
E           Problem downloading https://mind201910small.blob.core.windows.net/release/MINDsmall_train.zip
E           ------------------
E           
E           [0;31m---------------------------------------------------------------------------[0m
E           [0;31mHTTPError[0m                                 Traceback (most recent call last)
E           Cell [0;32mIn[3], line 3[0m
E           [1;32m      1[0m tmpdir [38;5;241m=[39m TemporaryDirectory()
E           [1;32m      2[0m data_path [38;5;241m=[39m tmpdir[38;5;241m.[39mname
E           [0;32m----> 3[0m train_zip, valid_zip [38;5;241m=[39m [43mdownload_mind[49m[43m([49m[43msize[49m[38;5;241;43m=[39;49m[43mmind_type[49m[43m,[49m[43m [49m[43mdest_path[49m[38;5;241;43m=[39;49m[43mdata_path[49m[43m)[49m
E           [1;32m      4[0m unzip_file(train_zip, os[38;5;241m.[39mpath[38;5;241m.[39mjoin(data_path, [38;5;124m'[39m[38;5;124mtrain[39m[38;5;124m'[39m), clean_zip_file[38;5;241m=[39m[38;5;28;01mFalse[39;00m)
E           [1;32m      5[0m unzip_file(valid_zip, os[38;5;241m.[39mpath[38;5;241m.[39mjoin(data_path, [38;5;124m'[39m[38;5;124mvalid[39m[38;5;124m'[39m), clean_zip_file[38;5;241m=[39m[38;5;28;01mFalse[39;00m)
E           
E           File [0;32m/mnt/azureml/cr/j/0ff71de6470e4f4eb33b284cd911e6c9/exe/wd/recommenders/datasets/mind.py:66[0m, in [0;36mdownload_mind[0;34m(size, dest_path)[0m
E           [1;32m     64[0m url_train, url_valid [38;5;241m=[39m URL_MIND[size]
E           [1;32m     65[0m [38;5;28;01mwith[39;00m download_path(dest_path) [38;5;28;01mas[39;00m path:
E           [0;32m---> 66[0m     train_path [38;5;241m=[39m [43mmaybe_download[49m[43m([49m[43murl[49m[38;5;241;43m=[39;49m[43murl_train[49m[43m,[49m[43m [49m[43mwork_directory[49m[38;5;241;43m=[39;49m[43mpath[49m[43m)[49m
E           [1;32m     67[0m     valid_path [38;5;241m=[39m maybe_download(url[38;5;241m=[39murl_valid, work_directory[38;5;241m=[39mpath)
E           [1;32m     68[0m [38;5;28;01mreturn[39;00m train_path, valid_path
E           
E           File [0;32m/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/retrying.py:56[0m, in [0;36mretry.<locals>.wrap.<locals>.wrapped_f[0;34m(*args, **kw)[0m
E           [1;32m     54[0m [38;5;129m@six[39m[38;5;241m.[39mwraps(f)
E           [1;32m     55[0m [38;5;28;01mdef[39;00m [38;5;21mwrapped_f[39m([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkw):
E           [0;32m---> 56[0m     [38;5;28;01mreturn[39;00m [43mRetrying[49m[43m([49m[38;5;241;43m*[39;49m[43mdargs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mdkw[49m[43m)[49m[38;5;241;43m.[39;49m[43mcall[49m[43m([49m[43mf[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkw[49m[43m)[49m
E           
E           File [0;32m/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/retrying.py:266[0m, in [0;36mRetrying.call[0;34m(self, fn, *args, **kwargs)[0m
E           [1;32m    263[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mstop(attempt_number, delay_since_first_attempt_ms):
E           [1;32m    264[0m     [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m [38;5;28mself[39m[38;5;241m.[39m_wrap_exception [38;5;129;01mand[39;00m attempt[38;5;241m.[39mhas_exception:
E           [1;32m    265[0m         [38;5;66;03m# get() on an attempt with an exception should cause it to be raised, but raise just in case[39;00m
E           [0;32m--> 266[0m         [38;5;28;01mraise[39;00m [43mattempt[49m[38;5;241;43m.[39;49m[43mget[49m[43m([49m[43m)[49m
E           [1;32m    267[0m     [38;5;28;01melse[39;00m:
E           [1;32m    268[0m         [38;5;28;01mraise[39;00m RetryError(attempt)
E           
E           File [0;32m/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/retrying.py:301[0m, in [0;36mAttempt.get[0;34m(self, wrap_exception)[0m
E           [1;32m    299[0m         [38;5;28;01mraise[39;00m RetryError([38;5;28mself[39m)
E           [1;32m    300[0m     [38;5;28;01melse[39;00m:
E           [0;32m--> 301[0m         [43msix[49m[38;5;241;43m.[39;49m[43mreraise[49m[43m([49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mvalue[49m[43m[[49m[38;5;241;43m0[39;49m[43m][49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mvalue[49m[43m[[49m[38;5;241;43m1[39;49m[43m][49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mvalue[49m[43m[[49m[38;5;241;43m2[39;49m[43m][49m[43m)[49m
E           [1;32m    302[0m [38;5;28;01melse[39;00m:
E           [1;32m    303[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39mvalue
E           
E           File [0;32m/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/six.py:719[0m, in [0;36mreraise[0;34m(tp, value, tb)[0m
E           [1;32m    717[0m     [38;5;28;01mif[39;00m value[38;5;241m.[39m__traceback__ [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m tb:
E           [1;32m    718[0m         [38;5;28;01mraise[39;00m value[38;5;241m.[39mwith_traceback(tb)
E           [0;32m--> 719[0m     [38;5;28;01mraise[39;00m value
E           [1;32m    720[0m [38;5;28;01mfinally[39;00m:
E           [1;32m    721[0m     value [38;5;241m=[39m [38;5;28;01mNone[39;00m
E           
E           File [0;32m/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/retrying.py:251[0m, in [0;36mRetrying.call[0;34m(self, fn, *args, **kwargs)[0m
E           [1;32m    248[0m     [38;5;28mself[39m[38;5;241m.[39m_before_attempts(attempt_number)
E           [1;32m    250[0m [38;5;28;01mtry[39;00m:
E           [0;32m--> 251[0m     attempt [38;5;241m=[39m Attempt([43mfn[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m, attempt_number, [38;5;28;01mFalse[39;00m)
E           [1;32m    252[0m [38;5;28;01mexcept[39;00m:
E           [1;32m    253[0m     tb [38;5;241m=[39m sys[38;5;241m.[39mexc_info()
E           
E           File [0;32m/mnt/azureml/cr/j/0ff71de6470e4f4eb33b284cd911e6c9/exe/wd/recommenders/datasets/download_utils.py:52[0m, in [0;36mmaybe_download[0;34m(url, filename, work_directory, expected_bytes)[0m
E           [1;32m     50[0m     [38;5;28;01melse[39;00m:
E           [1;32m     51[0m         log[38;5;241m.[39merror([38;5;124mf[39m[38;5;124m""[39m[38;5;124mProblem downloading [39m[38;5;132;01m{[39;00murl[38;5;132;01m}[39;00m[38;5;124m""[39m)
E           [0;32m---> 52[0m         [43mr[49m[38;5;241;43m.[39;49m[43mraise_for_status[49m[43m([49m[43m)[49m
E           [1;32m     53[0m [38;5;28;01melse[39;00m:
E           [1;32m     54[0m     log[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m""[39m[38;5;124mFile [39m[38;5;132;01m{[39;00mfilepath[38;5;132;01m}[39;00m[38;5;124m already downloaded[39m[38;5;124m""[39m)
E           
E           File [0;32m/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/requests/models.py:1024[0m, in [0;36mResponse.raise_for_status[0;34m(self)[0m
E           [1;32m   1019[0m     http_error_msg [38;5;241m=[39m (
E           [1;32m   1020[0m         [38;5;124mf[39m[38;5;124m""[39m[38;5;132;01m{[39;00m[38;5;28mself[39m[38;5;241m.[39mstatus_code[38;5;132;01m}[39;00m[38;5;124m Server Error: [39m[38;5;132;01m{[39;00mreason[38;5;132;01m}[39;00m[38;5;124m for url: [39m[38;5;132;01m{[39;00m[38;5;28mself[39m[38;5;241m.[39murl[38;5;132;01m}[39;00m[38;5;124m""[39m
E           [1;32m   1021[0m     )
E           [1;32m   1023[0m [38;5;28;01mif[39;00m http_error_msg:
E           [0;32m-> 1024[0m     [38;5;28;01mraise[39;00m HTTPError(http_error_msg, response[38;5;241m=[39m[38;5;28mself[39m)
E           
E           [0;31mHTTPError[0m: 409 Client Error: Public access is not permitted on this storage account. for url: https://mind201910small.blob.core.windows.net/release/MINDsmall_train.zip

/azureml-envs/azureml_ee05c39251ad373fce7f4861d6ed56fe/lib/python3.10/site-packages/nbclient/client.py:918: CellExecutionError
```


### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->
https://github.com/recommenders-team/recommenders/actions/runs/13447074780/job/37577703132

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
",miguelgfierro,3491412,open,False,11,2025-02-24T14:48:48+00:00,2025-05-02T06:44:53+00:00,,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2863886247,2209,Add files via upload,"### Description
Have added two Recommendation/prediction system (Energy Consumption(New Zealand Dataset) and Diabetics prediction with medicine recomendation)





### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ x] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [x ] I have added tests covering my contributions.
- [ x] I have updated the documentation accordingly.
- [ x] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ x] This PR is being made to `staging branch` AND NOT TO `main branch`.
- Signed-off-by: Author Name <rishiram20757@gmail.com>
",Rishiram20757,131481972,open,False,2,2025-02-19T16:47:35+00:00,2025-03-03T17:26:27+00:00,,,0,0,0,0,0,0,0
recommenders-team/recommenders,2846220383,2208,Update scenarios,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2025-02-11T18:50:37+00:00,2025-02-12T11:16:05+00:00,2025-02-12T10:13:02+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2840544718,2207,Scenarios of recommendation systems,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2025-02-09T09:39:04+00:00,2025-02-11T18:50:55+00:00,2025-02-10T06:13:51+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2792140929,2206,Staging to main: Fix issue with Cornac version,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2025-01-16T09:18:52+00:00,2025-01-19T03:16:46+00:00,2025-01-19T03:16:46+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2792138327,2205,[FEATURE] Add embeding ranker in PyTorch,"### Description
<!--- Describe your expected feature in detail -->
https://www.tensorflow.org/recommenders/examples/basic_ranking, but using PyTorch instead of TF

### Expected behavior with the suggested feature
<!--- For example:  -->
<!--- *Adding algorithm xxx will help people understand more about xxx use case scenarios. -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
",miguelgfierro,3491412,open,False,7,2025-01-16T09:17:38+00:00,2025-01-24T22:04:07+00:00,,enhancement,0,0,0,0,0,0,0
recommenders-team/recommenders,2786503734,2204,Use cornac 2.3.0 for Python 3.9+,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
The latest version of [cornac 2.3.0](https://pypi.org/project/cornac/#files) does not provide built distributions for Python 3.8.  This PR set cornac to 2.2.2 for Python 3.8.

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
* #2203

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [X] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [X] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [X] This PR is being made to `staging branch` AND NOT TO `main branch`.
",SimonYansenZhao,6165588,closed,False,0,2025-01-14T08:06:54+00:00,2025-01-14T17:07:27+00:00,2025-01-14T17:07:23+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2759402791,2203,[BUG] Error when building docker image Cornac Cython,"### Description
<!--- Describe your issue/bug/request in detail -->
```
2024-12-26T07:10:27: Collecting cornac<3,>=1.15.2 (from recommenders==1.2.1)
  2024-12-26T07:10:27:   Downloading cornac-2.3.0.tar.gz (5.9 MB)
  2024-12-26T07:10:28:       5.9/5.9 MB 71.2 MB/s eta 0:00:00
  2024-12-26T07:10:29:   Preparing metadata (setup.py): started
  2024-12-26T07:10:29:   Preparing metadata (setup.py): finished with status 'error'
  2024-12-26T07:10:29:   error: subprocess-exited-with-error
  2024-12-26T07:10:29:   
  2024-12-26T07:10:29:    python setup.py egg_info did not run successfully.
  2024-12-26T07:10:29:    exit code: 1
  2024-12-26T07:10:29:   > [2 lines of output]
  2024-12-26T07:10:29:       We need some dependencies to build Cornac.
  2024-12-26T07:10:29:       Run: pip3 install Cython ""numpy<2.0.0"" ""scipy<=1.13.1"" tqdm powerlaw
  2024-12-26T07:10:29:       [end of output]
  2024-12-26T07:10:29:   
  2024-12-26T07:10:29:   note: This error originates from a subprocess, and is likely not a problem with pip.
  2024-12-26T07:10:29: error: metadata-generation-failed
  
  2024-12-26T07:10:29:  Encountered error while generating package metadata.
  2024-12-26T07:10:29: > See above for output.
  
  2024-12-26T07:10:29: note: This is an issue with the package mentioned above, not pip.
  2024-12-26T07:10:29: hint: See above for details.
  2024-12-26T07:10:30: The command '/bin/bash -c source /root/conda/bin/activate &&     conda activate Recommenders &&     if [[ ""${EXTRAS}"" =~ spark ]]; then conda install -c conda-forge -y ""openjdk=${JDK_VERSION}""; fi &&     if [ -z ""${GIT_REF}"" ]; then         pip install ${RECO_DIR}${EXTRAS};     else         pip install recommenders${EXTRAS}@git+[https://github.com/recommenders-team/recommenders.git@${GIT_REF};](https://github.com/recommenders-team/recommenders.git@$%7BGIT_REF%7D;)     fi &&     jupyter notebook --generate-config &&     echo ""c.MultiKernelManager.default_kernel_name = 'Recommenders'"" >> /root/.jupyter/jupyter_notebook_config.py &&     python -m ipykernel install --user --name Recommenders --display-name ""Python (Recommenders)""' returned a non-zero code: 1
  
  2024-12-26T07:10:30: 
  
  2024-12-26T07:10:30: CalledProcessError(1, ['docker', 'build', '-f', 'tools/docker/Dockerfile', '.', '-t', '978a92daa2ad4447aae1b21196dd4a9b.azurecr.io/azureml/azureml_12a60390f9d03a5a12df1a1acae5a1bd', '-t', '978a92daa2ad4447aae1b21196dd4a9b.azurecr.io/azureml/azureml_12a60390f9d03a5a12df1a1acae5a1bd:1'])
  
  2024-12-26T07:10:30: Building docker image failed with exit code: 1
  
  2024-12-26T07:10:30: Logging out of Docker registry: 978a92daa2ad4447aae1b21196dd4a9b.azurecr.io
  2024-12-26T07:10:30: Removing login credentials for https://index.docker.io/v1/
```


### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->
See https://github.com/recommenders-team/recommenders/actions/runs/12497618466/job/34877449001

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
@SimonYansenZhao this error is weird, there is an error in building the docker image, but somehow the tests are running. Do you have any idea why this is happening?",miguelgfierro,3491412,closed,False,1,2024-12-26T07:30:03+00:00,2025-01-14T17:23:55+00:00,2025-01-14T17:23:55+00:00,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2756323525,2202,Note in markdown to add the release tag to the federeted credentials,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
If we don't add the federated credentials, we'll get an authentication error when doing a release. See https://github.com/recommenders-team/recommenders/actions/runs/12467800197/attempts/1

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2024-12-23T15:53:22+00:00,2025-01-14T17:07:47+00:00,2025-01-14T17:07:44+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2754784523,2201,Staging to main: Prepare for release,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,3,2024-12-22T18:27:22+00:00,2024-12-24T06:04:35+00:00,2024-12-23T13:35:54+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2748735810,2200,Prepare for release,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,2,2024-12-18T20:56:50+00:00,2024-12-22T13:29:29+00:00,2024-12-22T13:29:24+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2744288376,2199,Update Tao's user,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2024-12-17T08:45:47+00:00,2024-12-22T13:28:49+00:00,2024-12-22T13:28:43+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2743865492,2198,[BUG] Direct use of `numba.cuda.gpus` lead to error that module `numba` has no attribute `cuda`,"### Description
After installing `recommenders[gpu]`, doing `len(numba.cuda.gpus)` will lead to the following error

```
>>> len(numba.cuda.gpus)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: module 'numba' has no attribute 'cuda'
```

Changing to `from numba import cuda` and then `cuda.gpus` will resolve the issue.

### In which platform does it happen?
Linux Ubuntu 22.04

### How do we replicate the issue?
See above.

### Expected behavior (i.e. solution)
See above.

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
",lezhangamd,174602670,open,False,1,2024-12-17T03:53:20+00:00,2024-12-23T06:58:38+00:00,,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2743403739,2197,Execute tests when there are changes in the pipelines,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2024-12-16T21:09:09+00:00,2024-12-22T13:29:09+00:00,2024-12-22T13:29:05+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2743333213,2196,Python 3.12 in test pipelines,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2024-12-16T20:27:35+00:00,2024-12-16T21:06:31+00:00,2024-12-16T21:06:28+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2734523294,2195,[BUG] installation of recommenders[gpu] 1.2.0 failed in compiling statsmodel,"### Description
Installing `recommenders[gpu]==1.2.0`, the latest version, failed in compiling `statsmodel`.
```bash
INFO: pip is looking at multiple versions of statsmodels to determine which version is compatible with other requirements. This could take a while.
  Downloading statsmodels-0.13.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.0 MB)
      10.0/10.0 MB 1.7 MB/s eta 0:00:00
  Downloading statsmodels-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)
      9.9/9.9 MB 1.3 MB/s eta 0:00:00
  Downloading statsmodels-0.13.0.tar.gz (17.8 MB)
      17.8/17.8 MB 2.0 MB/s eta 0:00:00
  Installing build dependencies ... done
  Getting requirements to build wheel ... error
  error: subprocess-exited-with-error
  
   Getting requirements to build wheel did not run successfully.
   exit code: 1
  > [67 lines of output]
      <string>:19: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
      <string>:53: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
      <string>:56: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
      <string>:53: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
      
      Error compiling Cython file:
      ------------------------------------------------------------
      ...
      cimport cython
      cimport numpy as np
      import numpy as np
      
      ctypedef np.float64_t DOUBLE
      ctypedef np.int_t INT
               ^
      ------------------------------------------------------------
      
      statsmodels/nonparametric/linbin.pyx:13:9: 'int_t' is not a type identifier
      Compiling statsmodels/tsa/_stl.pyx because it changed.
      Compiling statsmodels/tsa/holtwinters/_exponential_smoothers.pyx because it changed.
      Compiling statsmodels/tsa/exponential_smoothing/_ets_smooth.pyx because it changed.
      Compiling statsmodels/tsa/_innovations.pyx because it changed.
      Compiling statsmodels/tsa/regime_switching/_hamilton_filter.pyx because it changed.
      Compiling statsmodels/tsa/regime_switching/_kim_smoother.pyx because it changed.
      Compiling statsmodels/tsa/innovations/_arma_innovations.pyx because it changed.
      Compiling statsmodels/nonparametric/linbin.pyx because it changed.
      Compiling statsmodels/robust/_qn.pyx because it changed.
      Compiling statsmodels/nonparametric/_smoothers_lowess.pyx because it changed.
      Compiling statsmodels/tsa/statespace/_initialization.pyx because it changed.
      Compiling statsmodels/tsa/statespace/_representation.pyx because it changed.
      Compiling statsmodels/tsa/statespace/_kalman_filter.pyx because it changed.
      Compiling statsmodels/tsa/statespace/_filters/_conventional.pyx because it changed.
      Compiling statsmodels/tsa/statespace/_filters/_inversions.pyx because it changed.
      Compiling statsmodels/tsa/statespace/_filters/_univariate.pyx because it changed.
      Compiling statsmodels/tsa/statespace/_filters/_univariate_diffuse.pyx because it changed.
      Compiling statsmodels/tsa/statespace/_kalman_smoother.pyx because it changed.
      Compiling statsmodels/tsa/statespace/_smoothers/_alternative.pyx because it changed.
      Compiling statsmodels/tsa/statespace/_smoothers/_classical.pyx because it changed.
      Compiling statsmodels/tsa/statespace/_smoothers/_conventional.pyx because it changed.
      Compiling statsmodels/tsa/statespace/_smoothers/_univariate.pyx because it changed.
      Compiling statsmodels/tsa/statespace/_smoothers/_univariate_diffuse.pyx because it changed.
      Compiling statsmodels/tsa/statespace/_simulation_smoother.pyx because it changed.
      Compiling statsmodels/tsa/statespace/_cfa_simulation_smoother.pyx because it changed.
      Compiling statsmodels/tsa/statespace/_tools.pyx because it changed.
      [ 1/26] Cythonizing statsmodels/nonparametric/_smoothers_lowess.pyx
      [ 2/26] Cythonizing statsmodels/nonparametric/linbin.pyx
      Traceback (most recent call last):
        File ""/home/lezhang/environment/reco/lib/python3.10/site-packages/pip/_vendor/pep517/in_process/_in_process.py"", line 363, in <module>
          main()
        File ""/home/lezhang/environment/reco/lib/python3.10/site-packages/pip/_vendor/pep517/in_process/_in_process.py"", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File ""/home/lezhang/environment/reco/lib/python3.10/site-packages/pip/_vendor/pep517/in_process/_in_process.py"", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File ""/tmp/pip-build-env-bi0vrxzo/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 334, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=[])
        File ""/tmp/pip-build-env-bi0vrxzo/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 304, in _get_build_requires
          self.run_setup()
        File ""/tmp/pip-build-env-bi0vrxzo/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 522, in run_setup
          super().run_setup(setup_script=setup_script)
        File ""/tmp/pip-build-env-bi0vrxzo/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 320, in run_setup
          exec(code, locals())
        File ""<string>"", line 304, in <module>
        File ""/tmp/pip-build-env-bi0vrxzo/overlay/lib/python3.10/site-packages/Cython/Build/Dependencies.py"", line 1154, in cythonize
          cythonize_one(*args)
        File ""/tmp/pip-build-env-bi0vrxzo/overlay/lib/python3.10/site-packages/Cython/Build/Dependencies.py"", line 1321, in cythonize_one
          raise CompileError(None, pyx_file)
      Cython.Compiler.Errors.CompileError: statsmodels/nonparametric/linbin.pyx
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

 Getting requirements to build wheel did not run successfully.
 exit code: 1
> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
```

It looks like the fix has been merged into `main` branch but it is not yet released. #2182

### In which platform does it happen?
Linux WSL Ubuntu 22.04

### How do we replicate the issue?
`pip install recommenders[gpu]==1.2.0`

### Expected behavior (i.e. solution)
Installation should be successful. 

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
",lezhangamd,174602670,closed,False,4,2024-12-12T02:14:15+00:00,2024-12-26T06:07:08+00:00,2024-12-26T06:07:08+00:00,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2727633406,2194,[BUG] SVAE problems with TypeError: You are passing KerasTensor,"### Description
In the example code examples/02_model_collaborative_filtering/standard_vae_deep_dive.ipynb I find an error like this one :
    TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=""created by layer 'tf.cast_2'""), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.

I have tried changing the libraries it uses, but I found no solution. The error occurs in the snippet code 
model_without_anneal = StandardVAE(n_users=train_data.shape[0], # Number of unique users in the training set
                                   original_dim=train_data.shape[1], # Number of unique items in the training set
                                   intermediate_dim=INTERMEDIATE_DIM, 
                                   latent_dim=LATENT_DIM, 
                                   n_epochs=EPOCHS, 
                                   batch_size=BATCH_SIZE, 
                                   k=TOP_K,
                                   verbose=0,
                                   seed=SEED,
                                   save_path=WEIGHTS_PATH,
                                   drop_encoder=0.5,
                                   drop_decoder=0.5,
                                   annealing=False,
                                   beta=1.0
                                   )
with Timer() as t:
    model_without_anneal.fit(x_train=train_data,
                             x_valid=val_data,
                             x_val_tr=val_data_tr,
                             x_val_te=val_data_te_ratings, # with the original ratings 
                             mapper=am_val
                             )

### In which platform does it happen?
I am using VScode but I'm sure it is not the problem.

### How do we replicate the issue?
Install pip install pandera==0.15.1 and execute the code.

### Expected behavior (i.e. solution)
It should train the model without problems.

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [X] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
I am using others versions of libraries because installing those older versions gave me some problems. I'm using:
- System version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
- Pandas version: 2.2.3
- Tensorflow version: 2.13.0
- Keras version: 2.13.1
The libraries are used in the original code:
- System version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
- Pandas version: 1.1.2
- Tensorflow version: 2.2.0-rc1
- Keras version: 2.3.1",Peanpepu,95430152,open,False,0,2024-12-09T16:28:30+00:00,2024-12-09T16:28:30+00:00,,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2722309826,2193,[BUG] Authentication error breaking AzureML tests,"### Description
<!--- Describe your issue/bug/request in detail -->
```
Pytest logs
  DefaultAzureCredential failed to retrieve a token from the included credentials.
  Attempted credentials:
  	EnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.
  Visit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.
  	ManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no response from the IMDS endpoint. invalid_request
  	SharedTokenCacheCredential: SharedTokenCacheCredential authentication unavailable. No accounts were found in the cache.
  	AzureCliCredential: Please run 'az login' to set up an account
  	AzurePowerShellCredential: Az.Account module >= 2.2.0 is not installed
  	AzureDeveloperCliCredential: Azure Developer CLI could not be found. Please visit https://aka.ms/azure-dev for installation instructions and then,once installed, authenticate to your Azure account using 'azd auth login'.
  To mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.
  Traceback (most recent call last):
    File ""/home/runner/work/recommenders/recommenders/tests/ci/azureml_tests/post_pytest.py"", line 60, in <module>
      client = get_client(
    File ""/home/runner/work/recommenders/recommenders/tests/ci/azureml_tests/aml_utils.py"", line 32, in get_client
      workspace = client.workspaces.get(workspace_name)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py"", line 292, in wrapper
      return f(*args, **kwargs)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/core/tracing/decorator.py"", line 105, in wrapper_use_tracer
      return func(*args, **kwargs)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/ai/ml/operations/_workspace_operations.py"", line 141, in get
      return super().get(workspace_name=name, **kwargs)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/ai/ml/operations/_workspace_operations_base.py"", line [88](https://github.com/recommenders-team/recommenders/actions/runs/12190267762/job/34007064737#step:3:94), in get
      obj = self._operation.get(resource_group, workspace_name)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/core/tracing/decorator.py"", line 105, in wrapper_use_tracer
      return func(*args, **kwargs)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/ai/ml/_restclient/v2024_07_01_preview/operations/_workspaces_operations.py"", line 947, in get
      pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/core/pipeline/_base.py"", line 240, in run
      return first_node.send(pipeline_request)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/core/pipeline/_base.py"", line 96, in send
      response = self.next.send(request)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/core/pipeline/_base.py"", line 96, in send
      response = self.next.send(request)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/core/pipeline/_base.py"", line 96, in send
      response = self.next.send(request)
    [Previous line repeated 2 more times]
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/mgmt/core/policies/_base.py"", line 95, in send
      response = self.next.send(request)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/core/pipeline/policies/_redirect.py"", line 204, in send
      response = self.next.send(request)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/core/pipeline/policies/_retry.py"", line 551, in send
      response = self.next.send(request)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/core/pipeline/policies/_authentication.py"", line 157, in send
      self.on_request(request)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/core/pipeline/policies/_authentication.py"", line 132, in on_request
      self._request_token(*self._scopes)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/core/pipeline/policies/_authentication.py"", line 108, in _request_token
      self._token = self._get_token(*scopes, **kwargs)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/core/pipeline/policies/_authentication.py"", line 98, in _get_token
      return cast(SupportsTokenInfo, self._credential).get_token_info(*scopes, options=options)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/identity/_credentials/default.py"", line 255, in get_token_info
      token_info = cast(SupportsTokenInfo, super()).get_token_info(*scopes, options=options)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/identity/_credentials/chained.py"", line 219, in get_token_info
      raise ClientAuthenticationError(message=message)
  azure.core.exceptions.ClientAuthenticationError: DefaultAzureCredential failed to retrieve a token from the included credentials.
  Attempted credentials:
  	EnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.
  Visit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.
  	ManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no response from the IMDS endpoint. invalid_request
  	SharedTokenCacheCredential: SharedTokenCacheCredential authentication unavailable. No accounts were found in the cache.
  	AzureCliCredential: Please run 'az login' to set up an account
  	AzurePowerShellCredential: Az.Account module >= 2.2.0 is not installed
  	AzureDeveloperCliCredential: Azure Developer CLI could not be found. Please visit https://aka.ms/azure-dev for installation instructions and then,once installed, authenticate to your Azure account using 'azd auth login'.
  To mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.
  Error: Process completed with exit code 1.
```

### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->
See https://github.com/recommenders-team/recommenders/actions/runs/12190267762/job/34007064737

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments

",miguelgfierro,3491412,closed,False,1,2024-12-06T07:48:03+00:00,2024-12-09T19:36:53+00:00,2024-12-09T19:36:53+00:00,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2712101732,2192,Install sbt for sarplus tests,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
This PR installs sbt in the testing workflow of sarplus, because GitHub hosted runner [ubuntu-24.04](https://github.com/actions/runner-images/blob/main/images/ubuntu/Ubuntu2404-Readme.md) removed the installation of sbt, [making the tests for sarplus fail](https://github.com/recommenders-team/recommenders/actions/runs/11889835469/job/33127202507).

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->
* https://github.com/actions/runner-images/issues/10636#issuecomment-2377837332
* https://github.com/yokra9/akka-http-example/pull/119

### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [X] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [X] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [X] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [X] This PR is being made to `staging branch` AND NOT TO `main branch`.
",SimonYansenZhao,6165588,closed,False,0,2024-12-02T14:23:56+00:00,2024-12-02T15:12:13+00:00,2024-12-02T15:12:08+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2708752356,2191,[BUG] Tests breaking due to a error in protobuf dependency,"### Description
<!--- Describe your issue/bug/request in detail -->
Protobuf made a new release https://pypi.org/project/protobuf/#history
on Nov 27, 2024. It's breaking the tests.

```
    File ""/home/runner/work/recommenders/recommenders/tests/ci/azureml_tests/post_pytest.py"", line 75, in <module>
      runs = mlflow.search_runs(
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/mlflow/tracking/fluent.py"", line 2069, in search_runs
      experiment_by_name = get_experiment_by_name(n)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/mlflow/tracking/fluent.py"", line 1671, in get_experiment_by_name
      return MlflowClient().get_experiment_by_name(name)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/mlflow/tracking/client.py"", line 134, in __init__
      self._tracking_client = TrackingServiceClient(final_tracking_uri)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py"", line 83, in __init__
      self.store
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py"", line 87, in store
      return utils._get_store(self.tracking_uri)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/utils.py"", line 208, in _get_store
      return _tracking_store_registry.get_store(store_uri, artifact_uri)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/registry.py"", line 45, in get_store
      return self._get_store_with_resolved_uri(resolved_store_uri, artifact_uri)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/registry.py"", line 56, in _get_store_with_resolved_uri
      return builder(store_uri=resolved_store_uri, artifact_uri=artifact_uri)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azureml/mlflow/entry_point_loaders.py"", line 33, in azureml_store_builder
      from azureml.mlflow._store.tracking.store import AzureMLRestStore
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azureml/mlflow/_store/tracking/store.py"", line 17, in <module>
      from azureml.mlflow._protos.aml_service_pb2 import (
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azureml/mlflow/_protos/aml_service_pb2.py"", line 10, in <module>
      from google.protobuf import service as _service
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/google/protobuf/service.py"", line 78
      raise NotImplementedError
                               ^
  IndentationError: unindent does not match any outer indentation level
  Error: Process completed with exit code 1.
```

### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->
https://github.com/recommenders-team/recommenders/actions/runs/12100479486/job/33739131547


### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->
I expect Google to test their libraries before making a release.

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
",miguelgfierro,3491412,closed,False,4,2024-12-01T08:05:46+00:00,2024-12-05T06:52:37+00:00,2024-12-05T06:52:37+00:00,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2665410730,2190,Update timeout of AzureML tests and add explicit runner in Ubuntu 24.04,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
I want to limit each of the computations to 2h, but not all the tests of 1 category. For example, each test process should take less than 2h, but the whole GPU tests can take longer because maybe they are waiting for a free VM.

I used https://docs.github.com/en/actions/writing-workflows/workflow-syntax-for-github-actions#jobsjob_idtimeout-minutes but if it doesn't work I would need to do the timeout within the steps: https://docs.github.com/en/actions/writing-workflows/workflow-syntax-for-github-actions#jobsjob_idstepstimeout-minutes

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
Related to this discussion: https://github.com/recommenders-team/recommenders/pull/2189#discussion_r1844827275

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2024-11-17T07:07:22+00:00,2024-11-18T09:48:38+00:00,2024-11-18T09:48:35+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2658260503,2189,Staging to main: Merge multiple Dockerfiles into a single one,"Merge multiple Dockerfiles into a single one
---------
Signed-off-by: Simon Zhao <simonyansenzhao@gmail.com>
Co-authored-by: Miguel Fierro <3491412+miguelgfierro@users.noreply.github.com>

### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,1,2024-11-14T09:54:11+00:00,2024-11-16T01:58:50+00:00,2024-11-15T09:23:37+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2651873476,2188,Staging to main: Add managed identity to authenticate in the AzureML test pipeline,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2024-11-12T11:19:08+00:00,2024-11-12T13:59:04+00:00,2024-11-12T13:59:04+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2651029393,2187,Try to add support for Python 3.12,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
This PR is just a test, and a fork of the PR https://github.com/recommenders-team/recommenders/pull/2098.

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",SimonYansenZhao,6165588,closed,False,0,2024-11-12T04:52:55+00:00,2024-11-12T07:53:48+00:00,2024-11-12T07:53:42+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2649575397,2186,[FEATURE] Replace the FastAI notebook by a cartesian product with PyTorch and remove the FastAI dependency,"### Description
<!--- Describe your expected feature in detail -->
We had some issues with the FastAI dependency #2182. And realised that the fastai notebook is just a fancy wrapper on [PyTorch cartesian product](https://pytorch.org/docs/stable/generated/torch.cartesian_prod.html) between user and item embeddings.
https://github.com/recommenders-team/recommenders/blob/main/examples/00_quick_start/fastai_movielens.ipynb



### Expected behavior with the suggested feature
<!--- For example:  -->
<!--- *Adding algorithm xxx will help people understand more about xxx use case scenarios. -->
We want replace the FastAI notebook with a PyTorch version


### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
Related to #1713
",miguelgfierro,3491412,open,False,8,2024-11-11T14:52:01+00:00,2025-01-27T09:58:41+00:00,,enhancement,0,0,0,0,0,0,0
recommenders-team/recommenders,2628827518,2185,[BUG] statsmodels compilation failures with Cython 3.0,"### Description
<!--- Describe your issue/bug/request in detail -->
[Cython](https://pypi.org/project/Cython) 3.0 introduces breaking changes that make [statsmodels](https://pypi.org/project/statsmodels/) compilation fail.  statsmodels is required by [category-encoders](https://pypi.org/project/category-encoders/) used in [lightgbm_utils.py](https://github.com/recommenders-team/recommenders/blob/83ebb5cbb966c4c7cab1c7e45defaf84578dc03f/recommenders/models/lightgbm/lightgbm_utils.py#L6)

See also:
* [Migrating from Cython 0.29 to 3.0](https://docs.cython.org/en/latest/src/userguide/migrating_to_cy30.html)



### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->

In Recommenders testing workflow.

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->

See the testing errors:
+ https://github.com/recommenders-team/recommenders/actions/runs/11621757878/job/32375041825#step:3:216
+ https://github.com/recommenders-team/recommenders/actions/runs/11625886718/job/32376639247#step:3:2191

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

Possible solutions:
1. Wait until the issue https://github.com/statsmodels/statsmodels/issues/8868 is resolved.
2. Use Cython < 3.0

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [X] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
",SimonYansenZhao,6165588,closed,False,1,2024-11-01T11:07:13+00:00,2024-11-11T15:03:14+00:00,2024-11-11T15:03:14+00:00,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2616414495,2183,[FEATURE] add a requirements.txt,"Can you add an available requirements.txt in order to resolve dependencies in python 3.9
",xxzsa,181358952,closed,False,1,2024-10-27T08:17:56+00:00,2024-12-27T06:27:43+00:00,2024-12-27T06:27:43+00:00,enhancement,0,0,0,0,0,0,0
recommenders-team/recommenders,2616383975,2182,Use managed identity with OpenID Connect for Azure login,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
This PR resolves
* the issue https://github.com/recommenders-team/recommenders/issues/2171 by updating the testing workflows to use the Azure managed identity with OpenID Connect for login.
* and the issue that breaks the testing workflow, which is caused by the Python packages spacy and thinc increase the version number of numpy in their latest version.  space and thinc is depended by fastai.

- [X] Additional federated identity credential may be required.  See [Configure a federated identity credential on a user-assigned managed identity](https://learn.microsoft.com/en-us/entra/workload-id/workload-identity-federation-create-trust-user-assigned-managed-identity?pivots=identity-wif-mi-methods-azp#configure-a-federated-identity-credential-on-a-user-assigned-managed-identity)

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
* #2171 
* #2175 

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [X] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [X] This PR is being made to `staging branch` AND NOT TO `main branch`.
",SimonYansenZhao,6165588,closed,False,4,2024-10-27T07:22:52+00:00,2024-11-12T00:58:08+00:00,2024-11-12T00:58:03+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2602123795,2181,Added setup instructions for databricks env,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
Added the setup instructions for using the library in databricks env. Instructuctions were tested with multiple runtimes. This will solve the silent error faced in databricks env mentioned here https://github.com/recommenders-team/recommenders/issues/2179.


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
https://github.com/recommenders-team/recommenders/issues/2179

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [x] I have updated the documentation accordingly.
- [x] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [x] This PR is being made to `staging branch` AND NOT TO `main branch`.
",ved93,8381908,closed,False,0,2024-10-21T10:42:59+00:00,2024-10-21T14:38:38+00:00,2024-10-21T14:38:38+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2602053794,2180,setup instructions for databricks env,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
Added the setup instructions for using the library in databricks env. Instructuctions were tested with multiple runtimes. This will solve the silent error faced in databricks env mentioned in below [issue](https://github.com/recommenders-team/recommenders/issues/2179). 


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
https://github.com/recommenders-team/recommenders/issues/2179

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [x] I have updated the documentation accordingly.
- [x] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [x] This PR is being made to `staging branch` AND NOT TO `main branch`.
",ved93,8381908,closed,False,0,2024-10-21T10:14:22+00:00,2024-10-21T10:35:06+00:00,2024-10-21T10:26:14+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2587710196,2179,[BUG] ,"### Description
<!--- Describe your issue/bug/request in detail -->

When running the example notebooks provided by the `recommenders` library, specifically when executing the following import statement:

```python
from recommenders.datasets import movielens
```

I encounter an `AttributeError` stating that the module `pandera` has no attribute `SchemaModel`. This error prevents the notebook from running further and seems to be related to the `movielens.py` module within the `recommenders.datasets` package.

The full error message and traceback are provided in the **Other Comments** section below.

### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->

- **Platform**:  Databricks
- **Runtime Versions Tried**:
  - Databricks Runtime 11.3 LTS (includes Apache Spark 3.3.0, Scala 2.12)
  - Databricks Runtime 12.2 LTS (includes Apache Spark 3.3.2, Scala 2.12)
  - Databricks Runtime 13.1 (includes Apache Spark 3.4.1, Scala 2.12)
  - Databricks Runtime 14.1 (includes Apache Spark 3.5.0, Scala 2.12)


Despite trying multiple runtimes, the issue persists across all of them.

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->

1. **Set Up  Databricks Environment**:
   - Launch an Databricks workspace.
   - Create a new cluster using any of the runtimes mentioned above.

2. **Install Required Libraries**:
   - Install the `recommenders` library on the cluster:
     ```bash
     pip install recommenders
     ```

3. **Create a New Notebook**:
   - In the workspace, create a new Python notebook attached to the cluster.

4. **Run the Following Code in a Notebook Cell**:
   ```python
   from recommenders.datasets import movielens
   ```

5. **Observe the Error**:
   - The `AttributeError` should occur, indicating that `pandera` has no attribute `SchemaModel`.

### Expected behavior (i.e. solution)

- The import statement `from recommenders.datasets import movielens` should execute without any errors.
- The `movielens` dataset module should be available for use in the notebook.
- All example notebooks using the `recommenders` library should run successfully on Azure Databricks.

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->

- [x] Yes, I can contribute for this issue independently.
- [x] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments

**Full Error Message and Traceback**:

```
AttributeError: module 'pandera' has no attribute 'SchemaModel'
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-1-abc123456789> in <module>
      1 # Other imports (if any)
----> 2 from recommenders.datasets import movielens
      3 # Rest of the code (if any)

~/databricks/python/lib/python3.10/site-packages/recommenders/datasets/movielens.py in <module>
    582     return not df[columns].duplicated().any()
    583 
--> 584 class MockMovielensSchema(pa.SchemaModel):
    585     """"""
    586     Mock dataset schema to generate fake data for testing purpose.

AttributeError: module 'pandera' has no attribute 'SchemaModel'
```

**Additional Information**:

- I have verified that `pandera` is installed and up-to-date in the environment:
  ```python
  import pandera
  print(pandera.__version__)   
  ```
- Attempted solutions:
  - Upgrading `pandera` to the latest version did not resolve the issue.
  - Uninstalling and reinstalling `pandera` did not resolve the issue.
  - Downgrading `pandera` to earlier versions leads to other compatibility issues.
- It appears that the `recommenders` library may not be compatible with the latest versions of `pandera`, or there may be an issue with how `SchemaModel` is imported or used in `movielens.py`.

**Environment Details**:

- **Python Version**: 3.10.x (as per the Databricks runtime)
- **recommenders Library Version**: Latest available via `pip` as of the date of this report.

**Request**:

- Guidance on resolving this import error.
- Confirmation on whether this is a known issue or a bug that needs fixing.",ved93,8381908,closed,False,4,2024-10-15T05:48:34+00:00,2024-10-28T15:51:36+00:00,2024-10-28T15:51:35+00:00,bug,1,1,0,0,0,0,0
recommenders-team/recommenders,2568609779,2178,Added user info to movielens 100k and 1m,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
Added capability to get user fields like gender, age, occupation and zip code to movielens dataset.

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
- #2176 

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [x] I have added tests covering my contributions.
- [x] I have updated the documentation accordingly.
- [x] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [x] This PR is being made to `staging branch` AND NOT TO `main branch`.
",daviddavo,10263941,open,False,4,2024-10-06T11:26:40+00:00,2024-10-28T15:55:01+00:00,,,0,0,0,0,0,0,0
recommenders-team/recommenders,2567745704,2177,Update the code of conduct,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
Minor update in the README

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [x] I have updated the documentation accordingly.
- [x] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [x] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2024-10-05T08:56:29+00:00,2024-10-09T12:26:05+00:00,2024-10-09T12:26:00+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2559873235,2176,[FEATURE] Adding user information to movielens,"### Description
<!--- Describe your expected feature in detail -->
Movielens has also some user demographics information
```
1|24|M|technician|85711
2|53|F|other|94043
3|23|M|writer|32067
4|24|M|technician|43537
5|33|F|other|15213
6|42|M|executive|98101
7|57|M|administrator|91344
8|36|M|administrator|05201
9|29|M|student|01002
10|53|M|lawyer|90703
```

### Expected behavior with the suggested feature
<!--- For example:  -->
<!--- *Adding algorithm xxx will help people understand more about xxx use case scenarios. -->
Diminishing the cold-start problem with new users with models that support it.

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [x] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
For example, this is used in Google's wide and deep model.
",daviddavo,10263941,open,False,0,2024-10-01T18:03:35+00:00,2024-10-01T18:03:35+00:00,,enhancement,0,0,0,0,0,0,0
recommenders-team/recommenders,2554682925,2175,Use VM managed identity for login,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
This PR resolves the issue https://github.com/recommenders-team/recommenders/issues/2171 by updating the testing workflows to use the Azure VM managed identity for login.  It's tested in the PR https://github.com/recommenders-team/recommenders/pull/2174 .

- [ ] Update the doc: tests/README.md
- [ ] **NOTE**: Additional setup is required before this PR is merged:
      1. Create a Azure VM with Ubuntu 22.04
         * Configure the managed identity on creation: Management  Identity  Enable system assigned managed identity
         * Choosee Ubuntu 22.04 instead of 24.04, because PowerShell does not have packages on 24.04
      2. Go to the AML workspace (azureml-test-workspace) and grant the following roles to the VM's managed identity
         * AzureML Compute Operator
         * AzureML Data Scientist
         * Reader
      3. Install [PowerShell](https://learn.microsoft.com/en-us/powershell/scripting/install/install-ubuntu), [Azure CLI](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli-linux) and [Azure PowerShell](https://learn.microsoft.com/en-us/powershell/azure/install-azps-linux) on the VM
      4. Go to [Recommenders](https://github.com/recommenders-team/recommenders)  Settings  Actions  [Runners](https://github.com/recommenders-team/recommenders/settings/actions/runners)  New self-hosted runner
Run the command on the VM
      5. Change the following secret values with the IDs of the VM: Settings  Secrets and variables  [Actions](https://github.com/recommenders-team/recommenders/settings/secrets/actions)  New repository secret
         * `AZURE_VM_TENANT_ID`
         * `AZURE_VM_SUBSCRIPTION_ID`

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
* https://github.com/recommenders-team/recommenders/issues/2171

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [X] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [X] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [X] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [X] This PR is being made to `staging branch` AND NOT TO `main branch`.
",SimonYansenZhao,6165588,closed,False,0,2024-09-29T03:29:23+00:00,2024-10-27T07:18:41+00:00,2024-10-27T07:18:16+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2554659080,2174,Try to use managed identity for login,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
This is just a test for using Azure VM managed identity for login instead of service principal.

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",SimonYansenZhao,6165588,closed,False,0,2024-09-29T02:18:30+00:00,2024-10-27T02:02:21+00:00,2024-10-27T02:02:12+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2552700004,2173,[BUG] Issue with installing the recommenders package while building cornac on macOS ARM64 (M2),"### Description
I am encountering an issue while trying to install the recommenders package on macOS ARM64 (Apple Silicon). The error occurs during the cornac building process, specifically while compiling the C++ source files. I've followed the instructions in the GitHub repository and tried installing via both pip and conda, but the issue persists.

### In which platform does it happen?
I am using VSCode as my development environment and have tried multiple approaches, including different compilers and package managers.

### My Setup:
macOS Version: macOS 14.3 (Sonoma)
Python Version: 3.10.12 (installed via pyenv and conda) and tried with 3.9 as well
Compiler:
Tried with clang++ and g++
Also tried Homebrew's LLVM and gcc
Package Managers:
Tried both pip and conda based on the instructions in the GitHub repository.

### Error Details
![image](https://github.com/user-attachments/assets/ef137865-28aa-40ad-9d07-bb9cff200856)

Additionally if I am trying to install through requirements file it fails saying while collecting cornac the dependencies are missing even if they are listed in the requirements file.



### Expected behavior (i.e. solution)
recommenders package installed without any issues
",Harikapl,24475496,closed,False,3,2024-09-27T11:33:11+00:00,2024-12-27T06:28:39+00:00,2024-12-27T06:28:39+00:00,bug,1,1,0,0,0,0,0
recommenders-team/recommenders,2552663791,2172,[BUG] ,"### Description
<!--- Describe your issue/bug/request in detail -->

### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
",Harikapl,24475496,closed,False,1,2024-09-27T11:13:16+00:00,2024-09-27T11:37:17+00:00,2024-09-27T11:37:16+00:00,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2542855303,2171,[FEATURE] Change the current service principal to managed identity for the AzureML tests,"### Description
<!--- Describe your expected feature in detail -->
Info: https://github.com/marketplace/actions/azure-login#login-with-system-assigned-managed-identity

Related to #2169

### Expected behavior with the suggested feature
<!--- For example:  -->
<!--- *Adding algorithm xxx will help people understand more about xxx use case scenarios. -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
FYI @SimonYansenZhao ",miguelgfierro,3491412,closed,False,0,2024-09-23T14:31:40+00:00,2024-11-14T07:33:38+00:00,2024-11-14T07:33:37+00:00,enhancement,0,0,0,0,0,0,0
recommenders-team/recommenders,2540004382,2170,[BUG] Authorization error with new SP role ,"### Description
<!--- Describe your issue/bug/request in detail -->
```
Traceback (most recent call last):
    File ""/home/runner/work/recommenders/recommenders/tests/ci/azureml_tests/submit_groupwise_azureml_pytest.py"", line 137, in <module>
      client = get_client(
    File ""/home/runner/work/recommenders/recommenders/tests/ci/azureml_tests/aml_utils.py"", line 31, in get_client
      workspace = client.workspaces.get(workspace_name)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py"", line 292, in wrapper
      return f(*args, **kwargs)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/core/tracing/decorator.py"", line 94, in wrapper_use_tracer
      return func(*args, **kwargs)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/ai/ml/operations/_workspace_operations.py"", line 141, in get
      return super().get(workspace_name=name, **kwargs)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/ai/ml/operations/_workspace_operations_base.py"", line 87, in get
      obj = self._operation.get(resource_group, workspace_name)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/core/tracing/decorator.py"", line 94, in wrapper_use_tracer
      return func(*args, **kwargs)
    File ""/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/azure/ai/ml/_restclient/v2024_07_01_preview/operations/_workspaces_operations.py"", line 957, in get
      raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
  azure.core.exceptions.HttpResponseError: (AuthorizationFailed) The client 'e4d8d62a-df42-4e04-9741-d9ab05ba6ab6' with object id 'e4d8d62a-df42-4e04-9741-d9ab05ba6ab6' does not have authorization to perform action 'Microsoft.MachineLearningServices/workspaces/read' over scope '/subscriptions/***/resourceGroups/recommenders_project_resources/providers/Microsoft.MachineLearningServices/workspaces/azureml-test-workspace' or the scope is invalid. If access was recently granted, please refresh your credentials.
  Code: AuthorizationFailed
  Message: The client 'e4d8d62a-df42-4e04-9741-d9ab05ba6ab6' with object id 'e4d8d62a-df42-4e04-9741-d9ab05ba6ab6' does not have authorization to perform action 'Microsoft.MachineLearningServices/workspaces/read' over scope '/subscriptions/***/resourceGroups/recommenders_project_resources/providers/Microsoft.MachineLearningServices/workspaces/azureml-test-workspace' or the scope is invalid. If access was recently granted, please refresh your credentials.
  Error: Process completed with exit code 1.
```
Source: https://github.com/recommenders-team/recommenders/actions/runs/10967867314/job/30458318230


### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
",miguelgfierro,3491412,closed,False,1,2024-09-21T06:16:05+00:00,2024-09-23T15:30:55+00:00,2024-09-23T15:30:55+00:00,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2538492991,2169,Update service principal role to AzureML Compute Operator for improved security,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,4,2024-09-20T10:44:23+00:00,2024-09-23T15:29:24+00:00,2024-09-23T15:29:20+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2533842479,2168,[WIP] Wide & Deep migration to PyTorch,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
Migrating Wide & Deep out of tensorflow.

**Note**: Previously I have only used models from high level libraries like Keras. I'm doing this to learn PyTorch, so feel free to give me any pointers or even scrap everything if it is not useful.

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
- #2072 

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->
- [The paper that defines the model](https://dl.acm.org/doi/10.1145/2988450.2988454)
- [A notebook from matanivanov which defines a PyTorch implementation](https://www.kaggle.com/code/matanivanov/wide-deep-learning-for-recsys-with-pytorch)
- [A full library of wide-deep models](https://github.com/jrzaurin/pytorch-widedeep)

### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [x] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [x] This PR is being made to `staging branch` AND NOT TO `main branch`.

### WIP Tasks
- [x] Implementing the model as PyTorch's `nn.Module`
  - [x] Allowing additional embeddings
  - [x] Allowing additional continuous features
  - [x] Allowing cross-features (sorry, I don't understand it yet)
- [x] Creating a wrapper with `.fit()` and `.recommend_k_items()` methods
  - [ ] Allowing additional embs in wrapper's .fit()
    - Can't test in notebook because there is no data to use embeddings for (see #2176)
  - [x] Allowing additional cont. feat. in wrapper's .fit()
  - [x] Caching the ""ranking pool""
  - [x] Save model every `save_checkpoints_steps` iterations in `model_dir`
  - [x] Eval test loss every `log_every_n_iter` iterations instead of every iter
- [x] Creating a `torch.data.Dataset` to pass to the wrapper class
- [ ] Creating tests
- [ ] Updating Jupyter Notebooks
",daviddavo,10263941,open,False,11,2024-09-18T14:03:03+00:00,2025-03-03T12:46:49+00:00,,,1,0,0,0,1,0,0
recommenders-team/recommenders,2527806868,2167,Merge multiple Dockerfiles into a single one,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
This PR merges the following multiple uses of Dockerfile into a single place in `tools/docker/Dockerfile` for easier maintainance in the future:
* Dev container in [.devcontainer/devcontainer.json](https://github.com/recommenders-team/recommenders/blob/main/.devcontainer/devcontainer.json) for development
* AML testing environment in [tests/ci/azureml_tests/aml_utils.py](https://github.com/recommenders-team/recommenders/blob/83ebb5cbb966c4c7cab1c7e45defaf84578dc03f/tests/ci/azureml_tests/aml_utils.py#L97-L131) for testing
* Dockerfile in [tools/docker/Dockerfile](https://github.com/recommenders-team/recommenders/blob/main/tools/docker/Dockerfile) for general users


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
None

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->
* [Developing inside a Container via VS Code](https://code.visualstudio.com/docs/devcontainers/containers)
* [Create Azure Machine Learning Custom Environment](https://github.com/Azure/azureml-examples/blob/main/sdk/python/assets/environment/environment.ipynb)
* [Recommenders Docker Support](https://github.com/recommenders-team/recommenders/blob/main/tools/docker/README.md)


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [X] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [X] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [X] This PR is being made to `staging branch` AND NOT TO `main branch`.
",SimonYansenZhao,6165588,closed,False,1,2024-09-16T08:20:57+00:00,2024-11-14T03:15:37+00:00,2024-11-14T03:15:30+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2514167909,2166,Staging to main: Dev container and small fixes,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,1,2024-09-09T14:42:09+00:00,2024-09-11T08:45:29+00:00,2024-09-11T08:45:29+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2510679835,2165,[FEATURE] Add Python notebook examples for Non accuracy based metrics,"### Description
Please add notebook examples demonstrating the use of Non accuracy based metrics (diversity, novelty, etc.) in Python

### Expected behavior with the suggested feature
Similar to the following PySpark notebook: https://github.com/recommenders-team/recommenders/blob/main/examples/03_evaluate/als_movielens_diversity_metrics.ipynb",DimitriosParaskevopoulos,177632723,closed,False,2,2024-09-06T15:24:03+00:00,2024-09-09T14:44:26+00:00,2024-09-09T14:40:32+00:00,enhancement,0,0,0,0,0,0,0
recommenders-team/recommenders,2509772368,2164,Fix #2163,"Signed-off-by: David Dav <david@ddavo.me>

### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
If a user has voted in every item, the `sample_neg` function in `ImplicitCF` will enter an infinite loop.

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
- #2163

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [x] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [x] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [x] This PR is being made to `staging branch` AND NOT TO `main branch`.
",daviddavo,10263941,closed,False,0,2024-09-06T07:54:58+00:00,2024-09-09T14:35:53+00:00,2024-09-09T14:35:49+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2508095667,2163,[BUG] ImplicitCF might stall if a user has interacted with every item,"### Description
<!--- Describe your issue/bug/request in detail -->
`ImplicitCF.train_loader` might stall if a user in the dataset has voted in every item.

### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->
All platforms

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->

By just reading the code:

https://github.com/recommenders-team/recommenders/blob/10d0c2960ec476b9790af3e2b7340ca27709d48c/recommenders/models/deeprec/DataModel/ImplicitCF.py#L195-L228

For each user, it calls `sample_neg(x)`, but if a user has voted in everything, that function will stall:
https://github.com/recommenders-team/recommenders/blob/10d0c2960ec476b9790af3e2b7340ca27709d48c/recommenders/models/deeprec/DataModel/ImplicitCF.py#L208-L212

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->
Do not stall. 

Before entering the `while True`, check if `len(x) == self.n_items`

I don't what it should return then. `-1`? `self.n_items`? raising an exception?

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [x] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments

A workaround might be just adding a ""phantom item"" that nobody interacted with.",daviddavo,10263941,closed,False,2,2024-09-05T15:19:48+00:00,2024-09-09T14:38:34+00:00,2024-09-09T14:38:34+00:00,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2492688994,2160,Added extra MIND urls,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2024-08-28T17:57:57+00:00,2024-08-30T18:30:53+00:00,2024-08-30T18:30:50+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2492366721,2159,Minor update to action.yml,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2024-08-28T15:02:50+00:00,2024-08-30T18:31:04+00:00,2024-08-30T18:31:02+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2489244226,2158,Correct variable used in pickle dump in `mind_utils.ipynb`,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
Fixed a minor mistake where the incorrect variable `word_dict` was being dumped to `word_dict_all.pkl` instead of `word_dict_all` in the mind_utils.ipynb notebook.


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [x] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
",ubergonmx,12420631,closed,False,2,2024-08-27T12:40:04+00:00,2024-08-28T05:48:47+00:00,2024-08-28T05:48:47+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2488653737,2157,Update dev container,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
Dev containers and GitHub Codespaces provide more convenient development environments for Recommenders users.  But the dev container configuration in the repo is not working and contains many deprecated settings.  This PR modifies the dev container configuration including the following updates:
* OS: Debian 12 $\to$ Ubuntu 24.04
* Python: 3.7 $\to$ 3.10
* Java: OpenJDK 8 $\to$ OpenJDK 21
* Use Conda for env management
* Install recommended VS Code extensions for Python
* Add several settings for Python and Pytest
* Specify minimum machine specification



### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [X] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [x] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [X] This PR is being made to `staging branch` AND NOT TO `main branch`.
",SimonYansenZhao,6165588,closed,False,0,2024-08-27T08:31:53+00:00,2024-08-27T10:45:48+00:00,2024-08-27T10:45:07+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2487507062,2156,"Staging to main: Move some tests to experimental, fix MIND dataset","### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2024-08-26T18:33:07+00:00,2024-08-27T10:39:25+00:00,2024-08-27T10:39:25+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2486301731,2155,Fix issue with MIND large and small,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
Fixing https://github.com/recommenders-team/recommenders/issues/2147#issuecomment-2308615469

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,2,2024-08-26T08:44:58+00:00,2024-08-26T14:36:07+00:00,2024-08-26T14:36:03+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2483337644,2154,"[BUG] Ranking Evaluation Metrics Exceed 1 with ""by_threshold"" Relevancy Method","### Description
Hello!

I encountered an issue while evaluating the BPR (Bayesian Personalized Ranking) model with basically the same code provided in the example on a different dataset. Specifically, when using the ""by_threshold"" relevancy method with ranking metrics, the computed values for precision@k, ndcg@k, and map@k exceed 1, which seems incorrect. This issue does not occur when switching the relevancy method to ""top_k.""

### How do we replicate the issue?
I use the following parameter for BPR (all using the default seed):
```
bpr = cornac.models.BPR(
    k=200,
    max_iter=100,
    learning_rate=0.01,
    lambda_reg=0.001,
    verbose=True 
)
```
Using these evaluation
```
TOP_K = 10
threshold =50
eval_map = map_at_k(test, all_predictions, col_prediction=""prediction"",
                    relevancy_method='by_threshold', threshold=threshold, k=TOP_K)
eval_ndcg = ndcg_at_k(test, all_predictions, col_prediction=""prediction"",
                      relevancy_method='by_threshold', threshold=threshold, k=TOP_K)
eval_precision = precision_at_k(
    test, all_predictions, col_prediction=""prediction"",
    relevancy_method='by_threshold', threshold=threshold, k=TOP_K)
```
Here is the dataset I test on:  https://github.com/mnhqut/rec_sys-dataset/blob/main/data.csv

My result: 
MAP:		1.417529
NDCG:		1.359902
Precision@K:	2.256466
### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [x ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.


",mnhqut,163323745,open,False,4,2024-08-23T15:01:27+00:00,2024-08-29T15:09:29+00:00,,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2483077633,2153,[BUG] Review new MIND tests,"### Description
<!--- Describe your issue/bug/request in detail -->
There is an error in staging, see https://github.com/recommenders-team/recommenders/issues/2147#issuecomment-2306967499


### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->
CPU

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time

### Other Comments
related to #2147 and #2133",miguelgfierro,3491412,closed,False,1,2024-08-23T12:48:23+00:00,2024-08-26T14:39:01+00:00,2024-08-26T14:39:01+00:00,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2473421085,2151,Pin azure-ai-ml==1.18.0 for testing,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
This PR tries to figure out what causes #2147.

A new version of AML SDK `azure-ai-ml` is released on Aug 13.  I suspect the new version introduces some breaking changes.

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->

* #2147 

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->
* [Relseas history of `azure-ai-ml`](https://pypi.org/project/azure-ai-ml/1.19.0/#history)

### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [X] This PR is being made to `staging branch` AND NOT TO `main branch`.
",SimonYansenZhao,6165588,closed,False,0,2024-08-19T13:50:36+00:00,2024-08-19T14:16:55+00:00,2024-08-19T14:16:46+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2473383781,2150,Try cluster with dedicated VMs,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
Addressing #2147 with dedicated VMs

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,1,2024-08-19T13:34:30+00:00,2024-08-19T13:39:05+00:00,2024-08-19T13:39:02+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2473371854,2149,[BUG] No detailed information in testing error ,"### Description
<!--- Describe your issue/bug/request in detail -->

The recent nightly build logs (https://github.com/recommenders-team/recommenders/actions/runs/10335387467/job/28609908093) don't provide sufficient information about the error.

![image](https://github.com/user-attachments/assets/c8a116d9-3fe6-4a0f-8454-24d9b264945f)


### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->

In the testing workflow.

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [x] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
",SimonYansenZhao,6165588,closed,False,1,2024-08-19T13:29:25+00:00,2024-08-20T03:23:26+00:00,2024-08-20T03:15:30+00:00,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2473357177,2148,New compute cluster,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
Trying to address #2147

Created a new compute cluster with the same VMs as before.

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,1,2024-08-19T13:22:52+00:00,2024-08-19T13:27:46+00:00,2024-08-19T13:27:40+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2470526005,2147,[BUG] Test failing Service invocation timed out,"### Description
<!--- Describe your issue/bug/request in detail -->
The VMs for the tests are not even starting:
```
Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.
  Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.
  Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.
  Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.
  Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.
  Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.
  
  Uploading recommenders (10.26 MBs):   0%|          | 0/10263396 [00:00<?, ?it/s]
  Uploading recommenders (10.26 MBs):   1%|          | 107280/10263396 [00:00<00:09, 1055618.87it/s]
  Uploading recommenders (10.26 MBs):  31%|       | 3174427/10263396 [00:00<00:00, 17968925.70it/s]
  Uploading recommenders (10.26 MBs):  52%|    | 5311634/10263396 [00:00<00:00, 15079703.44it/s]
  Uploading recommenders (10.26 MBs):  86%| | 8792146/10263396 [00:00<00:00, 21108647.33it/s]
  Uploading recommenders (10.26 MBs): 100%|| 10263396/10263396 [00:01<00:00, 9462800.48it/s]
  
  
  Traceback (most recent call last):
    File ""/home/runner/work/recommenders/recommenders/tests/ci/azureml_tests/submit_groupwise_azureml_pytest.py"", line 175, in <module>
      run_tests(
    File ""/home/runner/work/recommenders/recommenders/tests/ci/azureml_tests/aml_utils.py"", line 170, in run_tests
      job = client.jobs.create_or_update(
    File ""/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/azure/core/tracing/decorator.py"", line 94, in wrapper_use_tracer
      return func(*args, **kwargs)
    File ""/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py"", line 372, in wrapper
      return_value = f(*args, **kwargs)
    File ""/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py"", line 663, in create_or_update
      self._resolve_arm_id_or_upload_dependencies(job)
    File ""/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py"", line 1070, in _resolve_arm_id_or_upload_dependencies
      self._resolve_arm_id_or_azureml_id(job, self._orchestrators.get_asset_arm_id)
    File ""/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py"", line 1335, in _resolve_arm_id_or_azureml_id
      job = self._resolve_arm_id_for_command_job(job, resolver)
    File ""/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py"", line 1387, in _resolve_arm_id_for_command_job
      job.environment = resolver(job.environment, azureml_type=AzureMLResourceType.ENVIRONMENT)
    File ""/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/azure/ai/ml/operations/_operation_orchestrator.py"", line 183, in get_asset_arm_id
      name, version = self._resolve_name_version_from_name_label(asset, azureml_type)
    File ""/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/azure/ai/ml/operations/_operation_orchestrator.py"", line 443, in _resolve_name_version_from_name_label
      _resolve_label_to_asset(
    File ""/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/azure/ai/ml/_utils/_asset_utils.py"", line 1022, in _resolve_label_to_asset
      return resolver(name)
    File ""/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/azure/ai/ml/operations/_environment_operations.py"", line 448, in _get_latest_version
      result = _get_latest(
    File ""/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/azure/ai/ml/_utils/_asset_utils.py"", line [85](https://github.com/recommenders-team/recommenders/actions/runs/10406895552/job/28821110978#step:3:91)3, in _get_latest
      latest = result.next()
    File ""/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/azure/core/paging.py"", line 123, in __next__
      return next(self._page_iterator)
    File ""/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/azure/core/paging.py"", line 75, in __next__
      self._response = self._get_next(self.continuation_token)
    File ""/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_environment_versions_operations.py"", line 335, in get_next
      raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)
  azure.core.exceptions.HttpResponseError: (TransientError) Service invocation timed out. 
  Request: GET environment-management.vienna-eastus.svc/environment/v1.0/subscriptions/***/resourceGroups/recommenders_project_resources/providers/Microsoft.MachineLearningServices/workspaces/azureml-test-workspace/MFE/versions/environments/recommenders-61568e68746eceae2de11114618[86](https://github.com/recommenders-team/recommenders/actions/runs/10406895552/job/28821110978#step:3:92)594ca9a5e14-python3_8-spark 
   Message: Operation canceled Time waited: 00:00:09.9995201
  Code: TransientError
  Message: Service invocation timed out. 
  Request: GET environment-management.vienna-eastus.svc/environment/v1.0/subscriptions/***/resourceGroups/recommenders_project_resources/providers/Microsoft.MachineLearningServices/workspaces/azureml-test-workspace/MFE/versions/environments/recommenders-61568e6[87](https://github.com/recommenders-team/recommenders/actions/runs/10406895552/job/28821110978#step:3:93)46eceae2de1111461886594ca9a5e14-python3_8-spark 
   Message: Operation canceled Time waited: 00:00:09.9995201
  Target: GET https://environment-management.vienna-eastus.svc/environment/v1.0/subscriptions/***/resourceGroups/recommenders_project_resources/providers/Microsoft.MachineLearningServices/workspaces/azureml-test-workspace/MFE/versions/environments/recommenders-61568e68746eceae2de1111461[88](https://github.com/recommenders-team/recommenders/actions/runs/10406895552/job/28821110978#step:3:94)6594ca9a5e14-python3_8-spark?$orderby=createdtime desc&$top=1&listViewType=ActiveOnly
  Additional Information:Type: ComponentName
  Info: ***
      ""value"": ""managementfrontend""
  ***Type: Correlation
  Info: ***
      ""value"": ***
          ""operation"": ""5b[90](https://github.com/recommenders-team/recommenders/actions/runs/10406895552/job/28821110978#step:3:96)9b2c3dd76b888a4d120f149cb431"",
          ""request"": ""cbb3455b1e94a291""
      ***
  ***Type: Environment
  Info: ***
      ""value"": ""eastus""
  ***Type: Location
  Info: ***
      ""value"": ""eastus""
  ***Type: Time
  Info: ***
      ""value"": ""2024-08-15T16:26:53.8249469+00:00""
  ***
  Error: Process completed with exit code 1.
```

### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->

### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->
See example: https://github.com/recommenders-team/recommenders/actions/runs/10406895552/job/28821110978


### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments

FYI @SimonYansenZhao ",miguelgfierro,3491412,closed,False,15,2024-08-16T15:50:07+00:00,2024-08-26T10:16:02+00:00,2024-08-26T10:16:01+00:00,bug,0,0,0,0,0,0,0
recommenders-team/recommenders,2467128668,2146,Updated function signatures to comply with new tensorflow requirements,"### Description
I tried to run the sarsec notebook, but ran into issues because the function calls didn't comply with updated tensorflow requirements.  I fixed the function calls so that they comply with updated requirements.



### Related Issues
If you try running the sarsec notebook with a recent version of tensorflow, the training throws an error because tensorflow modules can only take non-tensor arguments if they are keyword arguments, so the 'training' argument, which is a boolean, throws an error unless it is a keyword argument.


### References
<[!--- References would be helpful to understand the changes. --](https://github.com/keras-team/keras-core/issues/737)>



### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [x ] I have updated the documentation accordingly.
- [x ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [x ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",siyerp,112425790,closed,False,2,2024-08-15T01:36:34+00:00,2024-08-16T15:43:26+00:00,2024-08-15T16:15:35+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2463875975,2145,Add new URL of MIND small and MIND large,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
Small uploaded, large still not found.

This will fix also the tests

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
#2133

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,1,2024-08-13T17:36:17+00:00,2024-08-22T15:17:59+00:00,2024-08-22T15:17:55+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2463499743,2144,Marked lightfm tests as experimental,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
Marked lightfm tests as experimental so they can be run locally by using `pytest -m ""not experimental""`

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [x] I have updated the documentation accordingly.
- [x] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [x] This PR is being made to `staging branch` AND NOT TO `main branch`.
",daviddavo,10263941,closed,False,0,2024-08-13T14:27:30+00:00,2024-08-14T09:58:54+00:00,2024-08-14T09:58:49+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2461698920,2143,Changing Function Name to reflect new Tensorflow interface.,"Changed a function call name to reflect a more recent version of tensorflow.

### Description
I changed .reset_states() to .reset_state().  
I was getting an error along the lines of ""'Mean' object has no attribute 'reset_states'."" It seems that in a newer version of tensorflow, the function has been renamed to .reset_state.


### Related Issues



### References
[<!--- References would be helpful to understand the changes. -->](https://github.com/tensorflow/tensorflow/issues/50359)
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ x] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ x] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ x] This PR is being made to `staging branch` AND NOT TO `main branch`.
",siyerp,112425790,closed,False,5,2024-08-12T19:05:27+00:00,2024-11-07T04:35:14+00:00,2024-08-15T16:13:55+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2461679253,2142,Update model.py,"Fixed a line for a newer version of tensorflow

### Description
https://github.com/tensorflow/tensorflow/issues/50359

I was getting a similar issue, and this seems to be the way to fix it.


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ x] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ x] This PR is being made to `staging branch` AND NOT TO `main branch`.
",siyerp,112425790,closed,False,0,2024-08-12T18:53:12+00:00,2024-08-12T18:54:24+00:00,2024-08-12T18:54:17+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2459327213,2141,Is the 'mrr_score' implementation correct?,"Hi, 

I was recently using the ```mrr_score``` implementation ([link](https://github.com/recommenders-team/recommenders/blob/4f86e4785337d455aa3cb7e8920c3fab9a2a0140/recommenders/models/deeprec/deeprec_utils.py#L447)):

```
def mrr_score(y_true, y_score):
    """"""Computing mrr score metric.

    Args:
        y_true (np.ndarray): Ground-truth labels.
        y_score (np.ndarray): Predicted labels.

    Returns:
        numpy.ndarray: mrr scores.
    """"""
    order = np.argsort(y_score)[::-1]
    y_true = np.take(y_true, order)
    rr_score = y_true / (np.arange(len(y_true)) + 1)
    return np.sum(rr_score) / np.sum(y_true)
```

I am not sure if I've misunderstood the current implementation, but as far as I can see, it does not account for situations where there are multiple positive examples in one sample:
```
>>> mrr_score([1, 0, 0], [1, 0, 0])
1.0
>>> mrr_score([1, 1, 0], [1, 1, 0])
0.75
```

Furthermore, according to documentation the input should be ```Predicted labels```, however, we are more interested in the ranking of the positive item in a given sample ([MRR-wiki](https://en.wikipedia.org/wiki/Mean_reciprocal_rank)).

My suggestion is 
```
def reciprocal_rank_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    order = np.argsort(y_pred)[::-1]
    y_true = np.take(y_true, order)
    first_positive_rank = np.argmax(y_true) + 1
    return 1.0 / first_positive_rank

>>> y_true_1 = np.array([0, 0, 1])
>>> y_pred_1 = np.array([0.5, 0.2, 0.1])
>>> reciprocal_rank_score(y_true_1, y_pred_1)
0.33

>>> y_true_2 = np.array([0, 1, 1])
>>> y_pred_2 = np.array([0.5, 0.2, 0.1])
>>> reciprocal_rank_score(y_true_2, y_pred_2)
0.5

>>> y_true_3 = np.array([1, 1, 0])
>>> y_pred_3 = np.array([0.5, 0.2, 0.1])
>>> reciprocal_rank_score(y_true_3, y_pred_3)
1.0

>>> np.mean([reciprocal_rank_score(y_true, y_pred)for y_true, y_pred in zip([y_true_1, y_true_2, y_true_3], [y_pred_1, y_pred_2, y_pred_3])])
0.611111111111111
```

The original implementation seems correct if asked for the rankings, not the labels for the prediction. When assuming all items are positive, as in my example:
```
mrr_score([1, 1, 1], [3, 2, 1])
0.611111111111111
```
But then, ```y_true``` is not a needed input. 

If I haven't misunderstood and you agree I would be happy to make a PR with suggested improvements.

I followed the example used in the Medium post: [MRR vs MAP vs NDCG: Rank-Aware Evaluation Metrics And When To Use Them](https://medium.com/swlh/rank-aware-recsys-evaluation-metrics-5191bba16832) (behind paywall).

Thanks for the awesome repo! ",johanneskruse,43001334,open,False,1,2024-08-10T23:10:39+00:00,2024-08-12T14:57:50+00:00,,enhancement,0,0,0,0,0,0,0
recommenders-team/recommenders,2459144632,2140,[ASK] Confusion between top_k and by_threshold relevancy_method in python_evaluation.py,"### Description
What is the different between k and threshold value here if they all get assigned to top_k?
Isn't threshold supposed to be a rating value that the predictions should exceed instead of being the number of items in the top_k list ?
Thanks.
```
def merge_ranking_true_pred(
    rating_true,
    rating_pred,
    col_user,
    col_item,
    col_prediction,
    relevancy_method,
    k=DEFAULT_K,
    threshold=DEFAULT_THRESHOLD,
    **_,
):
    if relevancy_method == ""top_k"":
        top_k = k
    elif relevancy_method == ""by_threshold"":
        top_k = threshold
```
### Other Comments
",mnhqut,163323745,open,False,2,2024-08-10T15:55:17+00:00,2024-08-15T16:17:37+00:00,,help wanted,0,0,0,0,0,0,0
recommenders-team/recommenders,2457418868,2139,Moved pymanopt tests to experimental test group #2138,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
Pymanopt is an extra dep, but its tests are run among other dependencies

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
- #2138 

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [x] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [x] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [x] This PR is being made to `staging branch` AND NOT TO `main branch`.
",daviddavo,10263941,closed,False,0,2024-08-09T08:39:05+00:00,2024-08-09T16:14:41+00:00,2024-08-09T16:14:38+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2441911010,2138,[FEATURE] On pymanopt,"### Description
<!--- Describe your expected feature in detail -->
The pymanopt dependency must currently be installed with an external command, making the setup more difficult. Setup should be transparent to the user and just `pip install recommenders`.

Although the dependency can be included in install_requires, it won't let you upload the recommenders package to pypi.

Nevertheless, pymanopt team doesn't update the pypi package anymore.

### Expected behavior with the suggested feature
<!--- For example:  -->
<!--- *Adding algorithm xxx will help people understand more about xxx use case scenarios. -->
`pip install recommenders` just works

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [x] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Possible solutions

- https://discuss.python.org/t/packages-installed-from-pypi-cannot-depend-on-packages-which-are-not-also-hosted-on-pypi/3736/4

tldr:
#### Forking
Making a fork or mirror in recommenders-team and then re-releasing it to pypi under a different name like recommenders-pymanopt

#### Vendoring
Including the code or the project as a git submodule, and then installing ""from file"".

#### Creating a requirements.txt-like file
Creating an external-dependencies.txt file, and then instructing people (and the CI flow) to use `pip install -r external-dependencies.txt`
",daviddavo,10263941,open,False,11,2024-08-01T09:07:19+00:00,2024-10-02T12:09:25+00:00,,enhancement,0,0,0,0,0,0,0
recommenders-team/recommenders,2439226548,2137,Staging to main: AzureML migration to v2,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
Adding the latest changes in AzureML.


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
There is still this issue unfixed https://github.com/recommenders-team/recommenders/issues/2133 which is breaking the tests (both stating and main). However, it is not a problem with the code itself, it is just that the dataset URL is broken.

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2024-07-31T06:20:05+00:00,2024-07-31T11:45:46+00:00,2024-07-31T11:45:45+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2439141134,2136,[BUG] Warnings from pytest,"### Description
<!--- Describe your issue/bug/request in detail -->
I saw lots of warnings from the result of pytest.  Those warnings were not taken into considration because they are suppressed in the CICD testing workflow.  Many warnings have something to do with deprecation usage in the code, such as https://github.com/recommenders-team/recommenders/actions/runs/10173799542/job/28139367400?pr=2134#step:3:1207

```
  ../../../../../../../azureml-envs/azureml_f165202b520dc80b574d66d71099a169/lib/python3.8/site-packages/pyspark/sql/pandas/utils.py:37: 2 warnings
  tests/unit/recommenders/datasets/test_spark_splitter.py: 8 warnings
  tests/unit/recommenders/evaluation/test_spark_evaluation.py: 160 warnings
    /azureml-envs/azureml_f165202b520dc80b574d66d71099a169/lib/python3.8/site-packages/pyspark/sql/pandas/utils.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
      if LooseVersion(pandas.__version__) < LooseVersion(minimum_pandas_version):
```


### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
<!--- * Azure Data Science Virtual Machine. -->
<!--- * Azure Databricks.  -->
<!--- * Other platforms.  -->
The warnings are from the CICD testing workflow.


### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->
The warnings were disabled in the testing workflow.

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

Resolve the warnings as soon as possible.

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [X] Yes, I can contribute for this issue independently.
- [X] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

",SimonYansenZhao,6165588,closed,False,1,2024-07-31T05:09:47+00:00,2024-11-17T07:17:02+00:00,2024-11-17T07:17:01+00:00,bug,1,1,0,0,0,0,0
recommenders-team/recommenders,2437127943,2135,Added free course on Recommendation systems,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2024-07-30T07:36:21+00:00,2024-07-30T12:12:00+00:00,2024-07-30T12:11:56+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2433196921,2134,Migrate AML SDK from v1 to v2,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
This PR migrate AzureML Python SDK used in recommenders' testing workflow from v1 to v2, because AML Python SDK v1 has the following limitations:
* [Support for CLI v1 will end on September 30, 2025](https://learn.microsoft.com/en-us/azure/machine-learning/concept-v2?view=azureml-api-2#should-i-use-v1-or-v2)
* [That we must pin `pip=20.1.1`](https://github.com/recommenders-team/recommenders/pull/1937#issuecomment-1585972791) makes [the version upgrade](https://github.com/recommenders-team/recommenders/pull/2098) difficult.
* [Snapshots in v1 seem to be buggy](https://github.com/recommenders-team/recommenders/pull/2130#discussion_r1679231135)
* [Logs are not easy to get](https://github.com/recommenders-team/recommenders/pull/2098#discussion_r1663980060)

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->
* #2066 
* #2098 

### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->
* [What is Azure Machine Learning Python SDK v2?](https://learn.microsoft.com/en-us/azure/machine-learning/concept-v2?view=azureml-api-2)
* [Should I use v1 or v2?](https://learn.microsoft.com/en-us/azure/machine-learning/concept-v2?view=azureml-api-2#should-i-use-v1-or-v2)
* [Migrate logging from SDK v1 to SDK v2](https://learn.microsoft.com/en-us/azure/machine-learning/reference-migrate-sdk-v1-mlflow-tracking?view=azureml-api-2&tabs=aml%2Ccli%2Cmlflow)

### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [X] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [X] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [X] This PR is being made to `staging branch` AND NOT TO `main branch`.
",SimonYansenZhao,6165588,closed,False,1,2024-07-27T02:41:45+00:00,2024-07-31T06:02:34+00:00,2024-07-31T05:38:22+00:00,,2,1,0,0,1,0,0
recommenders-team/recommenders,2431981866,2133,[BUG] Unable to access MIND dataset due to public access restriction on the storage account,"
Hi,

I am trying to download the MIND Dataset, but the storage account does not allow public access and returns a 409 error.

I'll attach an example of the error message that occurs on all the download links:

```
$ curl https://mind201910small.blob.core.windows.net/release/MINDsmall_train.zip

<?xml version=""1.0"" encoding=""utf-8""?><Error><Code>PublicAccessNotPermitted</Code><Message>Public access is not permitted on this storage account.
RequestId:2a55c6b5-401e-004d-0626-df374d000000
Time:2024-07-26T06:36:31.8660488Z</Message></Error>%
```

Many thanks for considering my request!


",mmahdigh,46849131,closed,False,6,2024-07-26T10:56:20+00:00,2024-08-16T15:57:52+00:00,2024-08-16T15:57:52+00:00,bug,1,1,0,0,0,0,0
recommenders-team/recommenders,2410241305,2132,Should I use jupyter notebook or vs code for this project [ASK] ,"### Description
<!--- Describe your general ask in detail -->

### Willingness to contribute
<!--- Go over all the following points, and put an `x` in the box that apply. -->
- [ ] Yes, I can contribute for this issue independently.
- [ ] Yes, I can contribute for this issue with guidance from Recommenders community.
- [ ] No, I cannot contribute at this time.

### Other Comments
",maushamkumar,144700160,closed,False,1,2024-07-16T05:24:31+00:00,2024-07-22T18:43:58+00:00,2024-07-22T18:43:58+00:00,help wanted,0,0,0,0,0,0,0
recommenders-team/recommenders,2408645417,2131,[ASK] The Training using a GPU is very slow for NCF model,"I've set up an virtual environment based on the following commands:
!conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1
!pip install recommenders[gpu]

Moreover I've added the following commands in the code:

tf.debugging.set_log_device_placement(True)
gpus = tf.config.experimental.list_physical_devices('GPU')
tf.config.set_visible_devices([], 'CPU') # hide the CPU
tf.config.set_visible_devices(gpus[0], 'GPU') # unhide potentially hidden GPU
tf.config.get_visible_devices()

# Set the environment to use GPU
physical_devices = tf.config.list_physical_devices('GPU')
if physical_devices:
    tf.config.experimental.set_memory_growth(physical_devices[0], True)


Non of the steps above helped me to increase the utilization of the gpu.
Any suggestion would be helpful.

Thanks,
Or





",orrimoch,30413691,closed,False,1,2024-07-15T12:39:44+00:00,2024-12-27T06:30:10+00:00,2024-12-27T06:30:10+00:00,help wanted,0,0,0,0,0,0,0
recommenders-team/recommenders,2406783590,2130,Review test readme and define best practices,"### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->
- Added some comments on the test README
- Defined some best practices when assert is True

The reasoning is to make the tests more explicit. For example, if a function returns True, we want to make sure the assert checks for True and not for a truthy value. 

Example:
```
result = True
assert result is True  # Passes because result is exactly True

result = 1
assert result  # Passes because 1 is a truthy value
assert result is True  # Fails because 1 is not the exact True object
```

### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,2,2024-07-13T08:12:42+00:00,2024-07-18T10:00:55+00:00,2024-07-18T10:00:52+00:00,,0,0,0,0,0,0,0
recommenders-team/recommenders,2398625192,2129,"Staging to main: Fix to NewsRec, LightFM to extras, issue with scipy","### Description
<!--- Describe your changes in detail -->
<!--- Why is this change required? What problem does it solve? -->


### Related Issues
<!--- If it fixes an open issue, please link to the issue here. -->


### References
<!--- References would be helpful to understand the changes. -->
<!--- References can be books, links, etc. -->


### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] I have followed the [contribution guidelines](CONTRIBUTING.md) and code style for this project.
- [ ] I have added tests covering my contributions.
- [ ] I have updated the documentation accordingly.
- [ ] I have [signed the commits](https://github.com/recommenders-team/recommenders/wiki/How-to-sign-commits), e.g. `git commit -s -m ""your commit message""`. 
- [ ] This PR is being made to `staging branch` AND NOT TO `main branch`.
",miguelgfierro,3491412,closed,False,0,2024-07-09T16:11:18+00:00,2024-07-10T05:04:06+00:00,2024-07-10T05:04:06+00:00,,0,0,0,0,0,0,0
